{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvRq2M5bj2N87goKeLAz2Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bcf5ffc770be4d3ba48ec85eaa48c76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99e55c83ac63423bb1205dadb34603a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_055490149aa144c791bbf0d336d7d60b",
              "IPY_MODEL_57011d2dce284e38a6d655338fb58e15"
            ]
          }
        },
        "99e55c83ac63423bb1205dadb34603a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "055490149aa144c791bbf0d336d7d60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c966fb8ff4cb42f4a1bd0889b476a6da",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0afafee48aff4bd2b957c6b3f9ce242b"
          }
        },
        "57011d2dce284e38a6d655338fb58e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b018c6a36ea24a52bcb7652fea04c96c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [02:02&lt;00:00, 30.59s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f00b73e919d0403c98ccf26ee8e9705b"
          }
        },
        "c966fb8ff4cb42f4a1bd0889b476a6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0afafee48aff4bd2b957c6b3f9ce242b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b018c6a36ea24a52bcb7652fea04c96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f00b73e919d0403c98ccf26ee8e9705b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rufimelo99/MNIST/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZnYjFYGo71_"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.decomposition\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb0wscvQxmcn"
      },
      "source": [
        "# Feed-Forward Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwf7L7rExxyg"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYesKuzdyes-"
      },
      "source": [
        "***MNIST Dataset***\n",
        "\n",
        "70000 Examples:\n",
        "\n",
        "**Splited**:\n",
        "\n",
        "* 60000 for training;\n",
        "\n",
        "* 10000 for tests;\n",
        "\n",
        "\n",
        "**10 Classes**: \n",
        "\n",
        "* 0, ..., 9\n",
        "\n",
        "**Features**\n",
        "\n",
        "* (28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "bcf5ffc770be4d3ba48ec85eaa48c76d",
            "99e55c83ac63423bb1205dadb34603a9",
            "055490149aa144c791bbf0d336d7d60b",
            "57011d2dce284e38a6d655338fb58e15",
            "c966fb8ff4cb42f4a1bd0889b476a6da",
            "0afafee48aff4bd2b957c6b3f9ce242b",
            "b018c6a36ea24a52bcb7652fea04c96c",
            "f00b73e919d0403c98ccf26ee8e9705b"
          ]
        },
        "id": "-cfdH1KbpdUX",
        "outputId": "d5f67747-29e9-477b-e610-80d10a1fea89"
      },
      "source": [
        "mnist_data, mnist_info = tfds.load('mnist', with_info=True)\n",
        "#print(mnist_data)\n",
        "#print(mnist_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcf5ffc770be4d3ba48ec85eaa48c76d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ie2tgR662H"
      },
      "source": [
        "It is needed to convert into numpy arrays and normalize the images. Each pixel range from 0 to 255.0, so:\n",
        "\n",
        "`pixels = pixels/255.0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXC3Eng6p4iE"
      },
      "source": [
        "mnist_x = np.asarray([instance['image'] for instance in tfds.as_numpy(mnist_data['train'])])\n",
        "mnist_y = np.asarray([instance['label'] for instance in tfds.as_numpy(mnist_data['train'])])\n",
        "mnist_x= mnist_x/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_NOVlEa0Hoy"
      },
      "source": [
        "**Example of visualizing data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "VH-DTKFE0MNo",
        "outputId": "47411cd6-b697-4fd1-8c2a-fd4655ec8ebe"
      },
      "source": [
        "def showImage(label,pixels):\n",
        "  #remove the normalization\n",
        "  pixels = pixels*255.0\n",
        "\n",
        "  # Make those columns into a array of 8-bits pixels\n",
        "  # This array will be of 1D with length 784\n",
        "  # The pixel intensity values are integers from 0 to 255\n",
        "  pixels = np.array(pixels, dtype='uint8')\n",
        "\n",
        "  # Reshape the array into 28 x 28 array (2-dimensional array)\n",
        "  pixels = pixels.reshape((28, 28))\n",
        "\n",
        "  # Plot\n",
        "  plt.title('Label is {label}'.format(label=label))\n",
        "  plt.imshow(pixels, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "showImage(mnist_y[0], mnist_x[0] )\n",
        "\n",
        "#or this\n",
        "plt.imshow(mnist_x[0].reshape(28,28))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1968cf9f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h17RQEmG-XBb"
      },
      "source": [
        "We will start by creating a very simple network without hidden layers.\n",
        "\n",
        "We'll use the softmax\n",
        "\n",
        "Additionally, we request the accuracy values. To update the weights, we will use Stochastic Gradient Descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h9L0YRZ4oOa"
      },
      "source": [
        "#print(mnist_info.features['image'].shape)\n",
        "#print(mnist_x.shape)\n",
        "#print(mnist_y.shape)\n",
        "\n",
        "single_layer_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzdCUl254-GY"
      },
      "source": [
        "single_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Y7d_yM5Ak0",
        "outputId": "adf9bdf5-5546-4f1e-fb54-6074de252bb7"
      },
      "source": [
        "single_layer_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e43AnzVt5Q8P"
      },
      "source": [
        "single_layer_model.save_weights('single_layer_init.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pnw-B-V5UVz",
        "outputId": "78160d83-50f0-4150-9993-54c615d7981d"
      },
      "source": [
        "single_layer_train = single_layer_model.fit(mnist_x, mnist_y, epochs=100, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1464 - accuracy: 0.7022\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4764 - accuracy: 0.8777\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4130 - accuracy: 0.8892\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3765 - accuracy: 0.8978\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3643 - accuracy: 0.9009\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3541 - accuracy: 0.9017\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3420 - accuracy: 0.9043\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3295 - accuracy: 0.9073\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3258 - accuracy: 0.9076\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3282 - accuracy: 0.9084\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3153 - accuracy: 0.9127\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3096 - accuracy: 0.9138\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3109 - accuracy: 0.9137\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3110 - accuracy: 0.9128\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3054 - accuracy: 0.9142\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3004 - accuracy: 0.9160\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3001 - accuracy: 0.9154\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2925 - accuracy: 0.9191\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2971 - accuracy: 0.9159\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2911 - accuracy: 0.9189\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2987 - accuracy: 0.9176\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2859 - accuracy: 0.9202\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2879 - accuracy: 0.9192\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2872 - accuracy: 0.9205\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2848 - accuracy: 0.9217\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2850 - accuracy: 0.9204\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2838 - accuracy: 0.9202\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2801 - accuracy: 0.9224\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2831 - accuracy: 0.9204\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2800 - accuracy: 0.9217\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2833 - accuracy: 0.9222\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2835 - accuracy: 0.9206\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2782 - accuracy: 0.9231\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2806 - accuracy: 0.9225\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2794 - accuracy: 0.9212\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2771 - accuracy: 0.9228\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2741 - accuracy: 0.9237\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2829 - accuracy: 0.9218\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2800 - accuracy: 0.9209\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2763 - accuracy: 0.9239\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2775 - accuracy: 0.9234\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2689 - accuracy: 0.9253\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2761 - accuracy: 0.9230\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2714 - accuracy: 0.9254\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2727 - accuracy: 0.9251\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2744 - accuracy: 0.9242\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2708 - accuracy: 0.9241\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2705 - accuracy: 0.9253\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2723 - accuracy: 0.9244\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2782 - accuracy: 0.9232\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2690 - accuracy: 0.9248\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2717 - accuracy: 0.9236\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2680 - accuracy: 0.9268\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2766 - accuracy: 0.9241\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2690 - accuracy: 0.9262\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2677 - accuracy: 0.9269\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2654 - accuracy: 0.9266\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2650 - accuracy: 0.9259\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2699 - accuracy: 0.9255\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2658 - accuracy: 0.9270\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2630 - accuracy: 0.9277\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2655 - accuracy: 0.9277\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2644 - accuracy: 0.9274\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2690 - accuracy: 0.9250\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2648 - accuracy: 0.9274\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2628 - accuracy: 0.9273\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2645 - accuracy: 0.9276\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2633 - accuracy: 0.9272\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2610 - accuracy: 0.9268\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2612 - accuracy: 0.9271\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2646 - accuracy: 0.9277\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2612 - accuracy: 0.9287\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2623 - accuracy: 0.9274\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2666 - accuracy: 0.9269\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2593 - accuracy: 0.9288\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2635 - accuracy: 0.9281\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2653 - accuracy: 0.9281\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2572 - accuracy: 0.9280\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2607 - accuracy: 0.9281\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2629 - accuracy: 0.9276\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2633 - accuracy: 0.9276\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2633 - accuracy: 0.9272\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2583 - accuracy: 0.9278\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2608 - accuracy: 0.9292\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2545 - accuracy: 0.9308\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2627 - accuracy: 0.9283\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2576 - accuracy: 0.9288\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2560 - accuracy: 0.9293\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2594 - accuracy: 0.9289\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2582 - accuracy: 0.9268\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2645 - accuracy: 0.9275\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2580 - accuracy: 0.9291\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2591 - accuracy: 0.9300\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2596 - accuracy: 0.9289\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2520 - accuracy: 0.9307\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2630 - accuracy: 0.9286\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2585 - accuracy: 0.9288\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2500 - accuracy: 0.9303\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2571 - accuracy: 0.9292\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2595 - accuracy: 0.9289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "ctsW_-bGfVsC",
        "outputId": "8f0cdd69-5afc-449f-c8da-bf5da61ed80a"
      },
      "source": [
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(single_layer_train.history['loss'], '-r', label='Train')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(single_layer_train.history['accuracy'], '-r', label='Train')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M61GBh8ffNB",
        "outputId": "c42146ea-2371-4509-ac3c-c442f2178ee8"
      },
      "source": [
        "predictions = single_layer_model.predict(mnist_x[:5])\n",
        "print(predictions)\n",
        "np.argmax(predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.6974591e-06 1.9755035e-03 6.5324933e-04 2.7393745e-04 9.6097839e-01\n",
            "  4.9377279e-03 9.6238889e-03 5.8178295e-04 1.2882602e-02 8.0831088e-03]\n",
            " [4.3804553e-07 9.4114238e-01 3.3229860e-03 4.0952084e-03 2.4276903e-04\n",
            "  1.4167618e-04 4.1380794e-05 4.7536906e-02 2.2229024e-03 1.2533524e-03]\n",
            " [9.9942136e-01 1.5339546e-13 2.3813365e-05 1.8157350e-05 1.2075019e-08\n",
            "  3.0735295e-04 2.2286379e-04 1.5234259e-09 6.4653727e-06 1.2336598e-07]\n",
            " [1.0875975e-05 1.6944592e-13 1.6724290e-06 1.7367572e-06 1.3772312e-07\n",
            "  2.7684885e-06 4.6083448e-10 9.9983191e-01 1.3712543e-06 1.4954359e-04]\n",
            " [1.5095135e-04 5.9341022e-07 3.8771268e-03 2.7431112e-02 3.6913207e-05\n",
            "  9.8165935e-03 3.2933815e-06 1.1717761e-05 9.5794725e-01 7.2446489e-04]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 0, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypkSjdR2fmaN",
        "outputId": "3f6d5faf-abcc-44e7-e0fd-1a73c5476de3"
      },
      "source": [
        "loss, acc = single_layer_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy: {}'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 2s 983us/step - loss: 0.2625 - accuracy: 0.9276\n",
            "Accuracy: 0.9275500178337097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3voTXywfx9k"
      },
      "source": [
        "single_layer_model.load_weights('single_layer_init.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4qdL4kJfyG7",
        "outputId": "7572a053-7112-4e4d-b82d-1d3e5865ba6b"
      },
      "source": [
        "single_layer_train = single_layer_model.fit(mnist_x, mnist_y, validation_split=0.2, epochs=100, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.8512 - accuracy: 0.7976 - val_loss: 0.5448 - val_accuracy: 0.8646\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4835 - accuracy: 0.8748 - val_loss: 0.4478 - val_accuracy: 0.8837\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4221 - accuracy: 0.8868 - val_loss: 0.4091 - val_accuracy: 0.8914\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3921 - accuracy: 0.8930 - val_loss: 0.3868 - val_accuracy: 0.8947\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3730 - accuracy: 0.8977 - val_loss: 0.3721 - val_accuracy: 0.8978\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3597 - accuracy: 0.9001 - val_loss: 0.3613 - val_accuracy: 0.9006\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.9032 - val_loss: 0.3531 - val_accuracy: 0.9024\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3414 - accuracy: 0.9044 - val_loss: 0.3470 - val_accuracy: 0.9040\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3348 - accuracy: 0.9070 - val_loss: 0.3415 - val_accuracy: 0.9050\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3293 - accuracy: 0.9080 - val_loss: 0.3376 - val_accuracy: 0.9073\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3246 - accuracy: 0.9094 - val_loss: 0.3329 - val_accuracy: 0.9085\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3205 - accuracy: 0.9105 - val_loss: 0.3303 - val_accuracy: 0.9087\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3168 - accuracy: 0.9117 - val_loss: 0.3271 - val_accuracy: 0.9095\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3136 - accuracy: 0.9116 - val_loss: 0.3248 - val_accuracy: 0.9110\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3107 - accuracy: 0.9134 - val_loss: 0.3224 - val_accuracy: 0.9119\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3082 - accuracy: 0.9137 - val_loss: 0.3207 - val_accuracy: 0.9122\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3057 - accuracy: 0.9147 - val_loss: 0.3183 - val_accuracy: 0.9126\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3036 - accuracy: 0.9154 - val_loss: 0.3165 - val_accuracy: 0.9132\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3015 - accuracy: 0.9162 - val_loss: 0.3152 - val_accuracy: 0.9133\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2995 - accuracy: 0.9163 - val_loss: 0.3138 - val_accuracy: 0.9149\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2979 - accuracy: 0.9166 - val_loss: 0.3127 - val_accuracy: 0.9147\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2964 - accuracy: 0.9174 - val_loss: 0.3114 - val_accuracy: 0.9147\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2946 - accuracy: 0.9181 - val_loss: 0.3099 - val_accuracy: 0.9144\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2934 - accuracy: 0.9183 - val_loss: 0.3088 - val_accuracy: 0.9157\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2920 - accuracy: 0.9185 - val_loss: 0.3083 - val_accuracy: 0.9159\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2908 - accuracy: 0.9192 - val_loss: 0.3075 - val_accuracy: 0.9160\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2896 - accuracy: 0.9191 - val_loss: 0.3062 - val_accuracy: 0.9165\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2884 - accuracy: 0.9197 - val_loss: 0.3058 - val_accuracy: 0.9169\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2873 - accuracy: 0.9202 - val_loss: 0.3051 - val_accuracy: 0.9174\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2863 - accuracy: 0.9203 - val_loss: 0.3041 - val_accuracy: 0.9177\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2853 - accuracy: 0.9203 - val_loss: 0.3037 - val_accuracy: 0.9165\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2844 - accuracy: 0.9206 - val_loss: 0.3023 - val_accuracy: 0.9177\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2835 - accuracy: 0.9212 - val_loss: 0.3023 - val_accuracy: 0.9173\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2827 - accuracy: 0.9214 - val_loss: 0.3023 - val_accuracy: 0.9172\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2817 - accuracy: 0.9219 - val_loss: 0.3011 - val_accuracy: 0.9181\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2811 - accuracy: 0.9221 - val_loss: 0.3009 - val_accuracy: 0.9175\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2803 - accuracy: 0.9217 - val_loss: 0.3005 - val_accuracy: 0.9171\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2795 - accuracy: 0.9221 - val_loss: 0.2994 - val_accuracy: 0.9178\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2789 - accuracy: 0.9222 - val_loss: 0.2999 - val_accuracy: 0.9172\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2782 - accuracy: 0.9227 - val_loss: 0.2986 - val_accuracy: 0.9175\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2776 - accuracy: 0.9229 - val_loss: 0.2983 - val_accuracy: 0.9179\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2769 - accuracy: 0.9229 - val_loss: 0.2978 - val_accuracy: 0.9185\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2763 - accuracy: 0.9234 - val_loss: 0.2976 - val_accuracy: 0.9177\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2756 - accuracy: 0.9235 - val_loss: 0.2968 - val_accuracy: 0.9185\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2752 - accuracy: 0.9234 - val_loss: 0.2970 - val_accuracy: 0.9180\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2745 - accuracy: 0.9235 - val_loss: 0.2966 - val_accuracy: 0.9188\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2740 - accuracy: 0.9238 - val_loss: 0.2961 - val_accuracy: 0.9187\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2734 - accuracy: 0.9243 - val_loss: 0.2963 - val_accuracy: 0.9187\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2729 - accuracy: 0.9243 - val_loss: 0.2958 - val_accuracy: 0.9186\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2724 - accuracy: 0.9247 - val_loss: 0.2954 - val_accuracy: 0.9185\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2719 - accuracy: 0.9242 - val_loss: 0.2953 - val_accuracy: 0.9190\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2715 - accuracy: 0.9247 - val_loss: 0.2949 - val_accuracy: 0.9185\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2710 - accuracy: 0.9252 - val_loss: 0.2944 - val_accuracy: 0.9185\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2705 - accuracy: 0.9249 - val_loss: 0.2943 - val_accuracy: 0.9195\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2701 - accuracy: 0.9250 - val_loss: 0.2941 - val_accuracy: 0.9193\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2697 - accuracy: 0.9252 - val_loss: 0.2938 - val_accuracy: 0.9185\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2693 - accuracy: 0.9253 - val_loss: 0.2934 - val_accuracy: 0.9196\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2688 - accuracy: 0.9255 - val_loss: 0.2934 - val_accuracy: 0.9197\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2684 - accuracy: 0.9257 - val_loss: 0.2940 - val_accuracy: 0.9190\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2681 - accuracy: 0.9254 - val_loss: 0.2933 - val_accuracy: 0.9187\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2676 - accuracy: 0.9259 - val_loss: 0.2939 - val_accuracy: 0.9190\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2673 - accuracy: 0.9254 - val_loss: 0.2928 - val_accuracy: 0.9193\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2669 - accuracy: 0.9259 - val_loss: 0.2926 - val_accuracy: 0.9202\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2666 - accuracy: 0.9264 - val_loss: 0.2923 - val_accuracy: 0.9197\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2663 - accuracy: 0.9262 - val_loss: 0.2923 - val_accuracy: 0.9193\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2659 - accuracy: 0.9262 - val_loss: 0.2915 - val_accuracy: 0.9197\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2656 - accuracy: 0.9262 - val_loss: 0.2918 - val_accuracy: 0.9197\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2652 - accuracy: 0.9263 - val_loss: 0.2917 - val_accuracy: 0.9207\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2650 - accuracy: 0.9266 - val_loss: 0.2911 - val_accuracy: 0.9198\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2646 - accuracy: 0.9265 - val_loss: 0.2916 - val_accuracy: 0.9195\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2642 - accuracy: 0.9270 - val_loss: 0.2912 - val_accuracy: 0.9199\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2640 - accuracy: 0.9270 - val_loss: 0.2914 - val_accuracy: 0.9191\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2637 - accuracy: 0.9270 - val_loss: 0.2915 - val_accuracy: 0.9183\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2633 - accuracy: 0.9270 - val_loss: 0.2914 - val_accuracy: 0.9188\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2631 - accuracy: 0.9273 - val_loss: 0.2909 - val_accuracy: 0.9202\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2628 - accuracy: 0.9273 - val_loss: 0.2902 - val_accuracy: 0.9197\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2626 - accuracy: 0.9273 - val_loss: 0.2903 - val_accuracy: 0.9202\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2622 - accuracy: 0.9275 - val_loss: 0.2906 - val_accuracy: 0.9200\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2620 - accuracy: 0.9277 - val_loss: 0.2904 - val_accuracy: 0.9201\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2617 - accuracy: 0.9272 - val_loss: 0.2900 - val_accuracy: 0.9203\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2615 - accuracy: 0.9279 - val_loss: 0.2898 - val_accuracy: 0.9202\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2612 - accuracy: 0.9276 - val_loss: 0.2897 - val_accuracy: 0.9210\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2610 - accuracy: 0.9280 - val_loss: 0.2900 - val_accuracy: 0.9204\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2607 - accuracy: 0.9278 - val_loss: 0.2892 - val_accuracy: 0.9202\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2605 - accuracy: 0.9282 - val_loss: 0.2894 - val_accuracy: 0.9198\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2603 - accuracy: 0.9279 - val_loss: 0.2894 - val_accuracy: 0.9205\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2599 - accuracy: 0.9278 - val_loss: 0.2891 - val_accuracy: 0.9200\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2597 - accuracy: 0.9281 - val_loss: 0.2894 - val_accuracy: 0.9204\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2595 - accuracy: 0.9283 - val_loss: 0.2892 - val_accuracy: 0.9207\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2594 - accuracy: 0.9280 - val_loss: 0.2891 - val_accuracy: 0.9205\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2590 - accuracy: 0.9281 - val_loss: 0.2891 - val_accuracy: 0.9195\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2589 - accuracy: 0.9285 - val_loss: 0.2886 - val_accuracy: 0.9203\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2586 - accuracy: 0.9284 - val_loss: 0.2887 - val_accuracy: 0.9211\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2584 - accuracy: 0.9282 - val_loss: 0.2886 - val_accuracy: 0.9197\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2581 - accuracy: 0.9288 - val_loss: 0.2886 - val_accuracy: 0.9203\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2580 - accuracy: 0.9280 - val_loss: 0.2889 - val_accuracy: 0.9198\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2578 - accuracy: 0.9289 - val_loss: 0.2889 - val_accuracy: 0.9202\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2574 - accuracy: 0.9287 - val_loss: 0.2882 - val_accuracy: 0.9204\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2574 - accuracy: 0.9288 - val_loss: 0.2883 - val_accuracy: 0.9204\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2572 - accuracy: 0.9288 - val_loss: 0.2884 - val_accuracy: 0.9204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et1LoPNqf4Xw"
      },
      "source": [
        "mnist_test_x = np.asarray([instance['image'] for instance in tfds.as_numpy(mnist_data['test'])])\n",
        "mnist_test_y = np.asarray([instance['label'] for instance in tfds.as_numpy(mnist_data['test'])])\n",
        "mnist_test_x= mnist_test_x/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiRke6AbgwEd",
        "outputId": "9796cad2-2c88-4b33-a3a2-653aecec0e71"
      },
      "source": [
        "predictions=single_layer_model.predict(mnist_test_x)\n",
        "predictedClasses = np.argmax(predictions, axis=1)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(mnist_test_y, predictedClasses))\n",
        "loss, acc = single_layer_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "\n",
        "loss, acc = single_layer_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9238\n",
            "1875/1875 [==============================] - 2s 964us/step - loss: 0.2625 - accuracy: 0.9276\n",
            "Accuracy for the training set: 0.9275500178337097\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.9238\n",
            "Accuracy for the testing set: 0.923799991607666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "9Cbfzvw0haTX",
        "outputId": "4d5d412a-7d2c-47a2-873c-46eb5f9ce9eb"
      },
      "source": [
        "#Example\n",
        "for i in range(1):\n",
        "  print(\"Predicted Label: \" , predictedClasses[i])\n",
        "  print(\"Actual Label: \" , mnist_test_y[i])\n",
        "  showImage(mnist_test_y[i],mnist_test_x[i] )\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Label:  2\n",
            "Actual Label:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARb0lEQVR4nO3de7BV5X3G8e/jvREVEUsZVEjEdkQ6NS2jmQ4iGU1qsIpOrRNEi0bFjmHaaOrUwarUWzIZk16s4xQviJd6i0YdL1WLVKzVFHSMgoYoFJW7igyaFuHAr3/shT3i2e86Z9/PeZ/PzJ6zz/rttdfPLc9Za+93r/UqIjCzgW+XdjdgZq3hsJtlwmE3y4TDbpYJh90sEw67WSYc9kxI+ndJ5zV6XUkzJd1SX3fWCg57PyNphaTj293HDhFxXUT06Y+IpD0l3SrpHUkfS3pV0rea1aNVOOzWDrsB7wHHAvsBfwPcL2lUG3sa8Bz2AULS/pIek/S+pI+K+wft9LBDJf2XpE2SHpE0pNv6X5P0n5I2SvqFpIm93O4sSXcV9/eSdJekD4vnWShp2M7rRMSvI2JWRKyIiO0R8Rjw38Af1P4KWBmHfeDYBZgDjAQOAf4X+KedHvNnwHeA4UAX8I8AkkYAjwPXAEOAvwIelHRgH3uYRmVPfTBwAPDnRR9JxR+E3waW9HF71gcO+wARER9GxIMR8T8R8TFwLZXD5O7ujIjFEfFr4HLgdEm7AmcCT0TEE8We9hlgETCpj21spRLy0RGxLSJejohNqRUk7Q7cDcyNiF/2cXvWBw77ACHpS5L+ufjQaxOwABhchHmH97rdfwfYHRhK5WjgT4tD742SNgLjqRwB9MWdwFPAvZJWS/pREeZqPe9SrLMFmNHHbVkfOewDx/eB3wGOjoh9gQnFcnV7zMHd7h9CZU/8AZU/AndGxOBut70j4od9aSAitkbE30bEGOAPgT+m8tbhCyQJuBUYBvxJRGzty7as7xz2/mn34sOwHbfdgH2ovD/eWHzwdmUP650paYykLwFXAT+NiG3AXcBJkv5I0q7Fc07s4QO+JElfl/S7xdHEJip/TLZXefhNwOHASRFR+r7e6uew909PUAn2jtss4O+B36Cyp34J+Nce1rsTuB1YC+wF/AVARLwHTAZmAu9T2dNfQt//ffwW8FMqQX8TeK7Y5udIGglcABwJrJX0SXGb2sftWR/IF68wy4P37GaZcNjNMuGwm2XCYTfLxG6t3Jgkfxpo1mQRoZ6W17Vnl3SCpKWS3pZ0aT3PZWbNVfPQW/HFiV8B3wBWAguBKRHxRmId79nNmqwZe/ajgLcjYnlEbAHupfLFDDPrQPWEfQSfP7FiZbHscyRNl7RI0qI6tmVmdWr6B3QRMRuYDT6MN2unevbsq/j8WVQHFcvMrAPVE/aFwGGSvixpD+DbwKONacvMGq3mw/iI6JI0g8rFCnYFbosIX1bIrEO19Kw3v2c3a76mfKnGzPoPh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmWjplM1mfTF8+PBkfciQIcl6V1dX1drSpUtr6qk/857dLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEx9mtbUaPHp2sz58/P1kvG4ffunVr1dpNN92UXPfiiy9O1vujusIuaQXwMbAN6IqIcY1oyswarxF79q9HxAcNeB4zayK/ZzfLRL1hD+BpSS9Lmt7TAyRNl7RI0qI6t2Vmdaj3MH58RKyS9JvAM5J+GRELuj8gImYDswEkRZ3bM7Ma1bVnj4hVxc/1wM+AoxrRlJk1Xs1hl7S3pH123Ae+CSxuVGNm1liKqO3IWtJXqOzNofJ24F8i4tqSdXwY32ITJkxI1h944IFkvezfx5w5c2re/tixY5PrDho0KFmv9d8upMfgAV544YVk/fjjj695280WEeppec3v2SNiOfB7NXdkZi3loTezTDjsZplw2M0y4bCbZcJhN8uET3EdAAYPHly1VjY0NnTo0GS9bHjrkksuSdZTVq9enayfe+65NT83wJVXXlm1dvjhhyfX3bJlS13b7kTes5tlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmfA4ez9w1FHpa4Jcc801VWsjR45sdDufUzaOv3z58prXXbt2bU097XD11VfXvO6yZcvq2nYn8p7dLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEx9n7gUmTJiXrxx13XM3PXXbJ5ClTpiTrq1atqnnbzTZkyJCqNanHqy1/ZsOGDY1up+28ZzfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuFx9n5gyZIlyXpq2uXFixcn102dC9/pzjvvvGR93333rVorux7+fffdV1NPnax0zy7pNknrJS3utmyIpGckvVX83L+5bZpZvXpzGH87cMJOyy4F5kXEYcC84ncz62ClYY+IBcDO3x2cDMwt7s8FTmlwX2bWYLW+Zx8WEWuK+2uBYdUeKGk6ML3G7ZhZg9T9AV1EhKSqn3ZExGxgNkDqcWbWXLUOva2TNByg+Lm+cS2ZWTPUGvZHgWnF/WnAI41px8yaRWXjjZLuASYCQ4F1wJXAw8D9wCHAO8DpEVF6ArAP462Rnn322WR9woQJVWvz5s1LrnviiScm611dXcl6O0VEjyfrl75nj4hqVy+o/YoJZtZy/rqsWSYcdrNMOOxmmXDYzTLhsJtlwqe4Wsc6+uijk/UxY8bU/Nw333xzst7JQ2u18p7dLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEx9mtbcaOHZusP/7448n64MGDk/UFCxZUrT399NPJdQci79nNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0x4nL0FjjjiiGT9lFPSU+WdfPLJyfq4ceP63NMOu+yS/nu/ffv2ZH3hwoU116dMqXbh4ooDDjggWd+4cWOyPmvWrKq1TZs2JdcdiLxnN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0yUTplc0M31o+nbD7ttNOq1i688MLkuscee2yy3sr/BzuTepzd9zOd3NuZZ56ZrN9zzz2NbKffqDZlc+meXdJtktZLWtxt2SxJqyS9WtwmNbJZM2u83hzG3w6c0MPyv4uII4vbE41ty8warTTsEbEA2NCCXsysier5gG6GpNeKw/z9qz1I0nRJiyQtqmNbZlanWsN+E3AocCSwBvhxtQdGxOyIGBcRtZ+tYWZ1qynsEbEuIrZFxHbgZuCoxrZlZo1WU9glDe/266nA4mqPNbPOUHo+u6R7gInAUEkrgSuBiZKOBAJYAVzQxB5b4tRTT03W77jjjqq1PfbYI7nu+++/n6yXjWXPmTMnWd+8eXPV2r333ptc96OPPkrWr7rqqmT9/PPPT9abafXq1W3bdn9UGvaI6OkKA7c2oRczayJ/XdYsEw67WSYcdrNMOOxmmXDYzTKRzaWkU6eoQnpoDdLDa2VDY+0cnipzxRVXJOtlQ5LtNHXq1GT9xRdfrFrbsmVLo9vpeN6zm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZyOZS0s8++2yyPmHChGQ9NZY+Y8aM5Lqffvppsl6vESNGVK1ddtllyXUvuCB9dnLZv4+yKZuvu+66qrVzzjknue7kyZOT9bLeLrrooqq1G264Ibluf1bzpaTNbGBw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmBsw4+/jx45P15557LllfunRpsj5mzJg+99Rbo0aNStYnTpyYrM+cObNq7dBDD02uW3Ze9/XXX5+sP/LII8n6okW1z/r14YcfJuuDBw9O1hcsWFC1VjaGv2nTpmS9k3mc3SxzDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLRG+mbD4YuAMYRmWK5tkR8Q+ShgD3AaOoTNt8ekSk5/9torLztsu+T1A2tXHK6NGjk/XjjjsuWU+d8w2w33779bmnHZ566qlkvey68fWMk9dr0qRJyfrDDz+crB9zzDFVazfeeGNy3bPOOitZ7496s2fvAr4fEWOArwHflTQGuBSYFxGHAfOK382sQ5WGPSLWRMQrxf2PgTeBEcBkYG7xsLnAKc1q0szq16f37JJGAV8Ffg4Mi4g1RWktlcN8M+tQvZ7rTdIg4EHgexGxSfr/r99GRFT73ruk6cD0ehs1s/r0as8uaXcqQb87Ih4qFq+TNLyoDwfW97RuRMyOiHERMa4RDZtZbUrDrsou/FbgzYj4SbfSo8C04v40IH36k5m1VekprpLGA88DrwPbi8Uzqbxvvx84BHiHytDbhpLnatoprtu2bUvWy/47y06B3WuvvarWxo4dm1x30KBByfrmzZuT9XXr1iXrZ5xxRtVa2dBZV1dXst7JHnrooWT9pJNOqlp79913k+uWXR78ySefTNbbqdoprqXv2SPiP4AeVwbSA8hm1jH8DTqzTDjsZplw2M0y4bCbZcJhN8uEw26WiQFzKelbbrklWT/77LPrev433nijam3+/PnJdZ9//vlkfeXKlcn6Sy+9lKxbz+bOnVu1NnXq1OS6l19+ebL+gx/8oKaeWsGXkjbLnMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMjFgxtn33HPPZL1s6uIyqbHw/jy970B24IEH1lQDWLZsWbL+6aef1tRTK3ic3SxzDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLxIAZZzezCo+zm2XOYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZKA27pIMlzZf0hqQlkv6yWD5L0ipJrxa3Sc1v18xqVfqlGknDgeER8YqkfYCXgVOA04FPIuL6Xm/MX6oxa7pqX6rZrRcrrgHWFPc/lvQmMKKx7ZlZs/XpPbukUcBXgZ8Xi2ZIek3SbZL2r7LOdEmLJC2qq1Mzq0uvvxsvaRDwHHBtRDwkaRjwARDA1VQO9b9T8hw+jDdrsmqH8b0Ku6TdgceApyLiJz3URwGPRcTYkudx2M2arOYTYSQJuBV4s3vQiw/udjgVWFxvk2bWPL35NH488DzwOrC9WDwTmAIcSeUwfgVwQfFhXuq5vGc3a7K6DuMbxWE3az6fz26WOYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0yUXrByQb7AHin2+9Di2WdqFN769S+wL3VqpG9jaxWaOn57F/YuLQoIsa1rYGETu2tU/sC91arVvXmw3izTDjsZplod9hnt3n7KZ3aW6f2Be6tVi3pra3v2c2sddq9ZzezFnHYzTLRlrBLOkHSUklvS7q0HT1UI2mFpNeLaajbOj9dMYfeekmLuy0bIukZSW8VP3ucY69NvXXENN6Jacbb+tq1e/rzlr9nl7Qr8CvgG8BKYCEwJSLeaGkjVUhaAYyLiLZ/AUPSBOAT4I4dU2tJ+hGwISJ+WPyh3D8i/rpDeptFH6fxblJv1aYZP5s2vnaNnP68Fu3Ysx8FvB0RyyNiC3AvMLkNfXS8iFgAbNhp8WRgbnF/LpV/LC1XpbeOEBFrIuKV4v7HwI5pxtv62iX6aol2hH0E8F6331fSWfO9B/C0pJclTW93Mz0Y1m2arbXAsHY204PSabxbaadpxjvmtatl+vN6+QO6LxofEb8PfAv4bnG42pGi8h6sk8ZObwIOpTIH4Brgx+1spphm/EHgexGxqXutna9dD3215HVrR9hXAQd3+/2gYllHiIhVxc/1wM+ovO3oJOt2zKBb/Fzf5n4+ExHrImJbRGwHbqaNr10xzfiDwN0R8VCxuO2vXU99tep1a0fYFwKHSfqypD2AbwOPtqGPL5C0d/HBCZL2Br5J501F/Sgwrbg/DXikjb18TqdM411tmnHa/Nq1ffrziGj5DZhE5RP5ZcBl7eihSl9fAX5R3Ja0uzfgHiqHdVupfLZxLnAAMA94C/g3YEgH9XYnlam9X6MSrOFt6m08lUP014BXi9ukdr92ib5a8rr567JmmfAHdGaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJv4P09yn6k8u8HoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg7Tj6MRY2Rr"
      },
      "source": [
        "## Multi-Layer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cBkVFTAaofQ",
        "outputId": "bcb950fa-32a5-4886-9929-d1937cd4c985"
      },
      "source": [
        "\n",
        "multi_layer_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(name='multi_layer', input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(200, activation='tanh', name='hidden'),\n",
        "    tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output')\n",
        "])\n",
        "\n",
        "multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "multi_layer_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "multi_layer (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 159,010\n",
            "Trainable params: 159,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDYrPFp-mrcE"
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('multi_layer_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYbMoNKCm1ub",
        "outputId": "c1d02ec7-1e21-4a77-bf22-1faff0a7a78d"
      },
      "source": [
        "multi_layer_train = multi_layer_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.97817, saving model to multi_layer_best.h5\n",
            "Epoch 2/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.97817\n",
            "Epoch 3/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.97817\n",
            "Epoch 4/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.97817\n",
            "Epoch 5/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.97817\n",
            "Epoch 6/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.97817\n",
            "Epoch 7/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.97817\n",
            "Epoch 8/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.97817 to 0.97825, saving model to multi_layer_best.h5\n",
            "Epoch 9/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.97825\n",
            "Epoch 10/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.97825\n",
            "Epoch 11/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.97825\n",
            "Epoch 12/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.97825\n",
            "Epoch 13/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.97825\n",
            "Epoch 14/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.97825\n",
            "Epoch 15/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.97825\n",
            "Epoch 16/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.97825\n",
            "Epoch 17/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.97825\n",
            "Epoch 18/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.97825\n",
            "Epoch 19/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.97825\n",
            "Epoch 20/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.97825 to 0.97833, saving model to multi_layer_best.h5\n",
            "Epoch 21/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.97833\n",
            "Epoch 22/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.97833\n",
            "Epoch 23/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.97833\n",
            "Epoch 24/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.97833\n",
            "Epoch 25/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.97833\n",
            "Epoch 26/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.97833\n",
            "Epoch 27/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.97833\n",
            "Epoch 28/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.97833\n",
            "Epoch 29/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.97833\n",
            "Epoch 30/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.97833\n",
            "Epoch 31/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.97833\n",
            "Epoch 32/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.97833\n",
            "Epoch 33/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.97833\n",
            "Epoch 34/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.97833\n",
            "Epoch 35/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.97833\n",
            "Epoch 36/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.97833\n",
            "Epoch 37/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.97833\n",
            "Epoch 38/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.97833\n",
            "Epoch 39/10000\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.97833\n",
            "Epoch 40/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.97833\n",
            "Epoch 00040: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "R3wzOBFVvM1Y",
        "outputId": "e81c141a-8bc7-45bf-f11f-be6c1030fc8a"
      },
      "source": [
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(multi_layer_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(multi_layer_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(multi_layer_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(multi_layer_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHmJon6PvWT6"
      },
      "source": [
        "Regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zkOrZ7AvX0S",
        "outputId": "8bd82210-a770-4758-e82a-9229cc30aa65"
      },
      "source": [
        "\n",
        "multi_layer_reg_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(name='multi_layer', input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(200, activation='tanh',  kernel_regularizer=tf.keras.regularizers.l2(0.01), name='hidden'),\n",
        "    tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output')\n",
        "])\n",
        "\n",
        "multi_layer_reg_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "multi_layer_reg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "multi_layer (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 159,010\n",
            "Trainable params: 159,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thXK_hpMvx0D",
        "outputId": "e002e90f-bd0a-44b6-cb04-d98243bd5d4c"
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('multi_layer_reg_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "multi_layer_reg_train = multi_layer_reg_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 3.7751 - accuracy: 0.7441 - val_loss: 2.2487 - val_accuracy: 0.8889\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88892, saving model to multi_layer_reg_best.h5\n",
            "Epoch 2/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 2.0021 - accuracy: 0.8910 - val_loss: 1.4216 - val_accuracy: 0.8994\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.88892 to 0.89942, saving model to multi_layer_reg_best.h5\n",
            "Epoch 3/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.2764 - accuracy: 0.9048 - val_loss: 0.9707 - val_accuracy: 0.9068\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89942 to 0.90675, saving model to multi_layer_reg_best.h5\n",
            "Epoch 4/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.8930 - accuracy: 0.9045 - val_loss: 0.7242 - val_accuracy: 0.9079\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.90675 to 0.90792, saving model to multi_layer_reg_best.h5\n",
            "Epoch 5/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6744 - accuracy: 0.9107 - val_loss: 0.5837 - val_accuracy: 0.9099\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90792 to 0.90992, saving model to multi_layer_reg_best.h5\n",
            "Epoch 6/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5518 - accuracy: 0.9111 - val_loss: 0.5036 - val_accuracy: 0.9111\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90992 to 0.91108, saving model to multi_layer_reg_best.h5\n",
            "Epoch 7/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4835 - accuracy: 0.9118 - val_loss: 0.4612 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91108\n",
            "Epoch 8/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4475 - accuracy: 0.9134 - val_loss: 0.4315 - val_accuracy: 0.9127\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91108 to 0.91267, saving model to multi_layer_reg_best.h5\n",
            "Epoch 9/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4157 - accuracy: 0.9156 - val_loss: 0.4148 - val_accuracy: 0.9137\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91267 to 0.91367, saving model to multi_layer_reg_best.h5\n",
            "Epoch 10/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3996 - accuracy: 0.9142 - val_loss: 0.4064 - val_accuracy: 0.9125\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91367\n",
            "Epoch 11/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3948 - accuracy: 0.9158 - val_loss: 0.3961 - val_accuracy: 0.9150\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91367 to 0.91500, saving model to multi_layer_reg_best.h5\n",
            "Epoch 12/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3802 - accuracy: 0.9174 - val_loss: 0.3935 - val_accuracy: 0.9152\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91500 to 0.91517, saving model to multi_layer_reg_best.h5\n",
            "Epoch 13/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3850 - accuracy: 0.9160 - val_loss: 0.3906 - val_accuracy: 0.9143\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91517\n",
            "Epoch 14/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3734 - accuracy: 0.9185 - val_loss: 0.3866 - val_accuracy: 0.9158\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.91517 to 0.91575, saving model to multi_layer_reg_best.h5\n",
            "Epoch 15/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3766 - accuracy: 0.9147 - val_loss: 0.3811 - val_accuracy: 0.9160\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91575 to 0.91600, saving model to multi_layer_reg_best.h5\n",
            "Epoch 16/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3678 - accuracy: 0.9184 - val_loss: 0.3774 - val_accuracy: 0.9170\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.91600 to 0.91700, saving model to multi_layer_reg_best.h5\n",
            "Epoch 17/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3700 - accuracy: 0.9171 - val_loss: 0.3854 - val_accuracy: 0.9134\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91700\n",
            "Epoch 18/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3571 - accuracy: 0.9204 - val_loss: 0.3776 - val_accuracy: 0.9150\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91700\n",
            "Epoch 19/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3657 - accuracy: 0.9178 - val_loss: 0.3709 - val_accuracy: 0.9176\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.91700 to 0.91758, saving model to multi_layer_reg_best.h5\n",
            "Epoch 20/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3576 - accuracy: 0.9204 - val_loss: 0.3708 - val_accuracy: 0.9168\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91758\n",
            "Epoch 21/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3580 - accuracy: 0.9222 - val_loss: 0.3658 - val_accuracy: 0.9196\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.91758 to 0.91958, saving model to multi_layer_reg_best.h5\n",
            "Epoch 22/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3523 - accuracy: 0.9232 - val_loss: 0.3626 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.91958 to 0.92050, saving model to multi_layer_reg_best.h5\n",
            "Epoch 23/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3552 - accuracy: 0.9205 - val_loss: 0.3592 - val_accuracy: 0.9220\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.92050 to 0.92200, saving model to multi_layer_reg_best.h5\n",
            "Epoch 24/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3535 - accuracy: 0.9213 - val_loss: 0.3632 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.92200\n",
            "Epoch 25/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3481 - accuracy: 0.9234 - val_loss: 0.3570 - val_accuracy: 0.9225\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.92200 to 0.92250, saving model to multi_layer_reg_best.h5\n",
            "Epoch 26/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3421 - accuracy: 0.9254 - val_loss: 0.3557 - val_accuracy: 0.9223\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.92250\n",
            "Epoch 27/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3435 - accuracy: 0.9245 - val_loss: 0.3514 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.92250 to 0.92525, saving model to multi_layer_reg_best.h5\n",
            "Epoch 28/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3472 - accuracy: 0.9245 - val_loss: 0.3488 - val_accuracy: 0.9259\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.92525 to 0.92592, saving model to multi_layer_reg_best.h5\n",
            "Epoch 29/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3375 - accuracy: 0.9254 - val_loss: 0.3486 - val_accuracy: 0.9246\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.92592\n",
            "Epoch 30/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3360 - accuracy: 0.9269 - val_loss: 0.3461 - val_accuracy: 0.9251\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.92592\n",
            "Epoch 31/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3375 - accuracy: 0.9287 - val_loss: 0.3459 - val_accuracy: 0.9242\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.92592\n",
            "Epoch 32/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3288 - accuracy: 0.9286 - val_loss: 0.3550 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.92592\n",
            "Epoch 33/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3351 - accuracy: 0.9278 - val_loss: 0.3391 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.92592 to 0.92675, saving model to multi_layer_reg_best.h5\n",
            "Epoch 34/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3283 - accuracy: 0.9299 - val_loss: 0.3452 - val_accuracy: 0.9244\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.92675\n",
            "Epoch 35/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3269 - accuracy: 0.9300 - val_loss: 0.3397 - val_accuracy: 0.9296\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.92675 to 0.92958, saving model to multi_layer_reg_best.h5\n",
            "Epoch 36/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3267 - accuracy: 0.9320 - val_loss: 0.3344 - val_accuracy: 0.9287\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.92958\n",
            "Epoch 37/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3235 - accuracy: 0.9330 - val_loss: 0.3372 - val_accuracy: 0.9290\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.92958\n",
            "Epoch 38/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3266 - accuracy: 0.9314 - val_loss: 0.3389 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.92958\n",
            "Epoch 39/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3155 - accuracy: 0.9333 - val_loss: 0.3345 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.92958 to 0.93058, saving model to multi_layer_reg_best.h5\n",
            "Epoch 40/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3194 - accuracy: 0.9317 - val_loss: 0.3364 - val_accuracy: 0.9274\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93058\n",
            "Epoch 41/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3154 - accuracy: 0.9340 - val_loss: 0.3341 - val_accuracy: 0.9293\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.93058\n",
            "Epoch 42/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3172 - accuracy: 0.9341 - val_loss: 0.3272 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.93058 to 0.93183, saving model to multi_layer_reg_best.h5\n",
            "Epoch 43/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3175 - accuracy: 0.9333 - val_loss: 0.3261 - val_accuracy: 0.9316\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.93183\n",
            "Epoch 44/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3141 - accuracy: 0.9351 - val_loss: 0.3294 - val_accuracy: 0.9279\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.93183\n",
            "Epoch 45/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3155 - accuracy: 0.9325 - val_loss: 0.3270 - val_accuracy: 0.9309\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.93183\n",
            "Epoch 46/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3076 - accuracy: 0.9365 - val_loss: 0.3250 - val_accuracy: 0.9321\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.93183 to 0.93208, saving model to multi_layer_reg_best.h5\n",
            "Epoch 47/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3053 - accuracy: 0.9374 - val_loss: 0.3212 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.93208 to 0.93217, saving model to multi_layer_reg_best.h5\n",
            "Epoch 48/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3090 - accuracy: 0.9364 - val_loss: 0.3192 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.93217 to 0.93333, saving model to multi_layer_reg_best.h5\n",
            "Epoch 49/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3061 - accuracy: 0.9353 - val_loss: 0.3176 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.93333 to 0.93350, saving model to multi_layer_reg_best.h5\n",
            "Epoch 50/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3045 - accuracy: 0.9379 - val_loss: 0.3168 - val_accuracy: 0.9345\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.93350 to 0.93450, saving model to multi_layer_reg_best.h5\n",
            "Epoch 51/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3056 - accuracy: 0.9371 - val_loss: 0.3169 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.93450\n",
            "Epoch 52/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3054 - accuracy: 0.9367 - val_loss: 0.3187 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.93450\n",
            "Epoch 53/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3015 - accuracy: 0.9386 - val_loss: 0.3151 - val_accuracy: 0.9339\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.93450\n",
            "Epoch 54/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2993 - accuracy: 0.9385 - val_loss: 0.3151 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.93450 to 0.93458, saving model to multi_layer_reg_best.h5\n",
            "Epoch 55/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2998 - accuracy: 0.9396 - val_loss: 0.3136 - val_accuracy: 0.9339\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.93458\n",
            "Epoch 56/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2969 - accuracy: 0.9389 - val_loss: 0.3106 - val_accuracy: 0.9349\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.93458 to 0.93492, saving model to multi_layer_reg_best.h5\n",
            "Epoch 57/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2976 - accuracy: 0.9392 - val_loss: 0.3096 - val_accuracy: 0.9365\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.93492 to 0.93650, saving model to multi_layer_reg_best.h5\n",
            "Epoch 58/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3004 - accuracy: 0.9376 - val_loss: 0.3102 - val_accuracy: 0.9363\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.93650\n",
            "Epoch 59/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2941 - accuracy: 0.9397 - val_loss: 0.3084 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.93650\n",
            "Epoch 60/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2938 - accuracy: 0.9403 - val_loss: 0.3079 - val_accuracy: 0.9365\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.93650\n",
            "Epoch 61/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2949 - accuracy: 0.9400 - val_loss: 0.3080 - val_accuracy: 0.9366\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.93650 to 0.93658, saving model to multi_layer_reg_best.h5\n",
            "Epoch 62/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2913 - accuracy: 0.9401 - val_loss: 0.3127 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.93658 to 0.93692, saving model to multi_layer_reg_best.h5\n",
            "Epoch 63/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2939 - accuracy: 0.9394 - val_loss: 0.3135 - val_accuracy: 0.9313\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.93692\n",
            "Epoch 64/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2912 - accuracy: 0.9407 - val_loss: 0.3047 - val_accuracy: 0.9361\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.93692\n",
            "Epoch 65/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2848 - accuracy: 0.9420 - val_loss: 0.3093 - val_accuracy: 0.9361\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93692\n",
            "Epoch 66/10000\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2891 - accuracy: 0.9416 - val_loss: 0.3055 - val_accuracy: 0.9356\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93692\n",
            "Epoch 67/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2883 - accuracy: 0.9413 - val_loss: 0.3030 - val_accuracy: 0.9373\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.93692 to 0.93725, saving model to multi_layer_reg_best.h5\n",
            "Epoch 68/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2901 - accuracy: 0.9419 - val_loss: 0.3060 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.93725 to 0.93767, saving model to multi_layer_reg_best.h5\n",
            "Epoch 69/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2840 - accuracy: 0.9420 - val_loss: 0.3117 - val_accuracy: 0.9356\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93767\n",
            "Epoch 70/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2873 - accuracy: 0.9427 - val_loss: 0.2996 - val_accuracy: 0.9396\n",
            "\n",
            "Epoch 00070: val_accuracy improved from 0.93767 to 0.93958, saving model to multi_layer_reg_best.h5\n",
            "Epoch 71/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2831 - accuracy: 0.9443 - val_loss: 0.2959 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.93958 to 0.94075, saving model to multi_layer_reg_best.h5\n",
            "Epoch 72/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2834 - accuracy: 0.9428 - val_loss: 0.2966 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.94075\n",
            "Epoch 73/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2860 - accuracy: 0.9424 - val_loss: 0.2958 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.94075\n",
            "Epoch 74/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2791 - accuracy: 0.9444 - val_loss: 0.2992 - val_accuracy: 0.9370\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.94075\n",
            "Epoch 75/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2827 - accuracy: 0.9429 - val_loss: 0.3019 - val_accuracy: 0.9385\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.94075\n",
            "Epoch 76/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2845 - accuracy: 0.9429 - val_loss: 0.2937 - val_accuracy: 0.9390\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.94075\n",
            "Epoch 77/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2816 - accuracy: 0.9439 - val_loss: 0.3078 - val_accuracy: 0.9361\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.94075\n",
            "Epoch 78/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2764 - accuracy: 0.9445 - val_loss: 0.3027 - val_accuracy: 0.9380\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.94075\n",
            "Epoch 79/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2752 - accuracy: 0.9458 - val_loss: 0.3040 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.94075\n",
            "Epoch 80/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2800 - accuracy: 0.9423 - val_loss: 0.2945 - val_accuracy: 0.9398\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.94075\n",
            "Epoch 81/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2742 - accuracy: 0.9439 - val_loss: 0.2912 - val_accuracy: 0.9412\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.94075 to 0.94117, saving model to multi_layer_reg_best.h5\n",
            "Epoch 82/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2776 - accuracy: 0.9454 - val_loss: 0.3017 - val_accuracy: 0.9357\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.94117\n",
            "Epoch 83/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2738 - accuracy: 0.9462 - val_loss: 0.2934 - val_accuracy: 0.9399\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.94117\n",
            "Epoch 84/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2777 - accuracy: 0.9448 - val_loss: 0.2885 - val_accuracy: 0.9411\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.94117\n",
            "Epoch 85/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2754 - accuracy: 0.9450 - val_loss: 0.2896 - val_accuracy: 0.9413\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.94117 to 0.94125, saving model to multi_layer_reg_best.h5\n",
            "Epoch 86/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2720 - accuracy: 0.9468 - val_loss: 0.2938 - val_accuracy: 0.9404\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.94125\n",
            "Epoch 87/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2768 - accuracy: 0.9449 - val_loss: 0.2883 - val_accuracy: 0.9418\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.94125 to 0.94183, saving model to multi_layer_reg_best.h5\n",
            "Epoch 88/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2759 - accuracy: 0.9461 - val_loss: 0.2870 - val_accuracy: 0.9407\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.94183\n",
            "Epoch 89/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2729 - accuracy: 0.9450 - val_loss: 0.2899 - val_accuracy: 0.9402\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.94183\n",
            "Epoch 90/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2723 - accuracy: 0.9463 - val_loss: 0.2973 - val_accuracy: 0.9380\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.94183\n",
            "Epoch 91/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2738 - accuracy: 0.9456 - val_loss: 0.2881 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.94183 to 0.94275, saving model to multi_layer_reg_best.h5\n",
            "Epoch 92/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2667 - accuracy: 0.9484 - val_loss: 0.2847 - val_accuracy: 0.9421\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.94275\n",
            "Epoch 93/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2732 - accuracy: 0.9457 - val_loss: 0.2906 - val_accuracy: 0.9405\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.94275\n",
            "Epoch 94/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2709 - accuracy: 0.9453 - val_loss: 0.2875 - val_accuracy: 0.9398\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.94275\n",
            "Epoch 95/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2688 - accuracy: 0.9459 - val_loss: 0.2905 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.94275\n",
            "Epoch 96/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2654 - accuracy: 0.9479 - val_loss: 0.2853 - val_accuracy: 0.9432\n",
            "\n",
            "Epoch 00096: val_accuracy improved from 0.94275 to 0.94317, saving model to multi_layer_reg_best.h5\n",
            "Epoch 97/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2702 - accuracy: 0.9476 - val_loss: 0.2849 - val_accuracy: 0.9413\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.94317\n",
            "Epoch 98/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2620 - accuracy: 0.9486 - val_loss: 0.2783 - val_accuracy: 0.9444\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.94317 to 0.94442, saving model to multi_layer_reg_best.h5\n",
            "Epoch 99/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2661 - accuracy: 0.9474 - val_loss: 0.2864 - val_accuracy: 0.9424\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.94442\n",
            "Epoch 100/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2636 - accuracy: 0.9481 - val_loss: 0.2834 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.94442\n",
            "Epoch 101/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2700 - accuracy: 0.9481 - val_loss: 0.2827 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.94442\n",
            "Epoch 102/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2630 - accuracy: 0.9486 - val_loss: 0.2794 - val_accuracy: 0.9451\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.94442 to 0.94508, saving model to multi_layer_reg_best.h5\n",
            "Epoch 103/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2623 - accuracy: 0.9490 - val_loss: 0.2871 - val_accuracy: 0.9419\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.94508\n",
            "Epoch 104/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2625 - accuracy: 0.9481 - val_loss: 0.2799 - val_accuracy: 0.9420\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.94508\n",
            "Epoch 105/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2628 - accuracy: 0.9492 - val_loss: 0.2839 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.94508\n",
            "Epoch 106/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2616 - accuracy: 0.9482 - val_loss: 0.2830 - val_accuracy: 0.9418\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.94508\n",
            "Epoch 107/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2676 - accuracy: 0.9465 - val_loss: 0.2838 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.94508\n",
            "Epoch 108/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2662 - accuracy: 0.9479 - val_loss: 0.2797 - val_accuracy: 0.9415\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.94508\n",
            "Epoch 109/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2600 - accuracy: 0.9490 - val_loss: 0.2831 - val_accuracy: 0.9410\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.94508\n",
            "Epoch 110/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2612 - accuracy: 0.9493 - val_loss: 0.2729 - val_accuracy: 0.9458\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.94508 to 0.94583, saving model to multi_layer_reg_best.h5\n",
            "Epoch 111/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2587 - accuracy: 0.9497 - val_loss: 0.2732 - val_accuracy: 0.9449\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.94583\n",
            "Epoch 112/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2617 - accuracy: 0.9486 - val_loss: 0.2813 - val_accuracy: 0.9422\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.94583\n",
            "Epoch 113/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2565 - accuracy: 0.9499 - val_loss: 0.2721 - val_accuracy: 0.9444\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.94583\n",
            "Epoch 114/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2601 - accuracy: 0.9474 - val_loss: 0.2751 - val_accuracy: 0.9436\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.94583\n",
            "Epoch 115/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2575 - accuracy: 0.9489 - val_loss: 0.2796 - val_accuracy: 0.9449\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.94583\n",
            "Epoch 116/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2633 - accuracy: 0.9486 - val_loss: 0.2721 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.94583\n",
            "Epoch 117/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2577 - accuracy: 0.9499 - val_loss: 0.2740 - val_accuracy: 0.9442\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.94583\n",
            "Epoch 118/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2590 - accuracy: 0.9489 - val_loss: 0.2741 - val_accuracy: 0.9452\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.94583\n",
            "Epoch 119/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2618 - accuracy: 0.9487 - val_loss: 0.2677 - val_accuracy: 0.9455\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.94583\n",
            "Epoch 120/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2592 - accuracy: 0.9481 - val_loss: 0.2812 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.94583\n",
            "Epoch 121/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2593 - accuracy: 0.9491 - val_loss: 0.2689 - val_accuracy: 0.9462\n",
            "\n",
            "Epoch 00121: val_accuracy improved from 0.94583 to 0.94617, saving model to multi_layer_reg_best.h5\n",
            "Epoch 122/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2626 - accuracy: 0.9482 - val_loss: 0.2757 - val_accuracy: 0.9436\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.94617\n",
            "Epoch 123/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2564 - accuracy: 0.9490 - val_loss: 0.2683 - val_accuracy: 0.9467\n",
            "\n",
            "Epoch 00123: val_accuracy improved from 0.94617 to 0.94667, saving model to multi_layer_reg_best.h5\n",
            "Epoch 124/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2565 - accuracy: 0.9490 - val_loss: 0.2787 - val_accuracy: 0.9434\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.94667\n",
            "Epoch 125/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2598 - accuracy: 0.9482 - val_loss: 0.2766 - val_accuracy: 0.9457\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.94667\n",
            "Epoch 126/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2543 - accuracy: 0.9514 - val_loss: 0.2733 - val_accuracy: 0.9452\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.94667\n",
            "Epoch 127/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2524 - accuracy: 0.9528 - val_loss: 0.2711 - val_accuracy: 0.9468\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.94667 to 0.94683, saving model to multi_layer_reg_best.h5\n",
            "Epoch 128/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2544 - accuracy: 0.9503 - val_loss: 0.2754 - val_accuracy: 0.9436\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.94683\n",
            "Epoch 129/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2487 - accuracy: 0.9516 - val_loss: 0.2782 - val_accuracy: 0.9404\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.94683\n",
            "Epoch 130/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2529 - accuracy: 0.9517 - val_loss: 0.2830 - val_accuracy: 0.9420\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.94683\n",
            "Epoch 131/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2496 - accuracy: 0.9507 - val_loss: 0.2679 - val_accuracy: 0.9466\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.94683\n",
            "Epoch 132/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2525 - accuracy: 0.9499 - val_loss: 0.2659 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.94683\n",
            "Epoch 133/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2530 - accuracy: 0.9499 - val_loss: 0.2723 - val_accuracy: 0.9458\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.94683\n",
            "Epoch 134/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2535 - accuracy: 0.9507 - val_loss: 0.2774 - val_accuracy: 0.9444\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.94683\n",
            "Epoch 135/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2526 - accuracy: 0.9523 - val_loss: 0.2654 - val_accuracy: 0.9483\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.94683 to 0.94833, saving model to multi_layer_reg_best.h5\n",
            "Epoch 136/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2502 - accuracy: 0.9513 - val_loss: 0.2703 - val_accuracy: 0.9458\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.94833\n",
            "Epoch 137/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2527 - accuracy: 0.9508 - val_loss: 0.2661 - val_accuracy: 0.9467\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.94833\n",
            "Epoch 138/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2456 - accuracy: 0.9521 - val_loss: 0.2728 - val_accuracy: 0.9438\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.94833\n",
            "Epoch 139/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2518 - accuracy: 0.9528 - val_loss: 0.2718 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.94833\n",
            "Epoch 140/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2497 - accuracy: 0.9518 - val_loss: 0.2626 - val_accuracy: 0.9465\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.94833\n",
            "Epoch 141/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2542 - accuracy: 0.9506 - val_loss: 0.2636 - val_accuracy: 0.9475\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.94833\n",
            "Epoch 142/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2451 - accuracy: 0.9530 - val_loss: 0.2649 - val_accuracy: 0.9464\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.94833\n",
            "Epoch 143/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2483 - accuracy: 0.9527 - val_loss: 0.2698 - val_accuracy: 0.9442\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.94833\n",
            "Epoch 144/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2469 - accuracy: 0.9522 - val_loss: 0.2639 - val_accuracy: 0.9467\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.94833\n",
            "Epoch 145/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2444 - accuracy: 0.9537 - val_loss: 0.2756 - val_accuracy: 0.9442\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.94833\n",
            "Epoch 146/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2465 - accuracy: 0.9532 - val_loss: 0.2612 - val_accuracy: 0.9490\n",
            "\n",
            "Epoch 00146: val_accuracy improved from 0.94833 to 0.94900, saving model to multi_layer_reg_best.h5\n",
            "Epoch 147/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2415 - accuracy: 0.9533 - val_loss: 0.2626 - val_accuracy: 0.9493\n",
            "\n",
            "Epoch 00147: val_accuracy improved from 0.94900 to 0.94933, saving model to multi_layer_reg_best.h5\n",
            "Epoch 148/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2433 - accuracy: 0.9545 - val_loss: 0.2637 - val_accuracy: 0.9477\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.94933\n",
            "Epoch 149/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2411 - accuracy: 0.9542 - val_loss: 0.2611 - val_accuracy: 0.9476\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.94933\n",
            "Epoch 150/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2468 - accuracy: 0.9522 - val_loss: 0.2763 - val_accuracy: 0.9423\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.94933\n",
            "Epoch 151/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2449 - accuracy: 0.9515 - val_loss: 0.2670 - val_accuracy: 0.9460\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.94933\n",
            "Epoch 152/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2460 - accuracy: 0.9528 - val_loss: 0.2647 - val_accuracy: 0.9464\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.94933\n",
            "Epoch 153/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2442 - accuracy: 0.9538 - val_loss: 0.2624 - val_accuracy: 0.9478\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.94933\n",
            "Epoch 154/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2417 - accuracy: 0.9537 - val_loss: 0.2624 - val_accuracy: 0.9488\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.94933\n",
            "Epoch 155/10000\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2386 - accuracy: 0.9532 - val_loss: 0.2594 - val_accuracy: 0.9481\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.94933\n",
            "Epoch 156/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2429 - accuracy: 0.9533 - val_loss: 0.2618 - val_accuracy: 0.9479\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.94933\n",
            "Epoch 157/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2426 - accuracy: 0.9527 - val_loss: 0.2585 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00157: val_accuracy improved from 0.94933 to 0.95092, saving model to multi_layer_reg_best.h5\n",
            "Epoch 158/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2409 - accuracy: 0.9542 - val_loss: 0.2611 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.95092\n",
            "Epoch 159/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2445 - accuracy: 0.9519 - val_loss: 0.2642 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.95092\n",
            "Epoch 160/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2443 - accuracy: 0.9526 - val_loss: 0.2601 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.95092\n",
            "Epoch 161/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2422 - accuracy: 0.9533 - val_loss: 0.2587 - val_accuracy: 0.9491\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.95092\n",
            "Epoch 162/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2385 - accuracy: 0.9563 - val_loss: 0.2667 - val_accuracy: 0.9452\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.95092\n",
            "Epoch 163/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2387 - accuracy: 0.9563 - val_loss: 0.2584 - val_accuracy: 0.9478\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.95092\n",
            "Epoch 164/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2436 - accuracy: 0.9529 - val_loss: 0.2566 - val_accuracy: 0.9470\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.95092\n",
            "Epoch 165/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2425 - accuracy: 0.9534 - val_loss: 0.2673 - val_accuracy: 0.9462\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.95092\n",
            "Epoch 166/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2461 - accuracy: 0.9519 - val_loss: 0.2541 - val_accuracy: 0.9508\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.95092\n",
            "Epoch 167/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2416 - accuracy: 0.9544 - val_loss: 0.2545 - val_accuracy: 0.9507\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.95092\n",
            "Epoch 168/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2411 - accuracy: 0.9551 - val_loss: 0.2556 - val_accuracy: 0.9489\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.95092\n",
            "Epoch 169/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2398 - accuracy: 0.9544 - val_loss: 0.2565 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.95092\n",
            "Epoch 170/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2411 - accuracy: 0.9545 - val_loss: 0.2662 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.95092\n",
            "Epoch 171/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2372 - accuracy: 0.9555 - val_loss: 0.2610 - val_accuracy: 0.9489\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.95092\n",
            "Epoch 172/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2384 - accuracy: 0.9539 - val_loss: 0.2544 - val_accuracy: 0.9498\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.95092\n",
            "Epoch 173/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2395 - accuracy: 0.9550 - val_loss: 0.2538 - val_accuracy: 0.9510\n",
            "\n",
            "Epoch 00173: val_accuracy improved from 0.95092 to 0.95100, saving model to multi_layer_reg_best.h5\n",
            "Epoch 174/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2358 - accuracy: 0.9561 - val_loss: 0.2536 - val_accuracy: 0.9497\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.95100\n",
            "Epoch 175/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2357 - accuracy: 0.9544 - val_loss: 0.2692 - val_accuracy: 0.9447\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.95100\n",
            "Epoch 176/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2367 - accuracy: 0.9548 - val_loss: 0.2638 - val_accuracy: 0.9478\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.95100\n",
            "Epoch 177/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2398 - accuracy: 0.9543 - val_loss: 0.2653 - val_accuracy: 0.9457\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.95100\n",
            "Epoch 178/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2338 - accuracy: 0.9548 - val_loss: 0.2561 - val_accuracy: 0.9487\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.95100\n",
            "Epoch 179/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2410 - accuracy: 0.9544 - val_loss: 0.2570 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.95100\n",
            "Epoch 180/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2371 - accuracy: 0.9549 - val_loss: 0.2520 - val_accuracy: 0.9520\n",
            "\n",
            "Epoch 00180: val_accuracy improved from 0.95100 to 0.95200, saving model to multi_layer_reg_best.h5\n",
            "Epoch 181/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2339 - accuracy: 0.9562 - val_loss: 0.2587 - val_accuracy: 0.9485\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.95200\n",
            "Epoch 182/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2362 - accuracy: 0.9559 - val_loss: 0.2632 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.95200\n",
            "Epoch 183/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2342 - accuracy: 0.9561 - val_loss: 0.2553 - val_accuracy: 0.9500\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.95200\n",
            "Epoch 184/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2341 - accuracy: 0.9563 - val_loss: 0.2524 - val_accuracy: 0.9490\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.95200\n",
            "Epoch 185/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2374 - accuracy: 0.9545 - val_loss: 0.2498 - val_accuracy: 0.9519\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.95200\n",
            "Epoch 186/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2350 - accuracy: 0.9540 - val_loss: 0.2478 - val_accuracy: 0.9518\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.95200\n",
            "Epoch 187/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2387 - accuracy: 0.9539 - val_loss: 0.2621 - val_accuracy: 0.9471\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.95200\n",
            "Epoch 188/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2352 - accuracy: 0.9543 - val_loss: 0.2501 - val_accuracy: 0.9512\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.95200\n",
            "Epoch 189/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2339 - accuracy: 0.9562 - val_loss: 0.2497 - val_accuracy: 0.9511\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.95200\n",
            "Epoch 190/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2365 - accuracy: 0.9541 - val_loss: 0.2505 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.95200\n",
            "Epoch 191/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2313 - accuracy: 0.9562 - val_loss: 0.2548 - val_accuracy: 0.9492\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.95200\n",
            "Epoch 192/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2350 - accuracy: 0.9535 - val_loss: 0.2464 - val_accuracy: 0.9526\n",
            "\n",
            "Epoch 00192: val_accuracy improved from 0.95200 to 0.95258, saving model to multi_layer_reg_best.h5\n",
            "Epoch 193/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2317 - accuracy: 0.9550 - val_loss: 0.2516 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.95258\n",
            "Epoch 194/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2335 - accuracy: 0.9553 - val_loss: 0.2518 - val_accuracy: 0.9495\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.95258\n",
            "Epoch 195/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2332 - accuracy: 0.9564 - val_loss: 0.2675 - val_accuracy: 0.9441\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.95258\n",
            "Epoch 196/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2368 - accuracy: 0.9554 - val_loss: 0.2525 - val_accuracy: 0.9487\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.95258\n",
            "Epoch 197/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2314 - accuracy: 0.9560 - val_loss: 0.2516 - val_accuracy: 0.9497\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.95258\n",
            "Epoch 198/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2354 - accuracy: 0.9560 - val_loss: 0.2516 - val_accuracy: 0.9489\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.95258\n",
            "Epoch 199/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2351 - accuracy: 0.9545 - val_loss: 0.2557 - val_accuracy: 0.9488\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.95258\n",
            "Epoch 200/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2405 - accuracy: 0.9526 - val_loss: 0.2572 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.95258\n",
            "Epoch 201/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2315 - accuracy: 0.9566 - val_loss: 0.2437 - val_accuracy: 0.9539\n",
            "\n",
            "Epoch 00201: val_accuracy improved from 0.95258 to 0.95392, saving model to multi_layer_reg_best.h5\n",
            "Epoch 202/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2361 - accuracy: 0.9548 - val_loss: 0.2516 - val_accuracy: 0.9492\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.95392\n",
            "Epoch 203/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2293 - accuracy: 0.9563 - val_loss: 0.2503 - val_accuracy: 0.9514\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.95392\n",
            "Epoch 204/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2308 - accuracy: 0.9566 - val_loss: 0.2411 - val_accuracy: 0.9526\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.95392\n",
            "Epoch 205/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2282 - accuracy: 0.9561 - val_loss: 0.2492 - val_accuracy: 0.9519\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.95392\n",
            "Epoch 206/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2295 - accuracy: 0.9573 - val_loss: 0.2447 - val_accuracy: 0.9521\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.95392\n",
            "Epoch 207/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2327 - accuracy: 0.9560 - val_loss: 0.2457 - val_accuracy: 0.9517\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.95392\n",
            "Epoch 208/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2278 - accuracy: 0.9579 - val_loss: 0.2436 - val_accuracy: 0.9531\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.95392\n",
            "Epoch 209/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2264 - accuracy: 0.9576 - val_loss: 0.2490 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.95392\n",
            "Epoch 210/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2345 - accuracy: 0.9555 - val_loss: 0.2601 - val_accuracy: 0.9474\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.95392\n",
            "Epoch 211/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2271 - accuracy: 0.9576 - val_loss: 0.2531 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.95392\n",
            "Epoch 212/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2258 - accuracy: 0.9577 - val_loss: 0.2456 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.95392\n",
            "Epoch 213/10000\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2225 - accuracy: 0.9574 - val_loss: 0.2511 - val_accuracy: 0.9500\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.95392\n",
            "Epoch 214/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2267 - accuracy: 0.9577 - val_loss: 0.2429 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.95392\n",
            "Epoch 215/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2312 - accuracy: 0.9556 - val_loss: 0.2465 - val_accuracy: 0.9518\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.95392\n",
            "Epoch 216/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2280 - accuracy: 0.9570 - val_loss: 0.2456 - val_accuracy: 0.9513\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.95392\n",
            "Epoch 217/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2298 - accuracy: 0.9556 - val_loss: 0.2444 - val_accuracy: 0.9540\n",
            "\n",
            "Epoch 00217: val_accuracy improved from 0.95392 to 0.95400, saving model to multi_layer_reg_best.h5\n",
            "Epoch 218/10000\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2289 - accuracy: 0.9574 - val_loss: 0.2447 - val_accuracy: 0.9511\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.95400\n",
            "Epoch 219/10000\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2269 - accuracy: 0.9577 - val_loss: 0.2526 - val_accuracy: 0.9493\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.95400\n",
            "Epoch 220/10000\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2314 - accuracy: 0.9557 - val_loss: 0.2404 - val_accuracy: 0.9538\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.95400\n",
            "Epoch 221/10000\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2302 - accuracy: 0.9563 - val_loss: 0.2495 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.95400\n",
            "Epoch 222/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2265 - accuracy: 0.9583 - val_loss: 0.2429 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.95400\n",
            "Epoch 223/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2274 - accuracy: 0.9576 - val_loss: 0.2739 - val_accuracy: 0.9423\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.95400\n",
            "Epoch 224/10000\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2302 - accuracy: 0.9563 - val_loss: 0.2514 - val_accuracy: 0.9499\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.95400\n",
            "Epoch 225/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2317 - accuracy: 0.9562 - val_loss: 0.2452 - val_accuracy: 0.9522\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.95400\n",
            "Epoch 226/10000\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2255 - accuracy: 0.9573 - val_loss: 0.2403 - val_accuracy: 0.9526\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.95400\n",
            "Epoch 227/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2253 - accuracy: 0.9580 - val_loss: 0.2404 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.95400\n",
            "Epoch 228/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2243 - accuracy: 0.9577 - val_loss: 0.2430 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.95400\n",
            "Epoch 229/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2226 - accuracy: 0.9582 - val_loss: 0.2616 - val_accuracy: 0.9447\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.95400\n",
            "Epoch 230/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2250 - accuracy: 0.9568 - val_loss: 0.2452 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.95400\n",
            "Epoch 231/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2279 - accuracy: 0.9574 - val_loss: 0.2423 - val_accuracy: 0.9536\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.95400\n",
            "Epoch 232/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2270 - accuracy: 0.9579 - val_loss: 0.2462 - val_accuracy: 0.9519\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.95400\n",
            "Epoch 233/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2271 - accuracy: 0.9568 - val_loss: 0.2449 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.95400\n",
            "Epoch 234/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2261 - accuracy: 0.9572 - val_loss: 0.2420 - val_accuracy: 0.9535\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.95400\n",
            "Epoch 235/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2227 - accuracy: 0.9587 - val_loss: 0.2481 - val_accuracy: 0.9511\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.95400\n",
            "Epoch 236/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2235 - accuracy: 0.9598 - val_loss: 0.2509 - val_accuracy: 0.9488\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.95400\n",
            "Epoch 237/10000\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2228 - accuracy: 0.9575 - val_loss: 0.2408 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.95400\n",
            "Epoch 00237: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "8yX3qpd7wOiF",
        "outputId": "7df0f9d4-b2e2-4c84-8202-e0e2ef69b725"
      },
      "source": [
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(multi_layer_reg_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(multi_layer_reg_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(multi_layer_reg_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(multi_layer_reg_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}