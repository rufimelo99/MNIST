{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nwf7L7rExxyg",
        "IF_ocoxbpP8b",
        "LkNsx8VK6xfr",
        "NlFjPjkp66qG",
        "Jy8rIlDxnbhU",
        "u-1RFhyasSlO",
        "heVQJrluGQ8Y",
        "76iJIfHdsbIs",
        "wDbUX2iDtBlP",
        "U7KQJhNBtHND"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAjWtTIdvW3CGH6ka8NGtC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fa37147734344b5b721ed2423d5164d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31575016c4f94cd8a8b0aea0dfe1a74e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8eaf00d8f28f4601bba767a169ab7501",
              "IPY_MODEL_62bca6d6fec34087890d3e65bec66a0c"
            ]
          }
        },
        "31575016c4f94cd8a8b0aea0dfe1a74e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8eaf00d8f28f4601bba767a169ab7501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a91387e280334425aad038667e478e65",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d616f1743b3a4f349688f5cb99d0b2bf"
          }
        },
        "62bca6d6fec34087890d3e65bec66a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_082c5f4a63bb4ef49541dedf1299a9b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00,  4.75 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61a532a0b87f447ca74d3473b63a2fcd"
          }
        },
        "a91387e280334425aad038667e478e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d616f1743b3a4f349688f5cb99d0b2bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "082c5f4a63bb4ef49541dedf1299a9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61a532a0b87f447ca74d3473b63a2fcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rufimelo99/MNIST/blob/main/MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwf7L7rExxyg"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZnYjFYGo71_"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.decomposition\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYesKuzdyes-"
      },
      "source": [
        "***MNIST Dataset***\n",
        "\n",
        "70000 Examples:\n",
        "\n",
        "**Splited**:\n",
        "\n",
        "* 60000 for training;\n",
        "\n",
        "* 10000 for tests;\n",
        "\n",
        "\n",
        "**10 Classes**: \n",
        "\n",
        "* 0, ..., 9\n",
        "\n",
        "**Features**\n",
        "\n",
        "* (28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "2fa37147734344b5b721ed2423d5164d",
            "31575016c4f94cd8a8b0aea0dfe1a74e",
            "8eaf00d8f28f4601bba767a169ab7501",
            "62bca6d6fec34087890d3e65bec66a0c",
            "a91387e280334425aad038667e478e65",
            "d616f1743b3a4f349688f5cb99d0b2bf",
            "082c5f4a63bb4ef49541dedf1299a9b7",
            "61a532a0b87f447ca74d3473b63a2fcd"
          ]
        },
        "id": "-cfdH1KbpdUX",
        "outputId": "cd6859b9-10ef-426a-eb91-f5ad3f5666d9"
      },
      "source": [
        "mnist_data, mnist_info = tfds.load('mnist', with_info=True)\n",
        "#print(mnist_data)\n",
        "#print(mnist_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fa37147734344b5b721ed2423d5164d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ie2tgR662H"
      },
      "source": [
        "It is needed to convert into numpy arrays and normalize the images. Each pixel range from 0 to 255.0, so:\n",
        "\n",
        "`pixels = pixels/255.0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXC3Eng6p4iE"
      },
      "source": [
        "mnist_x = np.asarray([instance['image'] for instance in tfds.as_numpy(mnist_data['train'])])\n",
        "mnist_y = np.asarray([instance['label'] for instance in tfds.as_numpy(mnist_data['train'])])\n",
        "mnist_x= mnist_x/255.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et1LoPNqf4Xw"
      },
      "source": [
        "mnist_test_x = np.asarray([instance['image'] for instance in tfds.as_numpy(mnist_data['test'])])\n",
        "mnist_test_y = np.asarray([instance['label'] for instance in tfds.as_numpy(mnist_data['test'])])\n",
        "mnist_test_x= mnist_test_x/255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX-DhgZiKsNL"
      },
      "source": [
        "# Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdyKBNPeaKZ8"
      },
      "source": [
        "##Number of Kernels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FwSIbpGDaQT5",
        "outputId": "52867880-6ace-47af-d657-79a9a44c173c"
      },
      "source": [
        "kernelSizes = [1,2,3,4,5,6]\n",
        "acc_values = [None] * len(kernelSizes)\n",
        "for kernels in range(len(kernelSizes)):\n",
        "  mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "  mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=kernelSizes[kernels], activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model.summary()\n",
        "\n",
        "  earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "  mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "  loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "  print('Accuracy for the training set: {}'.format(acc))\n",
        "  loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  print('Accuracy for the testing set: {}'.format(acc))\n",
        "  fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "  acc_values[kernels]=acc\n",
        "\n",
        "  loss_ax.set_title('Loss')\n",
        "  loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "  loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "  acc_ax.set_title('Accuracy')\n",
        "  acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "  acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "plt.plot(acc_values) # plotting by columns\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        32        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,482\n",
            "Trainable params: 125,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 29s 31ms/step - loss: 1.6907 - accuracy: 0.6895 - val_loss: 0.9967 - val_accuracy: 0.8163\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.81625, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.7130 - accuracy: 0.8412 - val_loss: 0.5612 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.81625 to 0.86075, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.4985 - accuracy: 0.8687 - val_loss: 0.4587 - val_accuracy: 0.8767\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.86075 to 0.87667, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.4297 - accuracy: 0.8819 - val_loss: 0.4129 - val_accuracy: 0.8864\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.87667 to 0.88642, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3936 - accuracy: 0.8904 - val_loss: 0.3856 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.88642 to 0.89167, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3705 - accuracy: 0.8962 - val_loss: 0.3686 - val_accuracy: 0.8965\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.89167 to 0.89650, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3547 - accuracy: 0.8996 - val_loss: 0.3554 - val_accuracy: 0.9007\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.89650 to 0.90067, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3429 - accuracy: 0.9029 - val_loss: 0.3461 - val_accuracy: 0.9018\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.90067 to 0.90183, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3338 - accuracy: 0.9046 - val_loss: 0.3392 - val_accuracy: 0.9042\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.90183 to 0.90417, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3264 - accuracy: 0.9067 - val_loss: 0.3321 - val_accuracy: 0.9059\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.90417 to 0.90592, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3204 - accuracy: 0.9089 - val_loss: 0.3280 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.90592 to 0.90650, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3151 - accuracy: 0.9100 - val_loss: 0.3246 - val_accuracy: 0.9084\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.90650 to 0.90842, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3109 - accuracy: 0.9116 - val_loss: 0.3216 - val_accuracy: 0.9093\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.90842 to 0.90933, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3070 - accuracy: 0.9128 - val_loss: 0.3176 - val_accuracy: 0.9105\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.90933 to 0.91050, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3036 - accuracy: 0.9135 - val_loss: 0.3166 - val_accuracy: 0.9108\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91050 to 0.91083, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.3007 - accuracy: 0.9144 - val_loss: 0.3123 - val_accuracy: 0.9123\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.91083 to 0.91233, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2980 - accuracy: 0.9154 - val_loss: 0.3105 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91233 to 0.91275, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2955 - accuracy: 0.9161 - val_loss: 0.3090 - val_accuracy: 0.9142\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.91275 to 0.91417, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2933 - accuracy: 0.9170 - val_loss: 0.3078 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.91417 to 0.91542, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2913 - accuracy: 0.9172 - val_loss: 0.3059 - val_accuracy: 0.9152\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91542\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2894 - accuracy: 0.9178 - val_loss: 0.3046 - val_accuracy: 0.9153\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91542\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2876 - accuracy: 0.9186 - val_loss: 0.3041 - val_accuracy: 0.9160\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.91542 to 0.91600, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2861 - accuracy: 0.9196 - val_loss: 0.3035 - val_accuracy: 0.9158\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91600\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2847 - accuracy: 0.9200 - val_loss: 0.3026 - val_accuracy: 0.9170\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.91600 to 0.91700, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2831 - accuracy: 0.9203 - val_loss: 0.3007 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.91700 to 0.91800, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2818 - accuracy: 0.9207 - val_loss: 0.2999 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91800\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2805 - accuracy: 0.9210 - val_loss: 0.2995 - val_accuracy: 0.9173\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91800\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2794 - accuracy: 0.9214 - val_loss: 0.2992 - val_accuracy: 0.9176\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91800\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2783 - accuracy: 0.9220 - val_loss: 0.2981 - val_accuracy: 0.9177\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91800\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2772 - accuracy: 0.9226 - val_loss: 0.2977 - val_accuracy: 0.9171\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91800\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2762 - accuracy: 0.9228 - val_loss: 0.2966 - val_accuracy: 0.9188\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.91800 to 0.91883, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2752 - accuracy: 0.9228 - val_loss: 0.2962 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91883\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2743 - accuracy: 0.9234 - val_loss: 0.2962 - val_accuracy: 0.9182\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91883\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2735 - accuracy: 0.9232 - val_loss: 0.2959 - val_accuracy: 0.9175\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91883\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2725 - accuracy: 0.9238 - val_loss: 0.2952 - val_accuracy: 0.9178\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91883\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2717 - accuracy: 0.9238 - val_loss: 0.2949 - val_accuracy: 0.9183\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91883\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2709 - accuracy: 0.9244 - val_loss: 0.2947 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91883\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2702 - accuracy: 0.9245 - val_loss: 0.2938 - val_accuracy: 0.9179\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91883\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2692 - accuracy: 0.9251 - val_loss: 0.2960 - val_accuracy: 0.9186\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91883\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2687 - accuracy: 0.9247 - val_loss: 0.2936 - val_accuracy: 0.9176\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91883\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2679 - accuracy: 0.9257 - val_loss: 0.2928 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.91883 to 0.91992, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2673 - accuracy: 0.9255 - val_loss: 0.2922 - val_accuracy: 0.9202\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.91992 to 0.92017, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2667 - accuracy: 0.9262 - val_loss: 0.2929 - val_accuracy: 0.9181\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.92017\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2662 - accuracy: 0.9259 - val_loss: 0.2918 - val_accuracy: 0.9193\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.92017\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2654 - accuracy: 0.9262 - val_loss: 0.2929 - val_accuracy: 0.9181\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.92017\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2650 - accuracy: 0.9262 - val_loss: 0.2930 - val_accuracy: 0.9183\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.92017\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2644 - accuracy: 0.9261 - val_loss: 0.2909 - val_accuracy: 0.9202\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.92017 to 0.92025, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2638 - accuracy: 0.9262 - val_loss: 0.2917 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.92025 to 0.92058, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2634 - accuracy: 0.9268 - val_loss: 0.2900 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.92058\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2628 - accuracy: 0.9270 - val_loss: 0.2903 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.92058\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2622 - accuracy: 0.9273 - val_loss: 0.2899 - val_accuracy: 0.9198\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.92058\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2618 - accuracy: 0.9271 - val_loss: 0.2899 - val_accuracy: 0.9203\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.92058\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2612 - accuracy: 0.9271 - val_loss: 0.2901 - val_accuracy: 0.9203\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.92058\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2607 - accuracy: 0.9276 - val_loss: 0.2892 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.92058\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2602 - accuracy: 0.9275 - val_loss: 0.2910 - val_accuracy: 0.9196\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.92058\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2596 - accuracy: 0.9275 - val_loss: 0.2891 - val_accuracy: 0.9188\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.92058\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2595 - accuracy: 0.9284 - val_loss: 0.2891 - val_accuracy: 0.9198\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.92058\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2590 - accuracy: 0.9280 - val_loss: 0.2886 - val_accuracy: 0.9208\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.92058 to 0.92075, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2585 - accuracy: 0.9283 - val_loss: 0.2898 - val_accuracy: 0.9193\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.92075\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2581 - accuracy: 0.9287 - val_loss: 0.2897 - val_accuracy: 0.9198\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.92075\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2577 - accuracy: 0.9290 - val_loss: 0.2886 - val_accuracy: 0.9197\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.92075\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2573 - accuracy: 0.9286 - val_loss: 0.2882 - val_accuracy: 0.9207\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.92075\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2568 - accuracy: 0.9286 - val_loss: 0.2879 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.92075\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2564 - accuracy: 0.9283 - val_loss: 0.2894 - val_accuracy: 0.9198\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.92075\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2561 - accuracy: 0.9287 - val_loss: 0.2879 - val_accuracy: 0.9207\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.92075\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2556 - accuracy: 0.9295 - val_loss: 0.2893 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.92075 to 0.92125, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2554 - accuracy: 0.9293 - val_loss: 0.2877 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.92125\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2552 - accuracy: 0.9290 - val_loss: 0.2879 - val_accuracy: 0.9201\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.92125\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2548 - accuracy: 0.9290 - val_loss: 0.2881 - val_accuracy: 0.9208\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.92125\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2544 - accuracy: 0.9292 - val_loss: 0.2882 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.92125\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2540 - accuracy: 0.9291 - val_loss: 0.2873 - val_accuracy: 0.9213\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.92125 to 0.92133, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2537 - accuracy: 0.9296 - val_loss: 0.2880 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.92133\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2535 - accuracy: 0.9296 - val_loss: 0.2871 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.92133\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2530 - accuracy: 0.9295 - val_loss: 0.2888 - val_accuracy: 0.9201\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92133\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2528 - accuracy: 0.9298 - val_loss: 0.2891 - val_accuracy: 0.9209\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92133\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2525 - accuracy: 0.9295 - val_loss: 0.2886 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92133\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2521 - accuracy: 0.9297 - val_loss: 0.2874 - val_accuracy: 0.9215\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.92133 to 0.92150, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2517 - accuracy: 0.9303 - val_loss: 0.2881 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.92150 to 0.92183, saving model to mnist_conv_best.h5\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2515 - accuracy: 0.9304 - val_loss: 0.2883 - val_accuracy: 0.9220\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.92183 to 0.92200, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2512 - accuracy: 0.9301 - val_loss: 0.2874 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92200\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2509 - accuracy: 0.9305 - val_loss: 0.2873 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92200\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2507 - accuracy: 0.9298 - val_loss: 0.2872 - val_accuracy: 0.9209\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92200\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2505 - accuracy: 0.9303 - val_loss: 0.2877 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92200\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2502 - accuracy: 0.9302 - val_loss: 0.2870 - val_accuracy: 0.9217\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92200\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2497 - accuracy: 0.9304 - val_loss: 0.2867 - val_accuracy: 0.9219\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92200\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2494 - accuracy: 0.9310 - val_loss: 0.2875 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92200\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2493 - accuracy: 0.9307 - val_loss: 0.2883 - val_accuracy: 0.9207\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92200\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2491 - accuracy: 0.9310 - val_loss: 0.2883 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92200\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2486 - accuracy: 0.9308 - val_loss: 0.2880 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.92200 to 0.92208, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2486 - accuracy: 0.9314 - val_loss: 0.2876 - val_accuracy: 0.9217\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92208\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2482 - accuracy: 0.9311 - val_loss: 0.2869 - val_accuracy: 0.9213\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92208\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2480 - accuracy: 0.9310 - val_loss: 0.2872 - val_accuracy: 0.9216\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92208\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2479 - accuracy: 0.9309 - val_loss: 0.2875 - val_accuracy: 0.9222\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.92208 to 0.92217, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2475 - accuracy: 0.9311 - val_loss: 0.2879 - val_accuracy: 0.9202\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92217\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2471 - accuracy: 0.9315 - val_loss: 0.2869 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92217\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2471 - accuracy: 0.9313 - val_loss: 0.2867 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92217\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2468 - accuracy: 0.9314 - val_loss: 0.2897 - val_accuracy: 0.9203\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92217\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2468 - accuracy: 0.9316 - val_loss: 0.2870 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92217\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2463 - accuracy: 0.9310 - val_loss: 0.2883 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92217\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2462 - accuracy: 0.9314 - val_loss: 0.2873 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92217\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2459 - accuracy: 0.9314 - val_loss: 0.2877 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92217\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2458 - accuracy: 0.9317 - val_loss: 0.2887 - val_accuracy: 0.9203\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92217\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.2458 - accuracy: 0.9313 - val_loss: 0.2878 - val_accuracy: 0.9216\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92217\n",
            "Epoch 00103: early stopping\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2546 - accuracy: 0.9301\n",
            "Accuracy for the training set: 0.9301000237464905\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2689 - accuracy: 0.9254\n",
            "Accuracy for the testing set: 0.9254000186920166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        80        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,530\n",
            "Trainable params: 125,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 11s 55ms/step - loss: 1.1566 - accuracy: 0.7581 - val_loss: 0.5683 - val_accuracy: 0.8563\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.85633, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.4746 - accuracy: 0.8724 - val_loss: 0.4223 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.85633 to 0.88425, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3942 - accuracy: 0.8897 - val_loss: 0.3784 - val_accuracy: 0.8946\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.88425 to 0.89458, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3618 - accuracy: 0.8972 - val_loss: 0.3557 - val_accuracy: 0.9013\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89458 to 0.90133, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3423 - accuracy: 0.9028 - val_loss: 0.3426 - val_accuracy: 0.9038\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90133 to 0.90375, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3290 - accuracy: 0.9064 - val_loss: 0.3304 - val_accuracy: 0.9082\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90375 to 0.90825, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.3188 - accuracy: 0.9094 - val_loss: 0.3247 - val_accuracy: 0.9081\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.90825\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3112 - accuracy: 0.9117 - val_loss: 0.3181 - val_accuracy: 0.9102\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.90825 to 0.91017, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3051 - accuracy: 0.9135 - val_loss: 0.3134 - val_accuracy: 0.9131\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91017 to 0.91308, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3000 - accuracy: 0.9150 - val_loss: 0.3090 - val_accuracy: 0.9139\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91308 to 0.91392, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.2962 - accuracy: 0.9159 - val_loss: 0.3075 - val_accuracy: 0.9145\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91392 to 0.91450, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2928 - accuracy: 0.9168 - val_loss: 0.3040 - val_accuracy: 0.9151\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91450 to 0.91508, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.2899 - accuracy: 0.9175 - val_loss: 0.3036 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91508 to 0.91633, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.2874 - accuracy: 0.9185 - val_loss: 0.2994 - val_accuracy: 0.9169\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.91633 to 0.91692, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.2849 - accuracy: 0.9198 - val_loss: 0.2981 - val_accuracy: 0.9178\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91692 to 0.91783, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.2829 - accuracy: 0.9194 - val_loss: 0.3007 - val_accuracy: 0.9181\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.91783 to 0.91808, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2811 - accuracy: 0.9208 - val_loss: 0.2963 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91808 to 0.91892, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2793 - accuracy: 0.9216 - val_loss: 0.2951 - val_accuracy: 0.9191\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.91892 to 0.91908, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2776 - accuracy: 0.9215 - val_loss: 0.2947 - val_accuracy: 0.9188\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91908\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2761 - accuracy: 0.9222 - val_loss: 0.2919 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91908\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2749 - accuracy: 0.9230 - val_loss: 0.2921 - val_accuracy: 0.9196\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.91908 to 0.91958, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2734 - accuracy: 0.9230 - val_loss: 0.2888 - val_accuracy: 0.9203\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.91958 to 0.92033, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2722 - accuracy: 0.9234 - val_loss: 0.2909 - val_accuracy: 0.9201\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.92033\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2711 - accuracy: 0.9244 - val_loss: 0.2885 - val_accuracy: 0.9208\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.92033 to 0.92075, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2699 - accuracy: 0.9240 - val_loss: 0.2923 - val_accuracy: 0.9183\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.92075\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2687 - accuracy: 0.9246 - val_loss: 0.2887 - val_accuracy: 0.9197\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.92075\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2676 - accuracy: 0.9250 - val_loss: 0.2895 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.92075 to 0.92108, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2668 - accuracy: 0.9250 - val_loss: 0.2859 - val_accuracy: 0.9209\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.92108\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2659 - accuracy: 0.9256 - val_loss: 0.2866 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.92108\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2649 - accuracy: 0.9254 - val_loss: 0.2845 - val_accuracy: 0.9203\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.92108\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2638 - accuracy: 0.9261 - val_loss: 0.2838 - val_accuracy: 0.9207\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.92108\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2628 - accuracy: 0.9259 - val_loss: 0.2829 - val_accuracy: 0.9214\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.92108 to 0.92142, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2619 - accuracy: 0.9267 - val_loss: 0.2846 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.92142\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2612 - accuracy: 0.9269 - val_loss: 0.2820 - val_accuracy: 0.9227\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.92142 to 0.92267, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2601 - accuracy: 0.9278 - val_loss: 0.2813 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.92267\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2592 - accuracy: 0.9277 - val_loss: 0.2804 - val_accuracy: 0.9227\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.92267 to 0.92275, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2583 - accuracy: 0.9278 - val_loss: 0.2829 - val_accuracy: 0.9215\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.92275\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2576 - accuracy: 0.9284 - val_loss: 0.2800 - val_accuracy: 0.9219\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.92275\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2567 - accuracy: 0.9283 - val_loss: 0.2796 - val_accuracy: 0.9227\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.92275\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2559 - accuracy: 0.9283 - val_loss: 0.2787 - val_accuracy: 0.9227\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.92275\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2549 - accuracy: 0.9292 - val_loss: 0.2766 - val_accuracy: 0.9235\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.92275 to 0.92350, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2540 - accuracy: 0.9290 - val_loss: 0.2770 - val_accuracy: 0.9228\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.92350\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2533 - accuracy: 0.9299 - val_loss: 0.2761 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.92350 to 0.92358, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2526 - accuracy: 0.9292 - val_loss: 0.2782 - val_accuracy: 0.9244\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.92358 to 0.92442, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2517 - accuracy: 0.9305 - val_loss: 0.2772 - val_accuracy: 0.9235\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.92442\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2507 - accuracy: 0.9299 - val_loss: 0.2741 - val_accuracy: 0.9244\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.92442\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2499 - accuracy: 0.9305 - val_loss: 0.2746 - val_accuracy: 0.9241\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.92442\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2494 - accuracy: 0.9302 - val_loss: 0.2726 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.92442 to 0.92517, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2482 - accuracy: 0.9307 - val_loss: 0.2757 - val_accuracy: 0.9250\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.92517\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2474 - accuracy: 0.9313 - val_loss: 0.2751 - val_accuracy: 0.9245\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.92517\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2466 - accuracy: 0.9317 - val_loss: 0.2711 - val_accuracy: 0.9250\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.92517\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2456 - accuracy: 0.9312 - val_loss: 0.2738 - val_accuracy: 0.9240\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.92517\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2447 - accuracy: 0.9320 - val_loss: 0.2740 - val_accuracy: 0.9232\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.92517\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2439 - accuracy: 0.9325 - val_loss: 0.2708 - val_accuracy: 0.9245\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.92517\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2430 - accuracy: 0.9324 - val_loss: 0.2709 - val_accuracy: 0.9263\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.92517 to 0.92633, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2423 - accuracy: 0.9327 - val_loss: 0.2708 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.92633\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2412 - accuracy: 0.9329 - val_loss: 0.2701 - val_accuracy: 0.9253\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.92633\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2402 - accuracy: 0.9329 - val_loss: 0.2685 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.92633 to 0.92675, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2392 - accuracy: 0.9343 - val_loss: 0.2672 - val_accuracy: 0.9287\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.92675 to 0.92875, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2382 - accuracy: 0.9334 - val_loss: 0.2664 - val_accuracy: 0.9263\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.92875\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2373 - accuracy: 0.9339 - val_loss: 0.2660 - val_accuracy: 0.9276\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.92875\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2367 - accuracy: 0.9345 - val_loss: 0.2647 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.92875\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2354 - accuracy: 0.9350 - val_loss: 0.2634 - val_accuracy: 0.9279\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.92875\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2344 - accuracy: 0.9349 - val_loss: 0.2648 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.92875\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2335 - accuracy: 0.9353 - val_loss: 0.2625 - val_accuracy: 0.9292\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.92875 to 0.92917, saving model to mnist_conv_best.h5\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2321 - accuracy: 0.9359 - val_loss: 0.2597 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.92917 to 0.93033, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2312 - accuracy: 0.9354 - val_loss: 0.2603 - val_accuracy: 0.9292\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.93033\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2299 - accuracy: 0.9360 - val_loss: 0.2607 - val_accuracy: 0.9290\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.93033\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2294 - accuracy: 0.9365 - val_loss: 0.2584 - val_accuracy: 0.9287\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93033\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.2280 - accuracy: 0.9371 - val_loss: 0.2571 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93033\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2268 - accuracy: 0.9374 - val_loss: 0.2582 - val_accuracy: 0.9302\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.93033\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2259 - accuracy: 0.9379 - val_loss: 0.2536 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.93033 to 0.93142, saving model to mnist_conv_best.h5\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2246 - accuracy: 0.9381 - val_loss: 0.2571 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.93142\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2239 - accuracy: 0.9380 - val_loss: 0.2575 - val_accuracy: 0.9292\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93142\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2222 - accuracy: 0.9392 - val_loss: 0.2521 - val_accuracy: 0.9308\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93142\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2214 - accuracy: 0.9388 - val_loss: 0.2511 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.93142 to 0.93150, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2200 - accuracy: 0.9389 - val_loss: 0.2504 - val_accuracy: 0.9330\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.93150 to 0.93300, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2184 - accuracy: 0.9397 - val_loss: 0.2537 - val_accuracy: 0.9295\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93300\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2175 - accuracy: 0.9392 - val_loss: 0.2497 - val_accuracy: 0.9325\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.93300\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2161 - accuracy: 0.9408 - val_loss: 0.2474 - val_accuracy: 0.9334\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.93300 to 0.93342, saving model to mnist_conv_best.h5\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2149 - accuracy: 0.9404 - val_loss: 0.2463 - val_accuracy: 0.9331\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.93342\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2137 - accuracy: 0.9417 - val_loss: 0.2452 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.93342 to 0.93458, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2124 - accuracy: 0.9414 - val_loss: 0.2432 - val_accuracy: 0.9339\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93458\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2109 - accuracy: 0.9417 - val_loss: 0.2422 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93458\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2096 - accuracy: 0.9427 - val_loss: 0.2399 - val_accuracy: 0.9354\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.93458 to 0.93542, saving model to mnist_conv_best.h5\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2081 - accuracy: 0.9429 - val_loss: 0.2413 - val_accuracy: 0.9357\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.93542 to 0.93567, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2068 - accuracy: 0.9427 - val_loss: 0.2386 - val_accuracy: 0.9358\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.93567 to 0.93583, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2056 - accuracy: 0.9434 - val_loss: 0.2373 - val_accuracy: 0.9354\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93583\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2043 - accuracy: 0.9440 - val_loss: 0.2363 - val_accuracy: 0.9368\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.93583 to 0.93683, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.2030 - accuracy: 0.9448 - val_loss: 0.2361 - val_accuracy: 0.9354\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93683\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2014 - accuracy: 0.9448 - val_loss: 0.2345 - val_accuracy: 0.9359\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93683\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2001 - accuracy: 0.9453 - val_loss: 0.2362 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93683\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1988 - accuracy: 0.9461 - val_loss: 0.2324 - val_accuracy: 0.9374\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.93683 to 0.93742, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1974 - accuracy: 0.9461 - val_loss: 0.2287 - val_accuracy: 0.9389\n",
            "\n",
            "Epoch 00094: val_accuracy improved from 0.93742 to 0.93892, saving model to mnist_conv_best.h5\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1957 - accuracy: 0.9466 - val_loss: 0.2295 - val_accuracy: 0.9373\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93892\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1947 - accuracy: 0.9471 - val_loss: 0.2291 - val_accuracy: 0.9378\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93892\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1931 - accuracy: 0.9471 - val_loss: 0.2263 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.93892 to 0.93925, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1915 - accuracy: 0.9482 - val_loss: 0.2246 - val_accuracy: 0.9406\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.93925 to 0.94058, saving model to mnist_conv_best.h5\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1900 - accuracy: 0.9487 - val_loss: 0.2234 - val_accuracy: 0.9399\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.94058\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1889 - accuracy: 0.9484 - val_loss: 0.2232 - val_accuracy: 0.9411\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.94058 to 0.94108, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1872 - accuracy: 0.9489 - val_loss: 0.2224 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.94108\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1857 - accuracy: 0.9496 - val_loss: 0.2207 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.94108\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1842 - accuracy: 0.9506 - val_loss: 0.2193 - val_accuracy: 0.9413\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.94108 to 0.94125, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1832 - accuracy: 0.9496 - val_loss: 0.2174 - val_accuracy: 0.9413\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.94125\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1810 - accuracy: 0.9509 - val_loss: 0.2166 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00105: val_accuracy improved from 0.94125 to 0.94275, saving model to mnist_conv_best.h5\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1799 - accuracy: 0.9513 - val_loss: 0.2152 - val_accuracy: 0.9421\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.94275\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1784 - accuracy: 0.9512 - val_loss: 0.2148 - val_accuracy: 0.9420\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.94275\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1770 - accuracy: 0.9520 - val_loss: 0.2120 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.94275 to 0.94325, saving model to mnist_conv_best.h5\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1759 - accuracy: 0.9521 - val_loss: 0.2111 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.94325\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1742 - accuracy: 0.9528 - val_loss: 0.2094 - val_accuracy: 0.9428\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.94325\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1729 - accuracy: 0.9532 - val_loss: 0.2084 - val_accuracy: 0.9437\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.94325 to 0.94367, saving model to mnist_conv_best.h5\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1714 - accuracy: 0.9538 - val_loss: 0.2067 - val_accuracy: 0.9434\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.94367\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1699 - accuracy: 0.9537 - val_loss: 0.2041 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.94367 to 0.94475, saving model to mnist_conv_best.h5\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1682 - accuracy: 0.9543 - val_loss: 0.2053 - val_accuracy: 0.9442\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.94475\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1672 - accuracy: 0.9551 - val_loss: 0.2013 - val_accuracy: 0.9457\n",
            "\n",
            "Epoch 00115: val_accuracy improved from 0.94475 to 0.94575, saving model to mnist_conv_best.h5\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1656 - accuracy: 0.9555 - val_loss: 0.1999 - val_accuracy: 0.9465\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.94575 to 0.94650, saving model to mnist_conv_best.h5\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1642 - accuracy: 0.9556 - val_loss: 0.2006 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.94650 to 0.94725, saving model to mnist_conv_best.h5\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1628 - accuracy: 0.9563 - val_loss: 0.1978 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.94725\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1613 - accuracy: 0.9563 - val_loss: 0.1972 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.94725\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1600 - accuracy: 0.9565 - val_loss: 0.1943 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.94725\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1586 - accuracy: 0.9573 - val_loss: 0.1951 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00121: val_accuracy improved from 0.94725 to 0.94817, saving model to mnist_conv_best.h5\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1573 - accuracy: 0.9581 - val_loss: 0.1922 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.94817 to 0.94858, saving model to mnist_conv_best.h5\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1557 - accuracy: 0.9578 - val_loss: 0.1923 - val_accuracy: 0.9481\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.94858\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1546 - accuracy: 0.9585 - val_loss: 0.1903 - val_accuracy: 0.9492\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.94858 to 0.94925, saving model to mnist_conv_best.h5\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1532 - accuracy: 0.9591 - val_loss: 0.1883 - val_accuracy: 0.9489\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.94925\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1517 - accuracy: 0.9594 - val_loss: 0.1873 - val_accuracy: 0.9500\n",
            "\n",
            "Epoch 00126: val_accuracy improved from 0.94925 to 0.95000, saving model to mnist_conv_best.h5\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1506 - accuracy: 0.9593 - val_loss: 0.1907 - val_accuracy: 0.9497\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.95000\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1492 - accuracy: 0.9599 - val_loss: 0.1857 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00128: val_accuracy improved from 0.95000 to 0.95017, saving model to mnist_conv_best.h5\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1479 - accuracy: 0.9600 - val_loss: 0.1833 - val_accuracy: 0.9508\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.95017 to 0.95083, saving model to mnist_conv_best.h5\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1466 - accuracy: 0.9604 - val_loss: 0.1826 - val_accuracy: 0.9513\n",
            "\n",
            "Epoch 00130: val_accuracy improved from 0.95083 to 0.95125, saving model to mnist_conv_best.h5\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1454 - accuracy: 0.9613 - val_loss: 0.1812 - val_accuracy: 0.9510\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.95125\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1441 - accuracy: 0.9615 - val_loss: 0.1805 - val_accuracy: 0.9513\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.95125\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1430 - accuracy: 0.9620 - val_loss: 0.1781 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00133: val_accuracy improved from 0.95125 to 0.95292, saving model to mnist_conv_best.h5\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1416 - accuracy: 0.9620 - val_loss: 0.1797 - val_accuracy: 0.9514\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.95292\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1407 - accuracy: 0.9628 - val_loss: 0.1765 - val_accuracy: 0.9523\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.95292\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.1392 - accuracy: 0.9632 - val_loss: 0.1745 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00136: val_accuracy improved from 0.95292 to 0.95325, saving model to mnist_conv_best.h5\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1380 - accuracy: 0.9630 - val_loss: 0.1736 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.95325\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1367 - accuracy: 0.9639 - val_loss: 0.1732 - val_accuracy: 0.9531\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.95325\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1356 - accuracy: 0.9644 - val_loss: 0.1730 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.95325\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1343 - accuracy: 0.9641 - val_loss: 0.1727 - val_accuracy: 0.9536\n",
            "\n",
            "Epoch 00140: val_accuracy improved from 0.95325 to 0.95358, saving model to mnist_conv_best.h5\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1333 - accuracy: 0.9648 - val_loss: 0.1700 - val_accuracy: 0.9542\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.95358 to 0.95425, saving model to mnist_conv_best.h5\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1321 - accuracy: 0.9647 - val_loss: 0.1705 - val_accuracy: 0.9536\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.95425\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1309 - accuracy: 0.9653 - val_loss: 0.1688 - val_accuracy: 0.9542\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.95425\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1298 - accuracy: 0.9654 - val_loss: 0.1669 - val_accuracy: 0.9557\n",
            "\n",
            "Epoch 00144: val_accuracy improved from 0.95425 to 0.95567, saving model to mnist_conv_best.h5\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1288 - accuracy: 0.9659 - val_loss: 0.1672 - val_accuracy: 0.9548\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.95567\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1276 - accuracy: 0.9666 - val_loss: 0.1648 - val_accuracy: 0.9559\n",
            "\n",
            "Epoch 00146: val_accuracy improved from 0.95567 to 0.95592, saving model to mnist_conv_best.h5\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1264 - accuracy: 0.9664 - val_loss: 0.1629 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00147: val_accuracy improved from 0.95592 to 0.95733, saving model to mnist_conv_best.h5\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1256 - accuracy: 0.9672 - val_loss: 0.1626 - val_accuracy: 0.9557\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.95733\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1245 - accuracy: 0.9672 - val_loss: 0.1627 - val_accuracy: 0.9565\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.95733\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1236 - accuracy: 0.9675 - val_loss: 0.1600 - val_accuracy: 0.9572\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.95733\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1222 - accuracy: 0.9679 - val_loss: 0.1587 - val_accuracy: 0.9583\n",
            "\n",
            "Epoch 00151: val_accuracy improved from 0.95733 to 0.95833, saving model to mnist_conv_best.h5\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1214 - accuracy: 0.9679 - val_loss: 0.1586 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.95833\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1203 - accuracy: 0.9683 - val_loss: 0.1588 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.95833\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1194 - accuracy: 0.9682 - val_loss: 0.1575 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.95833\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1185 - accuracy: 0.9690 - val_loss: 0.1557 - val_accuracy: 0.9584\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.95833 to 0.95842, saving model to mnist_conv_best.h5\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1177 - accuracy: 0.9688 - val_loss: 0.1543 - val_accuracy: 0.9586\n",
            "\n",
            "Epoch 00156: val_accuracy improved from 0.95842 to 0.95858, saving model to mnist_conv_best.h5\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1165 - accuracy: 0.9694 - val_loss: 0.1540 - val_accuracy: 0.9583\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.95858\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1156 - accuracy: 0.9695 - val_loss: 0.1545 - val_accuracy: 0.9585\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.95858\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1148 - accuracy: 0.9698 - val_loss: 0.1523 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00159: val_accuracy improved from 0.95858 to 0.95967, saving model to mnist_conv_best.h5\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1137 - accuracy: 0.9706 - val_loss: 0.1529 - val_accuracy: 0.9593\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.95967\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1130 - accuracy: 0.9704 - val_loss: 0.1516 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.95967\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1119 - accuracy: 0.9709 - val_loss: 0.1500 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.95967\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1112 - accuracy: 0.9708 - val_loss: 0.1491 - val_accuracy: 0.9607\n",
            "\n",
            "Epoch 00163: val_accuracy improved from 0.95967 to 0.96075, saving model to mnist_conv_best.h5\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1102 - accuracy: 0.9714 - val_loss: 0.1482 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.96075\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1094 - accuracy: 0.9711 - val_loss: 0.1471 - val_accuracy: 0.9611\n",
            "\n",
            "Epoch 00165: val_accuracy improved from 0.96075 to 0.96108, saving model to mnist_conv_best.h5\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1085 - accuracy: 0.9712 - val_loss: 0.1471 - val_accuracy: 0.9611\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.96108\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1077 - accuracy: 0.9719 - val_loss: 0.1467 - val_accuracy: 0.9611\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.96108\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1070 - accuracy: 0.9721 - val_loss: 0.1457 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00168: val_accuracy improved from 0.96108 to 0.96175, saving model to mnist_conv_best.h5\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1061 - accuracy: 0.9722 - val_loss: 0.1437 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00169: val_accuracy improved from 0.96175 to 0.96242, saving model to mnist_conv_best.h5\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1053 - accuracy: 0.9727 - val_loss: 0.1434 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.96242\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1043 - accuracy: 0.9729 - val_loss: 0.1443 - val_accuracy: 0.9615\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.96242\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1037 - accuracy: 0.9729 - val_loss: 0.1418 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.96242\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1030 - accuracy: 0.9731 - val_loss: 0.1423 - val_accuracy: 0.9618\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.96242\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1021 - accuracy: 0.9731 - val_loss: 0.1412 - val_accuracy: 0.9622\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.96242\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1013 - accuracy: 0.9737 - val_loss: 0.1406 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.96242\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1005 - accuracy: 0.9738 - val_loss: 0.1406 - val_accuracy: 0.9627\n",
            "\n",
            "Epoch 00176: val_accuracy improved from 0.96242 to 0.96267, saving model to mnist_conv_best.h5\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0999 - accuracy: 0.9742 - val_loss: 0.1395 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00177: val_accuracy improved from 0.96267 to 0.96367, saving model to mnist_conv_best.h5\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0993 - accuracy: 0.9744 - val_loss: 0.1383 - val_accuracy: 0.9633\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.96367\n",
            "Epoch 179/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0985 - accuracy: 0.9742 - val_loss: 0.1376 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.96367\n",
            "Epoch 180/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0979 - accuracy: 0.9745 - val_loss: 0.1370 - val_accuracy: 0.9632\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.96367\n",
            "Epoch 181/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0972 - accuracy: 0.9750 - val_loss: 0.1366 - val_accuracy: 0.9639\n",
            "\n",
            "Epoch 00181: val_accuracy improved from 0.96367 to 0.96392, saving model to mnist_conv_best.h5\n",
            "Epoch 182/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0963 - accuracy: 0.9752 - val_loss: 0.1371 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.96392\n",
            "Epoch 183/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0957 - accuracy: 0.9753 - val_loss: 0.1344 - val_accuracy: 0.9645\n",
            "\n",
            "Epoch 00183: val_accuracy improved from 0.96392 to 0.96450, saving model to mnist_conv_best.h5\n",
            "Epoch 184/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0951 - accuracy: 0.9755 - val_loss: 0.1349 - val_accuracy: 0.9646\n",
            "\n",
            "Epoch 00184: val_accuracy improved from 0.96450 to 0.96458, saving model to mnist_conv_best.h5\n",
            "Epoch 185/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0943 - accuracy: 0.9757 - val_loss: 0.1341 - val_accuracy: 0.9649\n",
            "\n",
            "Epoch 00185: val_accuracy improved from 0.96458 to 0.96492, saving model to mnist_conv_best.h5\n",
            "Epoch 186/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0937 - accuracy: 0.9758 - val_loss: 0.1344 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.96492\n",
            "Epoch 187/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0931 - accuracy: 0.9758 - val_loss: 0.1321 - val_accuracy: 0.9646\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.96492\n",
            "Epoch 188/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0926 - accuracy: 0.9763 - val_loss: 0.1321 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00188: val_accuracy improved from 0.96492 to 0.96533, saving model to mnist_conv_best.h5\n",
            "Epoch 189/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0917 - accuracy: 0.9767 - val_loss: 0.1317 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.96533\n",
            "Epoch 190/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0914 - accuracy: 0.9763 - val_loss: 0.1314 - val_accuracy: 0.9655\n",
            "\n",
            "Epoch 00190: val_accuracy improved from 0.96533 to 0.96550, saving model to mnist_conv_best.h5\n",
            "Epoch 191/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0907 - accuracy: 0.9769 - val_loss: 0.1304 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.96550\n",
            "Epoch 192/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0899 - accuracy: 0.9771 - val_loss: 0.1297 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.96550\n",
            "Epoch 193/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0895 - accuracy: 0.9770 - val_loss: 0.1291 - val_accuracy: 0.9648\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.96550\n",
            "Epoch 194/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0889 - accuracy: 0.9772 - val_loss: 0.1306 - val_accuracy: 0.9638\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.96550\n",
            "Epoch 195/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0884 - accuracy: 0.9777 - val_loss: 0.1280 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00195: val_accuracy improved from 0.96550 to 0.96575, saving model to mnist_conv_best.h5\n",
            "Epoch 196/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0876 - accuracy: 0.9774 - val_loss: 0.1296 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.96575\n",
            "Epoch 197/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0873 - accuracy: 0.9778 - val_loss: 0.1282 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.96575\n",
            "Epoch 198/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0867 - accuracy: 0.9780 - val_loss: 0.1269 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00198: val_accuracy improved from 0.96575 to 0.96625, saving model to mnist_conv_best.h5\n",
            "Epoch 199/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0861 - accuracy: 0.9776 - val_loss: 0.1264 - val_accuracy: 0.9655\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.96625\n",
            "Epoch 200/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0854 - accuracy: 0.9780 - val_loss: 0.1270 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.96625\n",
            "Epoch 201/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0849 - accuracy: 0.9783 - val_loss: 0.1258 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00201: val_accuracy improved from 0.96625 to 0.96650, saving model to mnist_conv_best.h5\n",
            "Epoch 202/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0844 - accuracy: 0.9787 - val_loss: 0.1244 - val_accuracy: 0.9662\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.96650\n",
            "Epoch 203/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0840 - accuracy: 0.9785 - val_loss: 0.1249 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.96650\n",
            "Epoch 204/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0835 - accuracy: 0.9786 - val_loss: 0.1245 - val_accuracy: 0.9661\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.96650\n",
            "Epoch 205/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0829 - accuracy: 0.9788 - val_loss: 0.1236 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.96650\n",
            "Epoch 206/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0822 - accuracy: 0.9793 - val_loss: 0.1233 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00206: val_accuracy improved from 0.96650 to 0.96733, saving model to mnist_conv_best.h5\n",
            "Epoch 207/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0819 - accuracy: 0.9793 - val_loss: 0.1231 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.96733\n",
            "Epoch 208/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0814 - accuracy: 0.9793 - val_loss: 0.1219 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.96733\n",
            "Epoch 209/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0808 - accuracy: 0.9798 - val_loss: 0.1218 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.96733\n",
            "Epoch 210/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0805 - accuracy: 0.9797 - val_loss: 0.1209 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.96733\n",
            "Epoch 211/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0799 - accuracy: 0.9795 - val_loss: 0.1228 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.96733\n",
            "Epoch 212/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0795 - accuracy: 0.9799 - val_loss: 0.1216 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.96733\n",
            "Epoch 213/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0790 - accuracy: 0.9802 - val_loss: 0.1206 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.96733\n",
            "Epoch 214/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0785 - accuracy: 0.9805 - val_loss: 0.1201 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.96733\n",
            "Epoch 215/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0781 - accuracy: 0.9803 - val_loss: 0.1200 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00215: val_accuracy improved from 0.96733 to 0.96775, saving model to mnist_conv_best.h5\n",
            "Epoch 216/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0776 - accuracy: 0.9800 - val_loss: 0.1194 - val_accuracy: 0.9671\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.96775\n",
            "Epoch 217/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0773 - accuracy: 0.9806 - val_loss: 0.1184 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00217: val_accuracy improved from 0.96775 to 0.96817, saving model to mnist_conv_best.h5\n",
            "Epoch 218/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0765 - accuracy: 0.9806 - val_loss: 0.1188 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.96817\n",
            "Epoch 219/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0763 - accuracy: 0.9805 - val_loss: 0.1177 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.96817\n",
            "Epoch 220/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0759 - accuracy: 0.9811 - val_loss: 0.1181 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.96817\n",
            "Epoch 221/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0754 - accuracy: 0.9811 - val_loss: 0.1183 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.96817\n",
            "Epoch 222/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0750 - accuracy: 0.9812 - val_loss: 0.1168 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.96817\n",
            "Epoch 223/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0745 - accuracy: 0.9812 - val_loss: 0.1172 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.96817\n",
            "Epoch 224/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0741 - accuracy: 0.9813 - val_loss: 0.1172 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.96817\n",
            "Epoch 225/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0738 - accuracy: 0.9813 - val_loss: 0.1157 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00225: val_accuracy improved from 0.96817 to 0.96858, saving model to mnist_conv_best.h5\n",
            "Epoch 226/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0733 - accuracy: 0.9816 - val_loss: 0.1160 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.96858\n",
            "Epoch 227/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0731 - accuracy: 0.9817 - val_loss: 0.1150 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.96858\n",
            "Epoch 228/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0725 - accuracy: 0.9816 - val_loss: 0.1154 - val_accuracy: 0.9676\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.96858\n",
            "Epoch 229/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0721 - accuracy: 0.9820 - val_loss: 0.1143 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00229: val_accuracy improved from 0.96858 to 0.96867, saving model to mnist_conv_best.h5\n",
            "Epoch 230/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0718 - accuracy: 0.9820 - val_loss: 0.1140 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.96867\n",
            "Epoch 231/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0713 - accuracy: 0.9821 - val_loss: 0.1144 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.96867\n",
            "Epoch 232/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0710 - accuracy: 0.9820 - val_loss: 0.1136 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00232: val_accuracy improved from 0.96867 to 0.96925, saving model to mnist_conv_best.h5\n",
            "Epoch 233/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0706 - accuracy: 0.9824 - val_loss: 0.1139 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.96925\n",
            "Epoch 234/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0702 - accuracy: 0.9825 - val_loss: 0.1139 - val_accuracy: 0.9677\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.96925\n",
            "Epoch 235/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0699 - accuracy: 0.9825 - val_loss: 0.1138 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.96925\n",
            "Epoch 236/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0695 - accuracy: 0.9826 - val_loss: 0.1126 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.96925\n",
            "Epoch 237/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0691 - accuracy: 0.9828 - val_loss: 0.1124 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.96925\n",
            "Epoch 238/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0687 - accuracy: 0.9826 - val_loss: 0.1123 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.96925\n",
            "Epoch 239/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0684 - accuracy: 0.9830 - val_loss: 0.1111 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.96925\n",
            "Epoch 240/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0681 - accuracy: 0.9828 - val_loss: 0.1114 - val_accuracy: 0.9694\n",
            "\n",
            "Epoch 00240: val_accuracy improved from 0.96925 to 0.96942, saving model to mnist_conv_best.h5\n",
            "Epoch 241/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0677 - accuracy: 0.9834 - val_loss: 0.1119 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.96942\n",
            "Epoch 242/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0674 - accuracy: 0.9829 - val_loss: 0.1106 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.96942\n",
            "Epoch 243/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0669 - accuracy: 0.9834 - val_loss: 0.1113 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.96942\n",
            "Epoch 244/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0666 - accuracy: 0.9834 - val_loss: 0.1094 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.96942\n",
            "Epoch 245/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0663 - accuracy: 0.9835 - val_loss: 0.1098 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.96942\n",
            "Epoch 246/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0660 - accuracy: 0.9837 - val_loss: 0.1092 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.96942\n",
            "Epoch 247/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0657 - accuracy: 0.9840 - val_loss: 0.1101 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.96942\n",
            "Epoch 248/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0655 - accuracy: 0.9836 - val_loss: 0.1091 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.96942\n",
            "Epoch 249/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0651 - accuracy: 0.9838 - val_loss: 0.1086 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.96942\n",
            "Epoch 250/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0647 - accuracy: 0.9842 - val_loss: 0.1084 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00250: val_accuracy improved from 0.96942 to 0.96983, saving model to mnist_conv_best.h5\n",
            "Epoch 251/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0644 - accuracy: 0.9843 - val_loss: 0.1084 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.96983\n",
            "Epoch 252/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0641 - accuracy: 0.9843 - val_loss: 0.1081 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.96983\n",
            "Epoch 253/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0638 - accuracy: 0.9843 - val_loss: 0.1075 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.96983\n",
            "Epoch 254/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0635 - accuracy: 0.9847 - val_loss: 0.1078 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.96983\n",
            "Epoch 255/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0631 - accuracy: 0.9846 - val_loss: 0.1080 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.96983\n",
            "Epoch 256/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0629 - accuracy: 0.9846 - val_loss: 0.1095 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.96983\n",
            "Epoch 257/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0626 - accuracy: 0.9848 - val_loss: 0.1066 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.96983\n",
            "Epoch 258/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0623 - accuracy: 0.9851 - val_loss: 0.1065 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.96983\n",
            "Epoch 259/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0620 - accuracy: 0.9848 - val_loss: 0.1064 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00259: val_accuracy improved from 0.96983 to 0.97017, saving model to mnist_conv_best.h5\n",
            "Epoch 260/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0617 - accuracy: 0.9851 - val_loss: 0.1064 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.97017\n",
            "Epoch 261/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0614 - accuracy: 0.9854 - val_loss: 0.1059 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.97017\n",
            "Epoch 262/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0611 - accuracy: 0.9851 - val_loss: 0.1066 - val_accuracy: 0.9694\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.97017\n",
            "Epoch 263/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0608 - accuracy: 0.9851 - val_loss: 0.1055 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.97017\n",
            "Epoch 264/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0605 - accuracy: 0.9852 - val_loss: 0.1047 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.97017\n",
            "Epoch 265/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0603 - accuracy: 0.9852 - val_loss: 0.1050 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.97017\n",
            "Epoch 266/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0601 - accuracy: 0.9851 - val_loss: 0.1050 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.97017\n",
            "Epoch 267/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0599 - accuracy: 0.9852 - val_loss: 0.1047 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.97017\n",
            "Epoch 268/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0594 - accuracy: 0.9853 - val_loss: 0.1046 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.97017\n",
            "Epoch 269/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0593 - accuracy: 0.9853 - val_loss: 0.1047 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.97017\n",
            "Epoch 00269: early stopping\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0702 - accuracy: 0.9820\n",
            "Accuracy for the training set: 0.9820166826248169\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0931 - accuracy: 0.9714\n",
            "Accuracy for the testing set: 0.9714000225067139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,610\n",
            "Trainable params: 125,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 1.1767 - accuracy: 0.7377 - val_loss: 0.5247 - val_accuracy: 0.8654\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.86542, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.4423 - accuracy: 0.8804 - val_loss: 0.4025 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.86542 to 0.88817, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.3759 - accuracy: 0.8929 - val_loss: 0.3643 - val_accuracy: 0.8959\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.88817 to 0.89592, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.3495 - accuracy: 0.8994 - val_loss: 0.3484 - val_accuracy: 0.9014\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89592 to 0.90142, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.3337 - accuracy: 0.9034 - val_loss: 0.3345 - val_accuracy: 0.9056\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90142 to 0.90558, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.3221 - accuracy: 0.9071 - val_loss: 0.3285 - val_accuracy: 0.9074\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90558 to 0.90742, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.3136 - accuracy: 0.9102 - val_loss: 0.3211 - val_accuracy: 0.9112\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90742 to 0.91117, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.3064 - accuracy: 0.9121 - val_loss: 0.3144 - val_accuracy: 0.9129\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91117 to 0.91292, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.3007 - accuracy: 0.9140 - val_loss: 0.3114 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91292 to 0.91483, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2962 - accuracy: 0.9158 - val_loss: 0.3124 - val_accuracy: 0.9140\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91483\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2922 - accuracy: 0.9170 - val_loss: 0.3036 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91483 to 0.91725, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2886 - accuracy: 0.9177 - val_loss: 0.2983 - val_accuracy: 0.9173\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91725 to 0.91733, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2857 - accuracy: 0.9189 - val_loss: 0.3023 - val_accuracy: 0.9149\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91733\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2831 - accuracy: 0.9199 - val_loss: 0.2956 - val_accuracy: 0.9196\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.91733 to 0.91958, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2804 - accuracy: 0.9203 - val_loss: 0.2922 - val_accuracy: 0.9209\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91958 to 0.92092, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2780 - accuracy: 0.9215 - val_loss: 0.2921 - val_accuracy: 0.9202\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.92092\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2764 - accuracy: 0.9218 - val_loss: 0.2916 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.92092\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2737 - accuracy: 0.9224 - val_loss: 0.2869 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92092 to 0.92108, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2718 - accuracy: 0.9226 - val_loss: 0.2866 - val_accuracy: 0.9216\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.92108 to 0.92158, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2696 - accuracy: 0.9242 - val_loss: 0.2856 - val_accuracy: 0.9222\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.92158 to 0.92225, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2677 - accuracy: 0.9245 - val_loss: 0.2838 - val_accuracy: 0.9209\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.92225\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2654 - accuracy: 0.9250 - val_loss: 0.2800 - val_accuracy: 0.9222\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.92225\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2636 - accuracy: 0.9260 - val_loss: 0.2912 - val_accuracy: 0.9184\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.92225\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2620 - accuracy: 0.9260 - val_loss: 0.2777 - val_accuracy: 0.9243\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.92225 to 0.92425, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2593 - accuracy: 0.9265 - val_loss: 0.2787 - val_accuracy: 0.9224\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.92425\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2576 - accuracy: 0.9277 - val_loss: 0.2731 - val_accuracy: 0.9249\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.92425 to 0.92492, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2559 - accuracy: 0.9284 - val_loss: 0.2710 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.92492\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.2534 - accuracy: 0.9279 - val_loss: 0.2747 - val_accuracy: 0.9217\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.92492\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2516 - accuracy: 0.9290 - val_loss: 0.2695 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.92492 to 0.92517, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.2495 - accuracy: 0.9300 - val_loss: 0.2690 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.92517 to 0.92625, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2476 - accuracy: 0.9310 - val_loss: 0.2655 - val_accuracy: 0.9270\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.92625 to 0.92700, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2454 - accuracy: 0.9313 - val_loss: 0.2644 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.92700\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2431 - accuracy: 0.9315 - val_loss: 0.2651 - val_accuracy: 0.9269\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.92700\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2409 - accuracy: 0.9325 - val_loss: 0.2584 - val_accuracy: 0.9282\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.92700 to 0.92817, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2382 - accuracy: 0.9337 - val_loss: 0.2584 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.92817 to 0.92833, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2361 - accuracy: 0.9344 - val_loss: 0.2546 - val_accuracy: 0.9298\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.92833 to 0.92975, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2341 - accuracy: 0.9348 - val_loss: 0.2504 - val_accuracy: 0.9316\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.92975 to 0.93158, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.2316 - accuracy: 0.9356 - val_loss: 0.2500 - val_accuracy: 0.9305\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.93158\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2288 - accuracy: 0.9366 - val_loss: 0.2485 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.93158\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2263 - accuracy: 0.9376 - val_loss: 0.2552 - val_accuracy: 0.9311\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93158\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.2240 - accuracy: 0.9381 - val_loss: 0.2425 - val_accuracy: 0.9328\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.93158 to 0.93283, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2209 - accuracy: 0.9388 - val_loss: 0.2451 - val_accuracy: 0.9316\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.93283\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2179 - accuracy: 0.9404 - val_loss: 0.2375 - val_accuracy: 0.9352\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.93283 to 0.93525, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2156 - accuracy: 0.9407 - val_loss: 0.2371 - val_accuracy: 0.9359\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.93525 to 0.93592, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2131 - accuracy: 0.9408 - val_loss: 0.2329 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.93592 to 0.93625, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.2105 - accuracy: 0.9422 - val_loss: 0.2284 - val_accuracy: 0.9380\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.93625 to 0.93800, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.2079 - accuracy: 0.9430 - val_loss: 0.2257 - val_accuracy: 0.9382\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.93800 to 0.93817, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.2046 - accuracy: 0.9433 - val_loss: 0.2249 - val_accuracy: 0.9402\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.93817 to 0.94025, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.2020 - accuracy: 0.9446 - val_loss: 0.2223 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.94025\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.1992 - accuracy: 0.9456 - val_loss: 0.2211 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.94025 to 0.94158, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1966 - accuracy: 0.9461 - val_loss: 0.2156 - val_accuracy: 0.9417\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.94158 to 0.94167, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1936 - accuracy: 0.9470 - val_loss: 0.2138 - val_accuracy: 0.9424\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.94167 to 0.94242, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1910 - accuracy: 0.9479 - val_loss: 0.2123 - val_accuracy: 0.9438\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.94242 to 0.94375, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.1883 - accuracy: 0.9488 - val_loss: 0.2097 - val_accuracy: 0.9415\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.94375\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1857 - accuracy: 0.9497 - val_loss: 0.2058 - val_accuracy: 0.9436\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.94375\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.1832 - accuracy: 0.9497 - val_loss: 0.2033 - val_accuracy: 0.9450\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.94375 to 0.94500, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1803 - accuracy: 0.9512 - val_loss: 0.2013 - val_accuracy: 0.9455\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.94500 to 0.94550, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1779 - accuracy: 0.9516 - val_loss: 0.2002 - val_accuracy: 0.9449\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.94550\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1753 - accuracy: 0.9525 - val_loss: 0.1964 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.94550 to 0.94592, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1725 - accuracy: 0.9537 - val_loss: 0.1940 - val_accuracy: 0.9479\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.94592 to 0.94792, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1702 - accuracy: 0.9539 - val_loss: 0.1917 - val_accuracy: 0.9479\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.94792\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1678 - accuracy: 0.9547 - val_loss: 0.1898 - val_accuracy: 0.9479\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.94792\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1656 - accuracy: 0.9550 - val_loss: 0.1873 - val_accuracy: 0.9481\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.94792 to 0.94808, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1634 - accuracy: 0.9561 - val_loss: 0.1846 - val_accuracy: 0.9488\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.94808 to 0.94875, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1610 - accuracy: 0.9566 - val_loss: 0.1816 - val_accuracy: 0.9508\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.94875 to 0.95083, saving model to mnist_conv_best.h5\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1587 - accuracy: 0.9577 - val_loss: 0.1795 - val_accuracy: 0.9518\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.95083 to 0.95183, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1564 - accuracy: 0.9578 - val_loss: 0.1795 - val_accuracy: 0.9519\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.95183 to 0.95192, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1543 - accuracy: 0.9584 - val_loss: 0.1766 - val_accuracy: 0.9523\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.95192 to 0.95225, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1524 - accuracy: 0.9587 - val_loss: 0.1747 - val_accuracy: 0.9526\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.95225 to 0.95258, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1506 - accuracy: 0.9592 - val_loss: 0.1733 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00070: val_accuracy improved from 0.95258 to 0.95267, saving model to mnist_conv_best.h5\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1485 - accuracy: 0.9600 - val_loss: 0.1697 - val_accuracy: 0.9542\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.95267 to 0.95425, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1463 - accuracy: 0.9611 - val_loss: 0.1687 - val_accuracy: 0.9544\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.95425 to 0.95442, saving model to mnist_conv_best.h5\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1445 - accuracy: 0.9616 - val_loss: 0.1702 - val_accuracy: 0.9536\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.95442\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1425 - accuracy: 0.9617 - val_loss: 0.1648 - val_accuracy: 0.9546\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.95442 to 0.95458, saving model to mnist_conv_best.h5\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1407 - accuracy: 0.9620 - val_loss: 0.1637 - val_accuracy: 0.9555\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.95458 to 0.95550, saving model to mnist_conv_best.h5\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1389 - accuracy: 0.9634 - val_loss: 0.1658 - val_accuracy: 0.9538\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.95550\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1374 - accuracy: 0.9631 - val_loss: 0.1593 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.95550 to 0.95708, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1358 - accuracy: 0.9639 - val_loss: 0.1624 - val_accuracy: 0.9545\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.95708\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1341 - accuracy: 0.9643 - val_loss: 0.1561 - val_accuracy: 0.9580\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.95708 to 0.95800, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1322 - accuracy: 0.9646 - val_loss: 0.1562 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.95800\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1309 - accuracy: 0.9654 - val_loss: 0.1549 - val_accuracy: 0.9576\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.95800\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1292 - accuracy: 0.9655 - val_loss: 0.1522 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.95800 to 0.95883, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1277 - accuracy: 0.9660 - val_loss: 0.1524 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00083: val_accuracy improved from 0.95883 to 0.95900, saving model to mnist_conv_best.h5\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1262 - accuracy: 0.9670 - val_loss: 0.1504 - val_accuracy: 0.9589\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.95900\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1248 - accuracy: 0.9670 - val_loss: 0.1490 - val_accuracy: 0.9599\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.95900 to 0.95992, saving model to mnist_conv_best.h5\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1235 - accuracy: 0.9673 - val_loss: 0.1478 - val_accuracy: 0.9602\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.95992 to 0.96017, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1224 - accuracy: 0.9674 - val_loss: 0.1465 - val_accuracy: 0.9598\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.96017\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1207 - accuracy: 0.9682 - val_loss: 0.1458 - val_accuracy: 0.9602\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.96017\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1194 - accuracy: 0.9688 - val_loss: 0.1432 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.96017 to 0.96050, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1183 - accuracy: 0.9694 - val_loss: 0.1417 - val_accuracy: 0.9619\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.96050 to 0.96192, saving model to mnist_conv_best.h5\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1169 - accuracy: 0.9693 - val_loss: 0.1418 - val_accuracy: 0.9613\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.96192\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1156 - accuracy: 0.9693 - val_loss: 0.1409 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.96192\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1146 - accuracy: 0.9699 - val_loss: 0.1398 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.96192 to 0.96242, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1133 - accuracy: 0.9704 - val_loss: 0.1384 - val_accuracy: 0.9618\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.96242\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1123 - accuracy: 0.9705 - val_loss: 0.1379 - val_accuracy: 0.9622\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.96242\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1109 - accuracy: 0.9712 - val_loss: 0.1364 - val_accuracy: 0.9638\n",
            "\n",
            "Epoch 00096: val_accuracy improved from 0.96242 to 0.96375, saving model to mnist_conv_best.h5\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1099 - accuracy: 0.9716 - val_loss: 0.1362 - val_accuracy: 0.9635\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.96375\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1090 - accuracy: 0.9713 - val_loss: 0.1339 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.96375\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.1079 - accuracy: 0.9719 - val_loss: 0.1348 - val_accuracy: 0.9625\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.96375\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1067 - accuracy: 0.9722 - val_loss: 0.1319 - val_accuracy: 0.9644\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.96375 to 0.96442, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1059 - accuracy: 0.9724 - val_loss: 0.1335 - val_accuracy: 0.9636\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.96442\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1048 - accuracy: 0.9727 - val_loss: 0.1303 - val_accuracy: 0.9644\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.96442\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1040 - accuracy: 0.9722 - val_loss: 0.1310 - val_accuracy: 0.9635\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.96442\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1029 - accuracy: 0.9730 - val_loss: 0.1287 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.96442 to 0.96542, saving model to mnist_conv_best.h5\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1019 - accuracy: 0.9732 - val_loss: 0.1293 - val_accuracy: 0.9646\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.96542\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.1010 - accuracy: 0.9732 - val_loss: 0.1262 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.96542\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 12s 67ms/step - loss: 0.1001 - accuracy: 0.9737 - val_loss: 0.1259 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.96542\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.0992 - accuracy: 0.9742 - val_loss: 0.1266 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.96542\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0983 - accuracy: 0.9742 - val_loss: 0.1256 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.96542 to 0.96583, saving model to mnist_conv_best.h5\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0975 - accuracy: 0.9740 - val_loss: 0.1235 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.96583\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0967 - accuracy: 0.9746 - val_loss: 0.1227 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.96583 to 0.96592, saving model to mnist_conv_best.h5\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0959 - accuracy: 0.9749 - val_loss: 0.1226 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.96592\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0949 - accuracy: 0.9747 - val_loss: 0.1227 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.96592\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0941 - accuracy: 0.9752 - val_loss: 0.1210 - val_accuracy: 0.9660\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.96592 to 0.96600, saving model to mnist_conv_best.h5\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0933 - accuracy: 0.9754 - val_loss: 0.1200 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00115: val_accuracy improved from 0.96600 to 0.96667, saving model to mnist_conv_best.h5\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0925 - accuracy: 0.9758 - val_loss: 0.1197 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.96667 to 0.96700, saving model to mnist_conv_best.h5\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0916 - accuracy: 0.9758 - val_loss: 0.1199 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.96700\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0910 - accuracy: 0.9760 - val_loss: 0.1180 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.96700\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0903 - accuracy: 0.9764 - val_loss: 0.1189 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.96700\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0898 - accuracy: 0.9767 - val_loss: 0.1161 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.96700 to 0.96725, saving model to mnist_conv_best.h5\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0889 - accuracy: 0.9764 - val_loss: 0.1170 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00121: val_accuracy improved from 0.96725 to 0.96817, saving model to mnist_conv_best.h5\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0882 - accuracy: 0.9773 - val_loss: 0.1157 - val_accuracy: 0.9662\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.96817\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0875 - accuracy: 0.9769 - val_loss: 0.1150 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.96817\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0869 - accuracy: 0.9775 - val_loss: 0.1148 - val_accuracy: 0.9677\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.96817\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0862 - accuracy: 0.9775 - val_loss: 0.1147 - val_accuracy: 0.9675\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.96817\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0856 - accuracy: 0.9778 - val_loss: 0.1133 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.96817\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 12s 67ms/step - loss: 0.0848 - accuracy: 0.9777 - val_loss: 0.1122 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.96817\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0842 - accuracy: 0.9782 - val_loss: 0.1120 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00128: val_accuracy improved from 0.96817 to 0.96825, saving model to mnist_conv_best.h5\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0835 - accuracy: 0.9784 - val_loss: 0.1122 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.96825\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0829 - accuracy: 0.9786 - val_loss: 0.1118 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00130: val_accuracy improved from 0.96825 to 0.96858, saving model to mnist_conv_best.h5\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0823 - accuracy: 0.9785 - val_loss: 0.1119 - val_accuracy: 0.9681\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.96858\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0817 - accuracy: 0.9783 - val_loss: 0.1110 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.96858\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0811 - accuracy: 0.9786 - val_loss: 0.1117 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.96858\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0806 - accuracy: 0.9790 - val_loss: 0.1097 - val_accuracy: 0.9681\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.96858\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0799 - accuracy: 0.9795 - val_loss: 0.1090 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.96858 to 0.96883, saving model to mnist_conv_best.h5\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 12s 67ms/step - loss: 0.0794 - accuracy: 0.9792 - val_loss: 0.1079 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.96883\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0788 - accuracy: 0.9795 - val_loss: 0.1080 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.96883\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0782 - accuracy: 0.9796 - val_loss: 0.1077 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.96883\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0776 - accuracy: 0.9797 - val_loss: 0.1086 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.96883\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0771 - accuracy: 0.9799 - val_loss: 0.1068 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.96883\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0765 - accuracy: 0.9798 - val_loss: 0.1064 - val_accuracy: 0.9684\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.96883\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 12s 66ms/step - loss: 0.0760 - accuracy: 0.9803 - val_loss: 0.1050 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.96883\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0755 - accuracy: 0.9803 - val_loss: 0.1059 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.96883 to 0.96900, saving model to mnist_conv_best.h5\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0749 - accuracy: 0.9802 - val_loss: 0.1040 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00144: val_accuracy improved from 0.96900 to 0.96992, saving model to mnist_conv_best.h5\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0744 - accuracy: 0.9804 - val_loss: 0.1039 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.96992\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0740 - accuracy: 0.9805 - val_loss: 0.1036 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00146: val_accuracy improved from 0.96992 to 0.97067, saving model to mnist_conv_best.h5\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0734 - accuracy: 0.9805 - val_loss: 0.1032 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97067\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0730 - accuracy: 0.9810 - val_loss: 0.1044 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.97067\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0725 - accuracy: 0.9811 - val_loss: 0.1027 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.97067\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0720 - accuracy: 0.9810 - val_loss: 0.1039 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.97067\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0715 - accuracy: 0.9813 - val_loss: 0.1026 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.97067\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0710 - accuracy: 0.9814 - val_loss: 0.1027 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97067\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0707 - accuracy: 0.9816 - val_loss: 0.1016 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.97067\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0702 - accuracy: 0.9818 - val_loss: 0.1007 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97067\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0698 - accuracy: 0.9820 - val_loss: 0.0999 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.97067\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 13s 67ms/step - loss: 0.0693 - accuracy: 0.9820 - val_loss: 0.1004 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.97067\n",
            "Epoch 00156: early stopping\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0795 - accuracy: 0.9789\n",
            "Accuracy for the training set: 0.9788833260536194\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0879 - accuracy: 0.9738\n",
            "Accuracy for the testing set: 0.973800003528595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,722\n",
            "Trainable params: 125,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 15s 76ms/step - loss: 1.1607 - accuracy: 0.7306 - val_loss: 0.5031 - val_accuracy: 0.8668\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.86683, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.4310 - accuracy: 0.8809 - val_loss: 0.3905 - val_accuracy: 0.8912\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.86683 to 0.89117, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.3703 - accuracy: 0.8952 - val_loss: 0.3591 - val_accuracy: 0.8987\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89117 to 0.89867, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.3455 - accuracy: 0.9003 - val_loss: 0.3434 - val_accuracy: 0.9043\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89867 to 0.90433, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.3299 - accuracy: 0.9049 - val_loss: 0.3308 - val_accuracy: 0.9074\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90433 to 0.90742, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.3190 - accuracy: 0.9084 - val_loss: 0.3241 - val_accuracy: 0.9102\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90742 to 0.91017, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.3100 - accuracy: 0.9108 - val_loss: 0.3162 - val_accuracy: 0.9098\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91017\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.3033 - accuracy: 0.9130 - val_loss: 0.3124 - val_accuracy: 0.9136\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91017 to 0.91358, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.2981 - accuracy: 0.9144 - val_loss: 0.3043 - val_accuracy: 0.9149\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91358 to 0.91492, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2929 - accuracy: 0.9158 - val_loss: 0.3024 - val_accuracy: 0.9170\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91492 to 0.91700, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.2883 - accuracy: 0.9177 - val_loss: 0.3004 - val_accuracy: 0.9178\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91700 to 0.91783, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.2844 - accuracy: 0.9184 - val_loss: 0.2958 - val_accuracy: 0.9165\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91783\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.2802 - accuracy: 0.9203 - val_loss: 0.2885 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91783 to 0.92108, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.2772 - accuracy: 0.9209 - val_loss: 0.2877 - val_accuracy: 0.9197\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.92108\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2732 - accuracy: 0.9219 - val_loss: 0.2830 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.92108 to 0.92308, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.2693 - accuracy: 0.9232 - val_loss: 0.2809 - val_accuracy: 0.9215\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.92308\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.2661 - accuracy: 0.9245 - val_loss: 0.2881 - val_accuracy: 0.9188\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.92308\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2624 - accuracy: 0.9256 - val_loss: 0.2715 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92308 to 0.92517, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2581 - accuracy: 0.9258 - val_loss: 0.2696 - val_accuracy: 0.9275\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.92517 to 0.92750, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2545 - accuracy: 0.9277 - val_loss: 0.2704 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.92750\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2507 - accuracy: 0.9294 - val_loss: 0.2642 - val_accuracy: 0.9284\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92750 to 0.92842, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2464 - accuracy: 0.9300 - val_loss: 0.2583 - val_accuracy: 0.9300\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.92842 to 0.93000, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2431 - accuracy: 0.9319 - val_loss: 0.2584 - val_accuracy: 0.9291\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.93000\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2384 - accuracy: 0.9330 - val_loss: 0.2525 - val_accuracy: 0.9313\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.93000 to 0.93133, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2341 - accuracy: 0.9339 - val_loss: 0.2471 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.93133 to 0.93333, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2298 - accuracy: 0.9358 - val_loss: 0.2443 - val_accuracy: 0.9334\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.93333 to 0.93342, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2254 - accuracy: 0.9367 - val_loss: 0.2379 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.93342 to 0.93625, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.2206 - accuracy: 0.9381 - val_loss: 0.2364 - val_accuracy: 0.9336\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.93625\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2167 - accuracy: 0.9395 - val_loss: 0.2292 - val_accuracy: 0.9378\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93625 to 0.93783, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.2122 - accuracy: 0.9407 - val_loss: 0.2257 - val_accuracy: 0.9385\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.93783 to 0.93850, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.2074 - accuracy: 0.9423 - val_loss: 0.2213 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.93850 to 0.93933, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.2027 - accuracy: 0.9436 - val_loss: 0.2213 - val_accuracy: 0.9397\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.93933 to 0.93967, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1981 - accuracy: 0.9455 - val_loss: 0.2112 - val_accuracy: 0.9421\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.93967 to 0.94208, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1938 - accuracy: 0.9459 - val_loss: 0.2086 - val_accuracy: 0.9424\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.94208 to 0.94242, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1890 - accuracy: 0.9479 - val_loss: 0.2038 - val_accuracy: 0.9436\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.94242 to 0.94358, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1849 - accuracy: 0.9488 - val_loss: 0.2010 - val_accuracy: 0.9444\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.94358 to 0.94442, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1805 - accuracy: 0.9498 - val_loss: 0.1971 - val_accuracy: 0.9447\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.94442 to 0.94467, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1763 - accuracy: 0.9509 - val_loss: 0.1912 - val_accuracy: 0.9464\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.94467 to 0.94642, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.1721 - accuracy: 0.9528 - val_loss: 0.1878 - val_accuracy: 0.9492\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.94642 to 0.94917, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1685 - accuracy: 0.9531 - val_loss: 0.1839 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.94917\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1644 - accuracy: 0.9541 - val_loss: 0.1827 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.94917 to 0.95008, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1606 - accuracy: 0.9558 - val_loss: 0.1762 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.95008 to 0.95325, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1570 - accuracy: 0.9568 - val_loss: 0.1723 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.95325\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1534 - accuracy: 0.9578 - val_loss: 0.1693 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.95325\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1500 - accuracy: 0.9589 - val_loss: 0.1661 - val_accuracy: 0.9548\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.95325 to 0.95483, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1469 - accuracy: 0.9601 - val_loss: 0.1632 - val_accuracy: 0.9553\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.95483 to 0.95533, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1439 - accuracy: 0.9613 - val_loss: 0.1619 - val_accuracy: 0.9557\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.95533 to 0.95575, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1408 - accuracy: 0.9618 - val_loss: 0.1581 - val_accuracy: 0.9565\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.95575 to 0.95650, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1379 - accuracy: 0.9628 - val_loss: 0.1559 - val_accuracy: 0.9582\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.95650 to 0.95825, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1352 - accuracy: 0.9635 - val_loss: 0.1535 - val_accuracy: 0.9583\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.95825 to 0.95833, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1323 - accuracy: 0.9646 - val_loss: 0.1503 - val_accuracy: 0.9586\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.95833 to 0.95858, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1301 - accuracy: 0.9652 - val_loss: 0.1475 - val_accuracy: 0.9599\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.95858 to 0.95992, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1273 - accuracy: 0.9655 - val_loss: 0.1449 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.95992 to 0.96042, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1252 - accuracy: 0.9661 - val_loss: 0.1427 - val_accuracy: 0.9622\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.96042 to 0.96225, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.1227 - accuracy: 0.9667 - val_loss: 0.1400 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.96225 to 0.96233, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1205 - accuracy: 0.9674 - val_loss: 0.1387 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.96233 to 0.96283, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1184 - accuracy: 0.9686 - val_loss: 0.1376 - val_accuracy: 0.9625\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.96283\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1163 - accuracy: 0.9689 - val_loss: 0.1337 - val_accuracy: 0.9635\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.96283 to 0.96350, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1145 - accuracy: 0.9695 - val_loss: 0.1327 - val_accuracy: 0.9639\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.96350 to 0.96392, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1125 - accuracy: 0.9699 - val_loss: 0.1316 - val_accuracy: 0.9635\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.96392\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1106 - accuracy: 0.9705 - val_loss: 0.1298 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.96392 to 0.96425, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1091 - accuracy: 0.9714 - val_loss: 0.1291 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.96425 to 0.96475, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1072 - accuracy: 0.9717 - val_loss: 0.1272 - val_accuracy: 0.9649\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.96475 to 0.96492, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1058 - accuracy: 0.9723 - val_loss: 0.1243 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.96492 to 0.96508, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1042 - accuracy: 0.9727 - val_loss: 0.1232 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.96508 to 0.96650, saving model to mnist_conv_best.h5\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.1027 - accuracy: 0.9730 - val_loss: 0.1223 - val_accuracy: 0.9662\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.96650\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1014 - accuracy: 0.9730 - val_loss: 0.1199 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.96650 to 0.96700, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0997 - accuracy: 0.9739 - val_loss: 0.1199 - val_accuracy: 0.9666\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.96700\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0985 - accuracy: 0.9737 - val_loss: 0.1185 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.96700 to 0.96733, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0972 - accuracy: 0.9743 - val_loss: 0.1193 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.96733\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0959 - accuracy: 0.9747 - val_loss: 0.1167 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.96733 to 0.96800, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0947 - accuracy: 0.9748 - val_loss: 0.1146 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.96800\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0934 - accuracy: 0.9752 - val_loss: 0.1139 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.96800 to 0.96817, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0922 - accuracy: 0.9756 - val_loss: 0.1125 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.96817 to 0.96825, saving model to mnist_conv_best.h5\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0912 - accuracy: 0.9759 - val_loss: 0.1118 - val_accuracy: 0.9684\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.96825 to 0.96842, saving model to mnist_conv_best.h5\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0900 - accuracy: 0.9759 - val_loss: 0.1114 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.96842\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0891 - accuracy: 0.9762 - val_loss: 0.1101 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.96842 to 0.96858, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0880 - accuracy: 0.9768 - val_loss: 0.1096 - val_accuracy: 0.9694\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.96858 to 0.96942, saving model to mnist_conv_best.h5\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0868 - accuracy: 0.9770 - val_loss: 0.1082 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.96942 to 0.96975, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0861 - accuracy: 0.9773 - val_loss: 0.1064 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.96975 to 0.97033, saving model to mnist_conv_best.h5\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0849 - accuracy: 0.9770 - val_loss: 0.1056 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.97033\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0842 - accuracy: 0.9777 - val_loss: 0.1054 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.97033\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0833 - accuracy: 0.9777 - val_loss: 0.1053 - val_accuracy: 0.9700\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.97033\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0823 - accuracy: 0.9783 - val_loss: 0.1044 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.97033\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0816 - accuracy: 0.9782 - val_loss: 0.1041 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.97033 to 0.97058, saving model to mnist_conv_best.h5\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0807 - accuracy: 0.9786 - val_loss: 0.1013 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.97058 to 0.97067, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0798 - accuracy: 0.9789 - val_loss: 0.1013 - val_accuracy: 0.9713\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.97067 to 0.97133, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0790 - accuracy: 0.9791 - val_loss: 0.1015 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.97133\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0783 - accuracy: 0.9792 - val_loss: 0.1008 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.97133 to 0.97217, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0775 - accuracy: 0.9794 - val_loss: 0.0997 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.97217\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0769 - accuracy: 0.9798 - val_loss: 0.0987 - val_accuracy: 0.9713\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.97217\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0761 - accuracy: 0.9800 - val_loss: 0.0989 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.97217\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0754 - accuracy: 0.9799 - val_loss: 0.0985 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.97217 to 0.97242, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0748 - accuracy: 0.9801 - val_loss: 0.0964 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.97242\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0741 - accuracy: 0.9800 - val_loss: 0.0958 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00095: val_accuracy improved from 0.97242 to 0.97300, saving model to mnist_conv_best.h5\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0734 - accuracy: 0.9806 - val_loss: 0.0961 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.97300\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0725 - accuracy: 0.9807 - val_loss: 0.0951 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.97300\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0721 - accuracy: 0.9812 - val_loss: 0.0939 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.97300\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0714 - accuracy: 0.9811 - val_loss: 0.0935 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00099: val_accuracy improved from 0.97300 to 0.97317, saving model to mnist_conv_best.h5\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0707 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.97317\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0702 - accuracy: 0.9811 - val_loss: 0.0921 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00101: val_accuracy improved from 0.97317 to 0.97367, saving model to mnist_conv_best.h5\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0696 - accuracy: 0.9814 - val_loss: 0.0927 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.97367\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0690 - accuracy: 0.9818 - val_loss: 0.0927 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.97367\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0684 - accuracy: 0.9819 - val_loss: 0.0910 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.97367 to 0.97392, saving model to mnist_conv_best.h5\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0679 - accuracy: 0.9818 - val_loss: 0.0917 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.97392\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0674 - accuracy: 0.9819 - val_loss: 0.0906 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97392\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0667 - accuracy: 0.9821 - val_loss: 0.0901 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00107: val_accuracy improved from 0.97392 to 0.97458, saving model to mnist_conv_best.h5\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0663 - accuracy: 0.9821 - val_loss: 0.0897 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.97458\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0657 - accuracy: 0.9826 - val_loss: 0.0901 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.97458\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0653 - accuracy: 0.9828 - val_loss: 0.0892 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.97458\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0648 - accuracy: 0.9828 - val_loss: 0.0882 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.97458\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0643 - accuracy: 0.9830 - val_loss: 0.0921 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.97458\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0638 - accuracy: 0.9826 - val_loss: 0.0895 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.97458\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0634 - accuracy: 0.9831 - val_loss: 0.0863 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.97458 to 0.97542, saving model to mnist_conv_best.h5\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0628 - accuracy: 0.9835 - val_loss: 0.0882 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.97542\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0623 - accuracy: 0.9834 - val_loss: 0.0860 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97542\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0616 - accuracy: 0.9837 - val_loss: 0.0872 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.97542\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0616 - accuracy: 0.9836 - val_loss: 0.0867 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.97542\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0612 - accuracy: 0.9837 - val_loss: 0.0853 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97542\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0606 - accuracy: 0.9837 - val_loss: 0.0852 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97542\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0602 - accuracy: 0.9843 - val_loss: 0.0843 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97542\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0598 - accuracy: 0.9837 - val_loss: 0.0842 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.97542\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0594 - accuracy: 0.9843 - val_loss: 0.0839 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00123: val_accuracy improved from 0.97542 to 0.97550, saving model to mnist_conv_best.h5\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0590 - accuracy: 0.9841 - val_loss: 0.0836 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.97550 to 0.97558, saving model to mnist_conv_best.h5\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0585 - accuracy: 0.9844 - val_loss: 0.0832 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00125: val_accuracy improved from 0.97558 to 0.97608, saving model to mnist_conv_best.h5\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0582 - accuracy: 0.9847 - val_loss: 0.0830 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97608\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0578 - accuracy: 0.9844 - val_loss: 0.0832 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.97608\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0574 - accuracy: 0.9848 - val_loss: 0.0823 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00128: val_accuracy improved from 0.97608 to 0.97642, saving model to mnist_conv_best.h5\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0570 - accuracy: 0.9850 - val_loss: 0.0842 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.97642\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0567 - accuracy: 0.9848 - val_loss: 0.0832 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97642\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0563 - accuracy: 0.9851 - val_loss: 0.0816 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97642\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0559 - accuracy: 0.9852 - val_loss: 0.0819 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97642\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0555 - accuracy: 0.9855 - val_loss: 0.0828 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97642\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0553 - accuracy: 0.9854 - val_loss: 0.0807 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00134: val_accuracy improved from 0.97642 to 0.97683, saving model to mnist_conv_best.h5\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0548 - accuracy: 0.9854 - val_loss: 0.0806 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97683\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0546 - accuracy: 0.9853 - val_loss: 0.0804 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.97683\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0543 - accuracy: 0.9855 - val_loss: 0.0805 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.97683\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0538 - accuracy: 0.9858 - val_loss: 0.0803 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.97683\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0535 - accuracy: 0.9857 - val_loss: 0.0800 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97683\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0531 - accuracy: 0.9860 - val_loss: 0.0799 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97683\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0530 - accuracy: 0.9859 - val_loss: 0.0796 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.97683\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0526 - accuracy: 0.9858 - val_loss: 0.0794 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.97683\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0520 - accuracy: 0.9865 - val_loss: 0.0790 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.97683 to 0.97692, saving model to mnist_conv_best.h5\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0519 - accuracy: 0.9864 - val_loss: 0.0787 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.97692\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0516 - accuracy: 0.9864 - val_loss: 0.0782 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.97692\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0513 - accuracy: 0.9861 - val_loss: 0.0780 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97692\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0511 - accuracy: 0.9865 - val_loss: 0.0776 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97692\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0507 - accuracy: 0.9865 - val_loss: 0.0774 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00148: val_accuracy improved from 0.97692 to 0.97733, saving model to mnist_conv_best.h5\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0505 - accuracy: 0.9866 - val_loss: 0.0774 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.97733\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0500 - accuracy: 0.9868 - val_loss: 0.0781 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.97733\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0498 - accuracy: 0.9868 - val_loss: 0.0767 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00151: val_accuracy improved from 0.97733 to 0.97758, saving model to mnist_conv_best.h5\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0496 - accuracy: 0.9871 - val_loss: 0.0765 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00152: val_accuracy improved from 0.97758 to 0.97800, saving model to mnist_conv_best.h5\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0492 - accuracy: 0.9869 - val_loss: 0.0770 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.97800\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0490 - accuracy: 0.9870 - val_loss: 0.0767 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97800\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0487 - accuracy: 0.9870 - val_loss: 0.0766 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.97800\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0485 - accuracy: 0.9874 - val_loss: 0.0762 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.97800\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0481 - accuracy: 0.9875 - val_loss: 0.0763 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97800\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0480 - accuracy: 0.9873 - val_loss: 0.0766 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.97800\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0477 - accuracy: 0.9876 - val_loss: 0.0776 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.97800\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0475 - accuracy: 0.9877 - val_loss: 0.0752 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.97800\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0471 - accuracy: 0.9876 - val_loss: 0.0758 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.97800\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0469 - accuracy: 0.9876 - val_loss: 0.0751 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.97800\n",
            "Epoch 00162: early stopping\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0547 - accuracy: 0.9852\n",
            "Accuracy for the training set: 0.9852166771888733\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0630 - accuracy: 0.9812\n",
            "Accuracy for the testing set: 0.9811999797821045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        416       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,866\n",
            "Trainable params: 125,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 19s 98ms/step - loss: 1.0395 - accuracy: 0.7587 - val_loss: 0.4747 - val_accuracy: 0.8721\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87208, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.4159 - accuracy: 0.8843 - val_loss: 0.3839 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87208 to 0.89175, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.3641 - accuracy: 0.8958 - val_loss: 0.3579 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89175 to 0.89825, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.3419 - accuracy: 0.9014 - val_loss: 0.3461 - val_accuracy: 0.9017\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89825 to 0.90167, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.3274 - accuracy: 0.9061 - val_loss: 0.3290 - val_accuracy: 0.9073\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90167 to 0.90733, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.3169 - accuracy: 0.9086 - val_loss: 0.3254 - val_accuracy: 0.9082\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90733 to 0.90817, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.3085 - accuracy: 0.9105 - val_loss: 0.3160 - val_accuracy: 0.9117\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90817 to 0.91167, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.3020 - accuracy: 0.9120 - val_loss: 0.3060 - val_accuracy: 0.9127\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91167 to 0.91267, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.2953 - accuracy: 0.9144 - val_loss: 0.3071 - val_accuracy: 0.9137\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91267 to 0.91367, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.2893 - accuracy: 0.9174 - val_loss: 0.3106 - val_accuracy: 0.9082\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91367\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2839 - accuracy: 0.9176 - val_loss: 0.2999 - val_accuracy: 0.9143\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91367 to 0.91425, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.2793 - accuracy: 0.9192 - val_loss: 0.2880 - val_accuracy: 0.9203\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91425 to 0.92033, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.2737 - accuracy: 0.9220 - val_loss: 0.2874 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.92033\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.2682 - accuracy: 0.9233 - val_loss: 0.2768 - val_accuracy: 0.9243\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.92033 to 0.92433, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2631 - accuracy: 0.9250 - val_loss: 0.2751 - val_accuracy: 0.9228\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.92433\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.2576 - accuracy: 0.9269 - val_loss: 0.2678 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.92433 to 0.92567, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2522 - accuracy: 0.9284 - val_loss: 0.2701 - val_accuracy: 0.9235\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.92567\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.2468 - accuracy: 0.9302 - val_loss: 0.2588 - val_accuracy: 0.9280\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92567 to 0.92800, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2410 - accuracy: 0.9324 - val_loss: 0.2539 - val_accuracy: 0.9299\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.92800 to 0.92992, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2345 - accuracy: 0.9336 - val_loss: 0.2572 - val_accuracy: 0.9278\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.92992\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2294 - accuracy: 0.9354 - val_loss: 0.2434 - val_accuracy: 0.9319\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92992 to 0.93192, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2230 - accuracy: 0.9369 - val_loss: 0.2351 - val_accuracy: 0.9342\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.93192 to 0.93417, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2169 - accuracy: 0.9385 - val_loss: 0.2308 - val_accuracy: 0.9374\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.93417 to 0.93742, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2112 - accuracy: 0.9405 - val_loss: 0.2296 - val_accuracy: 0.9356\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.93742\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.2045 - accuracy: 0.9424 - val_loss: 0.2197 - val_accuracy: 0.9385\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.93742 to 0.93850, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1990 - accuracy: 0.9444 - val_loss: 0.2172 - val_accuracy: 0.9402\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.93850 to 0.94017, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1933 - accuracy: 0.9459 - val_loss: 0.2068 - val_accuracy: 0.9430\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.94017 to 0.94300, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1876 - accuracy: 0.9475 - val_loss: 0.2025 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.94300 to 0.94350, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.1816 - accuracy: 0.9495 - val_loss: 0.1944 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.94350 to 0.94625, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1765 - accuracy: 0.9506 - val_loss: 0.1920 - val_accuracy: 0.9465\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.94625 to 0.94650, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1713 - accuracy: 0.9522 - val_loss: 0.1835 - val_accuracy: 0.9491\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.94650 to 0.94908, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.1663 - accuracy: 0.9541 - val_loss: 0.1795 - val_accuracy: 0.9500\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.94908 to 0.95000, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1615 - accuracy: 0.9551 - val_loss: 0.1781 - val_accuracy: 0.9499\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.95000\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1567 - accuracy: 0.9564 - val_loss: 0.1713 - val_accuracy: 0.9517\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.95000 to 0.95167, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1521 - accuracy: 0.9583 - val_loss: 0.1674 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.95167 to 0.95325, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1478 - accuracy: 0.9586 - val_loss: 0.1616 - val_accuracy: 0.9548\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.95325 to 0.95483, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1441 - accuracy: 0.9603 - val_loss: 0.1580 - val_accuracy: 0.9559\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.95483 to 0.95592, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1401 - accuracy: 0.9612 - val_loss: 0.1543 - val_accuracy: 0.9568\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.95592 to 0.95683, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1362 - accuracy: 0.9628 - val_loss: 0.1526 - val_accuracy: 0.9566\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.95683\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1330 - accuracy: 0.9631 - val_loss: 0.1479 - val_accuracy: 0.9586\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.95683 to 0.95858, saving model to mnist_conv_best.h5\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1298 - accuracy: 0.9641 - val_loss: 0.1431 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.95858 to 0.96000, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1265 - accuracy: 0.9654 - val_loss: 0.1433 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.96000 to 0.96050, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1235 - accuracy: 0.9659 - val_loss: 0.1371 - val_accuracy: 0.9614\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.96050 to 0.96142, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1204 - accuracy: 0.9672 - val_loss: 0.1353 - val_accuracy: 0.9622\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.96142 to 0.96217, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1177 - accuracy: 0.9674 - val_loss: 0.1326 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.96217 to 0.96300, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 19s 98ms/step - loss: 0.1149 - accuracy: 0.9687 - val_loss: 0.1318 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.96300 to 0.96367, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1128 - accuracy: 0.9688 - val_loss: 0.1275 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.96367 to 0.96475, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1103 - accuracy: 0.9700 - val_loss: 0.1261 - val_accuracy: 0.9649\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.96475 to 0.96492, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1080 - accuracy: 0.9710 - val_loss: 0.1241 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.96492 to 0.96592, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1057 - accuracy: 0.9712 - val_loss: 0.1221 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.96592\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1039 - accuracy: 0.9714 - val_loss: 0.1189 - val_accuracy: 0.9662\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.96592 to 0.96617, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1020 - accuracy: 0.9726 - val_loss: 0.1210 - val_accuracy: 0.9662\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.96617\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.1001 - accuracy: 0.9730 - val_loss: 0.1161 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.96617 to 0.96775, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0984 - accuracy: 0.9738 - val_loss: 0.1155 - val_accuracy: 0.9675\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.96775\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0965 - accuracy: 0.9740 - val_loss: 0.1121 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.96775 to 0.96858, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0949 - accuracy: 0.9744 - val_loss: 0.1112 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.96858\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0933 - accuracy: 0.9747 - val_loss: 0.1122 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.96858\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0919 - accuracy: 0.9754 - val_loss: 0.1083 - val_accuracy: 0.9700\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.96858 to 0.97000, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0905 - accuracy: 0.9756 - val_loss: 0.1070 - val_accuracy: 0.9695\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.97000\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0888 - accuracy: 0.9762 - val_loss: 0.1055 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.97000 to 0.97025, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0877 - accuracy: 0.9761 - val_loss: 0.1043 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.97025 to 0.97092, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0863 - accuracy: 0.9767 - val_loss: 0.1027 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.97092 to 0.97175, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0850 - accuracy: 0.9772 - val_loss: 0.1024 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.97175\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0841 - accuracy: 0.9771 - val_loss: 0.1008 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.97175\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0828 - accuracy: 0.9776 - val_loss: 0.1005 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.97175\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0816 - accuracy: 0.9780 - val_loss: 0.1001 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.97175\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0806 - accuracy: 0.9781 - val_loss: 0.0987 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.97175 to 0.97208, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0795 - accuracy: 0.9784 - val_loss: 0.0973 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.97208 to 0.97292, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0784 - accuracy: 0.9790 - val_loss: 0.0968 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.97292\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0776 - accuracy: 0.9788 - val_loss: 0.0951 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.97292\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0766 - accuracy: 0.9792 - val_loss: 0.0958 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.97292\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0758 - accuracy: 0.9795 - val_loss: 0.0953 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.97292\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0746 - accuracy: 0.9798 - val_loss: 0.0944 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.97292\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0738 - accuracy: 0.9801 - val_loss: 0.0924 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.97292 to 0.97442, saving model to mnist_conv_best.h5\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0730 - accuracy: 0.9800 - val_loss: 0.0919 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.97442\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0722 - accuracy: 0.9802 - val_loss: 0.0910 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.97442\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0713 - accuracy: 0.9805 - val_loss: 0.0895 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.97442 to 0.97475, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.0917 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.97475\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0699 - accuracy: 0.9809 - val_loss: 0.0890 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.97475 to 0.97500, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0692 - accuracy: 0.9816 - val_loss: 0.0879 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.97500 to 0.97525, saving model to mnist_conv_best.h5\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0685 - accuracy: 0.9816 - val_loss: 0.0868 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.97525\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0678 - accuracy: 0.9822 - val_loss: 0.0862 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.97525 to 0.97550, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0671 - accuracy: 0.9819 - val_loss: 0.0867 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.97550\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0665 - accuracy: 0.9824 - val_loss: 0.0850 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.97550 to 0.97558, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0864 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.97558\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0652 - accuracy: 0.9827 - val_loss: 0.0844 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.97558\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0646 - accuracy: 0.9828 - val_loss: 0.0840 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.97558 to 0.97567, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0639 - accuracy: 0.9829 - val_loss: 0.0843 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.97567\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0634 - accuracy: 0.9831 - val_loss: 0.0823 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.97567 to 0.97650, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0627 - accuracy: 0.9834 - val_loss: 0.0827 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.97650 to 0.97675, saving model to mnist_conv_best.h5\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0622 - accuracy: 0.9836 - val_loss: 0.0818 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.97675 to 0.97692, saving model to mnist_conv_best.h5\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0616 - accuracy: 0.9836 - val_loss: 0.0815 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.97692\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0611 - accuracy: 0.9838 - val_loss: 0.0813 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.97692\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0604 - accuracy: 0.9837 - val_loss: 0.0818 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.97692\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0601 - accuracy: 0.9841 - val_loss: 0.0801 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.97692\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0596 - accuracy: 0.9842 - val_loss: 0.0804 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.97692\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0590 - accuracy: 0.9841 - val_loss: 0.0802 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.97692\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0585 - accuracy: 0.9843 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.97692 to 0.97783, saving model to mnist_conv_best.h5\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0581 - accuracy: 0.9847 - val_loss: 0.0786 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00099: val_accuracy improved from 0.97783 to 0.97792, saving model to mnist_conv_best.h5\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0577 - accuracy: 0.9847 - val_loss: 0.0805 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.97792\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0572 - accuracy: 0.9847 - val_loss: 0.0784 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.97792\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0568 - accuracy: 0.9849 - val_loss: 0.0793 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.97792\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0562 - accuracy: 0.9847 - val_loss: 0.0777 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.97792\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.0558 - accuracy: 0.9852 - val_loss: 0.0771 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.97792\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0553 - accuracy: 0.9854 - val_loss: 0.0780 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.97792\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0550 - accuracy: 0.9855 - val_loss: 0.0768 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97792\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0546 - accuracy: 0.9858 - val_loss: 0.0772 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00107: val_accuracy improved from 0.97792 to 0.97817, saving model to mnist_conv_best.h5\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0542 - accuracy: 0.9856 - val_loss: 0.0759 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.97817 to 0.97850, saving model to mnist_conv_best.h5\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0537 - accuracy: 0.9858 - val_loss: 0.0758 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.97850\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0534 - accuracy: 0.9856 - val_loss: 0.0753 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.97850\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0529 - accuracy: 0.9858 - val_loss: 0.0752 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.97850\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0526 - accuracy: 0.9862 - val_loss: 0.0751 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00112: val_accuracy improved from 0.97850 to 0.97858, saving model to mnist_conv_best.h5\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0523 - accuracy: 0.9860 - val_loss: 0.0751 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.97858\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0519 - accuracy: 0.9863 - val_loss: 0.0746 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.97858 to 0.97917, saving model to mnist_conv_best.h5\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0516 - accuracy: 0.9860 - val_loss: 0.0740 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.97917\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0512 - accuracy: 0.9865 - val_loss: 0.0749 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97917\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0508 - accuracy: 0.9870 - val_loss: 0.0745 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.97917 to 0.97942, saving model to mnist_conv_best.h5\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0504 - accuracy: 0.9868 - val_loss: 0.0733 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.97942\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0502 - accuracy: 0.9867 - val_loss: 0.0732 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00119: val_accuracy improved from 0.97942 to 0.97950, saving model to mnist_conv_best.h5\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0498 - accuracy: 0.9869 - val_loss: 0.0727 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97950\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0495 - accuracy: 0.9867 - val_loss: 0.0726 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97950\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0491 - accuracy: 0.9871 - val_loss: 0.0737 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.97950\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0488 - accuracy: 0.9870 - val_loss: 0.0726 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.97950\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0486 - accuracy: 0.9871 - val_loss: 0.0720 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.97950\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0482 - accuracy: 0.9872 - val_loss: 0.0723 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97950\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0480 - accuracy: 0.9875 - val_loss: 0.0722 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97950\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0475 - accuracy: 0.9873 - val_loss: 0.0717 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.97950\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0473 - accuracy: 0.9875 - val_loss: 0.0724 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97950\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0471 - accuracy: 0.9874 - val_loss: 0.0711 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.97950 to 0.97967, saving model to mnist_conv_best.h5\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0466 - accuracy: 0.9879 - val_loss: 0.0718 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97967\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0464 - accuracy: 0.9878 - val_loss: 0.0719 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97967\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0462 - accuracy: 0.9878 - val_loss: 0.0711 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97967\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0458 - accuracy: 0.9879 - val_loss: 0.0709 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97967\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0457 - accuracy: 0.9881 - val_loss: 0.0700 - val_accuracy: 0.9801\n",
            "\n",
            "Epoch 00134: val_accuracy improved from 0.97967 to 0.98008, saving model to mnist_conv_best.h5\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0453 - accuracy: 0.9881 - val_loss: 0.0704 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.98008 to 0.98025, saving model to mnist_conv_best.h5\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0450 - accuracy: 0.9885 - val_loss: 0.0697 - val_accuracy: 0.9804\n",
            "\n",
            "Epoch 00136: val_accuracy improved from 0.98025 to 0.98042, saving model to mnist_conv_best.h5\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0447 - accuracy: 0.9880 - val_loss: 0.0708 - val_accuracy: 0.9799\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.98042\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0445 - accuracy: 0.9884 - val_loss: 0.0701 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.98042\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0442 - accuracy: 0.9884 - val_loss: 0.0697 - val_accuracy: 0.9796\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.98042\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0440 - accuracy: 0.9883 - val_loss: 0.0694 - val_accuracy: 0.9804\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.98042\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.0438 - accuracy: 0.9884 - val_loss: 0.0700 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.98042\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0436 - accuracy: 0.9886 - val_loss: 0.0695 - val_accuracy: 0.9801\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.98042\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0433 - accuracy: 0.9887 - val_loss: 0.0693 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.98042\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0430 - accuracy: 0.9886 - val_loss: 0.0705 - val_accuracy: 0.9802\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.98042\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0428 - accuracy: 0.9885 - val_loss: 0.0700 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.98042\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0426 - accuracy: 0.9889 - val_loss: 0.0685 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.98042\n",
            "Epoch 00146: early stopping\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0494 - accuracy: 0.9868\n",
            "Accuracy for the training set: 0.9867500066757202\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0558 - accuracy: 0.9823\n",
            "Accuracy for the testing set: 0.9822999835014343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        592       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 126,042\n",
            "Trainable params: 126,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 24s 124ms/step - loss: 1.0294 - accuracy: 0.7653 - val_loss: 0.4698 - val_accuracy: 0.8741\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87408, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.4163 - accuracy: 0.8841 - val_loss: 0.3858 - val_accuracy: 0.8926\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87408 to 0.89258, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.3683 - accuracy: 0.8957 - val_loss: 0.3652 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89258 to 0.89417, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.3467 - accuracy: 0.9005 - val_loss: 0.3454 - val_accuracy: 0.9025\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89417 to 0.90250, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.3316 - accuracy: 0.9050 - val_loss: 0.3324 - val_accuracy: 0.9068\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90250 to 0.90683, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.3204 - accuracy: 0.9078 - val_loss: 0.3206 - val_accuracy: 0.9090\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90683 to 0.90900, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.3101 - accuracy: 0.9107 - val_loss: 0.3136 - val_accuracy: 0.9125\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90900 to 0.91250, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.3020 - accuracy: 0.9130 - val_loss: 0.3083 - val_accuracy: 0.9150\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91250 to 0.91500, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2935 - accuracy: 0.9149 - val_loss: 0.3107 - val_accuracy: 0.9108\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91500\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2861 - accuracy: 0.9174 - val_loss: 0.2951 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91500 to 0.91717, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2784 - accuracy: 0.9202 - val_loss: 0.2947 - val_accuracy: 0.9177\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91717 to 0.91767, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2708 - accuracy: 0.9224 - val_loss: 0.2759 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91767 to 0.92358, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2632 - accuracy: 0.9250 - val_loss: 0.2729 - val_accuracy: 0.9243\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.92358 to 0.92433, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2547 - accuracy: 0.9276 - val_loss: 0.2612 - val_accuracy: 0.9284\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.92433 to 0.92842, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2463 - accuracy: 0.9299 - val_loss: 0.2546 - val_accuracy: 0.9298\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.92842 to 0.92975, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2375 - accuracy: 0.9334 - val_loss: 0.2458 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.92975 to 0.93100, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2301 - accuracy: 0.9350 - val_loss: 0.2399 - val_accuracy: 0.9344\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.93100 to 0.93442, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2215 - accuracy: 0.9379 - val_loss: 0.2344 - val_accuracy: 0.9367\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.93442 to 0.93675, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2137 - accuracy: 0.9401 - val_loss: 0.2247 - val_accuracy: 0.9396\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.93675 to 0.93958, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.2056 - accuracy: 0.9424 - val_loss: 0.2203 - val_accuracy: 0.9398\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.93958 to 0.93975, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1982 - accuracy: 0.9447 - val_loss: 0.2142 - val_accuracy: 0.9418\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.93975 to 0.94183, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.1912 - accuracy: 0.9472 - val_loss: 0.2074 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.94183 to 0.94475, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1838 - accuracy: 0.9491 - val_loss: 0.2011 - val_accuracy: 0.9449\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.94475 to 0.94492, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1776 - accuracy: 0.9504 - val_loss: 0.1932 - val_accuracy: 0.9468\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.94492 to 0.94683, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1712 - accuracy: 0.9526 - val_loss: 0.1814 - val_accuracy: 0.9516\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.94683 to 0.95158, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1650 - accuracy: 0.9544 - val_loss: 0.1761 - val_accuracy: 0.9524\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.95158 to 0.95242, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1598 - accuracy: 0.9557 - val_loss: 0.1733 - val_accuracy: 0.9535\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.95242 to 0.95350, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1551 - accuracy: 0.9569 - val_loss: 0.1683 - val_accuracy: 0.9550\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.95350 to 0.95500, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1498 - accuracy: 0.9587 - val_loss: 0.1639 - val_accuracy: 0.9562\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.95500 to 0.95617, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1455 - accuracy: 0.9595 - val_loss: 0.1587 - val_accuracy: 0.9557\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.95617\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1412 - accuracy: 0.9609 - val_loss: 0.1551 - val_accuracy: 0.9585\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.95617 to 0.95850, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.1374 - accuracy: 0.9619 - val_loss: 0.1512 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.95850 to 0.95900, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1336 - accuracy: 0.9629 - val_loss: 0.1477 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.95900 to 0.95950, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1300 - accuracy: 0.9643 - val_loss: 0.1444 - val_accuracy: 0.9607\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.95950 to 0.96075, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.1269 - accuracy: 0.9647 - val_loss: 0.1413 - val_accuracy: 0.9613\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.96075 to 0.96133, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1237 - accuracy: 0.9661 - val_loss: 0.1378 - val_accuracy: 0.9631\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.96133 to 0.96308, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1206 - accuracy: 0.9669 - val_loss: 0.1380 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.96308\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.1183 - accuracy: 0.9676 - val_loss: 0.1325 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.96308 to 0.96433, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1156 - accuracy: 0.9686 - val_loss: 0.1306 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.96433\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1131 - accuracy: 0.9693 - val_loss: 0.1298 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.96433\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1111 - accuracy: 0.9695 - val_loss: 0.1264 - val_accuracy: 0.9656\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.96433 to 0.96558, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1089 - accuracy: 0.9705 - val_loss: 0.1279 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.96558\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.1067 - accuracy: 0.9707 - val_loss: 0.1231 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.96558 to 0.96700, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1047 - accuracy: 0.9722 - val_loss: 0.1222 - val_accuracy: 0.9671\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.96700 to 0.96708, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1027 - accuracy: 0.9720 - val_loss: 0.1209 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.96708\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1013 - accuracy: 0.9726 - val_loss: 0.1204 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.96708\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0993 - accuracy: 0.9731 - val_loss: 0.1172 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.96708 to 0.96817, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0977 - accuracy: 0.9737 - val_loss: 0.1147 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.96817 to 0.96875, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0961 - accuracy: 0.9741 - val_loss: 0.1134 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.96875\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0950 - accuracy: 0.9742 - val_loss: 0.1120 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.96875 to 0.96908, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0936 - accuracy: 0.9749 - val_loss: 0.1127 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.96908\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0919 - accuracy: 0.9753 - val_loss: 0.1114 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.96908 to 0.97008, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0907 - accuracy: 0.9758 - val_loss: 0.1086 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.97008 to 0.97017, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0895 - accuracy: 0.9761 - val_loss: 0.1068 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.97017 to 0.97033, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0883 - accuracy: 0.9764 - val_loss: 0.1062 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.97033 to 0.97092, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0872 - accuracy: 0.9765 - val_loss: 0.1068 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.97092\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0860 - accuracy: 0.9768 - val_loss: 0.1041 - val_accuracy: 0.9713\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.97092 to 0.97133, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0849 - accuracy: 0.9769 - val_loss: 0.1042 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.97133\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0838 - accuracy: 0.9775 - val_loss: 0.1020 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.97133 to 0.97233, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0828 - accuracy: 0.9779 - val_loss: 0.1023 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.97233\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0821 - accuracy: 0.9779 - val_loss: 0.1008 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.97233\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0808 - accuracy: 0.9784 - val_loss: 0.0997 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.97233 to 0.97258, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0801 - accuracy: 0.9786 - val_loss: 0.0988 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.97258\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0793 - accuracy: 0.9786 - val_loss: 0.0983 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.97258 to 0.97333, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0785 - accuracy: 0.9790 - val_loss: 0.0983 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.97333\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0776 - accuracy: 0.9793 - val_loss: 0.0980 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.97333\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0766 - accuracy: 0.9790 - val_loss: 0.0981 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.97333\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0762 - accuracy: 0.9794 - val_loss: 0.0967 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.97333\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0753 - accuracy: 0.9800 - val_loss: 0.0944 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.97333 to 0.97400, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0746 - accuracy: 0.9803 - val_loss: 0.0967 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.97400\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0740 - accuracy: 0.9803 - val_loss: 0.0945 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.97400\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0732 - accuracy: 0.9803 - val_loss: 0.0931 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.97400 to 0.97500, saving model to mnist_conv_best.h5\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0725 - accuracy: 0.9804 - val_loss: 0.0922 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.97500\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0718 - accuracy: 0.9807 - val_loss: 0.0933 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.97500\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0713 - accuracy: 0.9813 - val_loss: 0.0921 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.97500\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.0705 - accuracy: 0.9809 - val_loss: 0.0909 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.97500 to 0.97575, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0700 - accuracy: 0.9811 - val_loss: 0.0899 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.97575\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0693 - accuracy: 0.9814 - val_loss: 0.0899 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.97575\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0688 - accuracy: 0.9816 - val_loss: 0.0904 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.97575\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0682 - accuracy: 0.9820 - val_loss: 0.0893 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.97575\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0676 - accuracy: 0.9818 - val_loss: 0.0898 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.97575\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0672 - accuracy: 0.9820 - val_loss: 0.0900 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.97575\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 0.0886 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.97575\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0660 - accuracy: 0.9825 - val_loss: 0.0882 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.97575\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0657 - accuracy: 0.9828 - val_loss: 0.0879 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.97575\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0651 - accuracy: 0.9829 - val_loss: 0.0876 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.97575 to 0.97625, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.0865 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.97625\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0641 - accuracy: 0.9832 - val_loss: 0.0859 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.97625\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0636 - accuracy: 0.9833 - val_loss: 0.0851 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.97625 to 0.97658, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0631 - accuracy: 0.9835 - val_loss: 0.0856 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.97658\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.0859 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.97658\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0623 - accuracy: 0.9833 - val_loss: 0.0859 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.97658\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0619 - accuracy: 0.9835 - val_loss: 0.0843 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.97658\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0613 - accuracy: 0.9837 - val_loss: 0.0848 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.97658\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0609 - accuracy: 0.9837 - val_loss: 0.0837 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.97658\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0605 - accuracy: 0.9840 - val_loss: 0.0835 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00096: val_accuracy improved from 0.97658 to 0.97708, saving model to mnist_conv_best.h5\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0601 - accuracy: 0.9837 - val_loss: 0.0829 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.97708\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0596 - accuracy: 0.9843 - val_loss: 0.0833 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.97708\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0595 - accuracy: 0.9841 - val_loss: 0.0849 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.97708\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: 0.0830 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.97708\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0586 - accuracy: 0.9842 - val_loss: 0.0820 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.97708\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0582 - accuracy: 0.9847 - val_loss: 0.0821 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.97708\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0578 - accuracy: 0.9846 - val_loss: 0.0814 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.97708\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0576 - accuracy: 0.9848 - val_loss: 0.0815 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.97708\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0570 - accuracy: 0.9849 - val_loss: 0.0818 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.97708\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0568 - accuracy: 0.9846 - val_loss: 0.0808 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00106: val_accuracy improved from 0.97708 to 0.97717, saving model to mnist_conv_best.h5\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0565 - accuracy: 0.9850 - val_loss: 0.0811 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.97717\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0560 - accuracy: 0.9853 - val_loss: 0.0801 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.97717\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0555 - accuracy: 0.9850 - val_loss: 0.0797 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.97717\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0554 - accuracy: 0.9850 - val_loss: 0.0799 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.97717 to 0.97750, saving model to mnist_conv_best.h5\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0551 - accuracy: 0.9851 - val_loss: 0.0807 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.97750\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0546 - accuracy: 0.9854 - val_loss: 0.0794 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.97750\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 23s 125ms/step - loss: 0.0545 - accuracy: 0.9854 - val_loss: 0.0791 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.97750 to 0.97783, saving model to mnist_conv_best.h5\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0542 - accuracy: 0.9856 - val_loss: 0.0787 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.97783\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0537 - accuracy: 0.9858 - val_loss: 0.0796 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.97783\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0535 - accuracy: 0.9858 - val_loss: 0.0784 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97783\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0533 - accuracy: 0.9858 - val_loss: 0.0788 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.97783\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0529 - accuracy: 0.9856 - val_loss: 0.0795 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.97783\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0528 - accuracy: 0.9858 - val_loss: 0.0796 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97783\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0524 - accuracy: 0.9860 - val_loss: 0.0781 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97783\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0519 - accuracy: 0.9859 - val_loss: 0.0775 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97783\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0518 - accuracy: 0.9861 - val_loss: 0.0782 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.97783\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.0514 - accuracy: 0.9861 - val_loss: 0.0769 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00123: val_accuracy improved from 0.97783 to 0.97817, saving model to mnist_conv_best.h5\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0511 - accuracy: 0.9864 - val_loss: 0.0768 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.97817 to 0.97842, saving model to mnist_conv_best.h5\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0508 - accuracy: 0.9861 - val_loss: 0.0782 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97842\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0505 - accuracy: 0.9861 - val_loss: 0.0770 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97842\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0503 - accuracy: 0.9864 - val_loss: 0.0801 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.97842\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0500 - accuracy: 0.9861 - val_loss: 0.0774 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97842\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0498 - accuracy: 0.9862 - val_loss: 0.0770 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.97842\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0497 - accuracy: 0.9871 - val_loss: 0.0772 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97842\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0492 - accuracy: 0.9868 - val_loss: 0.0755 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97842\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0490 - accuracy: 0.9868 - val_loss: 0.0763 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97842\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0489 - accuracy: 0.9868 - val_loss: 0.0754 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97842\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.0485 - accuracy: 0.9868 - val_loss: 0.0764 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97842\n",
            "Epoch 00134: early stopping\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0554 - accuracy: 0.9850\n",
            "Accuracy for the training set: 0.9849833250045776\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0600 - accuracy: 0.9816\n",
            "Accuracy for the testing set: 0.9815999865531921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAGrCAYAAABXOYc2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3yV5fnH8c8dMkiYYY+wlyBVVETFLQ6crVpH3Vq1rbW11bbO2qqts61tra2jtdbWhdpatS5EnOBPQVAQZMgKSyBA2Jn3748nYYkKGHLCyef9ej2vs55zznWitSffXPd1hxgjkiRJkiRJSm8ZqS5AkiRJkiRJO54hkCRJkiRJUj1gCCRJkiRJklQPGAJJkiRJkiTVA4ZAkiRJkiRJ9YAhkCRJkiRJUj1gCCRJkiRJklQPGAJJ2m4hhFkhhMNTXYckSdLOKoTwWghhWQghJ9W1SEp/hkCSJEmSlAIhhK7AgUAETqjF982srfeSVLcYAkmqUSGEnBDC70MI86uO31f/ZSuE0CqE8FwIYXkIYWkI4c0QQkbVY1eGEOaFEFaGEKaEEIak9pNIkiTtcOcA7wAPAudW3xlC6BRC+HcIYXEIoSiE8KeNHrsohDC56jvTpBDCnlX3xxBCz43OezCE8Kuq64eEEOZWfd9aCPw9hJBf9b1scVUn0nMhhIKNnt8ihPD3qu9zy0IIT1fdPzGEcPxG52WFEJaEEPbYYT8lSTXGEEhSTbsW2BcYAOwODAKuq3rsCmAu0BpoC1wDxBBCH+BSYO8YYxPgKGBW7ZYtSZJU684BHq46jgohtA0hNACeA2YDXYGOwGMAIYRTgF9WPa8pSfdQ0Va+VzugBdAFuJjkd8G/V93uDKwF/rTR+f8E8oBdgTbAnVX3PwSctdF5xwALYozjtrIOSSlkG6CkmnYm8IMY4yKAEMINwL3Az4EyoD3QJcY4HXiz6pwKIAfoF0JYHGOclYrCJUmSaksI4QCSAGZYjHFJCOET4AySzqAOwE9jjOVVp79VdXkhcHuM8b2q29O34S0rgV/EGEuqbq8Fntqonl8DI6uutweOBlrGGJdVnfJ61eW/gJ+HEJrGGFcAZ5MERpJ2AnYCSappHUj+clVtdtV9AHeQfFl5OYQwI4RwFUBVIPQjkr9sLQohPBZC6IAkSVL6Ohd4Oca4pOr2I1X3dQJmbxQAbawT8Ml2vt/iGOO66hshhLwQwr0hhNkhhBXAG0Dzqk6kTsDSjQKg9WKM84G3gZNDCM1JwqKHt7MmSbXMEEhSTZtP8letap2r7iPGuDLGeEWMsTtJ+/Ll1bN/YoyPxBir/yIWgdtqt2xJkqTaEULIBU4FDg4hLKya0/NjkqX0nwKdP2d4cyHQ43Nedg3J8q1q7TZ7PG52+wqgD7BPjLEpcFB1eVXv06Iq5NmSf5AsCTsFGB1jnPc550mqYwyBJH1VWSGEhtUH8ChwXQihdQihFXA9SdswIYTjQgg9QwgBKAYqgMoQQp8QwmFVA6TXkbQnV6bm40iSJO1w3yD5HtSPZI7iAKAvyVL5bwALgFtDCI2qvmPtX/W8vwI/CSHsFRI9QwjVf3wbD5wRQmgQQhgKHPwlNTQh+c61PITQAvhF9QMxxgXAC8CfqwZIZ4UQDtrouU8DewKXkcwIkrSTMASS9FU9T/IFovpoCIwBPgQmAO8Dv6o6txfwCrAKGA38OcY4kmQe0K3AEmAhyfDBq2vvI0iSJNWqc4G/xxjnxBgXVh8kg5m/BRwP9ATmkGyqcRpAjPEJ4NckS8dWkoQxLape87Kq5y0nmdH49JfU8Hsgl+T71zvAi5s9fjbJPMePgUUkS/epqqN6nlA34N/b+NklpVCIcfOuQEmSJEmSPl8I4Xqgd4zxrC89WVKd4e5gkiRJkqStVrV87Nsk3UKSdiIuB5MkSZIkbZUQwkUkg6NfiDG+kep6JG0bl4NJkiRJkiTVA3YCSZIkSZIk1QMpmwnUqlWr2LVr11S9vSRJ2sHGjh27JMbYOtV1aFN+B5MkKb190XewlIVAXbt2ZcyYMal6e0mStIOFEGanugZ9lt/BJElKb1/0HczlYJIkSZIkSfWAIZAkSZIkSVI9YAgkSZIkSZJUDxgCSZIkSZIk1QOGQJIkSZIkSfWAIZAkSZIkSVI9YAgkSZIkSZJUDxgCSZIkSZIk1QOGQJIkSZIkSfWAIZAkSZIkSVI9YAgkSZIkSZJUDxgCSZIkSZIk1QOGQJIkSZIkSfWAIZAkSZIkSVI9kH4h0Lx5MHlyqquQJEmSJEnpbM0a+OST5HInkZnqAmrcddfBq6/C7NmprkSSJEmSJKVajLBsGSxdCgUF0LDhF5+7cCE0bgxNmmz5nIkT4d574Z//hOLi5L5mzaB9++S1GzRIjszMDdc3v73rrnDLLTX/Wb9E+oVAmZlQXp7qKiRJkiRJEkBpKSxalIQrq1dDXl5yVIcxFRVQWQlZWZCfnwQqDRpASUnyvE8/TY7q60uXQk5O8hq5ucl5RUWwZAksX568X1lZcixalDSJrFq1oZ4OHaBbN2jRInmdnJzkOdOmwdSpGzp78vOha1do3TrJGcrKktefMAGys+Gb34QhQ5L3mD8fFixIaqmo2HCUlyeXpaWb3m7Rotb/MUC6hkBlZamuQpIkSZKkuq+yMglnZs+GOXOgUSPo2TMJSXJyPnvuqlVJ98vSpUnwUX2sWpUEICUlsHJl8prVR1HRttfVqFESGG1JdWgT44b7GjaEli2T4CY7OwmUMjOhVy84/HDo0iV5bM4cmDkTZsyAwsINNWdkJOcefHDy+VevTn4ms2Yl9WdlJUeHDnDuucnRqtW2f64US88QyE4gSZIkSVI6ihEmTYLXXkvCl9zcpCMmO3tDQLN8+YbL5cth7dokvOjSJTlWr05m6U6eDNOnJyHI5kKANm2SrpXqrpovmn2TnZ2EMw0bJkup2rWD3r3hoIOS69VHo0ZJPdVHCEkAU935s3x5snRrxYoktGnbdtOjTZvkNWJMgqA1azZ0BelLpV8IlJVlCCRJkiRJSp2KiiTIWLJkw1FSksyM6dAhCTImToSRI5Nj1qwk8GjVKrksLt7QRVNSkixHatMmCVfGjEmWH0ESnlRWbvreWVnQvHmypKp58+Ro0SIJjN55J+ngyciA7t2hb184+uik66dLF+jcOQmIPvkkCYfmzUsaLaq7aho3hqZNN7x2hw7QsWMS7mzeNbSjhbBhKZe2WvqFQHYCSZIkSZK+zJIlSZiybNlnj5IS+NrXYJ99koAkhCQcmTEjWUq0cbizZMmGeTTVx7Jlmy5V+iK77QYDByYdMEuWJHNpmjVLgpUBA5IOm+pa586FI4+EQw9Njq5dk99/16xJam7SJOnECeHz32/lyiTU+aLhyPvuu00/Su08DIEkSZIkSTuviopkzsuUKclQ3wULklBkzZrkd8O994ahQ5POl7Iy+O9/4c9/TjpwPk+DBsnrQtKFk5WVdNJsLicn6d5p1SqZRzNgwKa3q6+3apWEOQsXJt01Cxcmc2cOPvirz5XJykpCo631eTteqV4wBJIkSZIkpU6MsHhxEuA0bAidOiXBS0YGrFuXhC/z5iXH3Lkbrlcf8+dvujlQZmYyMyYvL1kq9eCDyf29eiUzcxYsSJY+3XhjMrMmPz9Z2pSfv+F6jMlyrf/7P3j33eR2r14bBia3aZOEPI0afXHXzeb696/RH520rb40BAohPAAcByyKMX7m39gQQgD+ABwDrAHOizG+X9OFbrXMzOR/oJWVyX80JEmSJEk7TvXuUm3bJh00W7J6NXz8cXLMnbth3k1hYTKceOnSTc/Pzk7mz2x+PyTBS8eOyXHggcllz57Qp08S6rRpsyGYiTGZbfPii/DSS0l9F12UzMH5vFqr7bFHcnz3u9v+M5HqqK3pBHoQ+BPw0Oc8fjTQq+rYB/hL1WVqZFZ9pPLy5D8ckiRJkqSaEWMym2b27KRDZuRIeP31ZCZOXh7sumsy4yYnZ0PQM3duslxrY9W7R3XsCKecArvskoQ4paVJMFRYmMyuqR48XH0UFCSDibe2+yaEpIOnVy/4wQ9q/uch7WS+NASKMb4RQuj6Bad8HXgoxhiBd0IIzUMI7WOMC2qoxm1jCCRJkiRJW1ZZmXTjTJ2aDDieMSPptglhw1bd1ddDSIYNVw9LLipKwpl16za8XpcucPzxySycmTNhwoRk5k5l5YYtwQ86KAl4+vZNwp4uXZIQSFKtq4mZQB2Bwo1uz6267zMhUAjhYuBigM6dO9fAW29BdQi08ZpQSZIkSaqPKiuTwOett+CVV+DVV5P5O9WaNk3m78S44ais3HA9O3vDrJzOneGEE5IQp0uXZPesbt1S99kkbbNaHQwdY7wPuA9g4MCBW7lf3jbauBNIkiRJktJJRUXSyfP++zBuXNLJU1iYLLlavToZqtylS7KMauZMGDs2WVYF0L59skvWYYclA4q7d0/CnW0ZbCxpp1YTIdA8oNNGtwuq7kuNrKzk0hBIkiRJ0s6ivDzZjWrUKBg/PtnBqnqmTknJhvNWrtywHCs3F3r0SObk7LVXMjC5sDCZ1/PBB0kgdPbZyRbp++yTLMUy8FE9UVFZwZj5Y5i8ZDJzV8ylsLiQ8spyvjPwOwzqOKhG36u8spxZy2dRWFzIPgX7kJeVV6OvX5NqIgR6Brg0hPAYyUDo4pTNAwI7gSRJkiTVLTHChx/Ce+8lQc9HHyUdPCEkf8TOzEy6dlavTs5v1SoJcNq1Szp2cnM3vFZeHuy+exL69Onz5TtcSTVg6dqlfLL0E3q06EGL3BZbPCfGyPiF4/nHB//g4yUf079Nfwa0G8BubXejaU7T9edlhAzysvLIzcwlq0EWc4rnMGXJFKYWTSU/N5/Tdj2N3KzcLb7HF1lZspK5K+YyafEknpv2HP+b+j8Wr9mw9LFNozasK1/HA+Mf4MgeR3LdgdeRn5vPqMJRjJ47moWrFrJ/p/0Z0m0Ie3fcm8yMLcclZRVlfPDpB+ufN27BOD5Z9gnllUkG0TqvNVfsdwWX7H0JTXKarH9eeWU5C1ctpLC4kMIVhTTMbMgJfU7Y5s/5VYVknvMXnBDCo8AhQCvgU+AXQBZAjPGeqi3i/wQMJdki/vwY45gve+OBAwfGMWO+9LRt9/e/wwUXwKxZSRukJElKiRDC2BjjwFTXoU3tsO9gUn1XUZEEOYsXJzN1Kipg+fJka/Lnnks6dCAJcfr1S7Y0DyH543VZWdLNM3hwcnTubMdOmlhbtpaxC8YyunA0y9ct56zdzqJv6741+h4xRiYumshrs16jd8ve7FOwD80bNgdg+brlvDP3HcYtGMei1YsoWltE0doiKioryMvKIy8rj+wG2awrX8easjWsLV9LRWXF+tdeXbaaaUXTKFpbBEB2g2xO6HMC5+1+Hod1O4w5xXOYWjSVCYsm8PhHj/Phpx+S3SCbvq36MqVoCuvK122x5i/SOq81l+x9Cd8d+F2K1xUzfuF4xi8cT3llOb1b9qZPqz60a9yO8QvHrw9ipiyZQnFJ8frXaN6wOUf3PJrjex/PoI6D6Ni0Iw0zG7KyZCV/GfMXfjPqN5sERK3yWtGucTsmLpoIQJPsJuzSahc6NetEQZMCcjJzmL50OlOKpjB96XRKK0oBKGhawMAOA9ml5S70btmb/Nx87hlzDy998hItcltwaNdDmb9yPoUrClmwcgEVccPPdu8Oe/PuRe9u889na3zRd7AvDYF2lB32BeSf/4RzzoHp05PWSEmSlBKGQHWTIZC0jWJMgp1p05IBy9OmbQh6KiuTpVlTp8KkSZvumlWtUSM44ohkB61DDoGuXZMduLTDVVRW8MbsNyirLCM3M5e8rDya5DShZW5L8nPziTEybuE4RswYwauzXmXeig1TTTIzMume350+LfvQu2Vv9my/J19r+zUyQvLPLsbIm3Pe5NEJj5KblcuQbkM4qMtBNM5uzMRFE3lu6nP8b9r/eHfeu5RVJpsWNQgNqIgVHNL1EL438HsM6jiIlrktaZzdmLBZ6Pfpqk/Xhx/zV85ff38IgWY5zWiZ15KWuS2ZtnQawz4axuQlkzecQ6Bf635EIpMWT1p/f5PsJrTMa0mL3BZkZmQmoU/ZWkoqSsjNzCU3K5fczNxNOmByMnPo1aIXvVv2pmvzrrw5+03+NeFfLFmz5DM/77077M35A87ntP6n0SK3BeWV5UlA9OkE1pavXX9eeWU5a8vWsrZ8LSXlJRQ0LaBPq+TnPHHRRH47+rc8N/W5TV47KyOLjJBBSUXJJvfnZuYyqOMg+rfpT6emnejUrBPd87uzV/u9yGqQ9bn/bqwpW8OjEx4lq0EWgzsNpkd+D0IILFmzhJEzR/LarNeYvmz6+q6dkvISerTosf7fh4EdBrJfwX50atZpi6//7rx3ueWtW5i0eBIFTQsoaFqQ1FdVY/VldVhX0+pXCPToo3DGGcmwtD59av71JUnSVjEEqpsMgaQvUFaWDFt+441k8HJ16LNixYZzMjOT5VqZmUmYk5WV/PG5f3/YdVfo2DFZopWRATk5ybKthg1T95lq2brydTw64VHWlq9lcKfB9G/Tf4vLalaWrGT4jOFMLZrK4E6D2bdgX7IbZG/z+5VXljN+4Xg6NulI+ybtgSSg+e+U/3Ldq9fx0eKPtvi8jJCxvgMGoH+b/vRu2ZtAEsaUVJTwydJPmL50+voQp3Veaw7tdijdmnfjiUlPMGPZDBplNaK8spySihIyMzJpldeKhasWAjCww0CGdBuy/vMFAg+Me4B7xt7DrOWz1teS3SCbJtlN1gdBZRVlm3S1NMtptv6xyljJypKVRJLf4wOBg7ocxGm7nsbQnkOZuXwmowpHMapwFCEEBhcMZr9O+7F3h703WZr0VZRWlPLCtBcYt3Dc+qCsV8ten7tMbHt8vORjnpz0JAVNCxjQbgD9WvejQWhA4YpCpiyZwvyV89mt7W7s1na3Lwx7akKMkUhcHwDuDOpXCPTEE3Dqqcla2113rfnXlyRJW8UQqG4yBJKqlJUlvzN8+CFMmJAMY37nnQ1zebp2hd69oVevDZe9eiUjJ7J27C+ddcX0pdOZt2IegzsN/tJftNeUreHeMfdyx6g7WLBqw4jYRlmN2LP9nrRt3DbpwGmYz/sL3+e1Wa+tX1IDkJeVx4GdD+SiPS/ipL4nbdIZU1FZwSszXqGkooRWea1omduSBasWMOyjYTw1+SkWrV4EQNfmXRncaTDTl07n3Xnv0qdlH64/+Hq6Nu/KmrI1rClbw4qSFRStKWLJmiWsLlvNwA4DOazbYbRr3G6Ln6u8spyZy5JgZcTMEYyYOYIFKxdwWLfDOG/AeZy4y4lkhIz1j89cPpPDuh7Gsb2PpUOTDlt8zeoOpZnLZ1K0JlmetbJk5frHQwj0bNGTAe0GsHvb3cnPzf/M85etW0bRmiKaN2xO28Ztv/Cfjeqf+hUC/ec/cNJJyX/Ed9+95l9fkiRtFUOguskQSPXSunVJN09REbz1VjKn55VXNnT4NGyYzOnZbz84+GA48MBkKHM9Nm7BOIY8NIRl65bRLKcZQ3sO5YjuR1AZK1myZsn62TLVgcqUoiksXbuUQ7oews8P+jnd87szunA0owpH8cGnH7B4zWKK1hSxdO1Suud35/jex3N8n+PZtfWuvF34NiNmjOD56c8zY9kMDuh8AL878nfs0X4PHpnwCDe/eTNTiqZ8psa8rDyO630cJ/Q+gUWrFzFqbtIBk9Mgh+sOuo5zdj/nc4f7bq8YI6vLVtM4u3GNvq5Uk+pXCPTss3DCCTBmTNJ6KUmSUsIQqG4yBFJaKyuDsWOTXbjGjk2WdE2ZAqWlm57XqRMMHQqHHQZ77JEMaa4nu2y9MfsNbn3rVk7b9TTO2f2cz8yiAfhg4Qcc9tBhNM5uzK8P+zUjZ47kuWnPre+4gWQWS6u8Vutn03Ro0oGL97qYAzof8IXvH2Pc4ntC0nXzwLgH+PnIn7No9SLaNW7HwlUL2a3tblxzwDX0aNFjfeiUm5XLUT2OolF2o6/2A5HS0Bd9B6vZWLQuqN4ivqwstXVIkiRJ2rFWrUpm+IweDSNHJl0+q1Ylj7Vpk/xR+KijID8fmjVLjj33hL59d7rdt2KMPDDuAf437X8M6jiIw7odxl7t96JBxtaFVwtWLuCnw3/KwxMepmFmQ16Y/gJPTX6Ke4+7d/0sHYAPP/2QIQ8NoVFWI0aeO5Lu+d05a7ezqIyVTF86nbysPFrmttyuLbyBzw2AIBnGfPFeF3N6/9O59a1bGb9wPN/Z6zsc3+f4nWoei1SXpW8IVF6e2jokSZIk1aw1a2DEiGTL9bffhsmTkx26IAl2zjkn2YFr8GDo0KFOBT3F64pZtm4ZnZp22mJws2ztMj749APGLxzPgpULOLTboRzS9RAaZjZkWtE0Ln7uYl6b9RrtG7fnPx//B0i2wT6i+xEc1/s4jul1DK3yWgFJYLR83XImLZ7E+IXjGbdwHMM+GkZJRQnXHXgdVx5wJfePvZ9rXr2GXf+8KxfscQFFa4soLC7kvfnv0SS7yfoAqFpGyKB3y9618rNqmtOUm4fcXCvvJdU36RcCVQ9pMwSSJEmSdk4ffQSXXprsztW6ddLVA/Dmm8l8nyZNkrk93/wm7L13clSfU8fEGPnnh//khy/8kOKSYnIa5NCzRU86N+vMytKV6wcDb7zUqkFowO2jbqdRViMO6HwAr816jYaZDbnvuPv49p7fZsmaJbw681WGfzKc56c/zxOTniAjZNAjvwfFJcUsXbuU8soNvw+1zG3JUT2P4pYht9CzRU8Afrzfjzmm1zFc8MwF3PnOnbRv3J5OzTpxXO/juOGQG+jRoket/6wk7XjpFwLZCSRJkiTtnEpL4ZZb4Ne/hqZN4fjjk2HOixbB2rVw8cXJfQcdBNnbvp34jlRSXsJ9Y+9jTvEc9inYh8GdBpMRMvjOc9/hmSnPsH+n/Tl7t7OZvnQ6U5dOZe6KuTTNaUq/1v1omduS7vnd2aP9HuzedneaNWzGyJkjeXbqswyfMZxv7PIN7jzqzvXLtto0asPp/U/n9P6nUxkreX/B+zw75VkmLZlEfsP89Tto9WnVhwHtBtCxScctLsPq06oPb1/wNhWVFVu9rEzSzs0QSJIkSVLtizFZ0vXuu0nIs2hRMtvn44/hjDPg979PuoBSrDJW8umqT3lzzpuMmDGCV2e9SkVlBWd+7UzOHXAuPfJ78NTkp7jylSuZsWwGWRlZlI1O5pNmZWSRETL47ZG/5bJ9LtumoOXoXkdzdK+jv/S8jJDBwA4DGdhh++fwGwBJ9YchkCRJkqTaU1YGTz4Jv/tdsqMvJCMd2rSBgoJkt9/jjqvVkhasXMD1I69nzoo5rC1by5qyNeuXai1du5RIsqNyk+wmHNL1EEorSrn5rZv51Zu/onOzzswpnsOurXflxTNf5NBuhzJ+4XhGFY5ixrIZXLL3JezSapda/TyS9HkMgSRJkiTtGCtXwn//m2zXvmABLFyYbNm+cCH06gV/+Qucemqye1ctDHFetnYZTXKakJmx4degZ6c8ywXPXMCq0lXs3nZ3crNyadu4LT2ye9AyN9n+vHWj1gzqOIiBHQauf+68FfP414f/4pWZr3DtgddywR4XrH9sUMdBDOo4aId/HknaVoZAkiRJkmpOeXmye9fDDyeX69ZBo0bJbl3t2sHBByfLvY47DjJqbtvvVaWreGP2G7w+63UikU5NO9GpWScCgZGzRjJi5ggmLppIk+wmHNz1YIZ0G8KUJVO4Z+w9DGg3gEdOeoS+rftu9ft1bNqRKw+4kisPuLLGPoMk7WiGQJIkSZK+upUr4W9/gz/8AWbNSpZ3ffvb8K1vwX771WjgUy3GyDNTnuG3o3/L6LmjKa8sJ7tBMjC6tKJ0/XkNMxtyQOcDOG3X05i7Yi4jZo7guanPAXDFflfw68N+TU5mTo3XJ0l1jSGQJEmSpO1TXAwjRsALL8ATTyS3DzgA7rwz6fTJ3P5fN2JM5vBsaVcrgOlLp/PDF37IC9NfoHfL3vxkv58wpPsQ9u+0PzmZOSxZs4TC4kLWla9jrw570TCz4SbPn1OczP/p06rPdtcoSTub9A2ByspSW4ckSZKUjlatgmHD4KGH4K23oKIi2c792GPhRz+CQds3C+fN2W/ynee+w+I1i9cPZ87LyqNTs050atqJdo3brZ+5s658HU9NfoqcBjn87sjfcemgS8lqkLXJ67Vp1IY2jdp87vt1btZ5u+qUpJ1Z+oVAWVX/8bcTSJIkSao5H38Md9wBjz8Oq1dD795w5ZUwdCjsu++G7+Hb4b1573HsI8fSplEbTul3CnlZeeRm5rKqdBWFKwopXFHI1KKpVMbK9c85bdfTuO3w22jfpH1NfDpJqhfSLwRyOZgkSZJUc9atg5tvhltvhexsOO20ZNbPfvtt845e7y94nwfGPcCBnQ/kxL4nkt0gmwmfTmDow0NpldeK1897nY5NO+6gDyJJMgSSJEmS9FnFxfDGG3DFFTBtGpx5Jvzud8nA5200b8U8rn31Wh764CFCCNz93t20bdSWc3c/l3988A9yM3MZcc4IAyBJ2sEMgSRJkiQlXn4Z7rsPxo2DGTOS+3r0SO4/4ojPfdpDHzzEYxMfIxI/81iMkTfnvEl5ZTk/2/9nXLn/lfzfvP/jz+/9mTtG3UGrvFa8cs4rdMvvtqM+lSSpiiGQJEmSVN/Nmwc//nGyw1eHDrD//smSrwED4NBDITd3i0+rjJVc/crV3D7qdnq16EV+bv4Wzzu578nccMgN64OeoT2HMrTnUAqLC8nMyHSujyTVEkMgSZIkqb5atQr+/Ge46abk+/NNN8FPfwo5OZucFmPkb+P+xovTX+TQrodyfJ/jaZ3XmnOePocnJz3J9wZ+jz8e/cf1u3dtrU7NOtXkp5EkfQlDIEmSJKm+WbQI7roL7r4bli1Ltnf/4x+he/fPnLq2bC2XPH8JD45/kJa5LXlq8lNc+sKltMhtwbK1y/jtkb/lx/v+mLCNQ6IlSbUv/UKgjIzk0hBIkiRJ2tSMGfCb38Df/w4lJfCNb8DPfpZs8b4Fs5bP4sNkFAwAACAASURBVORhJ/P+gvf5xcG/4PqDr2da0TSem/ocbxe+zbm7n8vXd/l6LX8ISdL2Sr8QKISkG8gQSJIkSUp88AHccksy8yczE84+O1n21afPJqdVxkrGzB/DiBkjeGXmK7w9520aZjbk2W89y3G9jwOgT6s+9GnVhyu4IhWfRJL0FaRfCASQlQVlZamuQpIkSUqtpUvh2mvh3nuhSRP4yU/gssuS4c+beWP2G1z+0uWMXTAWgN3a7sYle1/C9/f+Pj1a9KjtyiVJO0B6hkB2AkmSJKk+Ky+HBx+Eq66C5cvhhz+EX/4Smjff5LQYIx8v+ZjrRl7Hvyf/m4KmBdx//P2c0OcE2jRqk5LSJUk7jiGQJEmSlC4mToR//AP++U/49FM44IBk+PNuuwGwrnwd7y94n1GFoxg9dzSjCkexcNVCGmU14qZDb+Ly/S4nLysvxR9CkrSjGAJJkiRJO7slS+DMM+Hll5PvwscfD+efD8cdByFw1//dxSMTH+H9Be9TWlEKQPf87hze/XD2K9iPk/qeRLvG7VL8ISRJO5ohkCRJkrQzmzgRTjgB5s+H225Lwp/Wrdc//Lf3/8YPX/whe7Xfi8v2uYzBnQazX8F+tG3cNoVFS5JSwRBIkiRJ2lk980zSAdS4Mbz+OuyzzyYPjy4czSXPX8IR3Y/g+TOfJzMjPb/+S5K2TkaqC9ghDIEkSZKUzmbNgnPPhW98I9nm/b33PhMAzV85n5OHnUxB0wIe++ZjBkCSJDuBJEmSpJ3G4sXw61/DX/4CIcBPfkL8xS94es7L3HDPcRStLWJAuwEMaDuAlz55iRUlK3j57Jdpkdsi1ZVLkuoAQyBJkiSpristhbvughtvhFWrkrk/v/wlw0smc80jhzBm/hh2abULB3c5mA8+/YAXpr0AwLBThtG/Tf8UFy9JqivSNwQqK0t1FZIkSdJX9+yzcPnlMH06HHMM3HEHRV3b8v3nv8/jHz1O52adeeCEBzh797PXL/laV76O1aWraZnXMsXFS5LqkvQMgbKy7ASSJEnSzq2kBC67DO69F/r2hRdegKFDeWbKM1z858NYunYpNx16Ez8d/FNyMnM2eWrDzIY0zGyYosIlSXVVeoZALgeTJEnSzmz+fPjmN2H0aLjqKrjxRiYs/ZgbnziFJyc9ye5td+els15i93a7p7pSSdJOxBBIkiRJqkveeQdOPBFWroQnnmDs4G786t+n8vTHT9M4uzG/PPiXXH3g1WQ3yE51pZKknYwhkCRJklRXjBoFRx7J0s6teeyeb/Pgott57/73aJbTjOsPup7L9r3Mnb4kSdstfUOg0tJUVyFJkvSlQghDgT8ADYC/xhhv3ezxLsADQGtgKXBWjHFu1WMVwISqU+fEGE+otcJV8959F4YO5Q+H5vKzQfMpHf9rdmu7G3cedSfnDzifZg2bpbpCSdJOLn1DoDVrUl2FJEnSFwohNADuBo4A5gLvhRCeiTFO2ui03wAPxRj/EUI4DLgFOLvqsbUxxgG1WrR2jLFj4cgjKSpowbX7Lmb/gv353VG/Y0A7//FKkmpORqoL2CFcDiZJknYOg4DpMcYZMcZS4DHg65ud0w94ter6yC08rp1ZZSX87W9w+OHQvDl333ISq8vX8Mej/2gAJEmqcYZAkiRJqdMRKNzo9tyq+zb2AXBS1fUTgSYhhJZVtxuGEMaEEN4JIXzj894khHBx1XljFi9eXFO166saNQoGDYILL4R+/Vj98v/445SHOK73cfRv0z/V1UmS0pAhkCRJUt32E+DgEMI44GBgHlBR9ViXGONA4Azg9yGEHlt6gRjjfTHGgTHGga1bt66VovUFysrg0kth//1h4UJ4+GF46y0eWPYqRWuLuGr/q1JdoSQpTaXnTKCsrOT/XCVJkuq2eUCnjW4XVN23XoxxPlWdQCGExsDJMcblVY/Nq7qcEUJ4DdgD+GTHl63ttnw5nHIKvPIK/OhH8KtfQaNGlFWU8ZvRv+GAzgewf+f9U12lJClN2QkkSZKUOu8BvUII3UII2cDpwDMbnxBCaBVCqP7OdjXJTmGEEPJDCDnV5wD7AxsPlFZd88knsN9+8Prr8MADcOed0KgRAI9NfIw5xXPsApIk7VDp2QlkCCRJknYCMcbyEMKlwEskW8Q/EGP8KIRwIzAmxvgMcAhwSwghAm8A3696el/g3hBCJckf9m7dbFcx1SWTJ8NBByWDoIcPh4MPXv9QRWUFt719G/3b9OeYXseksEhJUrozBJIkSUqhGOPzwPOb3Xf9RtefBJ7cwvNGAV/b4QXqq5s7F448MvmO+sYb0KvX+odWla7ijKfO4KPFH/HoyY8SQkhhoZKkdGcIJEmSJO0oy5bB0KFQXPyZAGjBygUc9+hxjF84nj8d/SdO7396CguVJNUHhkCSJEnSjrB2LZxwAkybBi++yIIebflkzlsUrSli0epF3PTGTSxdu5RnTn+GY3sfm+pqJUn1gCGQJEmSVNNKS5NdwN5+Gx5/nFE9czj0D10prShdf0pB0wLePP9N9mi/RwoLlSTVJ4ZAkiRJUk0qL4czzoD//Q/uuYfFxxzCqffuQaemnbj7mLtp3ag1LXNb0r5Je7IbZKe6WklSPWIIJEmSJNWUigo47zx46im4804qLrqQMx8+miVrlvDOhe8woN2AVFcoSarHDIEkSZKkmlBZCd/9Ljz8MNx8M/zoR/zqtRsYPmM49x13nwGQJCnlMlJdwA6RlZX8FSbGVFciSZKk+qCyEi65BP76V7j2Wrj6ap6f9jw3vH4DZ+92NhfueWGqK5QkKU1DoMyqBie7gSRJkrSjxQiXXgr33gtXXQU33cR/Jv+HEx8/kd3b7c5fjv0LIYRUVylJkiGQJEmStN1ihB/8AP7yF/jZz+Dmm3now39yyhOnsGf7PXn1nFdplN0o1VVKkgSk80wgMASSJEnSjhMjXHYZc/51N4t+dhZFFx7K6Ndv4IbXb2BItyE8ffrTNM5unOoqJUlazxBIkiRJ2lYxwo9/zOVT7+LOHwP8Cx75FwAn7nIij5z8CA0zG6a0REmSNmcIJEmSJG2LGOHyy/nXyD9w50lw7u7nclLfk2iZ25LWjVrTq0UvZwBJkuokQyBJkiRpW1x5JR88+nsu/m4mB3UezP3H309Wg6xUVyVJ0pdyMLQkSZK0tR55hGV33cFJFzUlv2kbhp0yzABIkrTT2KoQKIQwNIQwJYQwPYRw1RYe7xxCGBlCGBdC+DCEcEzNl7oNDIEkSZJU06ZOpex7F3PmhfkUZq/lyVOepG3jtqmuSpKkrfalIVAIoQFwN3A00A/4Vgih32anXQcMizHuAZwO/LmmC90mWVV/jSkrS2kZkiRJShPr1lFx6imcd0wZL7Raxl1H38V+nfZLdVWSJG2TrekEGgRMjzHOiDGWAo8BX9/snAg0rbreDJhfcyVuBzuBJEmSVIPij3/E9zp/yCO7lHLzYTfznYHfSXVJkiRts60JgToChRvdnlt138Z+CZwVQpgLPA/8YEsvFEK4OIQwJoQwZvHixdtR7lYyBJIkSVJNqKgg3nQTl8+8l/v3gmsOuIarD7w61VVJkrRdamow9LeAB2OMBcAxwD9DCJ957RjjfTHGgTHGga1bt66ht94CQyBJkiR9VbNmwSGHcPdz1/P7/eCHAy/lV4f9KtVVSZK03bYmBJoHdNrodkHVfRv7NjAMIMY4GmgItKqJAreLIZAkSZK+iscfh912Y9as8Vx5bDZH9TiKO4/5AyGEVFcmSdJ225oQ6D2gVwihWwghm2Tw8zObnTMHGAIQQuhLEgLtwPVeX8IQSJIkSdtrwgQ46yxi/1256Oe7k5GVzX3H30fGZxvdJUnaqXzp/5PFGMuBS4GXgMkku4B9FEK4MYRwQtVpVwAXhRA+AB4Fzosxxh1V9JcyBJIkSdL2qKiACy+E/HwevO0MXlnwNrcdfhudm3VOdWWSJH1lmVtzUozxeZKBzxvfd/1G1ycB+9dsaV+BIZAkSZK2x5/+BO++y4J//InLR13HgZ0P5LsDv5vqqiRJqhHp2dNqCCRJkqRtNXs2XHst8044lLPiv1lXvo6/nvBXl4FJktLGVnUC7XSyspJLQyBJkiRtjRhZ/f2L+M3gUm4f9A7lhRXcfczd9G7ZO9WVSZJUY9IzBKruBCorS20dkiRJqvNijDz6m3P5aZ/hzG8Kp/Y5kVuH3Eq3/G6pLk2SpBqV3iGQnUCSJEn6Ah8t+ojvP3Ayr5dMYa/MZgw79xn273pQqsuSJGmHMASSJElSvXTbW7dx7YhraLamknvn7cK37x9Lg9y8VJclSdIOYwgkSZKkemfioolcM+Iavv5x5P4Fe9PyfyPBAEiSlOYMgSRJklTvXPXv79FkXSX3f9Kfli+/DI0apbokSZJ2OEMgSZIk1SuvvfcE//v0LW6d0IyW/30ZmjdPdUmSJNUKQyBJkiTVG3HlSn728HkUZAZ+eNPL0L59qkuSJKnWGAJJkiSpfqio4IlLD+W97mv4e7cfk7vHoFRXJElSrcpIdQE7hCGQJEmSNrP8pz/g6uZj+VqDDpx91h2pLkeSpFqXnp1AWVnJpSGQJElSvba6dDX/+fg/PP6/23ip8UTKGsALp/+NBhkNUl2aJEm1Lj1DoOpOoLKy1NYhSZKklDrx8RMZPmM4BcXwg7XdOePaR9mrwGVgkqT6Kb1DIDuBJEmS6q3pS6czfMZwrhudzQ2f9iXjzbegceNUlyVJUsqkZwjUoKq91xBIkiSp3npw+O1kVML3PsknY+RzBkCSpHovPUOgEJIgyBBIkiSpXqp47//4x3t/46hlOXT476tQUJDqkiRJSrn03B0MkiVhhkCSJEn1zxtvMPL8Q5nbpJLzzrwD+vVLdUWSJNUJhkCSJElKH+++C0OH8uDeWTTPbsYJB12U6ookSaozDIEkSZKUHhYtgpNPprigNU/1KOVbu51Bw8yGqa5KkqQ6wxBIkiRJO7/ycjj9dFiyhGG3n8O6inWcP+D8VFclSVKdkr4hUFaWIZAkSVJ9ce21MHIk3HMPDy59lX6t+zGww8BUVyVJUp2SnruDgZ1AkiRJ9UTpsEd5e9jtjPrJIEZlDWPUrFHcfvjthBBSXZokSXVKeodAZWWprkKSJEk70ujRXPDEWTx8HsC79F3Wl0sGXsJ3B343xYVJklT3pHcIZCeQJElS+poyhaUnH8OwCys5f5dv8dsT7iY/Nz/VVUmSVGel70wgQyBJkqT0tWABDB3KU70rKGsA3z/wCgMgSZK+hCGQJEmS6ryHPniIn7/68+RGUREceywsXsyj3+xD75a92bP9nqktUJKknYDLwSRJklSnDftoGOc9fR6RyGHZfTj0ghthzhzmPX4/r40/l18c/AuHQEuStBXsBJIkSVKd9fqs1zn7P2czuNNgCnLacNXD5xOXFsGIETzeZjGRyLe+9q1UlylJ0k7BEEiSJEl10sRFE/n6Y1+ne353nml8ETf8eynvtivn6Sdugv3355EJjzCww0B6t+yd6lIlSdopGAJJkiSpzlm6dinHPHwMeVl5vNj2ClqceSHnZO/NLvm9uGbSXUxaPImxC8ZyRv8zUl2qJEk7jfQNgbKyDIEkSZJ2Uj99+afMXzmfZ7pdQ5czvw977knm8y9y8xG38fGSjzntydMIBE7rf1qqS5UkaaeRviFQZiaUlaW6CkmSJG2jkTNH8sD4B/hJwakMPOtn0K8fvPgiNG3KN3b5Bvt03IeJiyZyaLdD6dCkQ6rLlSRpp5HeIZCdQJIkSTuVtWVr+c5z36F7o05cf8Uz0K0bvPwy5OcDEELg1sNvBeCc3c5JZamSJO103CJekiRJdcav3vgV05ZOY/jrXcjLyksCoNatNznnkK6HMO0H0+iR3yNFVUqStHMyBJIkSVKd8OGnH3L7qNs5d2UPDn9tRhIAdey4xXN7tuhZy9VJkrTzczmYJEmSUm5a0TSOfeRYWpDHb//8CVx/PRx+eKrLkiQprdgJJEmSpJSavHgyhz10GBWlJbxy/zpaDh4CP/95qsuSJCntGAJJkiQpZSZ8OoEhDw2hAYHXhuXRr7whPPwwNGiQ6tIkSUo7hkCSJElKieXrlnP4Pw8nu0E2r47sTO9JY+H116Ft21SXJklSWkrfmUBZWYZAkiRJddhvR/2WRasX8ey8g+j93Gi4917Yd99UlyVJUtpK3xDITiBJkqQ6a8maJfz+/37PKXkD2eN3j8KPfgTnnZfqsiRJSmvpvRysrCzVVUiSJGkL7nj7DlaXruaXf/oAhgyBO+5IdUmSJKW99A6B7ASSJEmqcxauWshd797FGSW96bfoE3j7r8l3N0mStEO5HEySJEm16ta3bqW0opRfPDgTzj4bunZNdUmSJNULhkCSJEmqNXNXzOWeMfdwbklfen1aDtdck+qSJEmqN9I/BIox1ZVIkiSpyr1j7qW8spyfPzAdzjgDevZMdUmSJNUb6R0CAVRWprYOSZKkLxBCGBpCmBJCmB5CuGoLj3cJIYwIIXwYQngthFCw0WPnhhCmVR3n1m7l2+flGS+zT0U7un5aAtdem+pyJEmqV9I/BHJJmCRJqqNCCA2Au4GjgX7At0II/TY77TfAQzHG3YAbgVuqntsC+AWwDzAI+EUIIb+2at8ey9YuY8z8MRzxziI49VTYZZdUlyRJUr2SviFQVlZyaQgkSZLqrkHA9BjjjBhjKfAY8PXNzukHvFp1feRGjx8FDI8xLo0xLgOGA0Nroebt9tqs16iMlRz+cZldQJIkpUD6hkB2AkmSpLqvI1C40e25Vfdt7APgpKrrJwJNQggtt/K5AIQQLg4hjAkhjFm8eHGNFL49XpnyAo1LYZ89joevfS1ldUiSVF8ZAkmSJNVtPwEODiGMAw4G5gEV2/ICMcb7YowDY4wDW7duvSNq3CrDJzzNITMh6yp3BJMkKRXSPwQqK0ttHZIkSZ9vHtBpo9sFVfetF2OcH2M8Kca4B3Bt1X3Lt+a5dcnsxdOYVrmYwzN6wr77procSZLqpfQPgewEkiRJddd7QK8QQrcQQjZwOvDMxieEEFqFEKq/s10NPFB1/SXgyBBCftVA6COr7quTRjx2CwCHn/yTFFciSVL9ZQgkSZKUIjHGcuBSkvBmMjAsxvhRCOHGEMIJVacdAkwJIUwF2gK/rnruUuAmkiDpPeDGqvvqnooKho97kvZrM+n39YtSXY0kSfVWZqoL2GEMgSRJ0k4gxvg88Pxm912/0fUngSc/57kPsKEzqM6qfPo/jGi1kqFtDyRkpO/fICVJquvS9/+FDYEkSZLqhAn33MDiRnD4weenuhRJkuo1QyBJkiTtOMuWMXzNRACG9DwyxcVIklS/GQJJkiRpxxk/nle6Q9/cznRs2jHV1UiSVK+lbwiUlZVcGgJJkiSlRFlFGde/cwvDu8PRvY5OdTmSJNV76RsC2QkkSZKUMp8s/YQD/34gN5UO5+xpudxw7G9SXZIkSfVe+u8OVlaW2jokSZLqmbHzx3LIPw4hMyOTx97pxGkZX4PsxqkuS5Kkes9OIEmSJNWo56Y+x6rSVYw/9x1OGz4f9tgj1SVJkiS2MgQKIQwNIUwJIUwPIVz1OeecGkKYFEL4KITwSM2WuR0MgSRJklJidvFs2jduT5fCFVBRYQgkSVId8aXLwUIIDYC7gSOAucB7IYRnYoyTNjqnF3A1sH+McVkIoc2OKnirGQJJkiSlxOzi2XRp3gXGjUvuMASSJKlO2JpOoEHA9BjjjBhjKfAY8PXNzrkIuDvGuAwgxrioZsvcDoZAkiRJKTGneA5dmnWB8eOhaVPo1i3VJUmSJLYuBOoIFG50e27VfRvrDfQOIbwdQngnhDB0Sy8UQrg4hDAmhDBm8eLF21fx1jIEkiRJqnWVsXJDCDRuHAwYACGkuixJkkTNDYbOBHoBhwDfAu4PITTf/KQY430xxoExxoGtW7euobf+vIoMgSRJkmrbp6s+pbSilM5NC+DDD10KJklSHbI1IdA8oNNGtwuq7tvYXOCZGGNZjHEmMJUkFEqdrKzk0hBIkiSp1swung1Al1WZsGaNIZAkSXXI1oRA7wG9QgjdQgjZwOnAM5ud8zRJFxAhhFYky8Nm1GCd285OIEmSpFo3p3gOAF3mFCd3GAJJklRnfGkIFGMsBy4FXgImA8NijB+FEG4MIZxQddpLQFEIYRIwEvhpjLFoRxW9VQyBJEmSat3s5VWdQJMXQE4O9O2b4ookSVK1L90iHiDG+Dzw/Gb3Xb/R9QhcXnXUDdUhUFlZauuQJEmqR2YXz6ZZTjOavjUJ+vffsERfkiSlXE0Nhq577ASSJEmqdbOLZ9Ol+UY7g0mSpDrDEEiSJEk1Zk7xHLpkt4GiIucBSZJUxxgCSZIkqcbMXj6bLutykhuGQJIk1SmGQJIkSaoRxeuKKS4ppvOqqu9hvXuntiBJkrQJQyBJkiTViPXbw1c2Se7IyUlhNZIkaXOGQJIkSaoRs4urtoevDoHcGUySpDolfUOgjIzkMASSJEmqFbOXV4VA5Y2TO6r/KCdJkuqE9A2BIPniYQgkSZJUK2YXzya7QTZtKhomdzRokNqCJEnSJgyBJEmSVCPmFM+hc7POZJSVJ0vBQkh1SZIkaSPpHwKVlaW6CkmSpHphdvFsujTrknz/ch6QJEl1TvqHQHYCSZIk1YrZyw2BJEmqywyBJEmS9JWVlJewYNUCOjfrnIRADoWWJKnOMQSSJEnSVzZ3xVwAujTvknz/shNIkqQ6xxBIkiRJX9ns4qrt4V0OJklSnWUIJEmSpK9s9vKqEKi5IZAkSXVVeodAWVmGQJIkSbVgdvFsAoGCpgXOBJIkqY5K7xDITiBJkqRaMad4Du2btCe7QbadQJIk1VGGQJIkSfrKZhdXbQ8PDoaWJKmOSv8QqKws1VVIkiSlvdnLZyfzgMBOIEmS6qj0XqxtJ5AkSVKtOONrZ7BLq12SG4ZAkiTVSYZAkiRJ+spuPPTGDTccDC1JUp2U/svBDIEkSZJql51AkiTVSYZAkiRJqlkOhpYkqU4yBJIkSVLNshNIkqQ6Kb1DoKwsQyBJkqTaZggkSVKdlN4hkJ1AkiRJtc/B0JIk1UmGQJIkSapZzgSSJKlOMgSSJElSzXI5mCRJdVL6h0BlZamuQpIkqX4xBJIkqU5K/xDITiBJkqTa5UwgSZLqJEMgSZIk1Sw7gSRJqpMMgSRJklSzHAwtSVKdZAgkSZKkmmUnkCRJdZIhkCRJkmqWIZAkSXVSeodAWVmGQJIkSbWpogJidDC0JEl1UHqHQHYCSZIk1a6ysuTSTiBJkuocQyBJkiTVnOrvXoZAkiTVOekfAlVWJockSZJ2PDuBJEmqs9I/BAK7gSRJkmqLIZAkSXVW2oVAv3ztlxz7yLHJDUMgSZKk2lUdAjkYWpKkOiftQqD/b+++46Oq8v+Pv85MeqWFmgChVynGBguCoiIqiIsusAXLfv3p2hUL6rrWXVHWtWFBXduqYEVcu6iIsiKhSlWaEDAQSgqpM5Pz++NOQkISCJBkhsn7+Xjcx8zcuffmM9cb5vjOOefmFOXwzS/fYCvelUIhkIiIiEjDUE8gERGRoBVyIVD7xPbsK9lHdlG2QiARERGRhqaJoUVERIJWSIZAAFtytigEEhEREWlo6gkkIiIStEI7BCprfCgEEhEREWkYmhNIREQkaIV2CKSeQCIiIiINSz2BREREglbIhUBJsUlEuiMVAomIiIgEguYEEhERCVohFwK5jIuUxBS25CoEEhEREWlw6gkkIiIStEIuBAJnSJh6AomIiIgEgEIgERGRoNU4QqCyxoiIiIiI1C9NDC0iIhK0QjMESmjP9rzteNz+FeoJJCIiItIw1BNIREQkaIVmCJTYnlJbyvbSHGeFQiARERGRhqGJoUVERIJWyIZAAFt8e5wVCoFEREREGoZ6AomIiASt0A6BPLudFQqBRERERBqGQiAREZGgFZIhUEpiCgBbvLucFQqBREREJEgZY0YaY9YZY9YbY26r5v32xpivjDFLjTErjDGj/Os7GmMKjTHL/MszDV99NTQxtIiISNAKyW/nmPAYWsS0YEtJlrNCIZCIiIgEIWOMG5gOnAFkAIuMMXOstasrbHYn8Ka19mljTC/gI6Cj/70N1tr+DVnzIaknkIiISNAKyZ5A4L9NfNFO54VCIBEREQlOJwLrrbUbrbUlwExgzAHbWCDB/zwR2N6A9R0+TQwtIiIStEI8BNrhvFAIJCIiIsGpHbC1wusM/7qK7gb+YIzJwOkFdE2F91L9w8TmGWOG1PRDjDGXG2PSjTHpWVlZdVR6DdQTSEREJGiFbAiUkpDClsJM50VZY0RERETk2DMBeMlamwyMAl41xriAX4H21toBwI3A68aYhOoOYK2dYa1Ns9amJSUl1W+1mhNIREQkaIVsCNQ+sT253n3kRAIlJYEuR0RERKQ624CUCq+T/esqugx4E8Ba+z8gCmhhrS221u72r18MbAC61XvFh6KeQCIiIkErpEMggC1NDaxbF+BqRERERKq1COhqjEk1xkQA44E5B2yzBTgdwBjTEycEyjLGJPknlsYY0wnoCmxssMprohBIREQkaIV+CNS3PSxaFOBqRERERKqy1nqBq4FPgTU4dwFbZYy51xgz2r/ZTcD/GWOWA28AF1trLTAUWGGMWQa8DVxhrd3T8J/iAJoYWkREJGjVarC2MWYk8BjgBp631j5Yw3a/xWmEnGCtTa+zKo9AeQjUsy28kQ7WgjGBLElERESkCmvtRzgTPldcd1eF56uBwdXs9w7wTr0XeLg8HnC71e4SEREJQofsCeTvZjwdOBvoBUwwxvSqZrt44DpgYV0XeSRax7Um3BXOluR4yMqCLVsCXZKIiIhI6PN4NCm0iIhIkKrNcLATgfXW2o3W2hJgJjCmmu3uA6YC4SfRgAAAIABJREFURXVY3xFzGRfJCclsaeL/K1R6QDsmiYiIiDQOHo+GgomIiASp2oRA7YCtFV5n+NeVM8YMBFKstR/WYW1HrX1ie7a48pyGiOYFEhEREal/Xq9CIBERkSB11BNDG2NcwCM4kxYeatvLjTHpxpj0rKyso/3Rh9Q+sT1b8jLguOPUE0hERESkIagnkIiISNCqTQi0DUip8DrZv65MPNAH+NoYsxk4GZhjjEk78EDW2hnW2jRrbVpSUtKRV11L7RPbsy13G94TjndCoNLSev+ZIiIiIo2aQiAREZGgVZsQaBHQ1RiTaoyJAMYDc8retNbmWGtbWGs7Wms7At8DowN9dzBwQiCf9fFr/y6QkwMbNgS6JBEREZHQpomhRUREgtYhQyBrrRe4GvgUWAO8aa1dZYy51xgzur4LPBrlt4nv1tJZoXmBREREROqXegKJiIgErVr9mcZa+xHw0QHr7qph22FHX1bdSG2SCsDiqD0MjopyhoRNnBjgqkRERERCmCaGFhERCVpHPTF0MOvWvBsntTuJR394Au/A/uoJJCIiIlLf1BNIREQkaIV0CGSMYcpvprApexOzBiXAkiXg8wW6LBEREZHQpTmBREREglZIh0AA53U/j95JvflH01WUFhbAmjWBLklEREQkdKknkIiISNAK+RDIZVxM+c0UVnm28UE3nHmBRERERKR+KAQSEREJWiEfAgH8rs/vSG2Syt+HubDpmhdIREREpN5oYmgREZGg1ShCoDBXGLcOvpUf2pTy1dpPwNpAlyQiIiISmtQTSEREJGg1ihAIYFL/SbRxJfJAu40wf36gyxEREREJTZoYWkREJGg1mhAoKiyKyadO4ctO8O3TUwJdjoiIiEhoUk8gERGRoNVoQiCAK065hpbEck/4At0lTERERKQ+KAQSEREJWo0qBIoJj+GWQTfzRWf47slbAl2OiIiISOjRxNAiIiJBq1GFQABXnDqZlr5o7tn3IWRmBrocERERkdCinkAiIiJBq9GFQLERsdycdi2fd7J8N/3WQJcjIiIiElo0MbSIiEjQanQhEMCVI/9KkieCe7a9Dvv2BbocERERkdChnkAiIiJBq1GGQLERsdzS+3I+7+Dls3/8OdDliIiIiIQOzQkkIiIStBplCATwl3FT6elpwp9KZpH53aeBLkdEREQkNKgnkIiISNBqtCFQTHgMb178IbmRMPH13+IrKgx0SSIiIiLHPoVAIiIiQavRhkAAfboM4qlO1/BVy3zunToq0OWIiIiIHPs0MbSIiEjQatQhEMDFlz7OpOyO3Ge/5vMvnwt0OSIiIiLHLmvB51NPIBERkSDV6EMggOk3f0WvPW7Gf3ElG7YuD3Q5IiIiIscmr9d5VAgkIiISlBQCAbFtOzL79OfA5+Pc6YPJzssKdEkiIiIixx6Px3lUCCQiIhKUFAL5dRlzCe+0n8z6iHx+9/cBeH2eQJckIiIicmwpC4E0J5CIiEhQUghUwbCrHuYZew6fRW3jhr8PDXQ5IiIiIscW9QQSEREJagqBDnDZvR9w096ePFn6Pb9/6GSyi7IDXZKIiIjIsUEhkIiISFBTCHQgY5j64GLu3dqVWfkL6f/Prsz/ZX6gqxIREREJfpoYWkREJKgpBKqGOyqavz6xnG+XDSBs5y6GvTSMmz69ib2FewNdmoiIiEjwUk8gERGRoKYQqCbR0Zz8n3ksXXIily21/Ov7f9H58c5MWzCNIm8RP+/+mReWvMCl71/K7LWzA12tiIiISOBpYmgREZGgpm/og4mPJ/6DT5kxYgRXL1zCbVe14ubPb+aOL++gxFcCgNu4eWfNO6y5ag1t49sGuGARERGRAFJPIBERkaCmnkCH0qQJfP01xw0ay0d/XcuX28/k//pdwrPnPsuaq9aw5qo1lPhKuPbjawNdqYiIiEhgKQQSEREJagqBaiMuDt56C+65h+EzPuPJ+5dyeZtz6dGiB12bd+WuoXfxzpp3mLNuTqArFREREQkcTQwtIiIS1BQC1ZbLBXfdBe++C6tWQVoaLFwIwORBk+nTsg9XfXQVecV5AS5UREREJEDUE0hERCSoKQQ6XGPHwv/+B1FRcOqp8MorhLvDmXHuDLblbuOmz25i1c5VbM7ezO6C3YGuVkRERKThaGJoERGRoKYQ6Ej07QuLFsHgwTBpEtx0E6e0OYG/nPAXnlvyHH2e7kPqY6m0eLgFd399d6CrFREREWkY6gkkIiIS1PRnmiPVvDl88gncdBM88gisXMljr7/G6O6j2Vu4l3xPPm+vfpsHv32QPw/8M8kJyYGuWERERKR+aU4gERGRoKaeQEcjPBwefxyeew6++gr3KYM4sySF3/X5HZcOuJSnz3maUlvKffPuC3SlIiIiIvVPPYFERESCmkKguvDnP8NXX0FODpx0kjN5NNChSQeuSLuCF5a+wPo96wNcpIiIiEg905xAIiIiQU0hUF0ZPBjS06FnT/jtb+GWW8Dr5fYhtxPhjuBvX/8t0BWKiIiI1C/1BBIREQlqCoHqUkoKfPMNXHklPPwwjBhB631w3UnX8caPb/Djjh8DXaGIiIhI/VEIJCIiEtQUAtW1yEh46il45RX44QcYOJCb3UNIiExg8ueT+TXv10BXKCIiIlI/NDG0iIhIUFMIVF/++EdYuBBiY2l2xmju4lQ+2/AZbR9pywnPncA9X9/DroJdga5SREREpO6oJ5CIiEhQUwhUn/r2deYJOu88bpwyhxXrz+SBwXcR5grjnnn3MPI/IynwFAS6ShEREZG6oYmhRUREgppCoPqWmOjcLWzqVPq+/gW3X/Mm/zvlBd4f/z5Lfl3CxbMvptSWBrpKERERkaOnnkAiIiJBTSFQQzDGuVvY3LmwZw+ceCLnLStg6oipvLX6Le6dd2+gKxQRERE5egqBREREgppCoIY0bBgsWQL9+sH48Uyek8XF/SZxz7x7mLlyZqCrExERETk6mhhaREQkqCkEamjt2sHXX8MVV2AeephnZu5jSPJgfv/u75nyxRSKvEWBrlBERETkyKgnkIiISFBTCBQI4eHObeQfeojIWe/w31e8XNJzAg9+9yADnx3IwoyFga5QRERE5PCVhUAuNTFFRESCkb6hA8UYuPlmmDWLhIXLeP7ORXxy2r/JK8lj0L8H8c8F/wx0hSIiIiKHx+Nx/thlTKArERERkWooBAq0iy5yJozetYuzfnsrq054iQt6XsDkzydz06c36c5hIiIicuwoC4FEREQkKCkECgaDB8P//gfx8SSccS6z3OO55sRreOT7R/jje3+kxFcS6ApFREREDs3rVQgkIiISxBQCBYtu3eD776F/f1zjLuSxtan84/R/8PqPr3PGq2ewbte6QFcoIiIicnAeD4SFBboKERERqYFCoGCSlARffgljx2JuvJHb3vqVV8e8zLLMZfR9ui+3fXEb+0r2BbpKERERkeppOJiIiEhQUwgUbKKj4c034YYb4PHH+cM97/HTZcuY2HciU7+bSs/pPXltxWuaK0hERESCj0IgERGRoKYQKBi53fDII/D44/D++7QadREv9b+b7y79jqSYJP7w3h84+fmTmf/L/EBXKiIiIrKf5gQSEREJagqBgtk118D778PPP8OAAQxakkX65em8fP7LbM/bztCXhjJp9iQ8Pk+gKxURERFRTyAREZEgpxAo2J13HixZAp06wfnn45p8M3/qNYGfrvmJO4bcwSvLX+Gity/SHcREREQk8DQxtIiISFBTCHQs6NQJFiyAq65yhomNGkVMgYf7T7ufx0c+zuy1s7nwrQsp9hYHulIRERFpzNQTSEREJKgpBDpWREbCk0/Cv/8NX38NQ4bA1q1cc9I1TB81nTnr5vDbN3/L3sK9ga5UREREGiuFQCIiIkFNIdCx5pJL4OOP4Zdf4KSTYOlS/nLCX3jmnGf48OcPSflXCtd+fC0b924MdKUiIiLS2GhiaBERkaCmEOhYNGIEfPutM+Z+8GB44w3+X9r/Y/kVyxnXaxzPpD9D1ye68sf3/kjmvsxAVysiIiKNhXoCiYiIBDWFQMeqvn3hhx/g+ONh4kS48UaOa96Ll85/ic3Xb2byKZN5c9Wb9HiyB08tegpfqS/QFYuIiEio08TQIiIiQU0h0LGsdWuYOxeuvhr+9S844wzYuZO28W2ZesZUfrzyR9LapnHVR1dxygunsGrnqkBXLCIiIqFMPYFERESCmkKgY11EBDzxBLz8Mnz/vdMzaNEiALo178bnf/yc1y54jU3Zmzh+xvE8+v2jlNrSABctIiIiIUkhkIiISFBTCBQq/vQn+O47cLudO4f9+98AGGOY2HciK69cyZmdz+SGT2/gjFfPYEvOlgAXLCIiIgDGmJHGmHXGmPXGmNuqeb+9MeYrY8xSY8wKY8yoCu9N8e+3zhhzVsNWXg1NDC0iIhLUahUC1aJxcqMxZrW/YTLXGNOh7kuVQxo4ENLTnRDossvgiiuguBiAVnGteH/8+zx/3vP8sO0Hej/Vm+k/TFevIBERkQAyxriB6cDZQC9ggjGm1wGb3Qm8aa0dAIwHnvLv28v/ujcwEnjKf7zA0ZxAIiIiQe2QIVAtGydLgTRr7XHA28BDdV2o1FKLFvDJJ3DrrfDsszBsGGzfDji9gi4beBkrrljBoJRBXP3x1Qx5cQirs1YHtmYREZHG60RgvbV2o7W2BJgJjDlgGwsk+J8nAtv9z8cAM621xdbaTcB6//ECR8PBREREglptegIdsnFirf3KWlvgf/k9kFy3ZcphcbvhwQfhrbfgxx+dHkLfflv+dmrTVD75/Se8cv4rrN21lgHPDuC5xc8FsGAREZFGqx2wtcLrDP+6iu4G/mCMyQA+Aq45jH0BMMZcboxJN8akZ2Vl1UXd1VMIJCIiEtRqEwLVuoHhdxnwcXVvNFgDRBzjxsHChZCQAMOHO8GQz7lVvDGGP/b7I2uuWsOwjsO4/L+Xc8V/r6DEVxLgokVEROQAE4CXrLXJwCjgVWPMYc3raK2dYa1Ns9amJSUl1UuRgEIgERGRIFenE0MbY/4ApAEPV/d+gzVAZL/evZ27hY0dC1OmwIgRsHV/ptcytiUfTfyIWwffyrOLn2X4y8P5Ne/XABYsIiLSqGwDUiq8Tvavq+gy4E0Aa+3/gCigRS33bViaGFpERCSo1SYEqlUDwxgzArgDGG2tLa6b8qROJCbCrFnw4ovOxNHHHQdvv13+ttvl5sERDzJr3CyWZS7jzP+cSW5xbgALFhERaTQWAV2NManGmAiciZ7nHLDNFuB0AGNMT5wQKMu/3XhjTKQxJhXoCvzQYJVXRxNDi4iIBLXahECHbJwYYwYAz+IEQDvrvkw5asbAxRfD0qXQrRtceCFcc0353cMALup9ER9M+IA1WWuY+M5EfKW+wNUrIiLSCFhrvcDVwKfAGpy7gK0yxtxrjBnt3+wm4P+MMcuBN4CLrWMVTg+h1cAnwFXW2sB+eWs4mIiISFA7ZAhUy8bJw0Ac8JYxZpkx5sC/YEmw6NIF5s+HG26AJ5+E3/wGNm0qf/u01NN44uwn+PDnD7nti9sCWKiIiEjjYK39yFrbzVrb2Vr7gH/dXdbaOf7nq621g621/ay1/a21n1XY9wH/ft2ttdXOydigFAKJiIgEtVr117XWfoRzN4qK6+6q8HxEHdcl9SkiAh55BIYOdXoHDRgA//wnXHopGMOVJ1zJqqxVTPvfNHol9eKSAZcEumIRERE5FmhOIBERkaBWpxNDyzHm/PNhyRLo1w/+/GfnDmI//QTAoyMfZUSnEfzfB//H//vg/7E9b3uAixUREZGg5vOBtQqBREREgphCoMauUyf46it47jlYvtyZNPr++wnzlvLORe/wlxP+wovLXqTL4124fe7tZO7LDHTFIiIiEow8HudRE0OLiIgELYVAAi6X0xNozRoYMwb++lcYOJCEJat4/OzHWXv1Wsb2HMs/vv0Hbf7ZhuNnHM9fv/wri7cvDnTlIiIiEizKQiD1BBIREQlaCoFkv9atnVvJz5kDubkweDBcfTWd3C147YLXWP2X1fz9tL8TEx7D37/9O2nPpTHyPyP5YVtg70YrIiIiQUAhkIiISNBTCCRVnXcerFrl3EL+qaegVy+YPZueST2ZMmQK8y+ZT9bNWTx8xsMs/nUxJz1/EqPfGK0wSEREpDHzep1HhUAiIiJBSyGQVC8+Hh57DL7/Hpo3h7Fj4YILICMDgGbRzZg8aDIbr93IA6c9wPwt8znp+ZMY8uIQZq+dja/UF+APICIiIg1KcwKJiIgEPYVAcnAnngjp6fCPf8DHH0PXrnDLLbBnDwDxkfHcPuR2tly/hX+d9S+25mxl7Kyx9Jzekzd+fINSWxrgDyAiIiINQsPBREREgp5CIDm08HC47TZn4uiLLoJp05y7iv39787cQThh0PUnX8/6a9fz5rg3iQqLYuK7E+n/TH/eX/s+1toAfwgRERGpVwqBREREgp5CIKm9jh3h5ZedW8kPGQJ33AEdOsBdd8Hu3QCEucK4sPeFLLtiGW/89g2KvEWcP+t8ujzRhbu/vpsNezYE9jOIiIhI/VAIJCIiEvQUAsnh69sXPvgAFi2C4cPhvvucMOj22yE7GwCXcTG+z3hWX7Wa/4z9D52aduLeeffS5Yku/Obfv+HV5a9S6CkM8AcRERGROqOJoUVERIKeQiA5cmlp8O67sHKlc0exf/zDGSb2z39CURHg9Az6/XG/5/M/fs6WG7bw4OkPklWQxZ9m/4l2j7Tjhk9uYFnmMg0XExEROdZpYmgREZGgpxBIjl7v3vDGG7BkiTOR9OTJ0LkzPPhg+QTSAMkJydz6m1tZe9VavvzTl5zR+QymL5rOgGcH0HN6T+7++m7W7lobwA8iIiIiR0zDwURERIKeQiCpOwMGwCefwNy50KsXTJkCyclw5ZWwdn+4Y4xheOpwZo2bxfabtvPsuc/SNr4t9867l57TezLg2QFM/XYqm7M3B+6ziIiIyOFRCCQiIhL0FAJJ3TvtNPj8c1ixAiZOhBdfhJ49YdQo+OwzqDD0q0VMCy4//nK+nPQlGTdm8NjIx4gOi+a2ubeR+lgqaTPSeOCbB1idtVpDxkRERIKZQiAREZGgpxBI6k/fvvD887B1K9x7LyxdCmed5fQSeugh+PXXSpu3jW/LtSddy4LLFrDpuk1MHTGVcHc4d351J72f6k2vp3px37z7dIcxERGRYKSJoUVERIKeCVTvirS0NJuenh6Qny0BUlwMs2bBjBnw3XfgdsPIkXDJJc7E0hER1e62PW877699n5mrZvLNL98AMKD1ABIiE/BZH95SL2lt0rhz6J20imvVkJ9IREQOwhiz2FqbFug6pLJ6a4N9+CGcey4sXOjMESgiIiIBcbA2mHoCScOJjIQ//Qm+/RbWrYNbbnF6B40bB23bwnXXwbJlVXZrG9+WK0+4knkXz2PL9VuYOmIqTaObOod0RxITHsMzi5+hyxNdeOCbByjwFDT0JxMRERENBxMREQl66gkkgeXzOfMHvfgizJ4NJSXQv7/TO2jiRGjRolaH+Wn3T9z2xW28t/Y9Wsa2ZGiHoQxoPYCBbQbSuWlnWsa2JCEyAWNMPX8gEREpo55Awane2mBvvQUXXQQ//gh9+tT98UVERKRWDtYGC2voYkQqKRsSNnKkczv51193AqHrrnNuNX/66TB2LIwZA61qHurVrXk33v3du8z/ZT5PLnqSxdsX8/bqtyttE+GOICUhhdHdRzO+z3hOaHsCxhi8pV42Z2+mxFdCr6Re9f2JRUREQpPmBBIREQl66gkkwWnFCnj1VXj3Xdi4EYyBwYOdQGjsWEhNPeQhcopyWJa5jK25W9mZv5Od+TtZlbWKT9d/iqfUQ8cmHYkJj2H9nvWU+EoAGN5xOHedehfDOg6r5w8oIhL61BMoONVbG+yVV2DSJFi/Hjp3rvvji4iISK0crA2mEEiCm7VOt/L33nOW5cud9f36OWHQBRc4Xc4PY5hXdlE2s9fO5r2172EwdG/enR4terCncA/T/jeNzH2ZDGk/hJFdRtI6rjVt4trQNr4tqU1TSYhMqKcPKiISehQCBad6a4O98AL8+c/wyy/Qvn3dH19ERERqRSGQhI6NG/cHQgsWOCFR584wahT85jfO0rbtER++0FPIC0tfYNqCafyS80uV95tFNyO1SSrNY5oTHxFPQmQC7RPbM7r7aAa0HqA5h0REKlAIFJzqrQ32zDNw5ZWwfTu0aVP3xxcREZFaUQgkoSkzE+bMcQKhb76BAv9dwVJTnbmERoyA006DpKQjOnyhp5DMfZlk7sskIzeDTdmb2LR3E5uyN5FdlE1ucS55JXlsz9tOqS2lQ2IHzu9xPiO7jGRI+yHERsTW4YcVETn2KAQKTvXWBnviCbj2WsjKqvWNHURERKTuaWJoCU2tW8PllzuLx+MMFfv2W5g3z7lDyfPPO9v16+cEQqefDkOGQFxcrQ4fHR5NatNUUpsefP6hrPwsPvjpA95b+x7PpD/DYwsfI9wVzsnJJ3NK8il0adaFTk070blZZ1ISUnC73Ef7yUVERIKPJoYWEREJeuoJJKHJ54PFi2HuXPjiCyccKilx7kbWrx+cdJKznHwydO0KLled/NgCTwHfbvmWuRvnMnfTXFbsWIGn1FP+frgrnA5NOtC5aWdiI2LZW7iXPYV7yPfk0y6+HZ2adqJT004MaD2AYR2HqTeRiBzT1BMoONVbG+yhh+DWW2HfPojV95eIiEigqCeQND5uN5x4orNMmQKFhfDdd/DVV7BwIfznP/D00862TZrsD4XK9jnCIWQx4TGc2flMzux8JgC+Uh8ZuRls3LuRDXs3sGHPBjZmb2TDng1sydlCs+hmtE9sT0x4DBm5GXyy/hN+3fcrAJHuSIZ2GMqZnc8krW0a/Vr1o2l00zo5PSIiInXO4/+jh3oCiYiIBC2FQNI4REc7Q8JGjHBe+3ywdq0TCH3/vfN4//1QWuq837Hj/kDoxBNh4MAj+qum2+WmQ5MOdGjSgeGpw2u1T4GngAVbF/Dxzx/zyYZPuPnzm8vfa5/Yng6JHUiMSiQxMpHosGjySvLIKc4htziXTk07cWanMzmj8xm0jmt92PWKiIgcMYVAIiIiQU/DwUTK7NsHS5bADz/sX37x3yHM5XJuRX/iiXDCCdC7N3TpAi1bHtbt6Y/Ejn07WJa5jOU7lrN8x3K2520npyiHnOIcCjwFJEQmkBiZSFxEHCt3riSrIAuA1CapuIwLn/XhK/XRpVkXBqUM4pTkU+jdsjfeUi/F3mJKfCW0jW9Ly9iWuruZiNQpDQcLTvXWBrvjDpg6df/cQCIiIhV4PB4yMjIoKioKdCkhIyoqiuTkZMIP+AOMhoOJ1EZcHAwd6ixlduyARYuc5Ycf4N139084XbZPjx5w/PGQluY89uwJUVF1VlaruFac1eUszupy1iG3LbWlLM9czmcbPmPZjmW4jIswl/NrvjprNQ9++yA+66t234TIBLo3707nZp1pF9+OtvFtaRffjnYJzvO28W2JCqu7zyUiIiHG61UvIBERqVFGRgbx8fF07NhRf3yuA9Zadu/eTUZGBqmpB7+ZUUUKgUQOplUrOPdcZwGwFjZtgp9+gvXrnWXlSpg1C5591tnG5YLOnaFXr8pLjx4QE1Ov5bqMiwFtBjCgzYBq388vySd9ezob9m4gwh1BpDuSMFcYGbkZrNu9jp92/8SibYuYnTebIm/VhD4+Ip64iDjiIuKICY8hzBWGMQaDwWVcGON/POB1s+hmdGnahS7NutCteTeOb3s8cRGV79KWXZTN5uzN9GjRQ2GTiMixyOOBMDUtRUSkekVFRQqA6pAxhubNm5OVlXVY++mbWuRwGAOdOjlLRdbCxo3OHclWrYLVq53lww8rd4tv0wZSU505hzp23P+8Uyfo0MGZ0LoexUbEcmrHUzm146kH3c5aS3ZRNtvytrE9bzvbcp3HrIIs8kvyyffks69kH6W2lFJbisVirS1/XmpLy1/7Sn2szlrNf3/6LyW+EgDcxs2ANgMYnDKYQk8h3239jtVZq7FYItwRHN/meAalDKJfq350adaFzs06kxSTVO0XhrUWn/WV93gSEZEA8XjUE0hERA5KAVDdOpLzqf9rEqkLxji9fzp3rrze43F6C5WFQps2webNsGCB03vIV2FoVlSU01uod2/ntvUdOjhL+/aQkgIREQ34cQxNo5vSNLopfVr2qZNjlt0pbVXWKhZsXcB3W79jxuIZRLgjGJQyiPF9xtO5aWeWZi5lwdYFPPnDkxT7isv3jw2PpXVca1rHtaZlbEvySvLYmrOVrblbKfQU0jquNSmJKaQkpNA+sf3+x0TnsWVsS1zGVWN91lp9KYmIHA2FQCIiIkFPIZBIfQoPd+YI6tkTfvvbyu95vbBtmxMMbdgAa9Y4vYi++QZee63ytsY4vYjKQqGKAVHZ84SEhvtcR6DindJGdR0FgLfUi8u4KoUzE/pOAKDEV8KmvZvYsHcD6/esZ3P2ZjL3ZZK5L5O1u9aSEJlA31Z9GdV1FHERcWzL3cbW3K2s3LmSj9d/TIGnoNLPD3eF0y6hHVFhURgMxhi8pV5yi3PJK86jwFNAUmwSyQnJJCckExcRR6GnkAJPQflS6HVex0fE0615N7o170bnpp2Jj4wnKiyK6LBoosOja3we6Y5U0CQioUshkIiIBLHdu3dz+umnA5CZmYnb7SYpKQmAH374gYiD/NE9PT2dV155hccff7xBaq1PCoFEAiUsbH+AM2xY5feKiyEjw7k7WdmyZYvzmJ4O770HJSWV92nSpGpAlJy8f2nbFiIjG+zj1cbBhnBFuCPo3qI73Vt0P+zjWmvZU7iHrblb2ZqzlS05W9iau5WM3AxKfCXlw9fCXGEkRCYQHxFPdHg0WflZZOTmfHNwAAAWN0lEQVRlsGnvJgo8BcSExxATHkN0eDSt4lqVhznZRdn8uPNH3l/3Pt7S2t8FJzY8tjxkahPfhubRzWke3Zxm0c0qLTHhMeWB04FBVMXeUQZD+8T29EzqSWqTVNwud/nnL/YVH3XoVOQtwm3chLv1P3UiUgter+YEEhGRoNW8eXOWLVsGwN13301cXByTJ08uf9/r9RJWw/dYWloaaWmhccNTfVOLBKPIyOqHl5UpLXXuXFYxJCoLijZvhnnzIDe36n4tWzqBULt2+8Ohdu2c9c2aOUurVkHfq+hQjDE0j2lO85jm9G/dv95+jsfnYVvetvKwpshbRKG3sMrzssesgiwycjPIyM1g/i/z2VO4h7ySvDqpJdIdSfOY5uwr2Vc+X1NcRFz50LgWMS0Ic4WVhzqJkYk0iWpCk6gmhLnCymvMKc5hza41rNy5kg17NhDuDue4VscxsPVA+rXuR/vE9uV3josJj3HmfbI+XMZFQmTCQYfciUiIU08gERGpreuvB38gU2f694dHHz2sXS6++GKioqJYunQpgwcPZvz48Vx33XUUFRURHR3Niy++SPfu3fn666+ZNm0a//3vf7n77rvZsmULGzduZMuWLVx//fVce+21dftZ6pFCIJFjkcvlDA9r0wZOPrn6bXJynOFmGRnOUvH5L7848xLt3l39vk2bOpNWp6Y6oVCLFpWX5s33P6/nO54Fs3B3OB2bdDyqY3h8HrKLstlTuKd8yffkEx0WXd4TqWKPpIq9e7ylXjbt3cSaXWtYk7WG3YW7iY+IJz4ynuiwaHbm72RrrtMT6uc9P+Mr9eEt9VLiKyGnOKd8ou6K3MZN1+Zd6deqHxP7TKTAU8CSzCW8ufpNZiyZcdDPYvDPJRXVFJdxUeIrwVPqocRXUr54fB6aRDWhXUI72sW3o2l0U0p8JRR7i/GUemgW3Yx28e1oG9+WFjEtKg2l81kfHp9zvLySPLLys9hVsIvsomzaxrctn0S8dVzr8v2iw6LLe0iVKfAUkLkvk5yiHJITkmkR06LGHlO+Uh/5nnzyS5zJ0PM9+RgMXZp1ITYi9gj/q9eOt9TLd1u+w1PqYXDKYKLDo+v154kcNYVAIiJyDMrIyGDBggW43W5yc3OZP38+YWFhfPHFF9x+++288847VfZZu3YtX331FXl5eXTv3p0rr7yS8GPkO1AhkEioSkx0ll69at6msNAJh3btcgKh3bshM3P/BNarVsHXX8OePc4d0KoTHV01JDowKDpwfZRuAV8m3B1OUmwSSbFJR7R/67jWnJJyyhHtW+QtYm/hXnzWVylsOTA0AWeI2fa87WzL28a23G1sy9tGsbe4fE4nn/WRXZTN3sK97Cnag7WWcHc4Ea4IItz7lzBXGHsK9zjHydvGut3riHRHEhkWSbgrnJ92/8S23G2Vhr0dTLgrnITIBHYX1hBo4gwtLPt8BZ4Ccosr95KLi4ijY5OORIVFOUGP/w54+SX5B60jJSGFHi160DquNYmRiSRGJRLhjnDOQ9FecotzaRHdgo5NOtKxSUdaxrbE7XLjMi5KbSlbc7ayYe8GNuzdQLG3mPaJ7Wmf2J7EyETmbprLhz9/yJ7CPYDT02toh6EM7zicpNik8mDQYMqDNpdx0b15d3om9SQqrPLvWKktrbaXlq/Ux878nbSJb1Or8y1yUAqBRESktg6zx059uvDCC3H779Kck5PDpEmT+PnnnzHG4PF4qt3nnHPOITIyksjISFq2bMmOHTtITk5uyLKPmEIgkcYsOhq6dHGWg/H5YO9eJyyquOzeXXXdpk3OY3Z2zceLizt4UHRgkNS8eYPeHa2xiAqLqvX//BtjnN47Ce2gXf3WZa1lb9FedhXsoshbVL64jbs8TIqNiCUpJomEyASMMRR6Ctm4dyMb9m4gKz+r0lC8suF6hd5CosOiaRPfhtZxrUmITCAjN4ONezeyKXsT3lIvqU1SiY2IJTbcv0RUffSWevlp90+s272OdbvWsX7PerKLsskpzikfhtc0qinxkfFk5WeRVZBV83nFkJyQTFRYFB/89AFF3iIAmkY15bzu5zGm+xiiw6L5fOPnfLbhM27/8vZDnr+y3lxRYVHsKtjF7oLdFHoLaRbdjFaxrWgZ25ICTwHb8raRuS+TUltK0R1FRIYF15xhcgzyehUCiYjIMSc2dn/v7r/+9a8MHz6c9957j82bNzPswLlb/SIrzLXqdrvxems/T2igKQQSkUNzu/cHM7Xl8Tg9iKoLig5cfv7ZeaxuHqMyCQmVA6KmTZ3JsA+1JCbqf0qOMcaY8kmyays6PJreLXvTu2Xveqzs4Ky1+KyvyoTn+SX5/JLzC1n5WVgspbYUay3tEtqR2iS1PHyx1rKrYBc783fSvUX3Ssc5u+vZAGQXZZffza7AU4DFEuGOINwVjqfUw5qsNazYsYKVWSvxlnrp37o/LaJbEBMew66CXezI38GO/B00jW5Kn5Z9aBfvBHultrThTpSELo9HE0OLiMgxLScnh3btnL94vvTSS4Etpp7om1pE6kd4uDOfUKtWtd+npKT60OjAdZmZsHat09soO9uZKPtgYmNrFxjFx1dd4uKcx+ho0O3d5SCMMYSZql+rsRGx9ErqBYcY8WeMOeTQwLLJvGvSp2UfLux9Ya1rFqlTGg4mIiLHuFtuuYVJkyZx//33c8455wS6nHphbE3zfNSztLQ0m56eHpCfLSIhxFrYt29/IHSwZe/equtycg4dIoHTG6osECp7rCkwOtS6+HhnXiSFShLijDGLrbWhcT/VEFJvbbAhQ5wQ6Msv6/7YIiJyzFuzZg09e/YMdBkhp7rzerA2mHoCicixzZj9wUpKyuHvX1q6P0TKy6u87NtXdd2B67OyKq8rrt2ExpVCpUMFRrUJlxQqiUigeTyN+o6RIiIixwKFQCLSuLlcznxDCQl1czyP5/BCpAPXlYVKZesOJ1Q6WGAUF+cMi6u4xMRUfR0T48zp4XY7S1TU/v1dVe8uJSJSThNDi4iIBD2FQCIidSk8HJo1c5a6UFJSNTQ6WIh04LJz5/738/OhsPDIa4mJqRoqRUcfeomJObxtwsPVq0nkWKSJoUVERIKevqlFRIJZRETdhkqlpU4QlJ/vLAUF+5+Xvfb59i9FRfsDpgMfCwqcY+3Z4zyWLWXrfb4jq9Hlql1YFBnp9FQqW+ridWSkejyJHClNDC0iIhL0FAKJiDQmLtf+4V/1zeOpHA4duJSFRYdaDtwuO9t5LC52Qqqyx8LC2k3yfSgREbULjeoqeFIQJaFCIZCIiEjQUwgkIiL1IzzcWepqvqXa8Hr3h0Jly9G+PnBdfr7T+6m69xs6iAoLcwIjl2v/HE7V9aCKitq/ncvlHKfivFCDBmkYjxw9hUAiIiJBTy0+EREJHWFhztIQPZ1qUh9B1IGvCwpg927nZ1nrBE9e7/4gqmyp7ZC8/HyFQHL0vF5dRyIiEtSGDx/ObbfdxllnnVW+7tFHH2XdunU8/fTTVbYfNmwY06ZNIy0tjVGjRvH666/TpEmTStvcfffdxMXFMXny5Bp/7uzZs+nWrRu9evUC4K677mLo0KGMGDGijj5Z7embWkREpC4FQxBVpmxIXlGRExRZ6wRDxcWV54GKjg50pRIK3noLmjYNdBUiIiI1mjBhAjNnzqwUAs2cOZOHHnrokPt+9NFHR/xzZ8+ezbnnnlseAt17771HfKyjpRBIREQkVAViSJ40XqecEugKRETkGHH9J9ezLHNZnR6zf+v+PDry0YNuM27cOO68805KSkqIiIhg8+bNbN++nTfeeIMbb7yRwsJCxo0bxz333FNl344dO5Kenk6LFi144IEHePnll2nZsiUpKSkcf/zxADz33HPMmDGDkpISunTpwquvvsqyZcuYM2cO8+bN4/777+edd97hvvvu49xzz2XcuHHMnTuXyZMn4/V6OeGEE3j66aeJjIykY8eOTJo0iQ8++ACPx8Nbb71Fjx49jvo8aeZJEREREREREQl5zZo148QTT+Tjjz8GnF5AF110EQ888ADp6emsWLGCefPmsWLFihqPsXjxYmbOnMmyZcv46KOPWLRoUfl7F1xwAYsWLWL58uX07NmTF154gUGDBjF69Ggefvhhli1bRufOncu3Lyoq4uKLL2bWrFn8+OOPeL3eSsPSWrRowZIlS7jyyiuZNm1anZwD9QQSERERERERkQZzqB479alsSNiYMWOYOXMmL7zwAm+++SYzZszA6/Xy66+/snr1ao477rhq958/fz5jx44lJiYGgNGjR5e/t3LlSu68806ys7PZt29fpWFn1Vm3bh2pqal069YNgEmTJjF9+nSuv/56wAmVAI4//njefffdo/7soJ5AIiIiIiIiItJIjBkzhrlz57JkyRIKCgpo1qwZ06ZNY+7cuaxYsYJzzjmHoqKiIzr2xRdfzJNPPsmPP/7I3/72tyM+TpnIyEgA3G43Xq/3qI5VRiGQiIiIiIiIiDQKcXFxDB8+nEsvvZQJEyaQm5tLbGwsiYmJ7Nixo3yoWE2GDh3K7NmzKSwsJC8vjw8++KD8vby8PNq0aYPH4+G1114rXx8fH09eXl6VY3Xv3p3Nmzezfv16AF599VVOPfXUOvqk1VMIJCIiIiIiIiKNxoQJE1i+fDkTJkygX79+DBgwgB49ejBx4kQGDx580H0HDhzI7373O/r168fZZ5/NCSecUP7efffdx0knncTgwYMrTeI8fvx4Hn74YQYMGMCGDRvK10dFRfHiiy9y4YUX0rdvX1wuF1dccUXdf+AKjLW2Xn9ATdLS0mx6enpAfraIiIjUP2PMYmttWqDrkMrUBhMRkUBYs2YNPXv2DHQZIae683qwNph6AomIiIiIiIiINAIKgUREREREREREGgGFQCIiIiIiIiJS7wI1HU2oOpLzqRBIREREREREROpVVFQUu3fvVhBUR6y17N69m6ioqMPaL6ye6hERERERERERASA5OZmMjAyysrICXUrIiIqKIjk5+bD2UQgkIiIiIiIiIvUqPDyc1NTUQJfR6NVqOJgxZqQxZp0xZr0x5rZq3o80xszyv7/QGNOxrgsVEREREREREZEjd8gQyBjjBqYDZwO9gAnGmF4HbHYZsNda2wX4FzC1rgsVEREREREREZEjV5ueQCcC6621G621JcBMYMwB24wBXvY/fxs43Rhj6q5MERERERERERE5GrWZE6gdsLXC6wzgpJq2sdZ6jTE5QHNgV8WNjDGXA5f7X+4zxqw7kqJrocWBP1t0Tmqg81KVzkn1dF6q0jmpSueksg6BLkCqWrx48S5jzC/1dHj9DlSlc1I9nZeqdE6q0jmpns5LVTonldXYBmvQiaGttTOAGfX9c4wx6dbatPr+OccSnZPq6bxUpXNSPZ2XqnROqtI5kWOBtTapvo6t34GqdE6qp/NSlc5JVTon1dN5qUrnpPZqMxxsG5BS4XWyf1212xhjwoBEYHddFCgiIiIiIiIiIkevNiHQIqCrMSbVGBMBjAfmHLDNHGCS//k44Etrra27MkVERERERERE5GgccjiYf46fq4FPATfwb2vtKmPMvUC6tXYO8ALwqjFmPbAHJygKpHofcnYM0jmpns5LVTon1dN5qUrnpCqdE2ns9DtQlc5J9XReqtI5qUrnpHo6L1XpnNSSUYcdEREREREREZHQV5vhYCIiIiIiIiIicoxTCCQiIiIiIiIi0giEXAhkjBlpjFlnjFlvjLkt0PUEgjEmxRjzlTFmtTFmlTHmOv/6ZsaYz40xP/sfmwa61oZmjHEbY5YaY/7rf51qjFnov15m+Sc/b1SMMU2MMW8bY9YaY9YYY05p7NeKMeYG/+/OSmPMG8aYqMZ4rRhj/m2M2WmMWVlhXbXXhnE87j8/K4wxAwNXef2p4Zw87P/9WWGMec8Y06TCe1P852SdMeaswFQtUv/U/nKoDVYztcEqU/uremqDqf1VE7XB6k5IhUDGGDcwHTgb6AVMMMb0CmxVAeEFbrLW9gJOBq7yn4fbgLnW2q7AXP/rxuY6YE2F11OBf1lruwB7gcsCUlVgPQZ8Yq3tAfTDOT+N9loxxrQDrgXSrLV9cCbEH0/jvFZeAkYesK6ma+NsoKt/uRx4uoFqbGgvUfWcfA70sdYeB/wETAHw/7s7Hujt3+cp//eUSEhR+6sStcFqpjZYZWp/HUBtsHIvofZXdV5CbbA6EVIhEHAisN5au9FaWwLMBMYEuKYGZ6391Vq7xP88D+dLpR3OuXjZv9nLwPmBqTAwjDHJwDnA8/7XBjgNeNu/SWM8J4nAUJw7/GGtLbHWZtPIrxWcOydGG2PCgBjgVxrhtWKt/Qbnjo8V1XRtjAFesY7vgSbGmDYNU2nDqe6cWGs/s9Z6/S+/B5L9z8cAM621xdbaTcB6nO8pkVCj9pef2mDVUxusMrW/DqrRt8HU/qqe2mB1J9RCoHbA1gqvM/zrGi1jTEdgALAQaGWt/dX/VibQKkBlBcqjwC1Aqf91cyC7wj8cjfF6SQWygBf9XbSfN8bE0oivFWvtNmAasAWn4ZEDLEbXSpmarg39++u4FPjY/1znRBoLXevVUBusErXBKlP7qxpqgx2U2l+HpjZYLYVaCCQVGGPigHeA6621uRXfs9ZawAaksAAwxpwL7LTWLg50LUEmDBgIPG2tHQDkc0DX40Z4rTTF+etBKtAWiKVq11Oh8V0bh2KMuQNnKMhrga5FRAJLbbD91Aarltpf1VAbrHYa47VxKGqDHZ5QC4G2ASkVXif71zU6xphwnMbHa9bad/2rd5R1D/Q/7gxUfQEwGBhtjNmM0039NJyx2E383U2hcV4vGUCGtXah//XbOI2SxnytjAA2WWuzrLUe4F2c66exXytlaro2GvW/v8aYi4Fzgd/7G2fQyM+JNCq61itQG6wKtcGqUvuremqD1UztrxqoDXb4Qi0EWgR09c8gH4EzGdScANfU4PzjrF8A1lhrH6nw1hxgkv/5JOD9hq4tUKy1U6y1ydbajjjXxZfW2t8DXwHj/Js1qnMCYK3NBLYaY7r7V50OrKYRXys4XZBPNsbE+H+Xys5Jo75WKqjp2pgD/Ml/l4qTgZwK3ZZDmjFmJM4wh9HW2oIKb80BxhtjIo0xqTiTNv4QiBpF6pnaX35qg1WlNlhVan/VSG2wmqn9VQ21wY6M2R+WhQZjzCicccdu4N/W2gcCXFKDM8b8BpgP/Mj+sde344xJfxNoD/wCXGStPXDSsZBnjBkGTLbWnmuM6YTzV6lmwFLgD9ba4kDW19CMMf1xJmqMADYCl+AExI32WjHG3AP8Dqdb6VLgzzjjiBvVtWKMeQMYBrQAdgB/A2ZTzbXhb6w9idNtuwC4xFqbHoi661MN52QKEAns9m/2vbX2Cv/2d+CMUffiDAv5+MBjioQCtb8caoMdnNpg+6n9VT21wdT+qonaYHUn5EIgERERERERERGpKtSGg4mIiIiIiIiISDUUAomIiIiIiIiINAIKgUREREREREREGgGFQCIiIiIiIiIijYBCIBERERERERGRRkAhkIiIiIiIiIhII6AQSERERERERESkEfj/1Z1kIEsfTjIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3nPVXnUAGdL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr9kcn-tU2K6"
      },
      "source": [
        "##Number of Filters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pfem_6juU2LB",
        "outputId": "7cc3afea-9890-4a51-ca5a-7dbcaf499f82"
      },
      "source": [
        "Amountfilters = [2,4,8,16,32,128,248,506,784]\n",
        "acc_values = [None] * len(Amountfilters)\n",
        "for filters in range(len(Amountfilters)-1):\n",
        "  mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "  mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model.add(tf.keras.layers.Conv2D(filters=Amountfilters[filters], kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model.summary()\n",
        "\n",
        "  earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "  mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "  loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "  print('Accuracy for the training set: {}'.format(acc))\n",
        "  loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  print('Accuracy for the testing set: {}'.format(acc))\n",
        "  fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "  acc_values[filters]=acc\n",
        "\n",
        "  loss_ax.set_title('Loss')\n",
        "  loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "  loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "  acc_ax.set_title('Accuracy')\n",
        "  acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "  acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "plt.plot(Amountfilters,acc_values) # plotting by columns\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 2)         34        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                15690     \n",
            "=================================================================\n",
            "Total params: 15,724\n",
            "Trainable params: 15,724\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 10s 50ms/step - loss: 1.3883 - accuracy: 0.5885 - val_loss: 0.5843 - val_accuracy: 0.8358\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83583, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.4721 - accuracy: 0.8658 - val_loss: 0.4229 - val_accuracy: 0.8787\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.83583 to 0.87867, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3926 - accuracy: 0.8880 - val_loss: 0.3854 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.87867 to 0.89192, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3645 - accuracy: 0.8965 - val_loss: 0.3636 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89192 to 0.89633, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3485 - accuracy: 0.9005 - val_loss: 0.3550 - val_accuracy: 0.9008\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.89633 to 0.90083, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3386 - accuracy: 0.9029 - val_loss: 0.3465 - val_accuracy: 0.9019\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90083 to 0.90192, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3306 - accuracy: 0.9062 - val_loss: 0.3451 - val_accuracy: 0.9040\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90192 to 0.90400, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3250 - accuracy: 0.9072 - val_loss: 0.3354 - val_accuracy: 0.9076\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.90400 to 0.90758, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3196 - accuracy: 0.9086 - val_loss: 0.3265 - val_accuracy: 0.9103\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.90758 to 0.91033, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3149 - accuracy: 0.9099 - val_loss: 0.3253 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91033\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3119 - accuracy: 0.9108 - val_loss: 0.3286 - val_accuracy: 0.9072\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91033\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3083 - accuracy: 0.9130 - val_loss: 0.3217 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91033 to 0.91133, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 9s 50ms/step - loss: 0.3057 - accuracy: 0.9132 - val_loss: 0.3225 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91133\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.3027 - accuracy: 0.9146 - val_loss: 0.3139 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.91133 to 0.91475, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 9s 50ms/step - loss: 0.3001 - accuracy: 0.9150 - val_loss: 0.3152 - val_accuracy: 0.9132\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91475\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2981 - accuracy: 0.9154 - val_loss: 0.3161 - val_accuracy: 0.9133\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91475\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2956 - accuracy: 0.9162 - val_loss: 0.3091 - val_accuracy: 0.9152\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91475 to 0.91517, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2943 - accuracy: 0.9178 - val_loss: 0.3093 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91517\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2916 - accuracy: 0.9175 - val_loss: 0.3066 - val_accuracy: 0.9162\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.91517 to 0.91625, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2910 - accuracy: 0.9179 - val_loss: 0.3081 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91625\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2885 - accuracy: 0.9186 - val_loss: 0.3051 - val_accuracy: 0.9183\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.91625 to 0.91833, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2873 - accuracy: 0.9191 - val_loss: 0.3067 - val_accuracy: 0.9158\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91833\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2860 - accuracy: 0.9193 - val_loss: 0.3070 - val_accuracy: 0.9126\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91833\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2846 - accuracy: 0.9201 - val_loss: 0.3156 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91833\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2837 - accuracy: 0.9204 - val_loss: 0.3053 - val_accuracy: 0.9143\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91833\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2821 - accuracy: 0.9201 - val_loss: 0.3002 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.91833 to 0.91892, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2814 - accuracy: 0.9202 - val_loss: 0.2950 - val_accuracy: 0.9202\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.91892 to 0.92025, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2802 - accuracy: 0.9208 - val_loss: 0.2953 - val_accuracy: 0.9188\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.92025\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2788 - accuracy: 0.9212 - val_loss: 0.3011 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.92025\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2783 - accuracy: 0.9215 - val_loss: 0.2961 - val_accuracy: 0.9202\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.92025\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2774 - accuracy: 0.9227 - val_loss: 0.3114 - val_accuracy: 0.9129\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.92025\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 9s 50ms/step - loss: 0.2763 - accuracy: 0.9216 - val_loss: 0.2944 - val_accuracy: 0.9192\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.92025\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2756 - accuracy: 0.9225 - val_loss: 0.2953 - val_accuracy: 0.9192\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.92025\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2747 - accuracy: 0.9229 - val_loss: 0.2913 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.92025\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2738 - accuracy: 0.9233 - val_loss: 0.2975 - val_accuracy: 0.9161\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.92025\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2726 - accuracy: 0.9230 - val_loss: 0.2998 - val_accuracy: 0.9167\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.92025\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 9s 49ms/step - loss: 0.2723 - accuracy: 0.9231 - val_loss: 0.2948 - val_accuracy: 0.9157\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.92025\n",
            "Epoch 00037: early stopping\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2803 - accuracy: 0.9217\n",
            "Accuracy for the training set: 0.9217000007629395\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.9241\n",
            "Accuracy for the testing set: 0.9240999817848206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 4)         68        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                31370     \n",
            "=================================================================\n",
            "Total params: 31,438\n",
            "Trainable params: 31,438\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 1.4687 - accuracy: 0.5900 - val_loss: 0.6104 - val_accuracy: 0.8428\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.84283, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.4737 - accuracy: 0.8698 - val_loss: 0.4092 - val_accuracy: 0.8858\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.84283 to 0.88583, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3791 - accuracy: 0.8916 - val_loss: 0.3714 - val_accuracy: 0.8924\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.88583 to 0.89242, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3472 - accuracy: 0.9002 - val_loss: 0.3444 - val_accuracy: 0.9018\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89242 to 0.90175, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3296 - accuracy: 0.9051 - val_loss: 0.3290 - val_accuracy: 0.9078\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90175 to 0.90775, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3177 - accuracy: 0.9081 - val_loss: 0.3192 - val_accuracy: 0.9116\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90775 to 0.91158, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3083 - accuracy: 0.9107 - val_loss: 0.3152 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91158\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 10s 54ms/step - loss: 0.3019 - accuracy: 0.9129 - val_loss: 0.3053 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91158 to 0.91483, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2953 - accuracy: 0.9145 - val_loss: 0.3054 - val_accuracy: 0.9156\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91483 to 0.91558, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2902 - accuracy: 0.9166 - val_loss: 0.2974 - val_accuracy: 0.9181\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91558 to 0.91808, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2849 - accuracy: 0.9184 - val_loss: 0.2962 - val_accuracy: 0.9181\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91808\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2798 - accuracy: 0.9204 - val_loss: 0.2903 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91808 to 0.91992, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2755 - accuracy: 0.9204 - val_loss: 0.2898 - val_accuracy: 0.9197\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91992\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2711 - accuracy: 0.9230 - val_loss: 0.2866 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.91992 to 0.92108, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2666 - accuracy: 0.9233 - val_loss: 0.2803 - val_accuracy: 0.9208\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.92108\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2630 - accuracy: 0.9247 - val_loss: 0.2734 - val_accuracy: 0.9248\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.92108 to 0.92483, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2585 - accuracy: 0.9268 - val_loss: 0.2709 - val_accuracy: 0.9258\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.92483 to 0.92575, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2545 - accuracy: 0.9274 - val_loss: 0.2710 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.92575\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2508 - accuracy: 0.9286 - val_loss: 0.2651 - val_accuracy: 0.9267\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.92575 to 0.92667, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2469 - accuracy: 0.9299 - val_loss: 0.2593 - val_accuracy: 0.9279\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.92667 to 0.92792, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2430 - accuracy: 0.9315 - val_loss: 0.2670 - val_accuracy: 0.9267\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.92792\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2390 - accuracy: 0.9323 - val_loss: 0.2544 - val_accuracy: 0.9295\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.92792 to 0.92950, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2350 - accuracy: 0.9331 - val_loss: 0.2553 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.92950 to 0.93058, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2317 - accuracy: 0.9343 - val_loss: 0.2468 - val_accuracy: 0.9323\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.93058 to 0.93225, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2282 - accuracy: 0.9348 - val_loss: 0.2464 - val_accuracy: 0.9320\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.93225\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.2245 - accuracy: 0.9375 - val_loss: 0.2395 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.93225 to 0.93458, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2207 - accuracy: 0.9382 - val_loss: 0.2391 - val_accuracy: 0.9323\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.93458\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2171 - accuracy: 0.9391 - val_loss: 0.2329 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.93458 to 0.93550, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2137 - accuracy: 0.9395 - val_loss: 0.2280 - val_accuracy: 0.9383\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93550 to 0.93825, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2105 - accuracy: 0.9399 - val_loss: 0.2276 - val_accuracy: 0.9372\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.93825\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.2071 - accuracy: 0.9413 - val_loss: 0.2215 - val_accuracy: 0.9388\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.93825 to 0.93875, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2039 - accuracy: 0.9417 - val_loss: 0.2201 - val_accuracy: 0.9395\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.93875 to 0.93950, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.2009 - accuracy: 0.9425 - val_loss: 0.2197 - val_accuracy: 0.9407\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.93950 to 0.94067, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1977 - accuracy: 0.9440 - val_loss: 0.2167 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.94067 to 0.94075, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1950 - accuracy: 0.9447 - val_loss: 0.2117 - val_accuracy: 0.9410\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.94075 to 0.94100, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1922 - accuracy: 0.9459 - val_loss: 0.2131 - val_accuracy: 0.9402\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.94100\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1891 - accuracy: 0.9464 - val_loss: 0.2078 - val_accuracy: 0.9411\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.94100 to 0.94108, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1866 - accuracy: 0.9467 - val_loss: 0.2037 - val_accuracy: 0.9436\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.94108 to 0.94358, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1842 - accuracy: 0.9474 - val_loss: 0.2065 - val_accuracy: 0.9434\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.94358\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1816 - accuracy: 0.9487 - val_loss: 0.2010 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.94358 to 0.94483, saving model to mnist_conv_best.h5\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1790 - accuracy: 0.9487 - val_loss: 0.1970 - val_accuracy: 0.9452\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.94483 to 0.94517, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 10s 56ms/step - loss: 0.1769 - accuracy: 0.9493 - val_loss: 0.1939 - val_accuracy: 0.9447\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.94517\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1748 - accuracy: 0.9501 - val_loss: 0.1967 - val_accuracy: 0.9432\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.94517\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1724 - accuracy: 0.9506 - val_loss: 0.1910 - val_accuracy: 0.9460\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.94517 to 0.94600, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1703 - accuracy: 0.9514 - val_loss: 0.1891 - val_accuracy: 0.9460\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.94600\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1685 - accuracy: 0.9509 - val_loss: 0.1871 - val_accuracy: 0.9476\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.94600 to 0.94758, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1661 - accuracy: 0.9524 - val_loss: 0.1867 - val_accuracy: 0.9467\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.94758\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1642 - accuracy: 0.9527 - val_loss: 0.1832 - val_accuracy: 0.9477\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.94758 to 0.94767, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1624 - accuracy: 0.9537 - val_loss: 0.1825 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.94767 to 0.94817, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1607 - accuracy: 0.9542 - val_loss: 0.1801 - val_accuracy: 0.9495\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.94817 to 0.94950, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1589 - accuracy: 0.9549 - val_loss: 0.1779 - val_accuracy: 0.9492\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.94950\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1574 - accuracy: 0.9548 - val_loss: 0.1793 - val_accuracy: 0.9500\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.94950 to 0.95000, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1556 - accuracy: 0.9554 - val_loss: 0.1766 - val_accuracy: 0.9512\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.95000 to 0.95117, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1541 - accuracy: 0.9566 - val_loss: 0.1749 - val_accuracy: 0.9517\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.95117 to 0.95167, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1528 - accuracy: 0.9563 - val_loss: 0.1757 - val_accuracy: 0.9519\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.95167 to 0.95192, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1510 - accuracy: 0.9568 - val_loss: 0.1713 - val_accuracy: 0.9516\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.95192\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1494 - accuracy: 0.9579 - val_loss: 0.1702 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.95192\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1480 - accuracy: 0.9575 - val_loss: 0.1692 - val_accuracy: 0.9530\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.95192 to 0.95300, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1464 - accuracy: 0.9584 - val_loss: 0.1662 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.95300 to 0.95317, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1451 - accuracy: 0.9582 - val_loss: 0.1659 - val_accuracy: 0.9536\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.95317 to 0.95358, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1437 - accuracy: 0.9594 - val_loss: 0.1650 - val_accuracy: 0.9539\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.95358 to 0.95392, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1425 - accuracy: 0.9595 - val_loss: 0.1632 - val_accuracy: 0.9544\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.95392 to 0.95442, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1413 - accuracy: 0.9601 - val_loss: 0.1618 - val_accuracy: 0.9549\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.95442 to 0.95492, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1398 - accuracy: 0.9606 - val_loss: 0.1624 - val_accuracy: 0.9554\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.95492 to 0.95542, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1387 - accuracy: 0.9604 - val_loss: 0.1627 - val_accuracy: 0.9535\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.95542\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1373 - accuracy: 0.9609 - val_loss: 0.1579 - val_accuracy: 0.9563\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.95542 to 0.95625, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1362 - accuracy: 0.9610 - val_loss: 0.1577 - val_accuracy: 0.9553\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.95625\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1348 - accuracy: 0.9617 - val_loss: 0.1576 - val_accuracy: 0.9560\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.95625\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1335 - accuracy: 0.9620 - val_loss: 0.1557 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.95625 to 0.95733, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1324 - accuracy: 0.9628 - val_loss: 0.1564 - val_accuracy: 0.9560\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.95733\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1315 - accuracy: 0.9626 - val_loss: 0.1546 - val_accuracy: 0.9575\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.95733 to 0.95750, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1304 - accuracy: 0.9631 - val_loss: 0.1519 - val_accuracy: 0.9563\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.95750\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1293 - accuracy: 0.9635 - val_loss: 0.1512 - val_accuracy: 0.9568\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.95750\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1281 - accuracy: 0.9635 - val_loss: 0.1513 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.95750\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1271 - accuracy: 0.9636 - val_loss: 0.1492 - val_accuracy: 0.9585\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.95750 to 0.95850, saving model to mnist_conv_best.h5\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1261 - accuracy: 0.9643 - val_loss: 0.1475 - val_accuracy: 0.9582\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.95850\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1249 - accuracy: 0.9648 - val_loss: 0.1488 - val_accuracy: 0.9578\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.95850\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1241 - accuracy: 0.9645 - val_loss: 0.1474 - val_accuracy: 0.9593\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.95850 to 0.95933, saving model to mnist_conv_best.h5\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1227 - accuracy: 0.9650 - val_loss: 0.1453 - val_accuracy: 0.9587\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.95933\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1216 - accuracy: 0.9659 - val_loss: 0.1452 - val_accuracy: 0.9577\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.95933\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1209 - accuracy: 0.9657 - val_loss: 0.1454 - val_accuracy: 0.9589\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.95933\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1201 - accuracy: 0.9661 - val_loss: 0.1427 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.95933 to 0.95975, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1190 - accuracy: 0.9665 - val_loss: 0.1423 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00083: val_accuracy improved from 0.95975 to 0.96050, saving model to mnist_conv_best.h5\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1180 - accuracy: 0.9664 - val_loss: 0.1401 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.96050\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1168 - accuracy: 0.9670 - val_loss: 0.1409 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.96050\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 11s 57ms/step - loss: 0.1159 - accuracy: 0.9669 - val_loss: 0.1387 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.96050\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1154 - accuracy: 0.9671 - val_loss: 0.1390 - val_accuracy: 0.9622\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.96050 to 0.96225, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1143 - accuracy: 0.9671 - val_loss: 0.1382 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.96225\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1134 - accuracy: 0.9681 - val_loss: 0.1379 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.96225 to 0.96233, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1125 - accuracy: 0.9678 - val_loss: 0.1375 - val_accuracy: 0.9612\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.96233\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1119 - accuracy: 0.9685 - val_loss: 0.1402 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.96233\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1109 - accuracy: 0.9686 - val_loss: 0.1345 - val_accuracy: 0.9616\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.96233\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1103 - accuracy: 0.9684 - val_loss: 0.1355 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.96233 to 0.96275, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1092 - accuracy: 0.9690 - val_loss: 0.1324 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.96275\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1086 - accuracy: 0.9693 - val_loss: 0.1330 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.96275\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1079 - accuracy: 0.9690 - val_loss: 0.1317 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.96275\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1067 - accuracy: 0.9697 - val_loss: 0.1311 - val_accuracy: 0.9632\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.96275 to 0.96325, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1061 - accuracy: 0.9699 - val_loss: 0.1299 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.96325\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1055 - accuracy: 0.9699 - val_loss: 0.1292 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.96325\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1050 - accuracy: 0.9698 - val_loss: 0.1290 - val_accuracy: 0.9636\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.96325 to 0.96358, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1039 - accuracy: 0.9706 - val_loss: 0.1308 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.96358\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1035 - accuracy: 0.9703 - val_loss: 0.1299 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.96358\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1025 - accuracy: 0.9709 - val_loss: 0.1267 - val_accuracy: 0.9638\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.96358 to 0.96383, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1021 - accuracy: 0.9708 - val_loss: 0.1262 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.96383 to 0.96425, saving model to mnist_conv_best.h5\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1015 - accuracy: 0.9711 - val_loss: 0.1259 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00105: val_accuracy improved from 0.96425 to 0.96467, saving model to mnist_conv_best.h5\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.1004 - accuracy: 0.9714 - val_loss: 0.1248 - val_accuracy: 0.9649\n",
            "\n",
            "Epoch 00106: val_accuracy improved from 0.96467 to 0.96492, saving model to mnist_conv_best.h5\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0998 - accuracy: 0.9714 - val_loss: 0.1242 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.96492\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0992 - accuracy: 0.9717 - val_loss: 0.1247 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.96492 to 0.96517, saving model to mnist_conv_best.h5\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0986 - accuracy: 0.9716 - val_loss: 0.1237 - val_accuracy: 0.9656\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.96517 to 0.96558, saving model to mnist_conv_best.h5\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0979 - accuracy: 0.9724 - val_loss: 0.1233 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.96558\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0973 - accuracy: 0.9725 - val_loss: 0.1225 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.96558 to 0.96592, saving model to mnist_conv_best.h5\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0966 - accuracy: 0.9722 - val_loss: 0.1218 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.96592\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0961 - accuracy: 0.9724 - val_loss: 0.1223 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.96592 to 0.96650, saving model to mnist_conv_best.h5\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0954 - accuracy: 0.9731 - val_loss: 0.1217 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.96650\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0949 - accuracy: 0.9732 - val_loss: 0.1223 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.96650\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0944 - accuracy: 0.9734 - val_loss: 0.1190 - val_accuracy: 0.9666\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.96650 to 0.96658, saving model to mnist_conv_best.h5\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0938 - accuracy: 0.9731 - val_loss: 0.1200 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.96658\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0931 - accuracy: 0.9734 - val_loss: 0.1180 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.96658 to 0.96675, saving model to mnist_conv_best.h5\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0927 - accuracy: 0.9735 - val_loss: 0.1189 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.96675\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0922 - accuracy: 0.9740 - val_loss: 0.1186 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.96675\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0916 - accuracy: 0.9740 - val_loss: 0.1190 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.96675\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0910 - accuracy: 0.9742 - val_loss: 0.1171 - val_accuracy: 0.9671\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.96675 to 0.96708, saving model to mnist_conv_best.h5\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0904 - accuracy: 0.9740 - val_loss: 0.1170 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.96708\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0897 - accuracy: 0.9743 - val_loss: 0.1171 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.96708\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0896 - accuracy: 0.9748 - val_loss: 0.1164 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00125: val_accuracy improved from 0.96708 to 0.96717, saving model to mnist_conv_best.h5\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0889 - accuracy: 0.9750 - val_loss: 0.1148 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.96717\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0886 - accuracy: 0.9751 - val_loss: 0.1153 - val_accuracy: 0.9675\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.96717 to 0.96750, saving model to mnist_conv_best.h5\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0882 - accuracy: 0.9750 - val_loss: 0.1151 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.96750\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0876 - accuracy: 0.9751 - val_loss: 0.1140 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.96750 to 0.96800, saving model to mnist_conv_best.h5\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0870 - accuracy: 0.9750 - val_loss: 0.1137 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.96800\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 0.0866 - accuracy: 0.9752 - val_loss: 0.1137 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.96800\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0859 - accuracy: 0.9758 - val_loss: 0.1143 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.96800\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0857 - accuracy: 0.9756 - val_loss: 0.1141 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.96800\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0853 - accuracy: 0.9757 - val_loss: 0.1129 - val_accuracy: 0.9675\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.96800\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0848 - accuracy: 0.9758 - val_loss: 0.1120 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.96800 to 0.96867, saving model to mnist_conv_best.h5\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0842 - accuracy: 0.9763 - val_loss: 0.1125 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.96867\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0839 - accuracy: 0.9763 - val_loss: 0.1133 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.96867\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0836 - accuracy: 0.9762 - val_loss: 0.1113 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.96867\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0833 - accuracy: 0.9761 - val_loss: 0.1118 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.96867\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0828 - accuracy: 0.9763 - val_loss: 0.1101 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00140: val_accuracy improved from 0.96867 to 0.96900, saving model to mnist_conv_best.h5\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0821 - accuracy: 0.9770 - val_loss: 0.1123 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.96900\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0819 - accuracy: 0.9769 - val_loss: 0.1098 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.96900\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0814 - accuracy: 0.9765 - val_loss: 0.1099 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.96900\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0809 - accuracy: 0.9770 - val_loss: 0.1093 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.96900\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0808 - accuracy: 0.9776 - val_loss: 0.1092 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.96900\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0804 - accuracy: 0.9774 - val_loss: 0.1091 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00146: val_accuracy improved from 0.96900 to 0.96983, saving model to mnist_conv_best.h5\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0800 - accuracy: 0.9772 - val_loss: 0.1082 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.96983\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0796 - accuracy: 0.9775 - val_loss: 0.1099 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.96983\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0794 - accuracy: 0.9769 - val_loss: 0.1083 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.96983\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0788 - accuracy: 0.9774 - val_loss: 0.1078 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.96983\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0787 - accuracy: 0.9779 - val_loss: 0.1073 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.96983\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0782 - accuracy: 0.9781 - val_loss: 0.1071 - val_accuracy: 0.9695\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.96983\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0779 - accuracy: 0.9778 - val_loss: 0.1074 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.96983\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0775 - accuracy: 0.9780 - val_loss: 0.1065 - val_accuracy: 0.9692\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.96983\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0774 - accuracy: 0.9781 - val_loss: 0.1069 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.96983 to 0.97017, saving model to mnist_conv_best.h5\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0767 - accuracy: 0.9786 - val_loss: 0.1059 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00156: val_accuracy improved from 0.97017 to 0.97025, saving model to mnist_conv_best.h5\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0765 - accuracy: 0.9785 - val_loss: 0.1054 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97025\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0762 - accuracy: 0.9786 - val_loss: 0.1065 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.97025\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0758 - accuracy: 0.9784 - val_loss: 0.1061 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.97025\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0756 - accuracy: 0.9791 - val_loss: 0.1061 - val_accuracy: 0.9695\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.97025\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0752 - accuracy: 0.9786 - val_loss: 0.1059 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.97025\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0751 - accuracy: 0.9790 - val_loss: 0.1051 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00162: val_accuracy improved from 0.97025 to 0.97058, saving model to mnist_conv_best.h5\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0747 - accuracy: 0.9791 - val_loss: 0.1074 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.97058\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.0745 - accuracy: 0.9787 - val_loss: 0.1051 - val_accuracy: 0.9700\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.97058\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0740 - accuracy: 0.9788 - val_loss: 0.1051 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.97058\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0738 - accuracy: 0.9790 - val_loss: 0.1040 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.97058\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0734 - accuracy: 0.9792 - val_loss: 0.1058 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.97058\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0732 - accuracy: 0.9793 - val_loss: 0.1042 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.97058\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.1043 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.97058\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0725 - accuracy: 0.9796 - val_loss: 0.1033 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.97058\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0724 - accuracy: 0.9793 - val_loss: 0.1047 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.97058\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0721 - accuracy: 0.9800 - val_loss: 0.1033 - val_accuracy: 0.9710\n",
            "\n",
            "Epoch 00172: val_accuracy improved from 0.97058 to 0.97100, saving model to mnist_conv_best.h5\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0719 - accuracy: 0.9797 - val_loss: 0.1031 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.97100\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0717 - accuracy: 0.9800 - val_loss: 0.1030 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.97100\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0712 - accuracy: 0.9797 - val_loss: 0.1039 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.97100\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0710 - accuracy: 0.9803 - val_loss: 0.1024 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.97100\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0710 - accuracy: 0.9800 - val_loss: 0.1020 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.97100\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0705 - accuracy: 0.9802 - val_loss: 0.1028 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.97100 to 0.97108, saving model to mnist_conv_best.h5\n",
            "Epoch 179/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0704 - accuracy: 0.9798 - val_loss: 0.1018 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00179: val_accuracy improved from 0.97108 to 0.97117, saving model to mnist_conv_best.h5\n",
            "Epoch 180/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0698 - accuracy: 0.9804 - val_loss: 0.1024 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.97117\n",
            "Epoch 181/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0698 - accuracy: 0.9802 - val_loss: 0.1029 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.97117\n",
            "Epoch 182/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0695 - accuracy: 0.9807 - val_loss: 0.1012 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00182: val_accuracy improved from 0.97117 to 0.97142, saving model to mnist_conv_best.h5\n",
            "Epoch 183/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0694 - accuracy: 0.9802 - val_loss: 0.1021 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.97142\n",
            "Epoch 184/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0691 - accuracy: 0.9805 - val_loss: 0.1028 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00184: val_accuracy improved from 0.97142 to 0.97150, saving model to mnist_conv_best.h5\n",
            "Epoch 185/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0688 - accuracy: 0.9806 - val_loss: 0.1013 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.97150\n",
            "Epoch 186/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0687 - accuracy: 0.9806 - val_loss: 0.1010 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.97150\n",
            "Epoch 187/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0683 - accuracy: 0.9806 - val_loss: 0.1019 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.97150\n",
            "Epoch 188/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0680 - accuracy: 0.9808 - val_loss: 0.1018 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.97150\n",
            "Epoch 189/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0677 - accuracy: 0.9811 - val_loss: 0.1014 - val_accuracy: 0.9716\n",
            "\n",
            "Epoch 00189: val_accuracy improved from 0.97150 to 0.97158, saving model to mnist_conv_best.h5\n",
            "Epoch 190/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0677 - accuracy: 0.9809 - val_loss: 0.1000 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.97158\n",
            "Epoch 191/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0674 - accuracy: 0.9809 - val_loss: 0.1004 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00191: val_accuracy improved from 0.97158 to 0.97175, saving model to mnist_conv_best.h5\n",
            "Epoch 192/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0673 - accuracy: 0.9811 - val_loss: 0.1024 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.97175\n",
            "Epoch 193/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0670 - accuracy: 0.9811 - val_loss: 0.1007 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.97175\n",
            "Epoch 194/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0667 - accuracy: 0.9805 - val_loss: 0.1007 - val_accuracy: 0.9716\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.97175\n",
            "Epoch 195/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0667 - accuracy: 0.9813 - val_loss: 0.1008 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.97175\n",
            "Epoch 196/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0663 - accuracy: 0.9813 - val_loss: 0.1009 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.97175\n",
            "Epoch 197/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0661 - accuracy: 0.9816 - val_loss: 0.1003 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.97175\n",
            "Epoch 198/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0657 - accuracy: 0.9818 - val_loss: 0.0997 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.97175\n",
            "Epoch 199/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0657 - accuracy: 0.9812 - val_loss: 0.1003 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.97175\n",
            "Epoch 200/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0656 - accuracy: 0.9815 - val_loss: 0.0991 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00200: val_accuracy improved from 0.97175 to 0.97242, saving model to mnist_conv_best.h5\n",
            "Epoch 201/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0654 - accuracy: 0.9814 - val_loss: 0.0993 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.97242\n",
            "Epoch 202/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0652 - accuracy: 0.9816 - val_loss: 0.1025 - val_accuracy: 0.9710\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.97242\n",
            "Epoch 203/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0650 - accuracy: 0.9819 - val_loss: 0.0994 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00203: val_accuracy improved from 0.97242 to 0.97258, saving model to mnist_conv_best.h5\n",
            "Epoch 204/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0647 - accuracy: 0.9820 - val_loss: 0.0998 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.97258\n",
            "Epoch 205/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0646 - accuracy: 0.9818 - val_loss: 0.0989 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.97258\n",
            "Epoch 206/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0643 - accuracy: 0.9819 - val_loss: 0.0987 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.97258\n",
            "Epoch 207/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0642 - accuracy: 0.9819 - val_loss: 0.0992 - val_accuracy: 0.9716\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.97258\n",
            "Epoch 208/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0640 - accuracy: 0.9818 - val_loss: 0.0988 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.97258\n",
            "Epoch 209/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0639 - accuracy: 0.9820 - val_loss: 0.0996 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.97258\n",
            "Epoch 210/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0635 - accuracy: 0.9820 - val_loss: 0.0986 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.97258\n",
            "Epoch 211/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0633 - accuracy: 0.9824 - val_loss: 0.0993 - val_accuracy: 0.9713\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.97258\n",
            "Epoch 212/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0632 - accuracy: 0.9821 - val_loss: 0.0984 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.97258\n",
            "Epoch 213/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0629 - accuracy: 0.9824 - val_loss: 0.0992 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.97258\n",
            "Epoch 00213: early stopping\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0706 - accuracy: 0.9807\n",
            "Accuracy for the training set: 0.9806666374206543\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0848 - accuracy: 0.9745\n",
            "Accuracy for the testing set: 0.9745000004768372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 8)         136       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                62730     \n",
            "=================================================================\n",
            "Total params: 62,866\n",
            "Trainable params: 62,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 11s 58ms/step - loss: 1.0815 - accuracy: 0.7389 - val_loss: 0.4911 - val_accuracy: 0.8712\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87125, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.4260 - accuracy: 0.8807 - val_loss: 0.3936 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87125 to 0.88792, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.3712 - accuracy: 0.8938 - val_loss: 0.3598 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.88792 to 0.89858, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.3477 - accuracy: 0.9002 - val_loss: 0.3456 - val_accuracy: 0.9025\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89858 to 0.90250, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.3335 - accuracy: 0.9054 - val_loss: 0.3368 - val_accuracy: 0.9053\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90250 to 0.90525, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.3234 - accuracy: 0.9068 - val_loss: 0.3280 - val_accuracy: 0.9082\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90525 to 0.90825, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.3146 - accuracy: 0.9094 - val_loss: 0.3258 - val_accuracy: 0.9071\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.90825\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.3080 - accuracy: 0.9124 - val_loss: 0.3129 - val_accuracy: 0.9133\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.90825 to 0.91333, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.3032 - accuracy: 0.9135 - val_loss: 0.3118 - val_accuracy: 0.9133\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91333\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2984 - accuracy: 0.9147 - val_loss: 0.3066 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91333 to 0.91467, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2951 - accuracy: 0.9160 - val_loss: 0.3029 - val_accuracy: 0.9157\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91467 to 0.91567, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2918 - accuracy: 0.9159 - val_loss: 0.3038 - val_accuracy: 0.9156\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91567\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2887 - accuracy: 0.9171 - val_loss: 0.2993 - val_accuracy: 0.9169\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91567 to 0.91692, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2858 - accuracy: 0.9181 - val_loss: 0.2954 - val_accuracy: 0.9184\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.91692 to 0.91842, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2828 - accuracy: 0.9193 - val_loss: 0.3006 - val_accuracy: 0.9155\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91842\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2804 - accuracy: 0.9202 - val_loss: 0.2916 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.91842 to 0.91875, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2773 - accuracy: 0.9210 - val_loss: 0.2902 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91875 to 0.91992, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2749 - accuracy: 0.9217 - val_loss: 0.2940 - val_accuracy: 0.9192\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91992\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2732 - accuracy: 0.9224 - val_loss: 0.2911 - val_accuracy: 0.9183\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91992\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 11s 59ms/step - loss: 0.2706 - accuracy: 0.9225 - val_loss: 0.2865 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.91992 to 0.92108, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2682 - accuracy: 0.9235 - val_loss: 0.2805 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92108 to 0.92183, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2655 - accuracy: 0.9245 - val_loss: 0.2801 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.92183\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2630 - accuracy: 0.9249 - val_loss: 0.2804 - val_accuracy: 0.9230\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.92183 to 0.92300, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2607 - accuracy: 0.9257 - val_loss: 0.2761 - val_accuracy: 0.9229\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.92300\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2576 - accuracy: 0.9271 - val_loss: 0.2744 - val_accuracy: 0.9235\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.92300 to 0.92350, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2552 - accuracy: 0.9283 - val_loss: 0.2708 - val_accuracy: 0.9251\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.92350 to 0.92508, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2527 - accuracy: 0.9291 - val_loss: 0.2780 - val_accuracy: 0.9235\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.92508\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2504 - accuracy: 0.9293 - val_loss: 0.2719 - val_accuracy: 0.9219\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.92508\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2473 - accuracy: 0.9305 - val_loss: 0.2666 - val_accuracy: 0.9270\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.92508 to 0.92700, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2445 - accuracy: 0.9307 - val_loss: 0.2583 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.92700 to 0.92825, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2414 - accuracy: 0.9314 - val_loss: 0.2553 - val_accuracy: 0.9293\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.92825 to 0.92925, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2384 - accuracy: 0.9327 - val_loss: 0.2558 - val_accuracy: 0.9294\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.92925 to 0.92942, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2350 - accuracy: 0.9343 - val_loss: 0.2546 - val_accuracy: 0.9288\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.92942\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2321 - accuracy: 0.9350 - val_loss: 0.2535 - val_accuracy: 0.9308\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.92942 to 0.93075, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2287 - accuracy: 0.9357 - val_loss: 0.2498 - val_accuracy: 0.9300\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.93075\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2255 - accuracy: 0.9364 - val_loss: 0.2432 - val_accuracy: 0.9354\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.93075 to 0.93542, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2226 - accuracy: 0.9374 - val_loss: 0.2389 - val_accuracy: 0.9338\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.93542\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2187 - accuracy: 0.9389 - val_loss: 0.2363 - val_accuracy: 0.9342\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.93542\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2152 - accuracy: 0.9401 - val_loss: 0.2325 - val_accuracy: 0.9367\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.93542 to 0.93667, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2114 - accuracy: 0.9414 - val_loss: 0.2335 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93667\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2083 - accuracy: 0.9421 - val_loss: 0.2250 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.93667 to 0.93842, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2039 - accuracy: 0.9432 - val_loss: 0.2213 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.93842\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.2006 - accuracy: 0.9439 - val_loss: 0.2185 - val_accuracy: 0.9401\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.93842 to 0.94008, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1971 - accuracy: 0.9457 - val_loss: 0.2154 - val_accuracy: 0.9401\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.94008\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1933 - accuracy: 0.9462 - val_loss: 0.2105 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.94008 to 0.94158, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1900 - accuracy: 0.9478 - val_loss: 0.2086 - val_accuracy: 0.9419\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.94158 to 0.94192, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1865 - accuracy: 0.9482 - val_loss: 0.2032 - val_accuracy: 0.9441\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.94192 to 0.94408, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1831 - accuracy: 0.9493 - val_loss: 0.2028 - val_accuracy: 0.9445\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.94408 to 0.94450, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1793 - accuracy: 0.9503 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.94450 to 0.94517, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1761 - accuracy: 0.9514 - val_loss: 0.1950 - val_accuracy: 0.9438\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.94517\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1729 - accuracy: 0.9522 - val_loss: 0.1932 - val_accuracy: 0.9452\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.94517 to 0.94525, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1693 - accuracy: 0.9532 - val_loss: 0.1894 - val_accuracy: 0.9474\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.94525 to 0.94742, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1661 - accuracy: 0.9538 - val_loss: 0.1855 - val_accuracy: 0.9489\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.94742 to 0.94892, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1630 - accuracy: 0.9553 - val_loss: 0.1813 - val_accuracy: 0.9493\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.94892 to 0.94933, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1598 - accuracy: 0.9560 - val_loss: 0.1801 - val_accuracy: 0.9498\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.94933 to 0.94983, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1569 - accuracy: 0.9569 - val_loss: 0.1761 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.94983 to 0.95092, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1538 - accuracy: 0.9576 - val_loss: 0.1771 - val_accuracy: 0.9510\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.95092 to 0.95100, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1514 - accuracy: 0.9578 - val_loss: 0.1758 - val_accuracy: 0.9520\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.95100 to 0.95200, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1486 - accuracy: 0.9595 - val_loss: 0.1698 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.95200 to 0.95367, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1459 - accuracy: 0.9603 - val_loss: 0.1652 - val_accuracy: 0.9542\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.95367 to 0.95425, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1434 - accuracy: 0.9609 - val_loss: 0.1661 - val_accuracy: 0.9553\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.95425 to 0.95533, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1405 - accuracy: 0.9617 - val_loss: 0.1654 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.95533 to 0.95558, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1384 - accuracy: 0.9624 - val_loss: 0.1584 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.95558 to 0.95733, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1362 - accuracy: 0.9631 - val_loss: 0.1575 - val_accuracy: 0.9580\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.95733 to 0.95800, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1337 - accuracy: 0.9638 - val_loss: 0.1561 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.95800\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1316 - accuracy: 0.9644 - val_loss: 0.1537 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.95800 to 0.95950, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1298 - accuracy: 0.9649 - val_loss: 0.1542 - val_accuracy: 0.9566\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.95950\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1279 - accuracy: 0.9660 - val_loss: 0.1515 - val_accuracy: 0.9596\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.95950 to 0.95958, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1259 - accuracy: 0.9659 - val_loss: 0.1468 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.95958 to 0.96033, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1237 - accuracy: 0.9662 - val_loss: 0.1452 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00070: val_accuracy improved from 0.96033 to 0.96050, saving model to mnist_conv_best.h5\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1218 - accuracy: 0.9676 - val_loss: 0.1436 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.96050 to 0.96167, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.1202 - accuracy: 0.9680 - val_loss: 0.1421 - val_accuracy: 0.9616\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.96167\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1185 - accuracy: 0.9685 - val_loss: 0.1402 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.96167 to 0.96233, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1168 - accuracy: 0.9682 - val_loss: 0.1403 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.96233\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.1154 - accuracy: 0.9689 - val_loss: 0.1367 - val_accuracy: 0.9632\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.96233 to 0.96317, saving model to mnist_conv_best.h5\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1139 - accuracy: 0.9692 - val_loss: 0.1350 - val_accuracy: 0.9632\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.96317 to 0.96325, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1123 - accuracy: 0.9701 - val_loss: 0.1365 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.96325 to 0.96367, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1109 - accuracy: 0.9706 - val_loss: 0.1317 - val_accuracy: 0.9639\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.96367 to 0.96392, saving model to mnist_conv_best.h5\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1096 - accuracy: 0.9703 - val_loss: 0.1320 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.96392 to 0.96425, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1082 - accuracy: 0.9712 - val_loss: 0.1308 - val_accuracy: 0.9649\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.96425 to 0.96492, saving model to mnist_conv_best.h5\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1068 - accuracy: 0.9715 - val_loss: 0.1279 - val_accuracy: 0.9648\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.96492\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1055 - accuracy: 0.9717 - val_loss: 0.1290 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.96492 to 0.96533, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.1043 - accuracy: 0.9722 - val_loss: 0.1283 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.96533\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1033 - accuracy: 0.9724 - val_loss: 0.1266 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.96533 to 0.96592, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1019 - accuracy: 0.9730 - val_loss: 0.1245 - val_accuracy: 0.9666\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.96592 to 0.96658, saving model to mnist_conv_best.h5\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.1009 - accuracy: 0.9728 - val_loss: 0.1228 - val_accuracy: 0.9662\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.96658\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0998 - accuracy: 0.9729 - val_loss: 0.1228 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.96658 to 0.96683, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0985 - accuracy: 0.9736 - val_loss: 0.1226 - val_accuracy: 0.9677\n",
            "\n",
            "Epoch 00088: val_accuracy improved from 0.96683 to 0.96767, saving model to mnist_conv_best.h5\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0977 - accuracy: 0.9735 - val_loss: 0.1204 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.96767\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0965 - accuracy: 0.9743 - val_loss: 0.1224 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.96767\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0955 - accuracy: 0.9745 - val_loss: 0.1191 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.96767\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0948 - accuracy: 0.9748 - val_loss: 0.1179 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.96767 to 0.96792, saving model to mnist_conv_best.h5\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0937 - accuracy: 0.9753 - val_loss: 0.1171 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.96792\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0930 - accuracy: 0.9752 - val_loss: 0.1171 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00094: val_accuracy improved from 0.96792 to 0.96875, saving model to mnist_conv_best.h5\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0921 - accuracy: 0.9752 - val_loss: 0.1152 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.96875\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0911 - accuracy: 0.9759 - val_loss: 0.1149 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.96875\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0905 - accuracy: 0.9757 - val_loss: 0.1139 - val_accuracy: 0.9676\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.96875\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0894 - accuracy: 0.9764 - val_loss: 0.1139 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.96875 to 0.96892, saving model to mnist_conv_best.h5\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0886 - accuracy: 0.9765 - val_loss: 0.1127 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.96892\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0879 - accuracy: 0.9763 - val_loss: 0.1120 - val_accuracy: 0.9684\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.96892\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0871 - accuracy: 0.9767 - val_loss: 0.1152 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.96892\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0865 - accuracy: 0.9771 - val_loss: 0.1104 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.96892 to 0.96967, saving model to mnist_conv_best.h5\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0856 - accuracy: 0.9773 - val_loss: 0.1101 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.96967\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0849 - accuracy: 0.9773 - val_loss: 0.1099 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.96967\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0841 - accuracy: 0.9774 - val_loss: 0.1100 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.96967\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 0.0835 - accuracy: 0.9776 - val_loss: 0.1088 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00106: val_accuracy improved from 0.96967 to 0.97008, saving model to mnist_conv_best.h5\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0827 - accuracy: 0.9778 - val_loss: 0.1090 - val_accuracy: 0.9692\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.97008\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0820 - accuracy: 0.9784 - val_loss: 0.1081 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.97008 to 0.97058, saving model to mnist_conv_best.h5\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0816 - accuracy: 0.9780 - val_loss: 0.1061 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.97058 to 0.97083, saving model to mnist_conv_best.h5\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0809 - accuracy: 0.9781 - val_loss: 0.1067 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.97083\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0803 - accuracy: 0.9787 - val_loss: 0.1060 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.97083\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0796 - accuracy: 0.9787 - val_loss: 0.1054 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.97083\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0790 - accuracy: 0.9787 - val_loss: 0.1044 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.97083 to 0.97142, saving model to mnist_conv_best.h5\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0785 - accuracy: 0.9788 - val_loss: 0.1048 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.97142\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0779 - accuracy: 0.9788 - val_loss: 0.1055 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.97142\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0774 - accuracy: 0.9793 - val_loss: 0.1027 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97142\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0769 - accuracy: 0.9792 - val_loss: 0.1026 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.97142\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0762 - accuracy: 0.9796 - val_loss: 0.1022 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.97142 to 0.97175, saving model to mnist_conv_best.h5\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 0.0756 - accuracy: 0.9797 - val_loss: 0.1015 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97175\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0752 - accuracy: 0.9798 - val_loss: 0.1009 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97175\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0745 - accuracy: 0.9799 - val_loss: 0.1008 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97175\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0742 - accuracy: 0.9797 - val_loss: 0.1003 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.97175 to 0.97192, saving model to mnist_conv_best.h5\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0736 - accuracy: 0.9803 - val_loss: 0.1000 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.97192\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0731 - accuracy: 0.9798 - val_loss: 0.0995 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.97192\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.0999 - val_accuracy: 0.9716\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97192\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0991 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97192\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0716 - accuracy: 0.9805 - val_loss: 0.1000 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.97192 to 0.97217, saving model to mnist_conv_best.h5\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0713 - accuracy: 0.9809 - val_loss: 0.0979 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97217\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0708 - accuracy: 0.9809 - val_loss: 0.0989 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.97217\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.1004 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97217\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0699 - accuracy: 0.9811 - val_loss: 0.0973 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00131: val_accuracy improved from 0.97217 to 0.97275, saving model to mnist_conv_best.h5\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0694 - accuracy: 0.9812 - val_loss: 0.0968 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97275\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0691 - accuracy: 0.9812 - val_loss: 0.0979 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97275\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0970 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97275\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0682 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97275\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0677 - accuracy: 0.9814 - val_loss: 0.0968 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.97275\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0674 - accuracy: 0.9811 - val_loss: 0.0954 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.97275\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0670 - accuracy: 0.9815 - val_loss: 0.0948 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.97275\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0663 - accuracy: 0.9815 - val_loss: 0.0956 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97275\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0662 - accuracy: 0.9817 - val_loss: 0.0943 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00140: val_accuracy improved from 0.97275 to 0.97342, saving model to mnist_conv_best.h5\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0657 - accuracy: 0.9822 - val_loss: 0.0943 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.97342\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0652 - accuracy: 0.9821 - val_loss: 0.0939 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.97342\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0650 - accuracy: 0.9820 - val_loss: 0.0942 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.97342\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0647 - accuracy: 0.9822 - val_loss: 0.0941 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00144: val_accuracy improved from 0.97342 to 0.97350, saving model to mnist_conv_best.h5\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0643 - accuracy: 0.9819 - val_loss: 0.0936 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.97350\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0636 - accuracy: 0.9819 - val_loss: 0.0936 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97350\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0636 - accuracy: 0.9821 - val_loss: 0.0930 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97350\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0631 - accuracy: 0.9824 - val_loss: 0.0925 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00148: val_accuracy improved from 0.97350 to 0.97367, saving model to mnist_conv_best.h5\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.0931 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.97367\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0625 - accuracy: 0.9827 - val_loss: 0.0928 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.97367\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0621 - accuracy: 0.9831 - val_loss: 0.0919 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00151: val_accuracy improved from 0.97367 to 0.97375, saving model to mnist_conv_best.h5\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0619 - accuracy: 0.9828 - val_loss: 0.0919 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97375\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0616 - accuracy: 0.9829 - val_loss: 0.0931 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.97375\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 0.0925 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97375\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0608 - accuracy: 0.9833 - val_loss: 0.0908 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.97375 to 0.97425, saving model to mnist_conv_best.h5\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0605 - accuracy: 0.9832 - val_loss: 0.0917 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.97425\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0601 - accuracy: 0.9837 - val_loss: 0.0906 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97425\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0598 - accuracy: 0.9834 - val_loss: 0.0904 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.97425\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0596 - accuracy: 0.9834 - val_loss: 0.0924 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.97425\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0592 - accuracy: 0.9834 - val_loss: 0.0893 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.97425\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0589 - accuracy: 0.9838 - val_loss: 0.0896 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00161: val_accuracy improved from 0.97425 to 0.97433, saving model to mnist_conv_best.h5\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0586 - accuracy: 0.9837 - val_loss: 0.0895 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.97433\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0584 - accuracy: 0.9838 - val_loss: 0.0888 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.97433\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0580 - accuracy: 0.9841 - val_loss: 0.0899 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.97433\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.0895 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.97433\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 0.0893 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00166: val_accuracy improved from 0.97433 to 0.97475, saving model to mnist_conv_best.h5\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0572 - accuracy: 0.9840 - val_loss: 0.0885 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.97475\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0568 - accuracy: 0.9841 - val_loss: 0.0878 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.97475\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0566 - accuracy: 0.9846 - val_loss: 0.0883 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.97475\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0564 - accuracy: 0.9842 - val_loss: 0.0873 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.97475\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0560 - accuracy: 0.9846 - val_loss: 0.0876 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.97475\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: 0.0879 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00172: val_accuracy improved from 0.97475 to 0.97492, saving model to mnist_conv_best.h5\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0553 - accuracy: 0.9849 - val_loss: 0.0881 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.97492\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0551 - accuracy: 0.9850 - val_loss: 0.0884 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.97492\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0550 - accuracy: 0.9848 - val_loss: 0.0872 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.97492\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0548 - accuracy: 0.9849 - val_loss: 0.0878 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.97492\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0543 - accuracy: 0.9852 - val_loss: 0.0867 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.97492\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0539 - accuracy: 0.9850 - val_loss: 0.0862 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.97492\n",
            "Epoch 179/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0537 - accuracy: 0.9850 - val_loss: 0.0860 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00179: val_accuracy improved from 0.97492 to 0.97533, saving model to mnist_conv_best.h5\n",
            "Epoch 180/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0537 - accuracy: 0.9851 - val_loss: 0.0863 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.97533\n",
            "Epoch 181/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0533 - accuracy: 0.9855 - val_loss: 0.0883 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.97533\n",
            "Epoch 182/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0531 - accuracy: 0.9854 - val_loss: 0.0859 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00182: val_accuracy improved from 0.97533 to 0.97542, saving model to mnist_conv_best.h5\n",
            "Epoch 183/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0530 - accuracy: 0.9854 - val_loss: 0.0863 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00183: val_accuracy improved from 0.97542 to 0.97583, saving model to mnist_conv_best.h5\n",
            "Epoch 184/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0527 - accuracy: 0.9856 - val_loss: 0.0866 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.97583\n",
            "Epoch 185/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.0523 - accuracy: 0.9858 - val_loss: 0.0853 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.97583\n",
            "Epoch 186/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.0522 - accuracy: 0.9857 - val_loss: 0.0859 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.97583\n",
            "Epoch 187/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0518 - accuracy: 0.9861 - val_loss: 0.0860 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.97583\n",
            "Epoch 188/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.0516 - accuracy: 0.9859 - val_loss: 0.0856 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.97583\n",
            "Epoch 189/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0513 - accuracy: 0.9856 - val_loss: 0.0866 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.97583\n",
            "Epoch 190/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0513 - accuracy: 0.9864 - val_loss: 0.0847 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.97583\n",
            "Epoch 191/10000\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0510 - accuracy: 0.9860 - val_loss: 0.0852 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.97583\n",
            "Epoch 192/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.0506 - accuracy: 0.9862 - val_loss: 0.0849 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.97583\n",
            "Epoch 193/10000\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.0505 - accuracy: 0.9860 - val_loss: 0.0846 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.97583\n",
            "Epoch 00193: early stopping\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0591 - accuracy: 0.9838\n",
            "Accuracy for the training set: 0.9837999939918518\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0702 - accuracy: 0.9778\n",
            "Accuracy for the testing set: 0.9778000116348267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,722\n",
            "Trainable params: 125,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 1.0345 - accuracy: 0.7682 - val_loss: 0.4805 - val_accuracy: 0.8715\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87150, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.4208 - accuracy: 0.8823 - val_loss: 0.3884 - val_accuracy: 0.8899\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87150 to 0.88992, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.3689 - accuracy: 0.8942 - val_loss: 0.3650 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.88992 to 0.89617, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.3463 - accuracy: 0.9006 - val_loss: 0.3460 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89617 to 0.90150, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.3320 - accuracy: 0.9039 - val_loss: 0.3390 - val_accuracy: 0.9027\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90150 to 0.90267, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.3214 - accuracy: 0.9075 - val_loss: 0.3256 - val_accuracy: 0.9083\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90267 to 0.90833, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.3137 - accuracy: 0.9095 - val_loss: 0.3215 - val_accuracy: 0.9095\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90833 to 0.90950, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.3074 - accuracy: 0.9114 - val_loss: 0.3147 - val_accuracy: 0.9130\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.90950 to 0.91300, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.3025 - accuracy: 0.9130 - val_loss: 0.3111 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91300\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2977 - accuracy: 0.9143 - val_loss: 0.3077 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91300 to 0.91383, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2938 - accuracy: 0.9153 - val_loss: 0.3014 - val_accuracy: 0.9157\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91383 to 0.91567, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.2908 - accuracy: 0.9158 - val_loss: 0.3062 - val_accuracy: 0.9146\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91567\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.2877 - accuracy: 0.9172 - val_loss: 0.3032 - val_accuracy: 0.9149\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91567\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.2843 - accuracy: 0.9179 - val_loss: 0.3021 - val_accuracy: 0.9181\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.91567 to 0.91808, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.2813 - accuracy: 0.9193 - val_loss: 0.2947 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91808 to 0.92042, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.2777 - accuracy: 0.9207 - val_loss: 0.2939 - val_accuracy: 0.9192\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.92042\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2747 - accuracy: 0.9217 - val_loss: 0.2902 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.92042 to 0.92108, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2719 - accuracy: 0.9232 - val_loss: 0.2847 - val_accuracy: 0.9217\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92108 to 0.92167, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2690 - accuracy: 0.9235 - val_loss: 0.2825 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.92167 to 0.92208, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2660 - accuracy: 0.9245 - val_loss: 0.2784 - val_accuracy: 0.9219\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.92208\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2629 - accuracy: 0.9251 - val_loss: 0.2742 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92208 to 0.92617, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2600 - accuracy: 0.9262 - val_loss: 0.2757 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.92617 to 0.92683, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2564 - accuracy: 0.9266 - val_loss: 0.2692 - val_accuracy: 0.9258\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.92683\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2531 - accuracy: 0.9283 - val_loss: 0.2671 - val_accuracy: 0.9259\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.92683\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2497 - accuracy: 0.9296 - val_loss: 0.2635 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.92683 to 0.92717, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2456 - accuracy: 0.9313 - val_loss: 0.2576 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.92717 to 0.93142, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.2424 - accuracy: 0.9322 - val_loss: 0.2554 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.93142 to 0.93217, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2378 - accuracy: 0.9342 - val_loss: 0.2538 - val_accuracy: 0.9319\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.93217\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2342 - accuracy: 0.9348 - val_loss: 0.2493 - val_accuracy: 0.9304\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.93217\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2306 - accuracy: 0.9355 - val_loss: 0.2445 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.93217 to 0.93325, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2266 - accuracy: 0.9376 - val_loss: 0.2400 - val_accuracy: 0.9339\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.93325 to 0.93392, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2222 - accuracy: 0.9386 - val_loss: 0.2415 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.93392\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2183 - accuracy: 0.9394 - val_loss: 0.2326 - val_accuracy: 0.9381\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.93392 to 0.93808, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2135 - accuracy: 0.9408 - val_loss: 0.2297 - val_accuracy: 0.9370\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.93808\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2099 - accuracy: 0.9416 - val_loss: 0.2241 - val_accuracy: 0.9390\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.93808 to 0.93900, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2058 - accuracy: 0.9431 - val_loss: 0.2224 - val_accuracy: 0.9383\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.93900\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2017 - accuracy: 0.9439 - val_loss: 0.2160 - val_accuracy: 0.9412\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.93900 to 0.94117, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1977 - accuracy: 0.9457 - val_loss: 0.2116 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.94117 to 0.94325, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1938 - accuracy: 0.9472 - val_loss: 0.2097 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.94325\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1899 - accuracy: 0.9481 - val_loss: 0.2059 - val_accuracy: 0.9429\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.94325\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1865 - accuracy: 0.9494 - val_loss: 0.2023 - val_accuracy: 0.9470\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.94325 to 0.94700, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1830 - accuracy: 0.9498 - val_loss: 0.1976 - val_accuracy: 0.9465\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.94700\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1790 - accuracy: 0.9511 - val_loss: 0.1946 - val_accuracy: 0.9476\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.94700 to 0.94758, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1757 - accuracy: 0.9520 - val_loss: 0.1931 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.94758 to 0.94858, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1724 - accuracy: 0.9528 - val_loss: 0.1900 - val_accuracy: 0.9490\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.94858 to 0.94900, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1689 - accuracy: 0.9539 - val_loss: 0.1841 - val_accuracy: 0.9507\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.94900 to 0.95067, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1655 - accuracy: 0.9548 - val_loss: 0.1814 - val_accuracy: 0.9513\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.95067 to 0.95133, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1627 - accuracy: 0.9559 - val_loss: 0.1806 - val_accuracy: 0.9505\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.95133\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1597 - accuracy: 0.9568 - val_loss: 0.1759 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.95133 to 0.95250, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1567 - accuracy: 0.9575 - val_loss: 0.1751 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.95250 to 0.95367, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1537 - accuracy: 0.9581 - val_loss: 0.1715 - val_accuracy: 0.9545\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.95367 to 0.95450, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1511 - accuracy: 0.9596 - val_loss: 0.1702 - val_accuracy: 0.9539\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.95450\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1483 - accuracy: 0.9595 - val_loss: 0.1660 - val_accuracy: 0.9558\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.95450 to 0.95583, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1464 - accuracy: 0.9606 - val_loss: 0.1643 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.95583 to 0.95708, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1438 - accuracy: 0.9610 - val_loss: 0.1625 - val_accuracy: 0.9568\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.95708\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1414 - accuracy: 0.9612 - val_loss: 0.1595 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.95708 to 0.95733, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1391 - accuracy: 0.9623 - val_loss: 0.1601 - val_accuracy: 0.9574\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.95733 to 0.95742, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1369 - accuracy: 0.9630 - val_loss: 0.1567 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.95742 to 0.95792, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1350 - accuracy: 0.9634 - val_loss: 0.1528 - val_accuracy: 0.9593\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.95792 to 0.95933, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1330 - accuracy: 0.9642 - val_loss: 0.1508 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.95933 to 0.96042, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1310 - accuracy: 0.9646 - val_loss: 0.1508 - val_accuracy: 0.9591\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.96042\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1289 - accuracy: 0.9653 - val_loss: 0.1490 - val_accuracy: 0.9592\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.96042\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1273 - accuracy: 0.9653 - val_loss: 0.1475 - val_accuracy: 0.9594\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.96042\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1253 - accuracy: 0.9659 - val_loss: 0.1452 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.96042 to 0.96050, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1237 - accuracy: 0.9661 - val_loss: 0.1482 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.96050\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1222 - accuracy: 0.9671 - val_loss: 0.1444 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.96050\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1204 - accuracy: 0.9678 - val_loss: 0.1406 - val_accuracy: 0.9616\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.96050 to 0.96158, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1191 - accuracy: 0.9684 - val_loss: 0.1385 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.96158 to 0.96233, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1176 - accuracy: 0.9681 - val_loss: 0.1374 - val_accuracy: 0.9631\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.96233 to 0.96308, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1162 - accuracy: 0.9690 - val_loss: 0.1385 - val_accuracy: 0.9618\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.96308\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.1147 - accuracy: 0.9693 - val_loss: 0.1363 - val_accuracy: 0.9622\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.96308\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1135 - accuracy: 0.9696 - val_loss: 0.1346 - val_accuracy: 0.9631\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.96308\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1121 - accuracy: 0.9700 - val_loss: 0.1324 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.96308 to 0.96425, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.1106 - accuracy: 0.9702 - val_loss: 0.1327 - val_accuracy: 0.9638\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.96425\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1095 - accuracy: 0.9709 - val_loss: 0.1325 - val_accuracy: 0.9631\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.96425\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1081 - accuracy: 0.9714 - val_loss: 0.1284 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.96425 to 0.96433, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1069 - accuracy: 0.9714 - val_loss: 0.1290 - val_accuracy: 0.9641\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.96433\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1058 - accuracy: 0.9718 - val_loss: 0.1270 - val_accuracy: 0.9648\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.96433 to 0.96483, saving model to mnist_conv_best.h5\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1046 - accuracy: 0.9718 - val_loss: 0.1257 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.96483 to 0.96508, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.1034 - accuracy: 0.9722 - val_loss: 0.1268 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.96508 to 0.96542, saving model to mnist_conv_best.h5\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1024 - accuracy: 0.9730 - val_loss: 0.1242 - val_accuracy: 0.9661\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.96542 to 0.96608, saving model to mnist_conv_best.h5\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1015 - accuracy: 0.9730 - val_loss: 0.1268 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.96608\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.1003 - accuracy: 0.9734 - val_loss: 0.1238 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.96608\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.0991 - accuracy: 0.9737 - val_loss: 0.1219 - val_accuracy: 0.9666\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.96608 to 0.96658, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.0981 - accuracy: 0.9738 - val_loss: 0.1208 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.96658\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0972 - accuracy: 0.9743 - val_loss: 0.1217 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.96658 to 0.96725, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0962 - accuracy: 0.9741 - val_loss: 0.1186 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.96725 to 0.96733, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.0953 - accuracy: 0.9747 - val_loss: 0.1193 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.96733\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0942 - accuracy: 0.9750 - val_loss: 0.1176 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.96733\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0934 - accuracy: 0.9748 - val_loss: 0.1170 - val_accuracy: 0.9676\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.96733 to 0.96758, saving model to mnist_conv_best.h5\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0924 - accuracy: 0.9755 - val_loss: 0.1154 - val_accuracy: 0.9671\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.96758\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0914 - accuracy: 0.9755 - val_loss: 0.1140 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.96758 to 0.96825, saving model to mnist_conv_best.h5\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0907 - accuracy: 0.9757 - val_loss: 0.1144 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.96825\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0897 - accuracy: 0.9759 - val_loss: 0.1168 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.96825\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0890 - accuracy: 0.9762 - val_loss: 0.1144 - val_accuracy: 0.9677\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.96825\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0883 - accuracy: 0.9768 - val_loss: 0.1119 - val_accuracy: 0.9684\n",
            "\n",
            "Epoch 00096: val_accuracy improved from 0.96825 to 0.96842, saving model to mnist_conv_best.h5\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0874 - accuracy: 0.9769 - val_loss: 0.1110 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.96842 to 0.96900, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0865 - accuracy: 0.9767 - val_loss: 0.1120 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.96900\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0857 - accuracy: 0.9774 - val_loss: 0.1092 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.96900\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0850 - accuracy: 0.9777 - val_loss: 0.1091 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.96900 to 0.96933, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0842 - accuracy: 0.9774 - val_loss: 0.1103 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.96933\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0834 - accuracy: 0.9776 - val_loss: 0.1086 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.96933 to 0.96967, saving model to mnist_conv_best.h5\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0824 - accuracy: 0.9780 - val_loss: 0.1070 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.96967 to 0.96983, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0820 - accuracy: 0.9781 - val_loss: 0.1059 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.96983\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0812 - accuracy: 0.9787 - val_loss: 0.1072 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00105: val_accuracy improved from 0.96983 to 0.97050, saving model to mnist_conv_best.h5\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0806 - accuracy: 0.9786 - val_loss: 0.1052 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97050\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0799 - accuracy: 0.9789 - val_loss: 0.1058 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.97050\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0790 - accuracy: 0.9793 - val_loss: 0.1038 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.97050\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0785 - accuracy: 0.9788 - val_loss: 0.1038 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.97050 to 0.97142, saving model to mnist_conv_best.h5\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0777 - accuracy: 0.9790 - val_loss: 0.1033 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.97142\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0772 - accuracy: 0.9791 - val_loss: 0.1023 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.97142\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0765 - accuracy: 0.9793 - val_loss: 0.1027 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.97142\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0758 - accuracy: 0.9797 - val_loss: 0.1014 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.97142\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0752 - accuracy: 0.9795 - val_loss: 0.1003 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.97142 to 0.97200, saving model to mnist_conv_best.h5\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0746 - accuracy: 0.9804 - val_loss: 0.1015 - val_accuracy: 0.9710\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.97200\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0741 - accuracy: 0.9802 - val_loss: 0.1004 - val_accuracy: 0.9713\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97200\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0734 - accuracy: 0.9801 - val_loss: 0.1010 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.97200\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0730 - accuracy: 0.9804 - val_loss: 0.0990 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.97200 to 0.97267, saving model to mnist_conv_best.h5\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0724 - accuracy: 0.9810 - val_loss: 0.0996 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97267\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0719 - accuracy: 0.9808 - val_loss: 0.0989 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97267\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0710 - accuracy: 0.9809 - val_loss: 0.0976 - val_accuracy: 0.9716\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97267\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.0968 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.97267 to 0.97283, saving model to mnist_conv_best.h5\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0701 - accuracy: 0.9815 - val_loss: 0.0965 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.97283\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0696 - accuracy: 0.9814 - val_loss: 0.0964 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.97283\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0691 - accuracy: 0.9817 - val_loss: 0.0952 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00125: val_accuracy improved from 0.97283 to 0.97317, saving model to mnist_conv_best.h5\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0685 - accuracy: 0.9819 - val_loss: 0.0954 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97317\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0679 - accuracy: 0.9820 - val_loss: 0.0946 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.97317 to 0.97358, saving model to mnist_conv_best.h5\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0675 - accuracy: 0.9819 - val_loss: 0.0948 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97358\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0669 - accuracy: 0.9823 - val_loss: 0.0953 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.97358\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0663 - accuracy: 0.9825 - val_loss: 0.0935 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00130: val_accuracy improved from 0.97358 to 0.97367, saving model to mnist_conv_best.h5\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0661 - accuracy: 0.9827 - val_loss: 0.0926 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97367\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0655 - accuracy: 0.9831 - val_loss: 0.0955 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97367\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0650 - accuracy: 0.9832 - val_loss: 0.0924 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00133: val_accuracy improved from 0.97367 to 0.97408, saving model to mnist_conv_best.h5\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0647 - accuracy: 0.9832 - val_loss: 0.0915 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97408\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0641 - accuracy: 0.9828 - val_loss: 0.0918 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97408\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0636 - accuracy: 0.9832 - val_loss: 0.0926 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.97408\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0631 - accuracy: 0.9836 - val_loss: 0.0904 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00137: val_accuracy improved from 0.97408 to 0.97442, saving model to mnist_conv_best.h5\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0629 - accuracy: 0.9834 - val_loss: 0.0913 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.97442\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0623 - accuracy: 0.9839 - val_loss: 0.0908 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97442\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0619 - accuracy: 0.9835 - val_loss: 0.0915 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97442\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0616 - accuracy: 0.9838 - val_loss: 0.0912 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.97442\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0611 - accuracy: 0.9838 - val_loss: 0.0885 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.97442\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0608 - accuracy: 0.9840 - val_loss: 0.0888 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.97442 to 0.97492, saving model to mnist_conv_best.h5\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0603 - accuracy: 0.9841 - val_loss: 0.0888 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.97492\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0599 - accuracy: 0.9842 - val_loss: 0.0898 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.97492\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0595 - accuracy: 0.9844 - val_loss: 0.0874 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97492\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0591 - accuracy: 0.9846 - val_loss: 0.0891 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97492\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0588 - accuracy: 0.9848 - val_loss: 0.0881 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.97492\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0585 - accuracy: 0.9849 - val_loss: 0.0867 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00149: val_accuracy improved from 0.97492 to 0.97500, saving model to mnist_conv_best.h5\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0581 - accuracy: 0.9847 - val_loss: 0.0863 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00150: val_accuracy improved from 0.97500 to 0.97517, saving model to mnist_conv_best.h5\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0575 - accuracy: 0.9848 - val_loss: 0.0876 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.97517\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0573 - accuracy: 0.9852 - val_loss: 0.0863 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97517\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0568 - accuracy: 0.9853 - val_loss: 0.0861 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00153: val_accuracy improved from 0.97517 to 0.97542, saving model to mnist_conv_best.h5\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0565 - accuracy: 0.9851 - val_loss: 0.0859 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97542\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0562 - accuracy: 0.9854 - val_loss: 0.0852 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.97542 to 0.97550, saving model to mnist_conv_best.h5\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0560 - accuracy: 0.9853 - val_loss: 0.0857 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00156: val_accuracy improved from 0.97550 to 0.97575, saving model to mnist_conv_best.h5\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0556 - accuracy: 0.9855 - val_loss: 0.0850 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97575\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.0840 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00158: val_accuracy improved from 0.97575 to 0.97608, saving model to mnist_conv_best.h5\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0549 - accuracy: 0.9857 - val_loss: 0.0838 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.97608\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0546 - accuracy: 0.9856 - val_loss: 0.0833 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00160: val_accuracy improved from 0.97608 to 0.97625, saving model to mnist_conv_best.h5\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0541 - accuracy: 0.9855 - val_loss: 0.0849 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.97625\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0538 - accuracy: 0.9859 - val_loss: 0.0839 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.97625\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0536 - accuracy: 0.9861 - val_loss: 0.0852 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.97625\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0533 - accuracy: 0.9860 - val_loss: 0.0832 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.97625\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0531 - accuracy: 0.9860 - val_loss: 0.0824 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.97625\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0527 - accuracy: 0.9860 - val_loss: 0.0821 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00166: val_accuracy improved from 0.97625 to 0.97667, saving model to mnist_conv_best.h5\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0524 - accuracy: 0.9860 - val_loss: 0.0828 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.97667\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0522 - accuracy: 0.9861 - val_loss: 0.0823 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.97667\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0519 - accuracy: 0.9865 - val_loss: 0.0820 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.97667\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0514 - accuracy: 0.9866 - val_loss: 0.0823 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.97667\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0512 - accuracy: 0.9864 - val_loss: 0.0821 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.97667\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0510 - accuracy: 0.9866 - val_loss: 0.0817 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00172: val_accuracy improved from 0.97667 to 0.97683, saving model to mnist_conv_best.h5\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0507 - accuracy: 0.9868 - val_loss: 0.0810 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.97683\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0505 - accuracy: 0.9869 - val_loss: 0.0817 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00174: val_accuracy improved from 0.97683 to 0.97717, saving model to mnist_conv_best.h5\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0503 - accuracy: 0.9867 - val_loss: 0.0809 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.97717\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0497 - accuracy: 0.9869 - val_loss: 0.0803 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.97717\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0497 - accuracy: 0.9871 - val_loss: 0.0816 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.97717\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0493 - accuracy: 0.9872 - val_loss: 0.0800 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.97717 to 0.97725, saving model to mnist_conv_best.h5\n",
            "Epoch 179/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0492 - accuracy: 0.9871 - val_loss: 0.0806 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.97725\n",
            "Epoch 180/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0488 - accuracy: 0.9873 - val_loss: 0.0794 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.97725\n",
            "Epoch 181/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0485 - accuracy: 0.9874 - val_loss: 0.0792 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00181: val_accuracy improved from 0.97725 to 0.97758, saving model to mnist_conv_best.h5\n",
            "Epoch 182/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0481 - accuracy: 0.9874 - val_loss: 0.0825 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.97758\n",
            "Epoch 183/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0481 - accuracy: 0.9874 - val_loss: 0.0790 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.97758\n",
            "Epoch 184/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0477 - accuracy: 0.9875 - val_loss: 0.0785 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00184: val_accuracy improved from 0.97758 to 0.97767, saving model to mnist_conv_best.h5\n",
            "Epoch 185/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0476 - accuracy: 0.9876 - val_loss: 0.0794 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.97767\n",
            "Epoch 186/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0472 - accuracy: 0.9878 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00186: val_accuracy improved from 0.97767 to 0.97775, saving model to mnist_conv_best.h5\n",
            "Epoch 187/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0471 - accuracy: 0.9879 - val_loss: 0.0781 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00187: val_accuracy improved from 0.97775 to 0.97792, saving model to mnist_conv_best.h5\n",
            "Epoch 188/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0467 - accuracy: 0.9880 - val_loss: 0.0779 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.97792\n",
            "Epoch 189/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0466 - accuracy: 0.9879 - val_loss: 0.0798 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.97792\n",
            "Epoch 190/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0463 - accuracy: 0.9881 - val_loss: 0.0798 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.97792\n",
            "Epoch 191/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0460 - accuracy: 0.9882 - val_loss: 0.0781 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.97792\n",
            "Epoch 192/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0458 - accuracy: 0.9880 - val_loss: 0.0771 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.97792\n",
            "Epoch 193/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0456 - accuracy: 0.9883 - val_loss: 0.0774 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00193: val_accuracy improved from 0.97792 to 0.97808, saving model to mnist_conv_best.h5\n",
            "Epoch 194/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0454 - accuracy: 0.9881 - val_loss: 0.0773 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.97808\n",
            "Epoch 195/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0453 - accuracy: 0.9881 - val_loss: 0.0781 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.97808\n",
            "Epoch 196/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0450 - accuracy: 0.9883 - val_loss: 0.0770 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.97808\n",
            "Epoch 197/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0447 - accuracy: 0.9885 - val_loss: 0.0762 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.97808\n",
            "Epoch 198/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0445 - accuracy: 0.9886 - val_loss: 0.0768 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.97808\n",
            "Epoch 199/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0442 - accuracy: 0.9882 - val_loss: 0.0774 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.97808\n",
            "Epoch 200/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0441 - accuracy: 0.9885 - val_loss: 0.0759 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00200: val_accuracy improved from 0.97808 to 0.97825, saving model to mnist_conv_best.h5\n",
            "Epoch 201/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0439 - accuracy: 0.9884 - val_loss: 0.0759 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.97825\n",
            "Epoch 202/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0436 - accuracy: 0.9887 - val_loss: 0.0780 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.97825\n",
            "Epoch 203/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0435 - accuracy: 0.9886 - val_loss: 0.0753 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00203: val_accuracy improved from 0.97825 to 0.97833, saving model to mnist_conv_best.h5\n",
            "Epoch 204/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0431 - accuracy: 0.9888 - val_loss: 0.0754 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00204: val_accuracy improved from 0.97833 to 0.97850, saving model to mnist_conv_best.h5\n",
            "Epoch 205/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0431 - accuracy: 0.9889 - val_loss: 0.0766 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.97850\n",
            "Epoch 206/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0429 - accuracy: 0.9888 - val_loss: 0.0754 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.97850\n",
            "Epoch 207/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0426 - accuracy: 0.9890 - val_loss: 0.0768 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.97850\n",
            "Epoch 208/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0424 - accuracy: 0.9891 - val_loss: 0.0751 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.97850\n",
            "Epoch 209/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0422 - accuracy: 0.9890 - val_loss: 0.0750 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.97850\n",
            "Epoch 210/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0420 - accuracy: 0.9891 - val_loss: 0.0750 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.97850\n",
            "Epoch 211/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0419 - accuracy: 0.9891 - val_loss: 0.0757 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.97850\n",
            "Epoch 212/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0417 - accuracy: 0.9887 - val_loss: 0.0750 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.97850\n",
            "Epoch 213/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0416 - accuracy: 0.9887 - val_loss: 0.0759 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.97850\n",
            "Epoch 214/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0414 - accuracy: 0.9891 - val_loss: 0.0756 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.97850\n",
            "Epoch 00214: early stopping\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0495 - accuracy: 0.9866\n",
            "Accuracy for the training set: 0.9865666627883911\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0615 - accuracy: 0.9811\n",
            "Accuracy for the testing set: 0.9811000227928162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 32)        544       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                250890    \n",
            "=================================================================\n",
            "Total params: 251,434\n",
            "Trainable params: 251,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 1.0344 - accuracy: 0.7718 - val_loss: 0.4807 - val_accuracy: 0.8704\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87042, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 18s 98ms/step - loss: 0.4175 - accuracy: 0.8838 - val_loss: 0.3860 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87042 to 0.89375, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.3647 - accuracy: 0.8954 - val_loss: 0.3584 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89375 to 0.89658, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.3419 - accuracy: 0.9019 - val_loss: 0.3405 - val_accuracy: 0.9042\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89658 to 0.90417, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.3274 - accuracy: 0.9064 - val_loss: 0.3294 - val_accuracy: 0.9070\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90417 to 0.90700, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.3173 - accuracy: 0.9095 - val_loss: 0.3283 - val_accuracy: 0.9078\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90700 to 0.90783, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.3095 - accuracy: 0.9113 - val_loss: 0.3172 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90783 to 0.91133, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.3028 - accuracy: 0.9129 - val_loss: 0.3139 - val_accuracy: 0.9130\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91133 to 0.91300, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2977 - accuracy: 0.9140 - val_loss: 0.3033 - val_accuracy: 0.9146\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91300 to 0.91458, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2925 - accuracy: 0.9165 - val_loss: 0.3043 - val_accuracy: 0.9153\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91458 to 0.91533, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2884 - accuracy: 0.9175 - val_loss: 0.2985 - val_accuracy: 0.9179\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91533 to 0.91792, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2851 - accuracy: 0.9184 - val_loss: 0.2965 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91792 to 0.91992, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2811 - accuracy: 0.9196 - val_loss: 0.2892 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91992 to 0.92042, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2770 - accuracy: 0.9208 - val_loss: 0.2894 - val_accuracy: 0.9194\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.92042\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2742 - accuracy: 0.9222 - val_loss: 0.2889 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.92042 to 0.92100, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.2707 - accuracy: 0.9223 - val_loss: 0.2836 - val_accuracy: 0.9225\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.92100 to 0.92250, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2667 - accuracy: 0.9239 - val_loss: 0.2800 - val_accuracy: 0.9234\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.92250 to 0.92342, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2623 - accuracy: 0.9250 - val_loss: 0.2734 - val_accuracy: 0.9255\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92342 to 0.92550, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.2594 - accuracy: 0.9265 - val_loss: 0.2717 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.92550\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2547 - accuracy: 0.9278 - val_loss: 0.2694 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.92550 to 0.92717, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2511 - accuracy: 0.9294 - val_loss: 0.2687 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.92717\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.2468 - accuracy: 0.9304 - val_loss: 0.2635 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.92717\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 19s 99ms/step - loss: 0.2429 - accuracy: 0.9318 - val_loss: 0.2595 - val_accuracy: 0.9287\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.92717 to 0.92875, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.2387 - accuracy: 0.9334 - val_loss: 0.2545 - val_accuracy: 0.9316\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.92875 to 0.93158, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.2337 - accuracy: 0.9352 - val_loss: 0.2477 - val_accuracy: 0.9320\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.93158 to 0.93200, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.2296 - accuracy: 0.9357 - val_loss: 0.2476 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.93200\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.2246 - accuracy: 0.9377 - val_loss: 0.2385 - val_accuracy: 0.9348\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.93200 to 0.93483, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.2203 - accuracy: 0.9383 - val_loss: 0.2339 - val_accuracy: 0.9365\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.93483 to 0.93650, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.2157 - accuracy: 0.9398 - val_loss: 0.2304 - val_accuracy: 0.9382\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93650 to 0.93817, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.2104 - accuracy: 0.9414 - val_loss: 0.2241 - val_accuracy: 0.9396\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.93817 to 0.93958, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.2057 - accuracy: 0.9431 - val_loss: 0.2216 - val_accuracy: 0.9390\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.93958\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.2006 - accuracy: 0.9445 - val_loss: 0.2177 - val_accuracy: 0.9401\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.93958 to 0.94008, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1958 - accuracy: 0.9455 - val_loss: 0.2125 - val_accuracy: 0.9425\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.94008 to 0.94250, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1915 - accuracy: 0.9467 - val_loss: 0.2081 - val_accuracy: 0.9442\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.94250 to 0.94425, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1862 - accuracy: 0.9492 - val_loss: 0.2021 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.94425 to 0.94558, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1821 - accuracy: 0.9492 - val_loss: 0.1955 - val_accuracy: 0.9462\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.94558 to 0.94617, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1774 - accuracy: 0.9514 - val_loss: 0.1941 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.94617 to 0.94625, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1728 - accuracy: 0.9525 - val_loss: 0.1873 - val_accuracy: 0.9493\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.94625 to 0.94933, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1690 - accuracy: 0.9540 - val_loss: 0.1833 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.94933 to 0.95017, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1642 - accuracy: 0.9550 - val_loss: 0.1837 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.95017\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1604 - accuracy: 0.9559 - val_loss: 0.1774 - val_accuracy: 0.9523\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.95017 to 0.95225, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1564 - accuracy: 0.9572 - val_loss: 0.1729 - val_accuracy: 0.9538\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.95225 to 0.95383, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1527 - accuracy: 0.9587 - val_loss: 0.1681 - val_accuracy: 0.9546\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.95383 to 0.95458, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1489 - accuracy: 0.9595 - val_loss: 0.1684 - val_accuracy: 0.9541\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.95458\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1454 - accuracy: 0.9607 - val_loss: 0.1620 - val_accuracy: 0.9568\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.95458 to 0.95683, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1421 - accuracy: 0.9617 - val_loss: 0.1572 - val_accuracy: 0.9582\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.95683 to 0.95817, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1387 - accuracy: 0.9625 - val_loss: 0.1544 - val_accuracy: 0.9586\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.95817 to 0.95858, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1358 - accuracy: 0.9633 - val_loss: 0.1533 - val_accuracy: 0.9592\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.95858 to 0.95925, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1326 - accuracy: 0.9640 - val_loss: 0.1512 - val_accuracy: 0.9592\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.95925\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1299 - accuracy: 0.9654 - val_loss: 0.1477 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.95925 to 0.96042, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1270 - accuracy: 0.9661 - val_loss: 0.1458 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.96042\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1243 - accuracy: 0.9670 - val_loss: 0.1428 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.96042 to 0.96167, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1218 - accuracy: 0.9673 - val_loss: 0.1402 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.96167 to 0.96242, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1194 - accuracy: 0.9683 - val_loss: 0.1377 - val_accuracy: 0.9615\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.96242\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1168 - accuracy: 0.9691 - val_loss: 0.1355 - val_accuracy: 0.9645\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.96242 to 0.96450, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1148 - accuracy: 0.9697 - val_loss: 0.1338 - val_accuracy: 0.9638\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.96450\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1126 - accuracy: 0.9702 - val_loss: 0.1323 - val_accuracy: 0.9639\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.96450\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1105 - accuracy: 0.9710 - val_loss: 0.1302 - val_accuracy: 0.9644\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.96450\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.1087 - accuracy: 0.9713 - val_loss: 0.1266 - val_accuracy: 0.9646\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.96450 to 0.96458, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1066 - accuracy: 0.9721 - val_loss: 0.1250 - val_accuracy: 0.9661\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.96458 to 0.96608, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1049 - accuracy: 0.9719 - val_loss: 0.1236 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.96608\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1031 - accuracy: 0.9724 - val_loss: 0.1226 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.96608\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.1016 - accuracy: 0.9733 - val_loss: 0.1213 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.96608 to 0.96733, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.0997 - accuracy: 0.9735 - val_loss: 0.1184 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.96733\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 19s 100ms/step - loss: 0.0983 - accuracy: 0.9741 - val_loss: 0.1168 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.96733\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.0967 - accuracy: 0.9746 - val_loss: 0.1159 - val_accuracy: 0.9671\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.96733\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 19s 101ms/step - loss: 0.0954 - accuracy: 0.9749 - val_loss: 0.1140 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.96733 to 0.96783, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0938 - accuracy: 0.9755 - val_loss: 0.1132 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.96783 to 0.96883, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0927 - accuracy: 0.9758 - val_loss: 0.1117 - val_accuracy: 0.9700\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.96883 to 0.97000, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0912 - accuracy: 0.9759 - val_loss: 0.1125 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.97000\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0900 - accuracy: 0.9765 - val_loss: 0.1112 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.97000\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0886 - accuracy: 0.9771 - val_loss: 0.1105 - val_accuracy: 0.9684\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.97000\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0877 - accuracy: 0.9770 - val_loss: 0.1079 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.97000 to 0.97067, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0864 - accuracy: 0.9772 - val_loss: 0.1063 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.97067\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0853 - accuracy: 0.9775 - val_loss: 0.1059 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.97067 to 0.97167, saving model to mnist_conv_best.h5\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0841 - accuracy: 0.9779 - val_loss: 0.1049 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.97167\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0833 - accuracy: 0.9784 - val_loss: 0.1039 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.97167\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0822 - accuracy: 0.9783 - val_loss: 0.1032 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.97167\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0812 - accuracy: 0.9789 - val_loss: 0.1037 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.97167\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0804 - accuracy: 0.9789 - val_loss: 0.1023 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.97167\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0794 - accuracy: 0.9790 - val_loss: 0.0999 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.97167 to 0.97233, saving model to mnist_conv_best.h5\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0785 - accuracy: 0.9795 - val_loss: 0.0994 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.97233\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0777 - accuracy: 0.9797 - val_loss: 0.0981 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.97233\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0768 - accuracy: 0.9795 - val_loss: 0.0985 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.97233\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0759 - accuracy: 0.9804 - val_loss: 0.0986 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.97233\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0751 - accuracy: 0.9804 - val_loss: 0.0969 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.97233 to 0.97242, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0742 - accuracy: 0.9806 - val_loss: 0.0961 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.97242\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0735 - accuracy: 0.9807 - val_loss: 0.0966 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.97242\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0727 - accuracy: 0.9813 - val_loss: 0.0948 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.97242\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0720 - accuracy: 0.9809 - val_loss: 0.0935 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.97242 to 0.97300, saving model to mnist_conv_best.h5\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0713 - accuracy: 0.9811 - val_loss: 0.0934 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.97300\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0706 - accuracy: 0.9816 - val_loss: 0.0937 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.97300\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0699 - accuracy: 0.9817 - val_loss: 0.0922 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.97300 to 0.97333, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0693 - accuracy: 0.9817 - val_loss: 0.0914 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.97333\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0686 - accuracy: 0.9816 - val_loss: 0.0908 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.97333\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0680 - accuracy: 0.9821 - val_loss: 0.0909 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.97333\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0674 - accuracy: 0.9826 - val_loss: 0.0897 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.97333 to 0.97392, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0668 - accuracy: 0.9825 - val_loss: 0.0896 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.97392\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0662 - accuracy: 0.9822 - val_loss: 0.0894 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.97392\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0655 - accuracy: 0.9826 - val_loss: 0.0894 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.97392\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0649 - accuracy: 0.9827 - val_loss: 0.0887 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.97392\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0644 - accuracy: 0.9832 - val_loss: 0.0876 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.97392\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0640 - accuracy: 0.9832 - val_loss: 0.0879 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.97392 to 0.97408, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0633 - accuracy: 0.9830 - val_loss: 0.0863 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.97408 to 0.97425, saving model to mnist_conv_best.h5\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0628 - accuracy: 0.9836 - val_loss: 0.0866 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.97425\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0624 - accuracy: 0.9835 - val_loss: 0.0856 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97425\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0618 - accuracy: 0.9837 - val_loss: 0.0856 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.97425\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0612 - accuracy: 0.9841 - val_loss: 0.0869 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.97425 to 0.97442, saving model to mnist_conv_best.h5\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0608 - accuracy: 0.9838 - val_loss: 0.0854 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.97442 to 0.97500, saving model to mnist_conv_best.h5\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0603 - accuracy: 0.9841 - val_loss: 0.0848 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.97500\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0598 - accuracy: 0.9843 - val_loss: 0.0839 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.97500 to 0.97550, saving model to mnist_conv_best.h5\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0594 - accuracy: 0.9845 - val_loss: 0.0841 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.97550\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0589 - accuracy: 0.9845 - val_loss: 0.0835 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.97550\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0585 - accuracy: 0.9844 - val_loss: 0.0828 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.97550 to 0.97558, saving model to mnist_conv_best.h5\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0581 - accuracy: 0.9848 - val_loss: 0.0840 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.97558\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0577 - accuracy: 0.9848 - val_loss: 0.0823 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.97558 to 0.97592, saving model to mnist_conv_best.h5\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0571 - accuracy: 0.9850 - val_loss: 0.0836 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.97592 to 0.97608, saving model to mnist_conv_best.h5\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0569 - accuracy: 0.9852 - val_loss: 0.0817 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.97608\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0564 - accuracy: 0.9856 - val_loss: 0.0826 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97608\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0559 - accuracy: 0.9852 - val_loss: 0.0816 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.97608 to 0.97633, saving model to mnist_conv_best.h5\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0556 - accuracy: 0.9854 - val_loss: 0.0806 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00121: val_accuracy improved from 0.97633 to 0.97658, saving model to mnist_conv_best.h5\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0552 - accuracy: 0.9854 - val_loss: 0.0807 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.97658 to 0.97683, saving model to mnist_conv_best.h5\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0547 - accuracy: 0.9858 - val_loss: 0.0811 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.97683\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0544 - accuracy: 0.9857 - val_loss: 0.0807 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.97683\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0539 - accuracy: 0.9860 - val_loss: 0.0812 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97683\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0535 - accuracy: 0.9860 - val_loss: 0.0794 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97683\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0532 - accuracy: 0.9860 - val_loss: 0.0791 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.97683 to 0.97692, saving model to mnist_conv_best.h5\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0527 - accuracy: 0.9860 - val_loss: 0.0808 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97692\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0526 - accuracy: 0.9865 - val_loss: 0.0793 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.97692\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 19s 102ms/step - loss: 0.0521 - accuracy: 0.9863 - val_loss: 0.0796 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97692\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0518 - accuracy: 0.9866 - val_loss: 0.0783 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97692\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0515 - accuracy: 0.9864 - val_loss: 0.0781 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97692\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0511 - accuracy: 0.9866 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00133: val_accuracy improved from 0.97692 to 0.97783, saving model to mnist_conv_best.h5\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0508 - accuracy: 0.9870 - val_loss: 0.0776 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97783\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0504 - accuracy: 0.9870 - val_loss: 0.0780 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97783\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0503 - accuracy: 0.9871 - val_loss: 0.0779 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.97783\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0498 - accuracy: 0.9871 - val_loss: 0.0768 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.97783\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 19s 104ms/step - loss: 0.0495 - accuracy: 0.9870 - val_loss: 0.0781 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.97783\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 20s 104ms/step - loss: 0.0493 - accuracy: 0.9872 - val_loss: 0.0767 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97783\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0489 - accuracy: 0.9875 - val_loss: 0.0781 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97783\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0487 - accuracy: 0.9873 - val_loss: 0.0761 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.97783\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 19s 103ms/step - loss: 0.0483 - accuracy: 0.9874 - val_loss: 0.0766 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.97783\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 19s 104ms/step - loss: 0.0481 - accuracy: 0.9875 - val_loss: 0.0758 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.97783\n",
            "Epoch 00143: early stopping\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0561 - accuracy: 0.9851\n",
            "Accuracy for the training set: 0.9851499795913696\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0633 - accuracy: 0.9806\n",
            "Accuracy for the testing set: 0.9805999994277954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 128)       2176      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1003530   \n",
            "=================================================================\n",
            "Total params: 1,005,706\n",
            "Trainable params: 1,005,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 60s 316ms/step - loss: 1.1063 - accuracy: 0.7720 - val_loss: 0.4910 - val_accuracy: 0.8711\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87108, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.4241 - accuracy: 0.8830 - val_loss: 0.3896 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87108 to 0.89075, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.3669 - accuracy: 0.8947 - val_loss: 0.3630 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89075 to 0.89850, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.3432 - accuracy: 0.9019 - val_loss: 0.3427 - val_accuracy: 0.9023\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89850 to 0.90233, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.3290 - accuracy: 0.9051 - val_loss: 0.3296 - val_accuracy: 0.9092\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90233 to 0.90917, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.3182 - accuracy: 0.9084 - val_loss: 0.3233 - val_accuracy: 0.9072\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.90917\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.3105 - accuracy: 0.9106 - val_loss: 0.3156 - val_accuracy: 0.9114\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90917 to 0.91142, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.3041 - accuracy: 0.9124 - val_loss: 0.3110 - val_accuracy: 0.9124\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91142 to 0.91242, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.2989 - accuracy: 0.9143 - val_loss: 0.3061 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91242 to 0.91542, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 60s 320ms/step - loss: 0.2942 - accuracy: 0.9158 - val_loss: 0.3031 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91542 to 0.91592, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.2903 - accuracy: 0.9166 - val_loss: 0.3123 - val_accuracy: 0.9123\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91592\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 60s 321ms/step - loss: 0.2862 - accuracy: 0.9181 - val_loss: 0.3002 - val_accuracy: 0.9179\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91592 to 0.91792, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.2827 - accuracy: 0.9190 - val_loss: 0.2910 - val_accuracy: 0.9197\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91792 to 0.91975, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.2792 - accuracy: 0.9202 - val_loss: 0.2960 - val_accuracy: 0.9162\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91975\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.2768 - accuracy: 0.9205 - val_loss: 0.2897 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91975\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.2727 - accuracy: 0.9226 - val_loss: 0.2833 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.91975 to 0.92183, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.2697 - accuracy: 0.9232 - val_loss: 0.2819 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.92183\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.2669 - accuracy: 0.9243 - val_loss: 0.2796 - val_accuracy: 0.9238\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92183 to 0.92383, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.2636 - accuracy: 0.9251 - val_loss: 0.2838 - val_accuracy: 0.9220\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.92383\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.2606 - accuracy: 0.9259 - val_loss: 0.2716 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.92383 to 0.92625, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.2568 - accuracy: 0.9271 - val_loss: 0.2708 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.92625\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.2532 - accuracy: 0.9283 - val_loss: 0.2669 - val_accuracy: 0.9271\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.92625 to 0.92708, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.2504 - accuracy: 0.9295 - val_loss: 0.2658 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.92708\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.2467 - accuracy: 0.9305 - val_loss: 0.2617 - val_accuracy: 0.9263\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.92708\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.2426 - accuracy: 0.9313 - val_loss: 0.2587 - val_accuracy: 0.9276\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.92708 to 0.92758, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.2386 - accuracy: 0.9331 - val_loss: 0.2517 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.92758 to 0.93058, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.2343 - accuracy: 0.9351 - val_loss: 0.2486 - val_accuracy: 0.9316\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.93058 to 0.93158, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 61s 325ms/step - loss: 0.2307 - accuracy: 0.9355 - val_loss: 0.2469 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.93158 to 0.93217, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 61s 325ms/step - loss: 0.2263 - accuracy: 0.9373 - val_loss: 0.2439 - val_accuracy: 0.9332\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93217 to 0.93317, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.2221 - accuracy: 0.9379 - val_loss: 0.2372 - val_accuracy: 0.9343\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.93317 to 0.93433, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.2181 - accuracy: 0.9400 - val_loss: 0.2330 - val_accuracy: 0.9367\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.93433 to 0.93675, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.2129 - accuracy: 0.9409 - val_loss: 0.2331 - val_accuracy: 0.9358\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.93675\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.2092 - accuracy: 0.9421 - val_loss: 0.2243 - val_accuracy: 0.9388\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.93675 to 0.93883, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.2042 - accuracy: 0.9437 - val_loss: 0.2196 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.93883 to 0.94000, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.1997 - accuracy: 0.9444 - val_loss: 0.2145 - val_accuracy: 0.9407\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.94000 to 0.94067, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 59s 311ms/step - loss: 0.1957 - accuracy: 0.9464 - val_loss: 0.2095 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.94067 to 0.94275, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.1910 - accuracy: 0.9482 - val_loss: 0.2068 - val_accuracy: 0.9436\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.94275 to 0.94358, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.1864 - accuracy: 0.9489 - val_loss: 0.2009 - val_accuracy: 0.9454\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.94358 to 0.94542, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 58s 311ms/step - loss: 0.1818 - accuracy: 0.9505 - val_loss: 0.1967 - val_accuracy: 0.9467\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.94542 to 0.94667, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.1774 - accuracy: 0.9518 - val_loss: 0.1933 - val_accuracy: 0.9476\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.94667 to 0.94758, saving model to mnist_conv_best.h5\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.1732 - accuracy: 0.9527 - val_loss: 0.1878 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.94758 to 0.95017, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.1689 - accuracy: 0.9537 - val_loss: 0.1923 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.95017\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.1651 - accuracy: 0.9549 - val_loss: 0.1804 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.95017 to 0.95267, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.1611 - accuracy: 0.9563 - val_loss: 0.1764 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.95267 to 0.95292, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.1573 - accuracy: 0.9572 - val_loss: 0.1735 - val_accuracy: 0.9528\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.95292\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.1535 - accuracy: 0.9586 - val_loss: 0.1697 - val_accuracy: 0.9552\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.95292 to 0.95517, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.1497 - accuracy: 0.9595 - val_loss: 0.1653 - val_accuracy: 0.9569\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.95517 to 0.95692, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.1462 - accuracy: 0.9600 - val_loss: 0.1648 - val_accuracy: 0.9548\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.95692\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.1427 - accuracy: 0.9616 - val_loss: 0.1610 - val_accuracy: 0.9572\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.95692 to 0.95717, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.1396 - accuracy: 0.9624 - val_loss: 0.1565 - val_accuracy: 0.9585\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.95717 to 0.95850, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.1365 - accuracy: 0.9634 - val_loss: 0.1528 - val_accuracy: 0.9596\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.95850 to 0.95958, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.1334 - accuracy: 0.9639 - val_loss: 0.1500 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.95958 to 0.96042, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 59s 317ms/step - loss: 0.1306 - accuracy: 0.9649 - val_loss: 0.1476 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.96042\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.1277 - accuracy: 0.9659 - val_loss: 0.1441 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.96042 to 0.96175, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.1250 - accuracy: 0.9669 - val_loss: 0.1409 - val_accuracy: 0.9633\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.96175 to 0.96333, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.1223 - accuracy: 0.9675 - val_loss: 0.1413 - val_accuracy: 0.9627\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.96333\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.1197 - accuracy: 0.9684 - val_loss: 0.1378 - val_accuracy: 0.9638\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.96333 to 0.96383, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.1173 - accuracy: 0.9687 - val_loss: 0.1352 - val_accuracy: 0.9642\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.96383 to 0.96417, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 60s 321ms/step - loss: 0.1151 - accuracy: 0.9697 - val_loss: 0.1361 - val_accuracy: 0.9635\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.96417\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.1129 - accuracy: 0.9702 - val_loss: 0.1313 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.96417 to 0.96475, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 60s 322ms/step - loss: 0.1110 - accuracy: 0.9705 - val_loss: 0.1287 - val_accuracy: 0.9662\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.96475 to 0.96617, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 60s 322ms/step - loss: 0.1090 - accuracy: 0.9715 - val_loss: 0.1268 - val_accuracy: 0.9660\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.96617\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.1067 - accuracy: 0.9722 - val_loss: 0.1261 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.96617 to 0.96692, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 60s 320ms/step - loss: 0.1049 - accuracy: 0.9730 - val_loss: 0.1229 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.96692\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 60s 321ms/step - loss: 0.1029 - accuracy: 0.9732 - val_loss: 0.1208 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.96692 to 0.96775, saving model to mnist_conv_best.h5\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.1012 - accuracy: 0.9735 - val_loss: 0.1229 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.96775\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 60s 321ms/step - loss: 0.0996 - accuracy: 0.9739 - val_loss: 0.1183 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.96775 to 0.96817, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0979 - accuracy: 0.9748 - val_loss: 0.1167 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.96817\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0964 - accuracy: 0.9750 - val_loss: 0.1155 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.96817 to 0.96883, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0948 - accuracy: 0.9756 - val_loss: 0.1147 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.96883\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0935 - accuracy: 0.9757 - val_loss: 0.1136 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.96883\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0920 - accuracy: 0.9762 - val_loss: 0.1123 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.96883 to 0.96908, saving model to mnist_conv_best.h5\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.0907 - accuracy: 0.9765 - val_loss: 0.1098 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.96908 to 0.96983, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.0892 - accuracy: 0.9772 - val_loss: 0.1080 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.96983 to 0.97075, saving model to mnist_conv_best.h5\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0878 - accuracy: 0.9774 - val_loss: 0.1089 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.97075\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.0867 - accuracy: 0.9776 - val_loss: 0.1072 - val_accuracy: 0.9700\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.97075\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 60s 322ms/step - loss: 0.0855 - accuracy: 0.9780 - val_loss: 0.1066 - val_accuracy: 0.9694\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.97075\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 60s 322ms/step - loss: 0.0842 - accuracy: 0.9782 - val_loss: 0.1041 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.97075\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 60s 320ms/step - loss: 0.0833 - accuracy: 0.9784 - val_loss: 0.1040 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.97075\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 60s 320ms/step - loss: 0.0821 - accuracy: 0.9788 - val_loss: 0.1024 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.97075 to 0.97150, saving model to mnist_conv_best.h5\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 61s 322ms/step - loss: 0.0810 - accuracy: 0.9791 - val_loss: 0.1022 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.97150\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 60s 320ms/step - loss: 0.0799 - accuracy: 0.9791 - val_loss: 0.1002 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.97150 to 0.97192, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.0791 - accuracy: 0.9799 - val_loss: 0.0997 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.97192\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 61s 324ms/step - loss: 0.0780 - accuracy: 0.9795 - val_loss: 0.0996 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.97192 to 0.97217, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 61s 324ms/step - loss: 0.0771 - accuracy: 0.9798 - val_loss: 0.0985 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.97217\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 61s 324ms/step - loss: 0.0763 - accuracy: 0.9804 - val_loss: 0.0971 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.97217\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0753 - accuracy: 0.9804 - val_loss: 0.0970 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.97217 to 0.97258, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0745 - accuracy: 0.9809 - val_loss: 0.0956 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00088: val_accuracy improved from 0.97258 to 0.97292, saving model to mnist_conv_best.h5\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.0736 - accuracy: 0.9810 - val_loss: 0.0948 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.97292\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0729 - accuracy: 0.9811 - val_loss: 0.0943 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.97292 to 0.97308, saving model to mnist_conv_best.h5\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0721 - accuracy: 0.9814 - val_loss: 0.0938 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.97308\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0711 - accuracy: 0.9813 - val_loss: 0.0926 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.97308 to 0.97367, saving model to mnist_conv_best.h5\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0704 - accuracy: 0.9817 - val_loss: 0.0925 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.97367\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0697 - accuracy: 0.9819 - val_loss: 0.0921 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.97367\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 60s 321ms/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.0924 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.97367\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0683 - accuracy: 0.9819 - val_loss: 0.0909 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00096: val_accuracy improved from 0.97367 to 0.97375, saving model to mnist_conv_best.h5\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0676 - accuracy: 0.9826 - val_loss: 0.0899 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.97375 to 0.97383, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0671 - accuracy: 0.9823 - val_loss: 0.0903 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.97383\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 58s 311ms/step - loss: 0.0663 - accuracy: 0.9824 - val_loss: 0.0899 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00099: val_accuracy improved from 0.97383 to 0.97400, saving model to mnist_conv_best.h5\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0657 - accuracy: 0.9830 - val_loss: 0.0886 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.97400 to 0.97425, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0650 - accuracy: 0.9831 - val_loss: 0.0884 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00101: val_accuracy improved from 0.97425 to 0.97442, saving model to mnist_conv_best.h5\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0645 - accuracy: 0.9830 - val_loss: 0.0873 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.97442\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.0638 - accuracy: 0.9835 - val_loss: 0.0882 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.97442 to 0.97458, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 58s 311ms/step - loss: 0.0633 - accuracy: 0.9836 - val_loss: 0.0861 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.97458\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 59s 311ms/step - loss: 0.0627 - accuracy: 0.9836 - val_loss: 0.0861 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00105: val_accuracy improved from 0.97458 to 0.97508, saving model to mnist_conv_best.h5\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 58s 311ms/step - loss: 0.0620 - accuracy: 0.9835 - val_loss: 0.0868 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97508\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 59s 311ms/step - loss: 0.0618 - accuracy: 0.9839 - val_loss: 0.0853 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.97508\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.0610 - accuracy: 0.9840 - val_loss: 0.0853 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.97508\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 58s 311ms/step - loss: 0.0605 - accuracy: 0.9841 - val_loss: 0.0838 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.97508\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 58s 309ms/step - loss: 0.0599 - accuracy: 0.9845 - val_loss: 0.0846 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.97508 to 0.97542, saving model to mnist_conv_best.h5\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0596 - accuracy: 0.9845 - val_loss: 0.0832 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.97542 to 0.97550, saving model to mnist_conv_best.h5\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0590 - accuracy: 0.9849 - val_loss: 0.0838 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00112: val_accuracy improved from 0.97550 to 0.97567, saving model to mnist_conv_best.h5\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.0584 - accuracy: 0.9849 - val_loss: 0.0834 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.97567\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.0582 - accuracy: 0.9849 - val_loss: 0.0818 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.97567\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0575 - accuracy: 0.9851 - val_loss: 0.0815 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00115: val_accuracy improved from 0.97567 to 0.97633, saving model to mnist_conv_best.h5\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0572 - accuracy: 0.9852 - val_loss: 0.0815 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97633\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.0567 - accuracy: 0.9853 - val_loss: 0.0822 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.97633\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.0561 - accuracy: 0.9857 - val_loss: 0.0820 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.97633\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0557 - accuracy: 0.9858 - val_loss: 0.0823 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97633\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 59s 311ms/step - loss: 0.0553 - accuracy: 0.9861 - val_loss: 0.0811 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97633\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0549 - accuracy: 0.9859 - val_loss: 0.0803 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97633\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0546 - accuracy: 0.9861 - val_loss: 0.0797 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.97633 to 0.97650, saving model to mnist_conv_best.h5\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0540 - accuracy: 0.9862 - val_loss: 0.0793 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00123: val_accuracy improved from 0.97650 to 0.97667, saving model to mnist_conv_best.h5\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.0536 - accuracy: 0.9862 - val_loss: 0.0789 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.97667 to 0.97675, saving model to mnist_conv_best.h5\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0533 - accuracy: 0.9864 - val_loss: 0.0787 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97675\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0529 - accuracy: 0.9864 - val_loss: 0.0786 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97675\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0525 - accuracy: 0.9869 - val_loss: 0.0782 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.97675 to 0.97708, saving model to mnist_conv_best.h5\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0521 - accuracy: 0.9866 - val_loss: 0.0774 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00128: val_accuracy improved from 0.97708 to 0.97717, saving model to mnist_conv_best.h5\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0518 - accuracy: 0.9867 - val_loss: 0.0779 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.97717 to 0.97725, saving model to mnist_conv_best.h5\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.0514 - accuracy: 0.9870 - val_loss: 0.0770 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97725\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.0511 - accuracy: 0.9869 - val_loss: 0.0767 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97725\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 58s 311ms/step - loss: 0.0506 - accuracy: 0.9871 - val_loss: 0.0772 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97725\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0503 - accuracy: 0.9870 - val_loss: 0.0771 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97725\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0499 - accuracy: 0.9873 - val_loss: 0.0767 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97725\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0497 - accuracy: 0.9874 - val_loss: 0.0758 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97725\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 59s 312ms/step - loss: 0.0493 - accuracy: 0.9875 - val_loss: 0.0760 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00136: val_accuracy improved from 0.97725 to 0.97775, saving model to mnist_conv_best.h5\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0490 - accuracy: 0.9874 - val_loss: 0.0756 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00137: val_accuracy improved from 0.97775 to 0.97825, saving model to mnist_conv_best.h5\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0486 - accuracy: 0.9874 - val_loss: 0.0750 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.97825\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0483 - accuracy: 0.9879 - val_loss: 0.0762 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97825\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0480 - accuracy: 0.9877 - val_loss: 0.0752 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97825\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0477 - accuracy: 0.9879 - val_loss: 0.0750 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.97825\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 61s 324ms/step - loss: 0.0474 - accuracy: 0.9881 - val_loss: 0.0740 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.97825\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0470 - accuracy: 0.9880 - val_loss: 0.0740 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.97825 to 0.97842, saving model to mnist_conv_best.h5\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0468 - accuracy: 0.9881 - val_loss: 0.0739 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.97842\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0465 - accuracy: 0.9882 - val_loss: 0.0740 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.97842\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0463 - accuracy: 0.9884 - val_loss: 0.0740 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97842\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0459 - accuracy: 0.9885 - val_loss: 0.0738 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97842\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 59s 313ms/step - loss: 0.0456 - accuracy: 0.9885 - val_loss: 0.0736 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.97842\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 58s 311ms/step - loss: 0.0454 - accuracy: 0.9886 - val_loss: 0.0744 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00149: val_accuracy improved from 0.97842 to 0.97883, saving model to mnist_conv_best.h5\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0452 - accuracy: 0.9885 - val_loss: 0.0735 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.97883\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0448 - accuracy: 0.9890 - val_loss: 0.0733 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.97883\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0445 - accuracy: 0.9888 - val_loss: 0.0729 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97883\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0443 - accuracy: 0.9888 - val_loss: 0.0729 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00153: val_accuracy improved from 0.97883 to 0.97900, saving model to mnist_conv_best.h5\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0440 - accuracy: 0.9890 - val_loss: 0.0742 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97900\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 60s 320ms/step - loss: 0.0438 - accuracy: 0.9889 - val_loss: 0.0723 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.97900\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 61s 323ms/step - loss: 0.0435 - accuracy: 0.9893 - val_loss: 0.0717 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00156: val_accuracy improved from 0.97900 to 0.97925, saving model to mnist_conv_best.h5\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 61s 322ms/step - loss: 0.0432 - accuracy: 0.9890 - val_loss: 0.0722 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97925\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 60s 322ms/step - loss: 0.0430 - accuracy: 0.9892 - val_loss: 0.0715 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.97925\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 61s 323ms/step - loss: 0.0427 - accuracy: 0.9892 - val_loss: 0.0716 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.97925\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.0424 - accuracy: 0.9892 - val_loss: 0.0717 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.97925\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 60s 319ms/step - loss: 0.0423 - accuracy: 0.9896 - val_loss: 0.0713 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.97925\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0420 - accuracy: 0.9893 - val_loss: 0.0711 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.97925\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0417 - accuracy: 0.9896 - val_loss: 0.0718 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.97925\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0414 - accuracy: 0.9896 - val_loss: 0.0713 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.97925\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0412 - accuracy: 0.9896 - val_loss: 0.0708 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.97925\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0410 - accuracy: 0.9895 - val_loss: 0.0704 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00166: val_accuracy improved from 0.97925 to 0.97942, saving model to mnist_conv_best.h5\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0407 - accuracy: 0.9897 - val_loss: 0.0704 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.97942\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0406 - accuracy: 0.9895 - val_loss: 0.0706 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00168: val_accuracy improved from 0.97942 to 0.97975, saving model to mnist_conv_best.h5\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0404 - accuracy: 0.9896 - val_loss: 0.0704 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.97975\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0401 - accuracy: 0.9899 - val_loss: 0.0702 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.97975\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 59s 315ms/step - loss: 0.0399 - accuracy: 0.9899 - val_loss: 0.0712 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.97975\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 59s 314ms/step - loss: 0.0397 - accuracy: 0.9900 - val_loss: 0.0699 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.97975\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 59s 316ms/step - loss: 0.0395 - accuracy: 0.9898 - val_loss: 0.0705 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.97975\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.0392 - accuracy: 0.9901 - val_loss: 0.0700 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.97975\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 60s 321ms/step - loss: 0.0392 - accuracy: 0.9899 - val_loss: 0.0702 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.97975\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 60s 320ms/step - loss: 0.0388 - accuracy: 0.9900 - val_loss: 0.0704 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.97975\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 60s 318ms/step - loss: 0.0386 - accuracy: 0.9900 - val_loss: 0.0697 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.97975\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 60s 317ms/step - loss: 0.0385 - accuracy: 0.9903 - val_loss: 0.0698 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.97975\n",
            "Epoch 00178: early stopping\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0461 - accuracy: 0.9877\n",
            "Accuracy for the training set: 0.987666666507721\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0574 - accuracy: 0.9824\n",
            "Accuracy for the testing set: 0.9824000000953674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 248)       4216      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 194432)            0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1944330   \n",
            "=================================================================\n",
            "Total params: 1,948,546\n",
            "Trainable params: 1,948,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 84s 441ms/step - loss: 1.1057 - accuracy: 0.7707 - val_loss: 0.4864 - val_accuracy: 0.8726\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87258, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 82s 437ms/step - loss: 0.4216 - accuracy: 0.8833 - val_loss: 0.3860 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87258 to 0.89167, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 82s 436ms/step - loss: 0.3658 - accuracy: 0.8957 - val_loss: 0.3554 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89167 to 0.89858, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 82s 436ms/step - loss: 0.3421 - accuracy: 0.9020 - val_loss: 0.3382 - val_accuracy: 0.9042\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89858 to 0.90417, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 82s 436ms/step - loss: 0.3279 - accuracy: 0.9060 - val_loss: 0.3283 - val_accuracy: 0.9088\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90417 to 0.90883, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 82s 436ms/step - loss: 0.3175 - accuracy: 0.9084 - val_loss: 0.3230 - val_accuracy: 0.9100\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90883 to 0.91000, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 82s 438ms/step - loss: 0.3094 - accuracy: 0.9110 - val_loss: 0.3223 - val_accuracy: 0.9103\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.91000 to 0.91025, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 83s 440ms/step - loss: 0.3041 - accuracy: 0.9125 - val_loss: 0.3159 - val_accuracy: 0.9114\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91025 to 0.91142, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 82s 436ms/step - loss: 0.2981 - accuracy: 0.9145 - val_loss: 0.3069 - val_accuracy: 0.9151\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91142 to 0.91508, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 82s 436ms/step - loss: 0.2943 - accuracy: 0.9154 - val_loss: 0.3065 - val_accuracy: 0.9151\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91508\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 82s 438ms/step - loss: 0.2894 - accuracy: 0.9169 - val_loss: 0.2978 - val_accuracy: 0.9186\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91508 to 0.91858, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 82s 437ms/step - loss: 0.2863 - accuracy: 0.9182 - val_loss: 0.2956 - val_accuracy: 0.9177\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91858\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 82s 437ms/step - loss: 0.2822 - accuracy: 0.9196 - val_loss: 0.2910 - val_accuracy: 0.9202\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91858 to 0.92017, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 82s 437ms/step - loss: 0.2789 - accuracy: 0.9208 - val_loss: 0.2886 - val_accuracy: 0.9207\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.92017 to 0.92067, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 82s 437ms/step - loss: 0.2755 - accuracy: 0.9219 - val_loss: 0.2885 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.92067\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 82s 436ms/step - loss: 0.2717 - accuracy: 0.9222 - val_loss: 0.2817 - val_accuracy: 0.9224\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.92067 to 0.92242, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 82s 436ms/step - loss: 0.2685 - accuracy: 0.9236 - val_loss: 0.2852 - val_accuracy: 0.9216\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.92242\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 82s 437ms/step - loss: 0.2651 - accuracy: 0.9247 - val_loss: 0.2801 - val_accuracy: 0.9228\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92242 to 0.92283, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            " 87/188 [============>.................] - ETA: 41s - loss: 0.2625 - accuracy: 0.9253"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E18W8f2JU2LF",
        "outputId": "1104278a-d9d5-4d13-b741-31b1c5b768f3"
      },
      "source": [
        "Amountfilters = [248,506,784]\n",
        "acc_values = [None] * len(Amountfilters)\n",
        "for filters in range(len(Amountfilters)-1):\n",
        "  mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "  mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  mnist_conv_model.add(tf.keras.layers.Conv2D(filters=Amountfilters[filters], kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "  mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  mnist_conv_model.summary()\n",
        "\n",
        "  earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "  mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "  mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "  loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "  print('Accuracy for the training set: {}'.format(acc))\n",
        "  loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "  print('Accuracy for the testing set: {}'.format(acc))\n",
        "  fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "  acc_values[filters]=acc\n",
        "\n",
        "  loss_ax.set_title('Loss')\n",
        "  loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "  loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "  acc_ax.set_title('Accuracy')\n",
        "  acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "  acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "plt.plot(Amountfilters,acc_values) # plotting by columns\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 248)       4216      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 194432)            0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1944330   \n",
            "=================================================================\n",
            "Total params: 1,948,546\n",
            "Trainable params: 1,948,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 1.0502 - accuracy: 0.7888 - val_loss: 0.4795 - val_accuracy: 0.8739\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87392, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.4180 - accuracy: 0.8843 - val_loss: 0.3883 - val_accuracy: 0.8901\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87392 to 0.89008, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.3648 - accuracy: 0.8953 - val_loss: 0.3575 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89008 to 0.89775, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.3422 - accuracy: 0.9019 - val_loss: 0.3436 - val_accuracy: 0.9013\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89775 to 0.90133, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.3276 - accuracy: 0.9061 - val_loss: 0.3294 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90133 to 0.90892, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.3175 - accuracy: 0.9087 - val_loss: 0.3209 - val_accuracy: 0.9095\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90892 to 0.90950, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.3097 - accuracy: 0.9118 - val_loss: 0.3187 - val_accuracy: 0.9112\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90950 to 0.91117, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.3032 - accuracy: 0.9126 - val_loss: 0.3111 - val_accuracy: 0.9120\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91117 to 0.91200, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.2982 - accuracy: 0.9144 - val_loss: 0.3067 - val_accuracy: 0.9142\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91200 to 0.91417, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.2929 - accuracy: 0.9157 - val_loss: 0.3011 - val_accuracy: 0.9156\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91417 to 0.91558, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.2893 - accuracy: 0.9162 - val_loss: 0.2990 - val_accuracy: 0.9175\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91558 to 0.91750, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.2852 - accuracy: 0.9182 - val_loss: 0.2977 - val_accuracy: 0.9169\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91750\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.2815 - accuracy: 0.9195 - val_loss: 0.2923 - val_accuracy: 0.9193\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91750 to 0.91933, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2780 - accuracy: 0.9203 - val_loss: 0.2963 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91933\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2743 - accuracy: 0.9212 - val_loss: 0.2843 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91933 to 0.92117, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.2713 - accuracy: 0.9231 - val_loss: 0.2868 - val_accuracy: 0.9213\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.92117 to 0.92133, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2676 - accuracy: 0.9242 - val_loss: 0.2924 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.92133\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2640 - accuracy: 0.9248 - val_loss: 0.2785 - val_accuracy: 0.9238\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92133 to 0.92383, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.2608 - accuracy: 0.9268 - val_loss: 0.2746 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.92383 to 0.92467, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2573 - accuracy: 0.9272 - val_loss: 0.2745 - val_accuracy: 0.9239\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.92467\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2533 - accuracy: 0.9281 - val_loss: 0.2694 - val_accuracy: 0.9256\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92467 to 0.92558, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2503 - accuracy: 0.9299 - val_loss: 0.2637 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.92558 to 0.92683, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2459 - accuracy: 0.9308 - val_loss: 0.2575 - val_accuracy: 0.9298\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.92683 to 0.92975, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2417 - accuracy: 0.9324 - val_loss: 0.2615 - val_accuracy: 0.9273\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.92975\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.2376 - accuracy: 0.9335 - val_loss: 0.2656 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.92975\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.2336 - accuracy: 0.9342 - val_loss: 0.2494 - val_accuracy: 0.9319\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.92975 to 0.93192, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 88s 470ms/step - loss: 0.2292 - accuracy: 0.9359 - val_loss: 0.2431 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.93192 to 0.93333, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.2246 - accuracy: 0.9371 - val_loss: 0.2407 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.93333 to 0.93367, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.2205 - accuracy: 0.9382 - val_loss: 0.2373 - val_accuracy: 0.9350\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93367 to 0.93500, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.2159 - accuracy: 0.9401 - val_loss: 0.2302 - val_accuracy: 0.9372\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.93500 to 0.93717, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.2110 - accuracy: 0.9419 - val_loss: 0.2271 - val_accuracy: 0.9380\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.93717 to 0.93800, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.2060 - accuracy: 0.9427 - val_loss: 0.2215 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.93800 to 0.94158, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 90s 477ms/step - loss: 0.2015 - accuracy: 0.9444 - val_loss: 0.2218 - val_accuracy: 0.9388\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.94158\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 90s 479ms/step - loss: 0.1972 - accuracy: 0.9455 - val_loss: 0.2120 - val_accuracy: 0.9429\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.94158 to 0.94292, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 90s 480ms/step - loss: 0.1922 - accuracy: 0.9473 - val_loss: 0.2074 - val_accuracy: 0.9440\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.94292 to 0.94400, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 89s 476ms/step - loss: 0.1875 - accuracy: 0.9484 - val_loss: 0.2095 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.94400\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 90s 477ms/step - loss: 0.1830 - accuracy: 0.9496 - val_loss: 0.1994 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.94400 to 0.94558, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 89s 473ms/step - loss: 0.1784 - accuracy: 0.9511 - val_loss: 0.1961 - val_accuracy: 0.9461\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.94558 to 0.94608, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 89s 472ms/step - loss: 0.1746 - accuracy: 0.9517 - val_loss: 0.1909 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.94608 to 0.94733, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 90s 477ms/step - loss: 0.1702 - accuracy: 0.9532 - val_loss: 0.1876 - val_accuracy: 0.9491\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.94733 to 0.94908, saving model to mnist_conv_best.h5\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 90s 480ms/step - loss: 0.1661 - accuracy: 0.9544 - val_loss: 0.1835 - val_accuracy: 0.9491\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.94908\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 89s 476ms/step - loss: 0.1623 - accuracy: 0.9553 - val_loss: 0.1822 - val_accuracy: 0.9488\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.94908\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 90s 480ms/step - loss: 0.1583 - accuracy: 0.9564 - val_loss: 0.1740 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.94908 to 0.95317, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 90s 479ms/step - loss: 0.1542 - accuracy: 0.9580 - val_loss: 0.1712 - val_accuracy: 0.9538\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.95317 to 0.95375, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.1508 - accuracy: 0.9594 - val_loss: 0.1673 - val_accuracy: 0.9550\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.95375 to 0.95500, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.1472 - accuracy: 0.9602 - val_loss: 0.1658 - val_accuracy: 0.9550\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.95500\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.1439 - accuracy: 0.9610 - val_loss: 0.1632 - val_accuracy: 0.9559\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.95500 to 0.95592, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.1403 - accuracy: 0.9623 - val_loss: 0.1564 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.95592 to 0.95875, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.1372 - accuracy: 0.9629 - val_loss: 0.1541 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.95875\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 88s 467ms/step - loss: 0.1344 - accuracy: 0.9638 - val_loss: 0.1514 - val_accuracy: 0.9602\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.95875 to 0.96017, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 87s 465ms/step - loss: 0.1314 - accuracy: 0.9650 - val_loss: 0.1476 - val_accuracy: 0.9612\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.96017 to 0.96117, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 88s 466ms/step - loss: 0.1285 - accuracy: 0.9660 - val_loss: 0.1473 - val_accuracy: 0.9609\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.96117\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 88s 471ms/step - loss: 0.1257 - accuracy: 0.9668 - val_loss: 0.1451 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.96117 to 0.96200, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 89s 472ms/step - loss: 0.1234 - accuracy: 0.9672 - val_loss: 0.1418 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.96200\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.1208 - accuracy: 0.9680 - val_loss: 0.1381 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.96200 to 0.96242, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.1185 - accuracy: 0.9684 - val_loss: 0.1360 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.96242 to 0.96300, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 86s 457ms/step - loss: 0.1160 - accuracy: 0.9692 - val_loss: 0.1346 - val_accuracy: 0.9638\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.96300 to 0.96375, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.1141 - accuracy: 0.9698 - val_loss: 0.1325 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.96375 to 0.96433, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 86s 457ms/step - loss: 0.1119 - accuracy: 0.9703 - val_loss: 0.1301 - val_accuracy: 0.9645\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.96433 to 0.96450, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.1100 - accuracy: 0.9710 - val_loss: 0.1283 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.96450 to 0.96508, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 86s 457ms/step - loss: 0.1080 - accuracy: 0.9721 - val_loss: 0.1273 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.96508\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.1062 - accuracy: 0.9718 - val_loss: 0.1251 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.96508 to 0.96642, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.1043 - accuracy: 0.9726 - val_loss: 0.1248 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.96642 to 0.96650, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 86s 457ms/step - loss: 0.1028 - accuracy: 0.9735 - val_loss: 0.1212 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.96650\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.1007 - accuracy: 0.9738 - val_loss: 0.1209 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.96650 to 0.96675, saving model to mnist_conv_best.h5\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0993 - accuracy: 0.9743 - val_loss: 0.1199 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.96675\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0978 - accuracy: 0.9744 - val_loss: 0.1174 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.96675 to 0.96775, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0963 - accuracy: 0.9747 - val_loss: 0.1183 - val_accuracy: 0.9677\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.96775\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0950 - accuracy: 0.9751 - val_loss: 0.1155 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.96775\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0935 - accuracy: 0.9753 - val_loss: 0.1141 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.96775\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0922 - accuracy: 0.9758 - val_loss: 0.1126 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.96775 to 0.96925, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.0909 - accuracy: 0.9758 - val_loss: 0.1109 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.96925\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0895 - accuracy: 0.9763 - val_loss: 0.1093 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.96925 to 0.96967, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0884 - accuracy: 0.9766 - val_loss: 0.1100 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.96967\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0871 - accuracy: 0.9775 - val_loss: 0.1079 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.96967\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0861 - accuracy: 0.9777 - val_loss: 0.1063 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.96967 to 0.97017, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0849 - accuracy: 0.9775 - val_loss: 0.1055 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.97017 to 0.97092, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0839 - accuracy: 0.9782 - val_loss: 0.1043 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.97092\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0828 - accuracy: 0.9784 - val_loss: 0.1082 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.97092\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0819 - accuracy: 0.9789 - val_loss: 0.1025 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.97092\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0809 - accuracy: 0.9787 - val_loss: 0.1027 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.97092\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0800 - accuracy: 0.9788 - val_loss: 0.1001 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.97092 to 0.97167, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0790 - accuracy: 0.9794 - val_loss: 0.1032 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.97167\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0781 - accuracy: 0.9792 - val_loss: 0.0993 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.97167 to 0.97208, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0773 - accuracy: 0.9798 - val_loss: 0.0987 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.97208\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0764 - accuracy: 0.9802 - val_loss: 0.0979 - val_accuracy: 0.9716\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.97208\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 86s 458ms/step - loss: 0.0756 - accuracy: 0.9805 - val_loss: 0.0975 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.97208 to 0.97242, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.0746 - accuracy: 0.9807 - val_loss: 0.0958 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00088: val_accuracy improved from 0.97242 to 0.97267, saving model to mnist_conv_best.h5\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.0739 - accuracy: 0.9806 - val_loss: 0.0952 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.97267\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0733 - accuracy: 0.9805 - val_loss: 0.0947 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.97267\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0723 - accuracy: 0.9811 - val_loss: 0.0955 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.97267 to 0.97300, saving model to mnist_conv_best.h5\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.0717 - accuracy: 0.9812 - val_loss: 0.0940 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.97300 to 0.97375, saving model to mnist_conv_best.h5\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 86s 459ms/step - loss: 0.0710 - accuracy: 0.9814 - val_loss: 0.0935 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.97375\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 87s 460ms/step - loss: 0.0704 - accuracy: 0.9815 - val_loss: 0.0932 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.97375\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0695 - accuracy: 0.9820 - val_loss: 0.0915 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.97375\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.0688 - accuracy: 0.9821 - val_loss: 0.0914 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00096: val_accuracy improved from 0.97375 to 0.97383, saving model to mnist_conv_best.h5\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.0682 - accuracy: 0.9824 - val_loss: 0.0917 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.97383 to 0.97417, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.0677 - accuracy: 0.9821 - val_loss: 0.0917 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.97417\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 86s 460ms/step - loss: 0.0671 - accuracy: 0.9823 - val_loss: 0.0900 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.97417\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0665 - accuracy: 0.9827 - val_loss: 0.0893 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.97417\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 113s 604ms/step - loss: 0.0658 - accuracy: 0.9825 - val_loss: 0.0880 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00101: val_accuracy improved from 0.97417 to 0.97475, saving model to mnist_conv_best.h5\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0652 - accuracy: 0.9829 - val_loss: 0.0886 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.97475\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0647 - accuracy: 0.9830 - val_loss: 0.0876 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.97475\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0640 - accuracy: 0.9835 - val_loss: 0.0872 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.97475\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0634 - accuracy: 0.9836 - val_loss: 0.0867 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.97475\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0630 - accuracy: 0.9836 - val_loss: 0.0868 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97475\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0624 - accuracy: 0.9837 - val_loss: 0.0864 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.97475\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0619 - accuracy: 0.9838 - val_loss: 0.0863 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.97475\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0614 - accuracy: 0.9839 - val_loss: 0.0851 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.97475 to 0.97508, saving model to mnist_conv_best.h5\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0609 - accuracy: 0.9843 - val_loss: 0.0847 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.97508 to 0.97517, saving model to mnist_conv_best.h5\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0604 - accuracy: 0.9846 - val_loss: 0.0843 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.97517 to 0.97525, saving model to mnist_conv_best.h5\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0598 - accuracy: 0.9844 - val_loss: 0.0840 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00112: val_accuracy improved from 0.97525 to 0.97542, saving model to mnist_conv_best.h5\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0594 - accuracy: 0.9843 - val_loss: 0.0847 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.97542\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: 0.0832 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.97542\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0585 - accuracy: 0.9848 - val_loss: 0.0829 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00115: val_accuracy improved from 0.97542 to 0.97558, saving model to mnist_conv_best.h5\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0580 - accuracy: 0.9851 - val_loss: 0.0839 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97558\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0575 - accuracy: 0.9852 - val_loss: 0.0818 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.97558 to 0.97583, saving model to mnist_conv_best.h5\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0572 - accuracy: 0.9852 - val_loss: 0.0830 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.97583 to 0.97600, saving model to mnist_conv_best.h5\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0568 - accuracy: 0.9851 - val_loss: 0.0824 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97600\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0563 - accuracy: 0.9857 - val_loss: 0.0819 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97600\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0559 - accuracy: 0.9855 - val_loss: 0.0820 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97600\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0554 - accuracy: 0.9857 - val_loss: 0.0813 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.97600\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0551 - accuracy: 0.9858 - val_loss: 0.0810 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.97600\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.0548 - accuracy: 0.9861 - val_loss: 0.0815 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.97600 to 0.97608, saving model to mnist_conv_best.h5\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0543 - accuracy: 0.9865 - val_loss: 0.0803 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97608\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0539 - accuracy: 0.9862 - val_loss: 0.0808 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00126: val_accuracy improved from 0.97608 to 0.97708, saving model to mnist_conv_best.h5\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0535 - accuracy: 0.9863 - val_loss: 0.0798 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.97708\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0531 - accuracy: 0.9861 - val_loss: 0.0792 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97708\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0528 - accuracy: 0.9859 - val_loss: 0.0788 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.97708 to 0.97725, saving model to mnist_conv_best.h5\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0523 - accuracy: 0.9865 - val_loss: 0.0807 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97725\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0521 - accuracy: 0.9867 - val_loss: 0.0784 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97725\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0518 - accuracy: 0.9867 - val_loss: 0.0780 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97725\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0513 - accuracy: 0.9869 - val_loss: 0.0775 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97725\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0510 - accuracy: 0.9872 - val_loss: 0.0777 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97725\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0506 - accuracy: 0.9868 - val_loss: 0.0772 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.97725 to 0.97733, saving model to mnist_conv_best.h5\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0504 - accuracy: 0.9871 - val_loss: 0.0771 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00136: val_accuracy improved from 0.97733 to 0.97767, saving model to mnist_conv_best.h5\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0501 - accuracy: 0.9874 - val_loss: 0.0775 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.97767\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0497 - accuracy: 0.9875 - val_loss: 0.0768 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.97767\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 87s 461ms/step - loss: 0.0493 - accuracy: 0.9873 - val_loss: 0.0774 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97767\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0490 - accuracy: 0.9877 - val_loss: 0.0776 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97767\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0489 - accuracy: 0.9874 - val_loss: 0.0767 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.97767\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0484 - accuracy: 0.9874 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00142: val_accuracy improved from 0.97767 to 0.97775, saving model to mnist_conv_best.h5\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0481 - accuracy: 0.9877 - val_loss: 0.0753 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.97775 to 0.97842, saving model to mnist_conv_best.h5\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0478 - accuracy: 0.9876 - val_loss: 0.0752 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.97842\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0476 - accuracy: 0.9878 - val_loss: 0.0753 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.97842\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 0.0749 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97842\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 87s 465ms/step - loss: 0.0469 - accuracy: 0.9881 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97842\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 88s 466ms/step - loss: 0.0467 - accuracy: 0.9880 - val_loss: 0.0746 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.97842\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 90s 479ms/step - loss: 0.0464 - accuracy: 0.9880 - val_loss: 0.0746 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.97842\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 89s 473ms/step - loss: 0.0461 - accuracy: 0.9882 - val_loss: 0.0746 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.97842\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 88s 470ms/step - loss: 0.0457 - accuracy: 0.9885 - val_loss: 0.0739 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00151: val_accuracy improved from 0.97842 to 0.97850, saving model to mnist_conv_best.h5\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 88s 470ms/step - loss: 0.0455 - accuracy: 0.9883 - val_loss: 0.0740 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97850\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 88s 466ms/step - loss: 0.0453 - accuracy: 0.9885 - val_loss: 0.0748 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.97850\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0450 - accuracy: 0.9885 - val_loss: 0.0755 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97850\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 87s 463ms/step - loss: 0.0448 - accuracy: 0.9886 - val_loss: 0.0748 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.97850\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0444 - accuracy: 0.9885 - val_loss: 0.0747 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.97850\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 87s 462ms/step - loss: 0.0441 - accuracy: 0.9887 - val_loss: 0.0732 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97850\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0440 - accuracy: 0.9889 - val_loss: 0.0729 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00158: val_accuracy improved from 0.97850 to 0.97892, saving model to mnist_conv_best.h5\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 87s 465ms/step - loss: 0.0436 - accuracy: 0.9888 - val_loss: 0.0735 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.97892\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0434 - accuracy: 0.9889 - val_loss: 0.0727 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.97892\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0433 - accuracy: 0.9888 - val_loss: 0.0725 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.97892\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0430 - accuracy: 0.9889 - val_loss: 0.0732 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.97892\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0427 - accuracy: 0.9890 - val_loss: 0.0729 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.97892\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 88s 466ms/step - loss: 0.0425 - accuracy: 0.9891 - val_loss: 0.0724 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.97892\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 87s 465ms/step - loss: 0.0423 - accuracy: 0.9890 - val_loss: 0.0725 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.97892\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 87s 465ms/step - loss: 0.0421 - accuracy: 0.9891 - val_loss: 0.0733 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.97892\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 87s 465ms/step - loss: 0.0418 - accuracy: 0.9892 - val_loss: 0.0715 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.97892\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 87s 464ms/step - loss: 0.0416 - accuracy: 0.9894 - val_loss: 0.0723 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.97892\n",
            "Epoch 00168: early stopping\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0488 - accuracy: 0.9873\n",
            "Accuracy for the training set: 0.9872833490371704\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.0587 - accuracy: 0.9822\n",
            "Accuracy for the testing set: 0.982200026512146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 506)       8602      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 396704)            0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                3967050   \n",
            "=================================================================\n",
            "Total params: 3,975,652\n",
            "Trainable params: 3,975,652\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 170s 902ms/step - loss: 1.0558 - accuracy: 0.7895 - val_loss: 0.4818 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87158, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 169s 897ms/step - loss: 0.4186 - accuracy: 0.8841 - val_loss: 0.3849 - val_accuracy: 0.8914\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87158 to 0.89142, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 169s 900ms/step - loss: 0.3647 - accuracy: 0.8964 - val_loss: 0.3619 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89142 to 0.89900, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 169s 900ms/step - loss: 0.3416 - accuracy: 0.9021 - val_loss: 0.3371 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89900 to 0.90542, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 169s 902ms/step - loss: 0.3268 - accuracy: 0.9055 - val_loss: 0.3309 - val_accuracy: 0.9070\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90542 to 0.90700, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 169s 900ms/step - loss: 0.3164 - accuracy: 0.9093 - val_loss: 0.3217 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90700 to 0.91067, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 169s 900ms/step - loss: 0.3080 - accuracy: 0.9128 - val_loss: 0.3147 - val_accuracy: 0.9121\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.91067 to 0.91208, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 168s 896ms/step - loss: 0.3018 - accuracy: 0.9134 - val_loss: 0.3068 - val_accuracy: 0.9158\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91208 to 0.91575, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 169s 899ms/step - loss: 0.2968 - accuracy: 0.9152 - val_loss: 0.3079 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91575\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 169s 898ms/step - loss: 0.2916 - accuracy: 0.9164 - val_loss: 0.2990 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91575 to 0.91800, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 169s 898ms/step - loss: 0.2872 - accuracy: 0.9180 - val_loss: 0.2982 - val_accuracy: 0.9170\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91800\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 169s 899ms/step - loss: 0.2830 - accuracy: 0.9195 - val_loss: 0.3002 - val_accuracy: 0.9161\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91800\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 169s 899ms/step - loss: 0.2791 - accuracy: 0.9204 - val_loss: 0.2892 - val_accuracy: 0.9222\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91800 to 0.92225, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 169s 896ms/step - loss: 0.2751 - accuracy: 0.9215 - val_loss: 0.2938 - val_accuracy: 0.9177\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.92225\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 169s 897ms/step - loss: 0.2712 - accuracy: 0.9220 - val_loss: 0.2827 - val_accuracy: 0.9220\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.92225\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 169s 898ms/step - loss: 0.2679 - accuracy: 0.9239 - val_loss: 0.2815 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.92225\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 169s 897ms/step - loss: 0.2642 - accuracy: 0.9244 - val_loss: 0.2767 - val_accuracy: 0.9245\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.92225 to 0.92450, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 169s 899ms/step - loss: 0.2602 - accuracy: 0.9266 - val_loss: 0.2698 - val_accuracy: 0.9270\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92450 to 0.92700, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 168s 896ms/step - loss: 0.2559 - accuracy: 0.9275 - val_loss: 0.2749 - val_accuracy: 0.9240\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.92700\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 168s 896ms/step - loss: 0.2523 - accuracy: 0.9283 - val_loss: 0.2632 - val_accuracy: 0.9273\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.92700 to 0.92725, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 169s 899ms/step - loss: 0.2476 - accuracy: 0.9301 - val_loss: 0.2631 - val_accuracy: 0.9266\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.92725\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 169s 897ms/step - loss: 0.2438 - accuracy: 0.9318 - val_loss: 0.2578 - val_accuracy: 0.9297\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.92725 to 0.92967, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 168s 896ms/step - loss: 0.2396 - accuracy: 0.9329 - val_loss: 0.2525 - val_accuracy: 0.9316\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.92967 to 0.93158, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 169s 901ms/step - loss: 0.2350 - accuracy: 0.9339 - val_loss: 0.2476 - val_accuracy: 0.9326\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.93158 to 0.93258, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 170s 903ms/step - loss: 0.2303 - accuracy: 0.9356 - val_loss: 0.2501 - val_accuracy: 0.9302\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.93258\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 169s 902ms/step - loss: 0.2260 - accuracy: 0.9370 - val_loss: 0.2406 - val_accuracy: 0.9344\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.93258 to 0.93442, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 169s 898ms/step - loss: 0.2214 - accuracy: 0.9388 - val_loss: 0.2382 - val_accuracy: 0.9342\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.93442\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 169s 897ms/step - loss: 0.2167 - accuracy: 0.9397 - val_loss: 0.2318 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.93442 to 0.93625, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 169s 900ms/step - loss: 0.2121 - accuracy: 0.9412 - val_loss: 0.2280 - val_accuracy: 0.9367\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93625 to 0.93675, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 170s 902ms/step - loss: 0.2072 - accuracy: 0.9429 - val_loss: 0.2245 - val_accuracy: 0.9398\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.93675 to 0.93983, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 170s 903ms/step - loss: 0.2023 - accuracy: 0.9441 - val_loss: 0.2156 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.93983 to 0.94142, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 170s 902ms/step - loss: 0.1983 - accuracy: 0.9454 - val_loss: 0.2130 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.94142\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 171s 909ms/step - loss: 0.1933 - accuracy: 0.9466 - val_loss: 0.2089 - val_accuracy: 0.9424\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.94142 to 0.94242, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 172s 914ms/step - loss: 0.1888 - accuracy: 0.9481 - val_loss: 0.2053 - val_accuracy: 0.9430\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.94242 to 0.94300, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 171s 910ms/step - loss: 0.1843 - accuracy: 0.9493 - val_loss: 0.2014 - val_accuracy: 0.9462\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.94300 to 0.94617, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 171s 908ms/step - loss: 0.1797 - accuracy: 0.9506 - val_loss: 0.1934 - val_accuracy: 0.9476\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.94617 to 0.94758, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 170s 905ms/step - loss: 0.1755 - accuracy: 0.9518 - val_loss: 0.1905 - val_accuracy: 0.9474\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.94758\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 171s 912ms/step - loss: 0.1711 - accuracy: 0.9530 - val_loss: 0.1876 - val_accuracy: 0.9494\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.94758 to 0.94942, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 171s 907ms/step - loss: 0.1670 - accuracy: 0.9538 - val_loss: 0.1867 - val_accuracy: 0.9478\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.94942\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 171s 908ms/step - loss: 0.1631 - accuracy: 0.9547 - val_loss: 0.1816 - val_accuracy: 0.9487\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.94942\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 171s 909ms/step - loss: 0.1592 - accuracy: 0.9563 - val_loss: 0.1749 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.94942 to 0.95250, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 171s 909ms/step - loss: 0.1555 - accuracy: 0.9576 - val_loss: 0.1731 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.95250\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 170s 905ms/step - loss: 0.1517 - accuracy: 0.9589 - val_loss: 0.1724 - val_accuracy: 0.9516\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.95250\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 171s 909ms/step - loss: 0.1483 - accuracy: 0.9600 - val_loss: 0.1661 - val_accuracy: 0.9551\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.95250 to 0.95508, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 171s 908ms/step - loss: 0.1450 - accuracy: 0.9606 - val_loss: 0.1620 - val_accuracy: 0.9564\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.95508 to 0.95642, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 170s 904ms/step - loss: 0.1417 - accuracy: 0.9611 - val_loss: 0.1584 - val_accuracy: 0.9578\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.95642 to 0.95783, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 170s 906ms/step - loss: 0.1385 - accuracy: 0.9625 - val_loss: 0.1553 - val_accuracy: 0.9587\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.95783 to 0.95867, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 171s 909ms/step - loss: 0.1355 - accuracy: 0.9636 - val_loss: 0.1527 - val_accuracy: 0.9592\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.95867 to 0.95917, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 170s 905ms/step - loss: 0.1327 - accuracy: 0.9644 - val_loss: 0.1508 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.95917 to 0.96000, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 171s 907ms/step - loss: 0.1299 - accuracy: 0.9651 - val_loss: 0.1479 - val_accuracy: 0.9607\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.96000 to 0.96067, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 171s 907ms/step - loss: 0.1273 - accuracy: 0.9657 - val_loss: 0.1450 - val_accuracy: 0.9609\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.96067 to 0.96092, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 171s 910ms/step - loss: 0.1246 - accuracy: 0.9662 - val_loss: 0.1420 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.96092 to 0.96242, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 170s 905ms/step - loss: 0.1218 - accuracy: 0.9678 - val_loss: 0.1417 - val_accuracy: 0.9614\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.96242\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 170s 904ms/step - loss: 0.1195 - accuracy: 0.9679 - val_loss: 0.1418 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.96242\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 170s 906ms/step - loss: 0.1175 - accuracy: 0.9690 - val_loss: 0.1346 - val_accuracy: 0.9641\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.96242 to 0.96408, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 170s 905ms/step - loss: 0.1153 - accuracy: 0.9695 - val_loss: 0.1325 - val_accuracy: 0.9646\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.96408 to 0.96458, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 170s 906ms/step - loss: 0.1131 - accuracy: 0.9700 - val_loss: 0.1319 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.96458 to 0.96517, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 170s 906ms/step - loss: 0.1111 - accuracy: 0.9708 - val_loss: 0.1297 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.96517\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 170s 906ms/step - loss: 0.1092 - accuracy: 0.9711 - val_loss: 0.1276 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.96517\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 171s 908ms/step - loss: 0.1074 - accuracy: 0.9720 - val_loss: 0.1252 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.96517 to 0.96625, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 170s 905ms/step - loss: 0.1055 - accuracy: 0.9721 - val_loss: 0.1242 - val_accuracy: 0.9666\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.96625 to 0.96658, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 197s 1s/step - loss: 0.1038 - accuracy: 0.9728 - val_loss: 0.1228 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.96658\n",
            "Epoch 63/10000\n",
            "181/188 [===========================>..] - ETA: 5s - loss: 0.1026 - accuracy: 0.9731"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ddcb1dd6ba1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_conv_best.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mmnist_conv_model_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_conv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mmnist_conv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_conv_best.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dzykHUwckHsE",
        "outputId": "613fa6cc-ead9-4a44-b80d-05de053a7751"
      },
      "source": [
        "plt.plot([2,4,8,16,32,124,248],[0.92409981,0.9745,0.9778,0.9811,0.9800,0.9824,0.9822]) # plotting by columns\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu5oKEP3mSCg"
      },
      "source": [
        "## Pooling vs No Pooling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0xysxEMm868"
      },
      "source": [
        "### No Pooling\n",
        "0.9809"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0j26un8mWV_",
        "outputId": "5b906aad-8b63-48eb-b730-24cf5fd80965"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,722\n",
            "Trainable params: 125,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.1035 - accuracy: 0.7476 - val_loss: 0.4903 - val_accuracy: 0.8678\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.86783, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.4232 - accuracy: 0.8821 - val_loss: 0.3863 - val_accuracy: 0.8924\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.86783 to 0.89242, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.3652 - accuracy: 0.8959 - val_loss: 0.3544 - val_accuracy: 0.9018\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89242 to 0.90183, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.3404 - accuracy: 0.9024 - val_loss: 0.3365 - val_accuracy: 0.9046\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.90183 to 0.90458, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3256 - accuracy: 0.9064 - val_loss: 0.3248 - val_accuracy: 0.9082\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90458 to 0.90817, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3140 - accuracy: 0.9102 - val_loss: 0.3157 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90817 to 0.91217, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.3055 - accuracy: 0.9120 - val_loss: 0.3210 - val_accuracy: 0.9106\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91217\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2983 - accuracy: 0.9146 - val_loss: 0.3046 - val_accuracy: 0.9145\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91217 to 0.91450, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2920 - accuracy: 0.9156 - val_loss: 0.3001 - val_accuracy: 0.9169\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91450 to 0.91692, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2859 - accuracy: 0.9175 - val_loss: 0.2917 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91692 to 0.92000, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2801 - accuracy: 0.9191 - val_loss: 0.2882 - val_accuracy: 0.9201\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.92000 to 0.92008, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2750 - accuracy: 0.9214 - val_loss: 0.2814 - val_accuracy: 0.9241\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.92008 to 0.92408, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2692 - accuracy: 0.9231 - val_loss: 0.2794 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.92408\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2636 - accuracy: 0.9251 - val_loss: 0.2726 - val_accuracy: 0.9258\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.92408 to 0.92583, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2585 - accuracy: 0.9268 - val_loss: 0.2663 - val_accuracy: 0.9277\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.92583 to 0.92767, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2533 - accuracy: 0.9286 - val_loss: 0.2631 - val_accuracy: 0.9277\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.92767 to 0.92775, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2481 - accuracy: 0.9303 - val_loss: 0.2612 - val_accuracy: 0.9289\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.92775 to 0.92892, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2432 - accuracy: 0.9320 - val_loss: 0.2552 - val_accuracy: 0.9302\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92892 to 0.93025, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2380 - accuracy: 0.9331 - val_loss: 0.2480 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.93025 to 0.93367, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2336 - accuracy: 0.9346 - val_loss: 0.2432 - val_accuracy: 0.9338\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.93367 to 0.93383, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2285 - accuracy: 0.9362 - val_loss: 0.2392 - val_accuracy: 0.9350\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.93383 to 0.93500, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2236 - accuracy: 0.9379 - val_loss: 0.2361 - val_accuracy: 0.9359\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.93500 to 0.93592, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2189 - accuracy: 0.9389 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.93592 to 0.93633, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2140 - accuracy: 0.9409 - val_loss: 0.2283 - val_accuracy: 0.9372\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.93633 to 0.93717, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2099 - accuracy: 0.9422 - val_loss: 0.2238 - val_accuracy: 0.9383\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.93717 to 0.93833, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2055 - accuracy: 0.9433 - val_loss: 0.2216 - val_accuracy: 0.9390\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.93833 to 0.93900, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2009 - accuracy: 0.9447 - val_loss: 0.2168 - val_accuracy: 0.9423\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.93900 to 0.94225, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1966 - accuracy: 0.9461 - val_loss: 0.2107 - val_accuracy: 0.9436\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.94225 to 0.94358, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1928 - accuracy: 0.9471 - val_loss: 0.2089 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.94358\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1890 - accuracy: 0.9476 - val_loss: 0.2042 - val_accuracy: 0.9442\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.94358 to 0.94425, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1853 - accuracy: 0.9494 - val_loss: 0.2047 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.94425\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1812 - accuracy: 0.9510 - val_loss: 0.1966 - val_accuracy: 0.9460\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.94425 to 0.94600, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1775 - accuracy: 0.9521 - val_loss: 0.1918 - val_accuracy: 0.9475\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.94600 to 0.94750, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1741 - accuracy: 0.9526 - val_loss: 0.1891 - val_accuracy: 0.9494\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.94750 to 0.94942, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1709 - accuracy: 0.9535 - val_loss: 0.1866 - val_accuracy: 0.9499\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.94942 to 0.94992, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1681 - accuracy: 0.9545 - val_loss: 0.1823 - val_accuracy: 0.9519\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.94992 to 0.95192, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1648 - accuracy: 0.9552 - val_loss: 0.1816 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.95192\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1621 - accuracy: 0.9563 - val_loss: 0.1770 - val_accuracy: 0.9528\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.95192 to 0.95275, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1593 - accuracy: 0.9572 - val_loss: 0.1753 - val_accuracy: 0.9524\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.95275\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1564 - accuracy: 0.9577 - val_loss: 0.1718 - val_accuracy: 0.9552\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.95275 to 0.95517, saving model to mnist_conv_best.h5\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1540 - accuracy: 0.9578 - val_loss: 0.1709 - val_accuracy: 0.9555\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.95517 to 0.95550, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1513 - accuracy: 0.9589 - val_loss: 0.1682 - val_accuracy: 0.9561\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.95550 to 0.95608, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1487 - accuracy: 0.9598 - val_loss: 0.1671 - val_accuracy: 0.9553\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.95608\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1467 - accuracy: 0.9607 - val_loss: 0.1647 - val_accuracy: 0.9572\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.95608 to 0.95717, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1443 - accuracy: 0.9608 - val_loss: 0.1611 - val_accuracy: 0.9583\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.95717 to 0.95833, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1421 - accuracy: 0.9616 - val_loss: 0.1599 - val_accuracy: 0.9578\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.95833\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1401 - accuracy: 0.9620 - val_loss: 0.1597 - val_accuracy: 0.9583\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.95833\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1380 - accuracy: 0.9621 - val_loss: 0.1563 - val_accuracy: 0.9591\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.95833 to 0.95908, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1359 - accuracy: 0.9628 - val_loss: 0.1547 - val_accuracy: 0.9593\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.95908 to 0.95933, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1342 - accuracy: 0.9635 - val_loss: 0.1547 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.95933 to 0.95950, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1325 - accuracy: 0.9641 - val_loss: 0.1500 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.95950 to 0.96033, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1309 - accuracy: 0.9647 - val_loss: 0.1485 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.96033 to 0.96050, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1292 - accuracy: 0.9650 - val_loss: 0.1486 - val_accuracy: 0.9606\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.96050 to 0.96058, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1276 - accuracy: 0.9656 - val_loss: 0.1508 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.96058\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1258 - accuracy: 0.9658 - val_loss: 0.1459 - val_accuracy: 0.9608\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.96058 to 0.96083, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1241 - accuracy: 0.9668 - val_loss: 0.1461 - val_accuracy: 0.9607\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.96083\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1224 - accuracy: 0.9665 - val_loss: 0.1469 - val_accuracy: 0.9608\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.96083\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1211 - accuracy: 0.9671 - val_loss: 0.1404 - val_accuracy: 0.9621\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.96083 to 0.96208, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1199 - accuracy: 0.9671 - val_loss: 0.1408 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.96208\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1182 - accuracy: 0.9678 - val_loss: 0.1397 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.96208 to 0.96258, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1171 - accuracy: 0.9683 - val_loss: 0.1396 - val_accuracy: 0.9627\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.96258 to 0.96267, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1156 - accuracy: 0.9686 - val_loss: 0.1376 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.96267 to 0.96367, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1145 - accuracy: 0.9690 - val_loss: 0.1384 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.96367\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1133 - accuracy: 0.9692 - val_loss: 0.1335 - val_accuracy: 0.9642\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.96367 to 0.96417, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1119 - accuracy: 0.9697 - val_loss: 0.1335 - val_accuracy: 0.9634\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.96417\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1110 - accuracy: 0.9698 - val_loss: 0.1330 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.96417 to 0.96467, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1096 - accuracy: 0.9703 - val_loss: 0.1332 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.96467\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1085 - accuracy: 0.9706 - val_loss: 0.1302 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.96467 to 0.96500, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1073 - accuracy: 0.9709 - val_loss: 0.1300 - val_accuracy: 0.9655\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.96500 to 0.96550, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1063 - accuracy: 0.9715 - val_loss: 0.1284 - val_accuracy: 0.9649\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.96550\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1050 - accuracy: 0.9715 - val_loss: 0.1274 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.96550 to 0.96583, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1040 - accuracy: 0.9720 - val_loss: 0.1298 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.96583\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1031 - accuracy: 0.9722 - val_loss: 0.1253 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.96583\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1020 - accuracy: 0.9723 - val_loss: 0.1244 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.96583 to 0.96625, saving model to mnist_conv_best.h5\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1010 - accuracy: 0.9727 - val_loss: 0.1236 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.96625\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1002 - accuracy: 0.9725 - val_loss: 0.1251 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.96625\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0992 - accuracy: 0.9731 - val_loss: 0.1224 - val_accuracy: 0.9660\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.96625\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0983 - accuracy: 0.9734 - val_loss: 0.1217 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.96625 to 0.96667, saving model to mnist_conv_best.h5\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0971 - accuracy: 0.9732 - val_loss: 0.1209 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.96667 to 0.96700, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0963 - accuracy: 0.9740 - val_loss: 0.1193 - val_accuracy: 0.9675\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.96700 to 0.96750, saving model to mnist_conv_best.h5\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0953 - accuracy: 0.9742 - val_loss: 0.1220 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.96750\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0947 - accuracy: 0.9742 - val_loss: 0.1192 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.96750\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0937 - accuracy: 0.9746 - val_loss: 0.1175 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00083: val_accuracy improved from 0.96750 to 0.96825, saving model to mnist_conv_best.h5\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0928 - accuracy: 0.9748 - val_loss: 0.1176 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.96825\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0920 - accuracy: 0.9748 - val_loss: 0.1162 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.96825\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0909 - accuracy: 0.9751 - val_loss: 0.1149 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.96825\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0903 - accuracy: 0.9754 - val_loss: 0.1150 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.96825\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0895 - accuracy: 0.9754 - val_loss: 0.1143 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.96825\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0890 - accuracy: 0.9761 - val_loss: 0.1127 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.96825 to 0.96900, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0880 - accuracy: 0.9764 - val_loss: 0.1133 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.96900\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0871 - accuracy: 0.9763 - val_loss: 0.1126 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.96900 to 0.96908, saving model to mnist_conv_best.h5\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0865 - accuracy: 0.9764 - val_loss: 0.1112 - val_accuracy: 0.9692\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.96908 to 0.96917, saving model to mnist_conv_best.h5\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0859 - accuracy: 0.9767 - val_loss: 0.1123 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.96917\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0849 - accuracy: 0.9771 - val_loss: 0.1102 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.96917\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0844 - accuracy: 0.9771 - val_loss: 0.1098 - val_accuracy: 0.9695\n",
            "\n",
            "Epoch 00095: val_accuracy improved from 0.96917 to 0.96950, saving model to mnist_conv_best.h5\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0837 - accuracy: 0.9774 - val_loss: 0.1084 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00096: val_accuracy improved from 0.96950 to 0.96992, saving model to mnist_conv_best.h5\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0829 - accuracy: 0.9779 - val_loss: 0.1086 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.96992\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0822 - accuracy: 0.9776 - val_loss: 0.1078 - val_accuracy: 0.9692\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.96992\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0816 - accuracy: 0.9777 - val_loss: 0.1090 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.96992\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0808 - accuracy: 0.9782 - val_loss: 0.1066 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.96992\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0803 - accuracy: 0.9780 - val_loss: 0.1062 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00101: val_accuracy improved from 0.96992 to 0.97108, saving model to mnist_conv_best.h5\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0796 - accuracy: 0.9786 - val_loss: 0.1052 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.97108\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0790 - accuracy: 0.9787 - val_loss: 0.1047 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.97108\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0783 - accuracy: 0.9791 - val_loss: 0.1051 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.97108\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0775 - accuracy: 0.9788 - val_loss: 0.1060 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.97108\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0772 - accuracy: 0.9790 - val_loss: 0.1048 - val_accuracy: 0.9700\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97108\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0765 - accuracy: 0.9794 - val_loss: 0.1040 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.97108\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0757 - accuracy: 0.9799 - val_loss: 0.1023 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.97108 to 0.97125, saving model to mnist_conv_best.h5\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0754 - accuracy: 0.9794 - val_loss: 0.1022 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.97125\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0748 - accuracy: 0.9797 - val_loss: 0.1025 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.97125\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0740 - accuracy: 0.9802 - val_loss: 0.1008 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.97125 to 0.97225, saving model to mnist_conv_best.h5\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0736 - accuracy: 0.9800 - val_loss: 0.1018 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.97225\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0730 - accuracy: 0.9807 - val_loss: 0.1009 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.97225\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0725 - accuracy: 0.9804 - val_loss: 0.0996 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.97225 to 0.97233, saving model to mnist_conv_best.h5\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0717 - accuracy: 0.9811 - val_loss: 0.0988 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00115: val_accuracy improved from 0.97233 to 0.97275, saving model to mnist_conv_best.h5\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0714 - accuracy: 0.9804 - val_loss: 0.0988 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97275\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0707 - accuracy: 0.9812 - val_loss: 0.0994 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.97275\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0704 - accuracy: 0.9812 - val_loss: 0.0988 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.97275\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0698 - accuracy: 0.9814 - val_loss: 0.0969 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00119: val_accuracy improved from 0.97275 to 0.97300, saving model to mnist_conv_best.h5\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0691 - accuracy: 0.9818 - val_loss: 0.0971 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97300\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0689 - accuracy: 0.9816 - val_loss: 0.0978 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97300\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0683 - accuracy: 0.9816 - val_loss: 0.0958 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.97300\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0677 - accuracy: 0.9818 - val_loss: 0.0961 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00123: val_accuracy improved from 0.97300 to 0.97308, saving model to mnist_conv_best.h5\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0673 - accuracy: 0.9819 - val_loss: 0.0970 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.97308\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0668 - accuracy: 0.9823 - val_loss: 0.0951 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97308\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 0.0953 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00126: val_accuracy improved from 0.97308 to 0.97383, saving model to mnist_conv_best.h5\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0659 - accuracy: 0.9824 - val_loss: 0.0942 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.97383\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0653 - accuracy: 0.9826 - val_loss: 0.0943 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97383\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0650 - accuracy: 0.9829 - val_loss: 0.0941 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.97383\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0930 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97383\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0640 - accuracy: 0.9829 - val_loss: 0.0932 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97383\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0635 - accuracy: 0.9833 - val_loss: 0.0932 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97383\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0631 - accuracy: 0.9834 - val_loss: 0.0934 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97383\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0628 - accuracy: 0.9835 - val_loss: 0.0916 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00134: val_accuracy improved from 0.97383 to 0.97450, saving model to mnist_conv_best.h5\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0925 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97450\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0620 - accuracy: 0.9837 - val_loss: 0.0910 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.97450\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0616 - accuracy: 0.9837 - val_loss: 0.0917 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.97450\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0611 - accuracy: 0.9839 - val_loss: 0.0918 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.97450\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0607 - accuracy: 0.9841 - val_loss: 0.0902 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97450\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0603 - accuracy: 0.9842 - val_loss: 0.0900 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97450\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0600 - accuracy: 0.9843 - val_loss: 0.0898 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.97450 to 0.97483, saving model to mnist_conv_best.h5\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0596 - accuracy: 0.9841 - val_loss: 0.0905 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.97483\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0592 - accuracy: 0.9846 - val_loss: 0.0896 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.97483\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0589 - accuracy: 0.9846 - val_loss: 0.0884 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.97483\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0583 - accuracy: 0.9852 - val_loss: 0.0887 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00145: val_accuracy improved from 0.97483 to 0.97517, saving model to mnist_conv_best.h5\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0579 - accuracy: 0.9848 - val_loss: 0.0900 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97517\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0576 - accuracy: 0.9847 - val_loss: 0.0885 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97517\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0573 - accuracy: 0.9853 - val_loss: 0.0875 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.97517\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0569 - accuracy: 0.9852 - val_loss: 0.0868 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.97517\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0565 - accuracy: 0.9851 - val_loss: 0.0877 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00150: val_accuracy improved from 0.97517 to 0.97525, saving model to mnist_conv_best.h5\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0562 - accuracy: 0.9854 - val_loss: 0.0890 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.97525\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0560 - accuracy: 0.9855 - val_loss: 0.0869 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97525\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0554 - accuracy: 0.9857 - val_loss: 0.0875 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.97525\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.0855 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97525\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0549 - accuracy: 0.9860 - val_loss: 0.0848 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.97525 to 0.97608, saving model to mnist_conv_best.h5\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0546 - accuracy: 0.9859 - val_loss: 0.0853 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.97608\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0543 - accuracy: 0.9860 - val_loss: 0.0865 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97608\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0539 - accuracy: 0.9861 - val_loss: 0.0852 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.97608\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0535 - accuracy: 0.9863 - val_loss: 0.0849 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.97608\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0532 - accuracy: 0.9862 - val_loss: 0.0842 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.97608\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0530 - accuracy: 0.9860 - val_loss: 0.0856 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.97608\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0526 - accuracy: 0.9864 - val_loss: 0.0841 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00162: val_accuracy improved from 0.97608 to 0.97617, saving model to mnist_conv_best.h5\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0523 - accuracy: 0.9866 - val_loss: 0.0851 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.97617\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0522 - accuracy: 0.9863 - val_loss: 0.0836 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.97617\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0515 - accuracy: 0.9867 - val_loss: 0.0864 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.97617\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0514 - accuracy: 0.9865 - val_loss: 0.0842 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.97617\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0509 - accuracy: 0.9871 - val_loss: 0.0834 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.97617\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0507 - accuracy: 0.9869 - val_loss: 0.0826 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00168: val_accuracy improved from 0.97617 to 0.97692, saving model to mnist_conv_best.h5\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0504 - accuracy: 0.9869 - val_loss: 0.0827 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.97692\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0501 - accuracy: 0.9874 - val_loss: 0.0825 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.97692\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0499 - accuracy: 0.9869 - val_loss: 0.0816 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00171: val_accuracy improved from 0.97692 to 0.97750, saving model to mnist_conv_best.h5\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0496 - accuracy: 0.9872 - val_loss: 0.0816 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.97750\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0494 - accuracy: 0.9874 - val_loss: 0.0817 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.97750\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0489 - accuracy: 0.9878 - val_loss: 0.0830 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.97750\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0489 - accuracy: 0.9875 - val_loss: 0.0820 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.97750\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0484 - accuracy: 0.9878 - val_loss: 0.0810 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.97750\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0483 - accuracy: 0.9875 - val_loss: 0.0825 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.97750\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0481 - accuracy: 0.9877 - val_loss: 0.0810 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.97750\n",
            "Epoch 179/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0478 - accuracy: 0.9875 - val_loss: 0.0815 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.97750\n",
            "Epoch 180/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0474 - accuracy: 0.9880 - val_loss: 0.0802 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.97750\n",
            "Epoch 181/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 0.0808 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.97750\n",
            "Epoch 00181: early stopping\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0554 - accuracy: 0.9856\n",
            "Accuracy for the training set: 0.9855833053588867\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 0.9809\n",
            "Accuracy for the testing set: 0.98089998960495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xetqtm4WnBGB"
      },
      "source": [
        "### Pooling Max Pooling Layer\n",
        "0.9811"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-Vf5lazznF7h",
        "outputId": "eeba1f65-e92f-4102-e032-818c838e6481"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "pooling (MaxPooling2D)       (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                31370     \n",
            "=================================================================\n",
            "Total params: 31,642\n",
            "Trainable params: 31,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 1.5536 - accuracy: 0.6335 - val_loss: 0.7555 - val_accuracy: 0.8303\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83033, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.5658 - accuracy: 0.8564 - val_loss: 0.4691 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.83033 to 0.87317, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.4294 - accuracy: 0.8803 - val_loss: 0.4031 - val_accuracy: 0.8854\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.87317 to 0.88542, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 0.3853 - accuracy: 0.8894 - val_loss: 0.3733 - val_accuracy: 0.8939\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.88542 to 0.89392, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 0.3629 - accuracy: 0.8945 - val_loss: 0.3586 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.89392 to 0.89808, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.3483 - accuracy: 0.8982 - val_loss: 0.3460 - val_accuracy: 0.9008\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.89808 to 0.90083, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.3375 - accuracy: 0.9012 - val_loss: 0.3373 - val_accuracy: 0.9035\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90083 to 0.90350, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 0.3296 - accuracy: 0.9034 - val_loss: 0.3368 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.90350\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 0.3227 - accuracy: 0.9061 - val_loss: 0.3295 - val_accuracy: 0.9046\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.90350 to 0.90458, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 0.3168 - accuracy: 0.9077 - val_loss: 0.3218 - val_accuracy: 0.9074\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.90458 to 0.90742, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.3119 - accuracy: 0.9087 - val_loss: 0.3178 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.90742 to 0.91042, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.3074 - accuracy: 0.9105 - val_loss: 0.3166 - val_accuracy: 0.9112\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91042 to 0.91125, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.3027 - accuracy: 0.9123 - val_loss: 0.3087 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.91125 to 0.91275, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 0.2991 - accuracy: 0.9132 - val_loss: 0.3057 - val_accuracy: 0.9126\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91275\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2954 - accuracy: 0.9140 - val_loss: 0.3034 - val_accuracy: 0.9137\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91275 to 0.91375, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2913 - accuracy: 0.9153 - val_loss: 0.2988 - val_accuracy: 0.9146\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.91375 to 0.91458, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2879 - accuracy: 0.9162 - val_loss: 0.2973 - val_accuracy: 0.9182\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91458 to 0.91817, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2844 - accuracy: 0.9174 - val_loss: 0.2942 - val_accuracy: 0.9166\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91817\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2810 - accuracy: 0.9189 - val_loss: 0.2920 - val_accuracy: 0.9177\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91817\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2780 - accuracy: 0.9195 - val_loss: 0.2856 - val_accuracy: 0.9207\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.91817 to 0.92067, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2746 - accuracy: 0.9209 - val_loss: 0.2841 - val_accuracy: 0.9208\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92067 to 0.92075, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2719 - accuracy: 0.9217 - val_loss: 0.2805 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.92075 to 0.92175, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2682 - accuracy: 0.9231 - val_loss: 0.2794 - val_accuracy: 0.9209\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.92175\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2655 - accuracy: 0.9232 - val_loss: 0.2776 - val_accuracy: 0.9219\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.92175 to 0.92192, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2625 - accuracy: 0.9244 - val_loss: 0.2730 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.92192 to 0.92358, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2595 - accuracy: 0.9250 - val_loss: 0.2684 - val_accuracy: 0.9258\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.92358 to 0.92575, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2562 - accuracy: 0.9261 - val_loss: 0.2682 - val_accuracy: 0.9249\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.92575\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2533 - accuracy: 0.9269 - val_loss: 0.2623 - val_accuracy: 0.9271\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.92575 to 0.92708, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2501 - accuracy: 0.9282 - val_loss: 0.2606 - val_accuracy: 0.9269\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.92708\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2469 - accuracy: 0.9287 - val_loss: 0.2573 - val_accuracy: 0.9282\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.92708 to 0.92817, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2439 - accuracy: 0.9303 - val_loss: 0.2541 - val_accuracy: 0.9292\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.92817 to 0.92917, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2407 - accuracy: 0.9311 - val_loss: 0.2539 - val_accuracy: 0.9295\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.92917 to 0.92950, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2373 - accuracy: 0.9318 - val_loss: 0.2488 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.92950 to 0.93142, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2338 - accuracy: 0.9328 - val_loss: 0.2470 - val_accuracy: 0.9307\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.93142\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2307 - accuracy: 0.9339 - val_loss: 0.2414 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.93142 to 0.93367, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2274 - accuracy: 0.9346 - val_loss: 0.2395 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.93367 to 0.93375, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2241 - accuracy: 0.9362 - val_loss: 0.2366 - val_accuracy: 0.9352\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.93375 to 0.93517, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2205 - accuracy: 0.9368 - val_loss: 0.2321 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.93517 to 0.93617, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2169 - accuracy: 0.9379 - val_loss: 0.2290 - val_accuracy: 0.9367\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.93617 to 0.93667, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.2133 - accuracy: 0.9391 - val_loss: 0.2279 - val_accuracy: 0.9366\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93667\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2099 - accuracy: 0.9407 - val_loss: 0.2284 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.93667\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2064 - accuracy: 0.9414 - val_loss: 0.2188 - val_accuracy: 0.9405\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.93667 to 0.94050, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.2030 - accuracy: 0.9427 - val_loss: 0.2153 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.94050 to 0.94142, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1994 - accuracy: 0.9435 - val_loss: 0.2113 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.94142\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1959 - accuracy: 0.9448 - val_loss: 0.2089 - val_accuracy: 0.9438\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.94142 to 0.94383, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1925 - accuracy: 0.9461 - val_loss: 0.2055 - val_accuracy: 0.9449\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.94383 to 0.94492, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1889 - accuracy: 0.9465 - val_loss: 0.2017 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.94492 to 0.94558, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1857 - accuracy: 0.9476 - val_loss: 0.1985 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.94558 to 0.94625, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1822 - accuracy: 0.9488 - val_loss: 0.1992 - val_accuracy: 0.9454\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.94625\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1789 - accuracy: 0.9494 - val_loss: 0.1917 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.94625 to 0.94800, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1757 - accuracy: 0.9506 - val_loss: 0.1915 - val_accuracy: 0.9467\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.94800\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1724 - accuracy: 0.9514 - val_loss: 0.1850 - val_accuracy: 0.9496\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.94800 to 0.94958, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1693 - accuracy: 0.9529 - val_loss: 0.1842 - val_accuracy: 0.9504\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.94958 to 0.95042, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1660 - accuracy: 0.9534 - val_loss: 0.1786 - val_accuracy: 0.9515\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.95042 to 0.95150, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1632 - accuracy: 0.9546 - val_loss: 0.1753 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.95150 to 0.95250, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1601 - accuracy: 0.9558 - val_loss: 0.1743 - val_accuracy: 0.9523\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.95250\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1574 - accuracy: 0.9561 - val_loss: 0.1697 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.95250 to 0.95325, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1545 - accuracy: 0.9572 - val_loss: 0.1689 - val_accuracy: 0.9543\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.95325 to 0.95433, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1518 - accuracy: 0.9580 - val_loss: 0.1651 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.95433 to 0.95558, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.1489 - accuracy: 0.9592 - val_loss: 0.1619 - val_accuracy: 0.9557\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.95558 to 0.95575, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 0.1466 - accuracy: 0.9597 - val_loss: 0.1592 - val_accuracy: 0.9578\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.95575 to 0.95775, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 15s 83ms/step - loss: 0.1441 - accuracy: 0.9601 - val_loss: 0.1569 - val_accuracy: 0.9582\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.95775 to 0.95817, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1417 - accuracy: 0.9612 - val_loss: 0.1542 - val_accuracy: 0.9589\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.95817 to 0.95892, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1392 - accuracy: 0.9619 - val_loss: 0.1520 - val_accuracy: 0.9607\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.95892 to 0.96067, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1370 - accuracy: 0.9621 - val_loss: 0.1499 - val_accuracy: 0.9592\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.96067\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1348 - accuracy: 0.9630 - val_loss: 0.1482 - val_accuracy: 0.9609\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.96067 to 0.96092, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1328 - accuracy: 0.9636 - val_loss: 0.1462 - val_accuracy: 0.9612\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.96092 to 0.96117, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1306 - accuracy: 0.9639 - val_loss: 0.1447 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.96117\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1286 - accuracy: 0.9650 - val_loss: 0.1427 - val_accuracy: 0.9615\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.96117 to 0.96150, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1266 - accuracy: 0.9649 - val_loss: 0.1397 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00070: val_accuracy improved from 0.96150 to 0.96200, saving model to mnist_conv_best.h5\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1248 - accuracy: 0.9660 - val_loss: 0.1378 - val_accuracy: 0.9631\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.96200 to 0.96308, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.1227 - accuracy: 0.9663 - val_loss: 0.1364 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.96308 to 0.96367, saving model to mnist_conv_best.h5\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.1212 - accuracy: 0.9666 - val_loss: 0.1343 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.96367\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1194 - accuracy: 0.9674 - val_loss: 0.1329 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.96367 to 0.96467, saving model to mnist_conv_best.h5\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1177 - accuracy: 0.9676 - val_loss: 0.1330 - val_accuracy: 0.9635\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.96467\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1161 - accuracy: 0.9686 - val_loss: 0.1298 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.96467 to 0.96508, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1147 - accuracy: 0.9689 - val_loss: 0.1294 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.96508\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1130 - accuracy: 0.9691 - val_loss: 0.1262 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.96508 to 0.96567, saving model to mnist_conv_best.h5\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1117 - accuracy: 0.9698 - val_loss: 0.1251 - val_accuracy: 0.9655\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.96567\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1102 - accuracy: 0.9701 - val_loss: 0.1242 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.96567\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.1089 - accuracy: 0.9705 - val_loss: 0.1222 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.96567 to 0.96675, saving model to mnist_conv_best.h5\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1076 - accuracy: 0.9708 - val_loss: 0.1210 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.96675\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 16s 83ms/step - loss: 0.1062 - accuracy: 0.9713 - val_loss: 0.1203 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.96675\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.1050 - accuracy: 0.9716 - val_loss: 0.1182 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.96675 to 0.96717, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.1037 - accuracy: 0.9723 - val_loss: 0.1188 - val_accuracy: 0.9674\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.96717 to 0.96742, saving model to mnist_conv_best.h5\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.1027 - accuracy: 0.9724 - val_loss: 0.1158 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.96742 to 0.96850, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.1013 - accuracy: 0.9724 - val_loss: 0.1152 - val_accuracy: 0.9682\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.96850\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.1001 - accuracy: 0.9727 - val_loss: 0.1148 - val_accuracy: 0.9684\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.96850\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0991 - accuracy: 0.9734 - val_loss: 0.1138 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.96850 to 0.96892, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0981 - accuracy: 0.9735 - val_loss: 0.1135 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.96892\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0970 - accuracy: 0.9735 - val_loss: 0.1114 - val_accuracy: 0.9695\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.96892 to 0.96950, saving model to mnist_conv_best.h5\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0962 - accuracy: 0.9740 - val_loss: 0.1109 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.96950\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0949 - accuracy: 0.9748 - val_loss: 0.1085 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.96950 to 0.96967, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0941 - accuracy: 0.9747 - val_loss: 0.1083 - val_accuracy: 0.9694\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.96967\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0931 - accuracy: 0.9751 - val_loss: 0.1079 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00095: val_accuracy improved from 0.96967 to 0.96975, saving model to mnist_conv_best.h5\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.1079 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.96975\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0914 - accuracy: 0.9752 - val_loss: 0.1057 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.96975 to 0.97042, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0905 - accuracy: 0.9756 - val_loss: 0.1053 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.97042 to 0.97092, saving model to mnist_conv_best.h5\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0897 - accuracy: 0.9759 - val_loss: 0.1048 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.97092\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0889 - accuracy: 0.9765 - val_loss: 0.1028 - val_accuracy: 0.9713\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.97092 to 0.97133, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0881 - accuracy: 0.9761 - val_loss: 0.1027 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.97133\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0873 - accuracy: 0.9762 - val_loss: 0.1022 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.97133 to 0.97142, saving model to mnist_conv_best.h5\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0866 - accuracy: 0.9768 - val_loss: 0.1014 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.97142 to 0.97183, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0858 - accuracy: 0.9772 - val_loss: 0.1005 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.97183 to 0.97192, saving model to mnist_conv_best.h5\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0851 - accuracy: 0.9770 - val_loss: 0.1000 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.97192\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0842 - accuracy: 0.9773 - val_loss: 0.1004 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97192\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0838 - accuracy: 0.9772 - val_loss: 0.0993 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00107: val_accuracy improved from 0.97192 to 0.97225, saving model to mnist_conv_best.h5\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.0977 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.97225 to 0.97275, saving model to mnist_conv_best.h5\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0824 - accuracy: 0.9776 - val_loss: 0.0975 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.97275\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0818 - accuracy: 0.9776 - val_loss: 0.0967 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.97275\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0811 - accuracy: 0.9779 - val_loss: 0.0963 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.97275\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0805 - accuracy: 0.9782 - val_loss: 0.0952 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00112: val_accuracy improved from 0.97275 to 0.97325, saving model to mnist_conv_best.h5\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0799 - accuracy: 0.9786 - val_loss: 0.0951 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.97325\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0793 - accuracy: 0.9784 - val_loss: 0.0952 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.97325\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0788 - accuracy: 0.9788 - val_loss: 0.0948 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00115: val_accuracy improved from 0.97325 to 0.97358, saving model to mnist_conv_best.h5\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0782 - accuracy: 0.9790 - val_loss: 0.0932 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.97358\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0775 - accuracy: 0.9789 - val_loss: 0.0933 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.97358 to 0.97383, saving model to mnist_conv_best.h5\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0770 - accuracy: 0.9791 - val_loss: 0.0933 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.97383 to 0.97417, saving model to mnist_conv_best.h5\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0766 - accuracy: 0.9794 - val_loss: 0.0921 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97417\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0761 - accuracy: 0.9793 - val_loss: 0.0912 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.97417\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0755 - accuracy: 0.9799 - val_loss: 0.0905 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97417\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0750 - accuracy: 0.9798 - val_loss: 0.0904 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.97417\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0746 - accuracy: 0.9797 - val_loss: 0.0900 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00123: val_accuracy improved from 0.97417 to 0.97442, saving model to mnist_conv_best.h5\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0740 - accuracy: 0.9802 - val_loss: 0.0902 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.97442\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0737 - accuracy: 0.9801 - val_loss: 0.0895 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97442\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0730 - accuracy: 0.9805 - val_loss: 0.0888 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00126: val_accuracy improved from 0.97442 to 0.97450, saving model to mnist_conv_best.h5\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.0885 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.97450\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.0874 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00128: val_accuracy improved from 0.97450 to 0.97500, saving model to mnist_conv_best.h5\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0716 - accuracy: 0.9808 - val_loss: 0.0882 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.97500\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0713 - accuracy: 0.9805 - val_loss: 0.0880 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97500\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0709 - accuracy: 0.9809 - val_loss: 0.0869 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97500\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0704 - accuracy: 0.9811 - val_loss: 0.0859 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00132: val_accuracy improved from 0.97500 to 0.97533, saving model to mnist_conv_best.h5\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0699 - accuracy: 0.9812 - val_loss: 0.0865 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97533\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0696 - accuracy: 0.9810 - val_loss: 0.0856 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97533\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0691 - accuracy: 0.9814 - val_loss: 0.0861 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97533\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 16s 84ms/step - loss: 0.0688 - accuracy: 0.9811 - val_loss: 0.0858 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00136: val_accuracy improved from 0.97533 to 0.97542, saving model to mnist_conv_best.h5\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0684 - accuracy: 0.9816 - val_loss: 0.0848 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00137: val_accuracy improved from 0.97542 to 0.97567, saving model to mnist_conv_best.h5\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0680 - accuracy: 0.9818 - val_loss: 0.0848 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00138: val_accuracy improved from 0.97567 to 0.97575, saving model to mnist_conv_best.h5\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0677 - accuracy: 0.9819 - val_loss: 0.0847 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97575\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0674 - accuracy: 0.9819 - val_loss: 0.0835 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97575\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0670 - accuracy: 0.9821 - val_loss: 0.0833 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.97575 to 0.97600, saving model to mnist_conv_best.h5\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0667 - accuracy: 0.9819 - val_loss: 0.0831 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00142: val_accuracy improved from 0.97600 to 0.97658, saving model to mnist_conv_best.h5\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0663 - accuracy: 0.9823 - val_loss: 0.0832 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.97658\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0659 - accuracy: 0.9823 - val_loss: 0.0823 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.97658\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0654 - accuracy: 0.9823 - val_loss: 0.0824 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.97658\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0653 - accuracy: 0.9825 - val_loss: 0.0819 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97658\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0647 - accuracy: 0.9826 - val_loss: 0.0828 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97658\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0815 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00148: val_accuracy improved from 0.97658 to 0.97675, saving model to mnist_conv_best.h5\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0643 - accuracy: 0.9828 - val_loss: 0.0811 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.97675\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0638 - accuracy: 0.9827 - val_loss: 0.0813 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.97675\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0636 - accuracy: 0.9827 - val_loss: 0.0804 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.97675\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0631 - accuracy: 0.9831 - val_loss: 0.0804 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97675\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0630 - accuracy: 0.9830 - val_loss: 0.0800 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.97675\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0626 - accuracy: 0.9831 - val_loss: 0.0803 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00154: val_accuracy improved from 0.97675 to 0.97683, saving model to mnist_conv_best.h5\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.0794 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.97683\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0620 - accuracy: 0.9831 - val_loss: 0.0791 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.97683\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0618 - accuracy: 0.9833 - val_loss: 0.0789 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97683\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0616 - accuracy: 0.9833 - val_loss: 0.0787 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.97683\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0611 - accuracy: 0.9833 - val_loss: 0.0787 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00159: val_accuracy improved from 0.97683 to 0.97725, saving model to mnist_conv_best.h5\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 0.0610 - accuracy: 0.9834 - val_loss: 0.0791 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.97725\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0605 - accuracy: 0.9834 - val_loss: 0.0787 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.97725\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0604 - accuracy: 0.9836 - val_loss: 0.0787 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00162: val_accuracy improved from 0.97725 to 0.97750, saving model to mnist_conv_best.h5\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0601 - accuracy: 0.9837 - val_loss: 0.0789 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.97750\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0598 - accuracy: 0.9837 - val_loss: 0.0781 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.97750\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0595 - accuracy: 0.9838 - val_loss: 0.0777 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.97750\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0593 - accuracy: 0.9840 - val_loss: 0.0773 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.97750\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0592 - accuracy: 0.9835 - val_loss: 0.0771 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.97750\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0588 - accuracy: 0.9841 - val_loss: 0.0771 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.97750\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0586 - accuracy: 0.9842 - val_loss: 0.0769 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00169: val_accuracy improved from 0.97750 to 0.97758, saving model to mnist_conv_best.h5\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0583 - accuracy: 0.9843 - val_loss: 0.0765 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.97758\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0580 - accuracy: 0.9843 - val_loss: 0.0762 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.97758\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0577 - accuracy: 0.9844 - val_loss: 0.0772 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.97758\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.0761 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00173: val_accuracy improved from 0.97758 to 0.97800, saving model to mnist_conv_best.h5\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0574 - accuracy: 0.9844 - val_loss: 0.0763 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.97800\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0571 - accuracy: 0.9845 - val_loss: 0.0758 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.97800\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0569 - accuracy: 0.9848 - val_loss: 0.0760 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.97800\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0567 - accuracy: 0.9847 - val_loss: 0.0748 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.97800\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0564 - accuracy: 0.9846 - val_loss: 0.0747 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.97800 to 0.97808, saving model to mnist_conv_best.h5\n",
            "Epoch 179/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0562 - accuracy: 0.9849 - val_loss: 0.0759 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.97808\n",
            "Epoch 180/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0559 - accuracy: 0.9847 - val_loss: 0.0754 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.97808\n",
            "Epoch 181/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0558 - accuracy: 0.9851 - val_loss: 0.0757 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.97808\n",
            "Epoch 182/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0556 - accuracy: 0.9850 - val_loss: 0.0741 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00182: val_accuracy improved from 0.97808 to 0.97875, saving model to mnist_conv_best.h5\n",
            "Epoch 183/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0553 - accuracy: 0.9850 - val_loss: 0.0740 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.97875\n",
            "Epoch 184/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0551 - accuracy: 0.9850 - val_loss: 0.0735 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.97875\n",
            "Epoch 185/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0549 - accuracy: 0.9850 - val_loss: 0.0745 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00185: val_accuracy improved from 0.97875 to 0.97892, saving model to mnist_conv_best.h5\n",
            "Epoch 186/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0547 - accuracy: 0.9852 - val_loss: 0.0733 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.97892\n",
            "Epoch 187/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0545 - accuracy: 0.9854 - val_loss: 0.0733 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.97892\n",
            "Epoch 188/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0542 - accuracy: 0.9853 - val_loss: 0.0733 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.97892\n",
            "Epoch 189/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0541 - accuracy: 0.9852 - val_loss: 0.0727 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.97892\n",
            "Epoch 190/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0539 - accuracy: 0.9854 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.97892\n",
            "Epoch 191/10000\n",
            "188/188 [==============================] - 16s 86ms/step - loss: 0.0536 - accuracy: 0.9853 - val_loss: 0.0728 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.97892\n",
            "Epoch 192/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0535 - accuracy: 0.9854 - val_loss: 0.0726 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.97892\n",
            "Epoch 193/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0532 - accuracy: 0.9856 - val_loss: 0.0735 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00193: val_accuracy improved from 0.97892 to 0.97908, saving model to mnist_conv_best.h5\n",
            "Epoch 194/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0531 - accuracy: 0.9859 - val_loss: 0.0720 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.97908\n",
            "Epoch 195/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0528 - accuracy: 0.9856 - val_loss: 0.0729 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.97908\n",
            "Epoch 196/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0527 - accuracy: 0.9856 - val_loss: 0.0719 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.97908\n",
            "Epoch 197/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0525 - accuracy: 0.9858 - val_loss: 0.0719 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.97908\n",
            "Epoch 198/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0522 - accuracy: 0.9859 - val_loss: 0.0714 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.97908\n",
            "Epoch 199/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0522 - accuracy: 0.9856 - val_loss: 0.0719 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.97908\n",
            "Epoch 200/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0519 - accuracy: 0.9858 - val_loss: 0.0720 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.97908\n",
            "Epoch 201/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0518 - accuracy: 0.9858 - val_loss: 0.0715 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.97908\n",
            "Epoch 202/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0516 - accuracy: 0.9860 - val_loss: 0.0713 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.97908\n",
            "Epoch 203/10000\n",
            "188/188 [==============================] - 16s 87ms/step - loss: 0.0514 - accuracy: 0.9860 - val_loss: 0.0709 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.97908\n",
            "Epoch 00203: early stopping\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0572 - accuracy: 0.9840\n",
            "Accuracy for the training set: 0.9839666485786438\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0604 - accuracy: 0.9811\n",
            "Accuracy for the testing set: 0.9811000227928162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF_ocoxbpP8b"
      },
      "source": [
        "### Pooling Average Pooling Layer\n",
        "accuracy: 0.9733"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MsgWSZCtpP8i",
        "outputId": "0a2c1465-61d4-4b40-9556-25ab8867fad4"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.AveragePooling2D(pool_size=2, name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "pooling (AveragePooling2D)   (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                31370     \n",
            "=================================================================\n",
            "Total params: 31,642\n",
            "Trainable params: 31,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.9940 - accuracy: 0.4956 - val_loss: 1.2943 - val_accuracy: 0.7722\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.77217, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.7933 - accuracy: 0.8295 - val_loss: 0.5594 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.77217 to 0.86075, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.4911 - accuracy: 0.8698 - val_loss: 0.4488 - val_accuracy: 0.8807\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.86075 to 0.88067, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.4225 - accuracy: 0.8831 - val_loss: 0.4077 - val_accuracy: 0.8885\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.88067 to 0.88850, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3913 - accuracy: 0.8904 - val_loss: 0.3838 - val_accuracy: 0.8940\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.88850 to 0.89400, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3722 - accuracy: 0.8949 - val_loss: 0.3702 - val_accuracy: 0.8964\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.89400 to 0.89642, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3595 - accuracy: 0.8978 - val_loss: 0.3593 - val_accuracy: 0.9001\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.89642 to 0.90008, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3498 - accuracy: 0.8997 - val_loss: 0.3531 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.90008 to 0.90033, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.3420 - accuracy: 0.9018 - val_loss: 0.3447 - val_accuracy: 0.9036\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.90033 to 0.90358, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.3355 - accuracy: 0.9038 - val_loss: 0.3421 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.90358 to 0.90550, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3297 - accuracy: 0.9050 - val_loss: 0.3343 - val_accuracy: 0.9062\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.90550 to 0.90617, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3253 - accuracy: 0.9063 - val_loss: 0.3304 - val_accuracy: 0.9076\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.90617 to 0.90758, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3208 - accuracy: 0.9078 - val_loss: 0.3296 - val_accuracy: 0.9080\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.90758 to 0.90800, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3174 - accuracy: 0.9084 - val_loss: 0.3238 - val_accuracy: 0.9094\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.90800 to 0.90942, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3141 - accuracy: 0.9097 - val_loss: 0.3207 - val_accuracy: 0.9103\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.90942 to 0.91033, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3113 - accuracy: 0.9105 - val_loss: 0.3200 - val_accuracy: 0.9114\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.91033 to 0.91142, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3083 - accuracy: 0.9118 - val_loss: 0.3158 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91142 to 0.91275, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3060 - accuracy: 0.9118 - val_loss: 0.3146 - val_accuracy: 0.9137\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.91275 to 0.91367, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3037 - accuracy: 0.9128 - val_loss: 0.3134 - val_accuracy: 0.9124\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91367\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.3018 - accuracy: 0.9129 - val_loss: 0.3111 - val_accuracy: 0.9133\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91367\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2999 - accuracy: 0.9139 - val_loss: 0.3078 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.91367 to 0.91475, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2979 - accuracy: 0.9146 - val_loss: 0.3071 - val_accuracy: 0.9157\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.91475 to 0.91567, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2963 - accuracy: 0.9149 - val_loss: 0.3053 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.91567 to 0.91592, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.2945 - accuracy: 0.9153 - val_loss: 0.3068 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91592\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2929 - accuracy: 0.9156 - val_loss: 0.3034 - val_accuracy: 0.9162\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.91592 to 0.91625, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2916 - accuracy: 0.9162 - val_loss: 0.3030 - val_accuracy: 0.9168\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.91625 to 0.91675, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2899 - accuracy: 0.9171 - val_loss: 0.3027 - val_accuracy: 0.9144\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91675\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2888 - accuracy: 0.9174 - val_loss: 0.3001 - val_accuracy: 0.9166\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91675\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2873 - accuracy: 0.9175 - val_loss: 0.3002 - val_accuracy: 0.9175\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.91675 to 0.91750, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2862 - accuracy: 0.9179 - val_loss: 0.2971 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91750\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2847 - accuracy: 0.9185 - val_loss: 0.2958 - val_accuracy: 0.9192\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.91750 to 0.91917, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2835 - accuracy: 0.9191 - val_loss: 0.2954 - val_accuracy: 0.9179\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91917\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2823 - accuracy: 0.9192 - val_loss: 0.2999 - val_accuracy: 0.9166\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91917\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2811 - accuracy: 0.9203 - val_loss: 0.2960 - val_accuracy: 0.9178\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91917\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2800 - accuracy: 0.9200 - val_loss: 0.2947 - val_accuracy: 0.9183\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91917\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2787 - accuracy: 0.9204 - val_loss: 0.2939 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91917\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2776 - accuracy: 0.9213 - val_loss: 0.2902 - val_accuracy: 0.9198\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.91917 to 0.91983, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2767 - accuracy: 0.9213 - val_loss: 0.2893 - val_accuracy: 0.9214\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.91983 to 0.92142, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2753 - accuracy: 0.9221 - val_loss: 0.2881 - val_accuracy: 0.9213\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.92142\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2742 - accuracy: 0.9217 - val_loss: 0.2897 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.92142\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2729 - accuracy: 0.9221 - val_loss: 0.2864 - val_accuracy: 0.9216\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.92142 to 0.92158, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.2719 - accuracy: 0.9226 - val_loss: 0.2870 - val_accuracy: 0.9208\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.92158\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2706 - accuracy: 0.9234 - val_loss: 0.2850 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.92158 to 0.92208, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2694 - accuracy: 0.9238 - val_loss: 0.2837 - val_accuracy: 0.9230\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.92208 to 0.92300, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2682 - accuracy: 0.9241 - val_loss: 0.2817 - val_accuracy: 0.9237\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.92300 to 0.92367, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2672 - accuracy: 0.9246 - val_loss: 0.2823 - val_accuracy: 0.9218\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.92367\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2658 - accuracy: 0.9247 - val_loss: 0.2804 - val_accuracy: 0.9244\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.92367 to 0.92442, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2644 - accuracy: 0.9250 - val_loss: 0.2793 - val_accuracy: 0.9232\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.92442\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2632 - accuracy: 0.9254 - val_loss: 0.2780 - val_accuracy: 0.9235\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.92442\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2620 - accuracy: 0.9254 - val_loss: 0.2777 - val_accuracy: 0.9234\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.92442\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2606 - accuracy: 0.9259 - val_loss: 0.2740 - val_accuracy: 0.9260\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.92442 to 0.92600, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2593 - accuracy: 0.9264 - val_loss: 0.2734 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.92600\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2579 - accuracy: 0.9272 - val_loss: 0.2730 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.92600\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2566 - accuracy: 0.9279 - val_loss: 0.2733 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.92600\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2549 - accuracy: 0.9280 - val_loss: 0.2712 - val_accuracy: 0.9251\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.92600\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2538 - accuracy: 0.9280 - val_loss: 0.2691 - val_accuracy: 0.9273\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.92600 to 0.92725, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2525 - accuracy: 0.9283 - val_loss: 0.2671 - val_accuracy: 0.9274\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.92725 to 0.92742, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2507 - accuracy: 0.9299 - val_loss: 0.2647 - val_accuracy: 0.9277\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.92742 to 0.92767, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2493 - accuracy: 0.9299 - val_loss: 0.2662 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.92767\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2477 - accuracy: 0.9301 - val_loss: 0.2631 - val_accuracy: 0.9287\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.92767 to 0.92875, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2463 - accuracy: 0.9305 - val_loss: 0.2616 - val_accuracy: 0.9282\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.92875\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2445 - accuracy: 0.9313 - val_loss: 0.2646 - val_accuracy: 0.9279\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.92875\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2427 - accuracy: 0.9323 - val_loss: 0.2570 - val_accuracy: 0.9309\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.92875 to 0.93092, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2412 - accuracy: 0.9322 - val_loss: 0.2557 - val_accuracy: 0.9298\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.93092\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2398 - accuracy: 0.9326 - val_loss: 0.2560 - val_accuracy: 0.9298\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93092\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2379 - accuracy: 0.9339 - val_loss: 0.2548 - val_accuracy: 0.9289\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93092\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2361 - accuracy: 0.9339 - val_loss: 0.2518 - val_accuracy: 0.9311\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.93092 to 0.93108, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2344 - accuracy: 0.9350 - val_loss: 0.2484 - val_accuracy: 0.9327\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.93108 to 0.93275, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2328 - accuracy: 0.9353 - val_loss: 0.2501 - val_accuracy: 0.9323\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93275\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2309 - accuracy: 0.9355 - val_loss: 0.2480 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93275\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2291 - accuracy: 0.9361 - val_loss: 0.2442 - val_accuracy: 0.9330\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.93275 to 0.93300, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2275 - accuracy: 0.9371 - val_loss: 0.2422 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.93300 to 0.93350, saving model to mnist_conv_best.h5\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2255 - accuracy: 0.9374 - val_loss: 0.2396 - val_accuracy: 0.9352\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.93350 to 0.93517, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2239 - accuracy: 0.9379 - val_loss: 0.2395 - val_accuracy: 0.9347\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93517\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2220 - accuracy: 0.9388 - val_loss: 0.2374 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93517\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2198 - accuracy: 0.9390 - val_loss: 0.2355 - val_accuracy: 0.9347\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.93517\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2181 - accuracy: 0.9398 - val_loss: 0.2327 - val_accuracy: 0.9361\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.93517 to 0.93608, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2162 - accuracy: 0.9408 - val_loss: 0.2323 - val_accuracy: 0.9361\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93608\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2141 - accuracy: 0.9406 - val_loss: 0.2297 - val_accuracy: 0.9367\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.93608 to 0.93667, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2125 - accuracy: 0.9417 - val_loss: 0.2272 - val_accuracy: 0.9382\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.93667 to 0.93817, saving model to mnist_conv_best.h5\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2105 - accuracy: 0.9424 - val_loss: 0.2248 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.93817 to 0.93842, saving model to mnist_conv_best.h5\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2087 - accuracy: 0.9425 - val_loss: 0.2242 - val_accuracy: 0.9391\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.93842 to 0.93908, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2067 - accuracy: 0.9428 - val_loss: 0.2228 - val_accuracy: 0.9388\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93908\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2050 - accuracy: 0.9438 - val_loss: 0.2200 - val_accuracy: 0.9407\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.93908 to 0.94067, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2030 - accuracy: 0.9446 - val_loss: 0.2183 - val_accuracy: 0.9406\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.94067\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.2014 - accuracy: 0.9448 - val_loss: 0.2156 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.94067 to 0.94142, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1996 - accuracy: 0.9454 - val_loss: 0.2139 - val_accuracy: 0.9415\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.94142 to 0.94150, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1974 - accuracy: 0.9456 - val_loss: 0.2132 - val_accuracy: 0.9417\n",
            "\n",
            "Epoch 00088: val_accuracy improved from 0.94150 to 0.94167, saving model to mnist_conv_best.h5\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1958 - accuracy: 0.9460 - val_loss: 0.2103 - val_accuracy: 0.9426\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.94167 to 0.94258, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1940 - accuracy: 0.9467 - val_loss: 0.2090 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.94258 to 0.94350, saving model to mnist_conv_best.h5\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1922 - accuracy: 0.9472 - val_loss: 0.2092 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.94350\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1903 - accuracy: 0.9475 - val_loss: 0.2052 - val_accuracy: 0.9451\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.94350 to 0.94508, saving model to mnist_conv_best.h5\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1886 - accuracy: 0.9489 - val_loss: 0.2039 - val_accuracy: 0.9453\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.94508 to 0.94533, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1870 - accuracy: 0.9488 - val_loss: 0.2035 - val_accuracy: 0.9451\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.94533\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1850 - accuracy: 0.9497 - val_loss: 0.2006 - val_accuracy: 0.9444\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.94533\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1836 - accuracy: 0.9499 - val_loss: 0.1987 - val_accuracy: 0.9471\n",
            "\n",
            "Epoch 00096: val_accuracy improved from 0.94533 to 0.94708, saving model to mnist_conv_best.h5\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.1817 - accuracy: 0.9507 - val_loss: 0.1988 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.94708\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1800 - accuracy: 0.9512 - val_loss: 0.1960 - val_accuracy: 0.9471\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.94708\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1784 - accuracy: 0.9517 - val_loss: 0.1948 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.94708\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1767 - accuracy: 0.9513 - val_loss: 0.1919 - val_accuracy: 0.9488\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.94708 to 0.94875, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1752 - accuracy: 0.9521 - val_loss: 0.1915 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.94875\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1737 - accuracy: 0.9527 - val_loss: 0.1906 - val_accuracy: 0.9475\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.94875\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1722 - accuracy: 0.9533 - val_loss: 0.1887 - val_accuracy: 0.9489\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.94875 to 0.94892, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1706 - accuracy: 0.9536 - val_loss: 0.1867 - val_accuracy: 0.9499\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.94892 to 0.94992, saving model to mnist_conv_best.h5\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1690 - accuracy: 0.9543 - val_loss: 0.1853 - val_accuracy: 0.9505\n",
            "\n",
            "Epoch 00105: val_accuracy improved from 0.94992 to 0.95050, saving model to mnist_conv_best.h5\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1677 - accuracy: 0.9544 - val_loss: 0.1826 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00106: val_accuracy improved from 0.95050 to 0.95092, saving model to mnist_conv_best.h5\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1661 - accuracy: 0.9547 - val_loss: 0.1816 - val_accuracy: 0.9513\n",
            "\n",
            "Epoch 00107: val_accuracy improved from 0.95092 to 0.95125, saving model to mnist_conv_best.h5\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1649 - accuracy: 0.9552 - val_loss: 0.1818 - val_accuracy: 0.9504\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.95125\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1633 - accuracy: 0.9553 - val_loss: 0.1791 - val_accuracy: 0.9524\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.95125 to 0.95242, saving model to mnist_conv_best.h5\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1619 - accuracy: 0.9562 - val_loss: 0.1779 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.95242 to 0.95250, saving model to mnist_conv_best.h5\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1605 - accuracy: 0.9570 - val_loss: 0.1760 - val_accuracy: 0.9524\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.95250\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1592 - accuracy: 0.9567 - val_loss: 0.1751 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00112: val_accuracy improved from 0.95250 to 0.95267, saving model to mnist_conv_best.h5\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1580 - accuracy: 0.9571 - val_loss: 0.1731 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.95267 to 0.95367, saving model to mnist_conv_best.h5\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1564 - accuracy: 0.9577 - val_loss: 0.1722 - val_accuracy: 0.9542\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.95367 to 0.95417, saving model to mnist_conv_best.h5\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1552 - accuracy: 0.9577 - val_loss: 0.1713 - val_accuracy: 0.9538\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.95417\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1540 - accuracy: 0.9579 - val_loss: 0.1696 - val_accuracy: 0.9552\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.95417 to 0.95517, saving model to mnist_conv_best.h5\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1528 - accuracy: 0.9585 - val_loss: 0.1686 - val_accuracy: 0.9548\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.95517\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1516 - accuracy: 0.9588 - val_loss: 0.1678 - val_accuracy: 0.9553\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.95517 to 0.95533, saving model to mnist_conv_best.h5\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1504 - accuracy: 0.9592 - val_loss: 0.1662 - val_accuracy: 0.9562\n",
            "\n",
            "Epoch 00119: val_accuracy improved from 0.95533 to 0.95617, saving model to mnist_conv_best.h5\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1492 - accuracy: 0.9593 - val_loss: 0.1644 - val_accuracy: 0.9570\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.95617 to 0.95700, saving model to mnist_conv_best.h5\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1480 - accuracy: 0.9601 - val_loss: 0.1641 - val_accuracy: 0.9558\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.95700\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1468 - accuracy: 0.9602 - val_loss: 0.1646 - val_accuracy: 0.9572\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.95700 to 0.95725, saving model to mnist_conv_best.h5\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1458 - accuracy: 0.9606 - val_loss: 0.1616 - val_accuracy: 0.9570\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.95725\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1445 - accuracy: 0.9607 - val_loss: 0.1605 - val_accuracy: 0.9577\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.95725 to 0.95767, saving model to mnist_conv_best.h5\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1436 - accuracy: 0.9611 - val_loss: 0.1596 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00125: val_accuracy improved from 0.95767 to 0.95792, saving model to mnist_conv_best.h5\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1425 - accuracy: 0.9615 - val_loss: 0.1589 - val_accuracy: 0.9574\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.95792\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1413 - accuracy: 0.9618 - val_loss: 0.1580 - val_accuracy: 0.9578\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.95792\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1404 - accuracy: 0.9618 - val_loss: 0.1559 - val_accuracy: 0.9589\n",
            "\n",
            "Epoch 00128: val_accuracy improved from 0.95792 to 0.95892, saving model to mnist_conv_best.h5\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1395 - accuracy: 0.9624 - val_loss: 0.1553 - val_accuracy: 0.9593\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.95892 to 0.95933, saving model to mnist_conv_best.h5\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1385 - accuracy: 0.9628 - val_loss: 0.1547 - val_accuracy: 0.9591\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.95933\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1374 - accuracy: 0.9629 - val_loss: 0.1539 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.95933\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1364 - accuracy: 0.9634 - val_loss: 0.1522 - val_accuracy: 0.9596\n",
            "\n",
            "Epoch 00132: val_accuracy improved from 0.95933 to 0.95958, saving model to mnist_conv_best.h5\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1356 - accuracy: 0.9635 - val_loss: 0.1519 - val_accuracy: 0.9602\n",
            "\n",
            "Epoch 00133: val_accuracy improved from 0.95958 to 0.96017, saving model to mnist_conv_best.h5\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1347 - accuracy: 0.9635 - val_loss: 0.1512 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.96017\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1339 - accuracy: 0.9641 - val_loss: 0.1493 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.96017 to 0.96033, saving model to mnist_conv_best.h5\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1328 - accuracy: 0.9643 - val_loss: 0.1492 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.96033\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1319 - accuracy: 0.9641 - val_loss: 0.1476 - val_accuracy: 0.9611\n",
            "\n",
            "Epoch 00137: val_accuracy improved from 0.96033 to 0.96108, saving model to mnist_conv_best.h5\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1310 - accuracy: 0.9648 - val_loss: 0.1478 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.96108\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1304 - accuracy: 0.9646 - val_loss: 0.1465 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00139: val_accuracy improved from 0.96108 to 0.96167, saving model to mnist_conv_best.h5\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1293 - accuracy: 0.9651 - val_loss: 0.1458 - val_accuracy: 0.9615\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.96167\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1285 - accuracy: 0.9655 - val_loss: 0.1444 - val_accuracy: 0.9625\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.96167 to 0.96250, saving model to mnist_conv_best.h5\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1278 - accuracy: 0.9655 - val_loss: 0.1448 - val_accuracy: 0.9608\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.96250\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1270 - accuracy: 0.9659 - val_loss: 0.1431 - val_accuracy: 0.9613\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.96250\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1260 - accuracy: 0.9661 - val_loss: 0.1427 - val_accuracy: 0.9617\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.96250\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1253 - accuracy: 0.9662 - val_loss: 0.1411 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00145: val_accuracy improved from 0.96250 to 0.96258, saving model to mnist_conv_best.h5\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1245 - accuracy: 0.9666 - val_loss: 0.1408 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00146: val_accuracy improved from 0.96258 to 0.96300, saving model to mnist_conv_best.h5\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1239 - accuracy: 0.9668 - val_loss: 0.1397 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.96300\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1230 - accuracy: 0.9671 - val_loss: 0.1390 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.96300\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1223 - accuracy: 0.9670 - val_loss: 0.1386 - val_accuracy: 0.9629\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.96300\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1216 - accuracy: 0.9673 - val_loss: 0.1377 - val_accuracy: 0.9634\n",
            "\n",
            "Epoch 00150: val_accuracy improved from 0.96300 to 0.96342, saving model to mnist_conv_best.h5\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1209 - accuracy: 0.9677 - val_loss: 0.1374 - val_accuracy: 0.9641\n",
            "\n",
            "Epoch 00151: val_accuracy improved from 0.96342 to 0.96408, saving model to mnist_conv_best.h5\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1203 - accuracy: 0.9679 - val_loss: 0.1360 - val_accuracy: 0.9641\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.96408\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1195 - accuracy: 0.9682 - val_loss: 0.1363 - val_accuracy: 0.9627\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.96408\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1189 - accuracy: 0.9679 - val_loss: 0.1350 - val_accuracy: 0.9636\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.96408\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1181 - accuracy: 0.9681 - val_loss: 0.1347 - val_accuracy: 0.9645\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.96408 to 0.96450, saving model to mnist_conv_best.h5\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1175 - accuracy: 0.9681 - val_loss: 0.1334 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.96450\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1167 - accuracy: 0.9686 - val_loss: 0.1346 - val_accuracy: 0.9633\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.96450\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1161 - accuracy: 0.9684 - val_loss: 0.1329 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.96450\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1155 - accuracy: 0.9691 - val_loss: 0.1317 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.96450\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1151 - accuracy: 0.9688 - val_loss: 0.1313 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.96450\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1143 - accuracy: 0.9693 - val_loss: 0.1307 - val_accuracy: 0.9649\n",
            "\n",
            "Epoch 00161: val_accuracy improved from 0.96450 to 0.96492, saving model to mnist_conv_best.h5\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1138 - accuracy: 0.9690 - val_loss: 0.1302 - val_accuracy: 0.9646\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.96492\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1131 - accuracy: 0.9693 - val_loss: 0.1305 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.96492\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1126 - accuracy: 0.9698 - val_loss: 0.1293 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00164: val_accuracy improved from 0.96492 to 0.96533, saving model to mnist_conv_best.h5\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1119 - accuracy: 0.9694 - val_loss: 0.1285 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.96533\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1113 - accuracy: 0.9699 - val_loss: 0.1281 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.96533\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1106 - accuracy: 0.9702 - val_loss: 0.1271 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00167: val_accuracy improved from 0.96533 to 0.96567, saving model to mnist_conv_best.h5\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1101 - accuracy: 0.9701 - val_loss: 0.1264 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00168: val_accuracy improved from 0.96567 to 0.96650, saving model to mnist_conv_best.h5\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1095 - accuracy: 0.9707 - val_loss: 0.1271 - val_accuracy: 0.9659\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.96650\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.1091 - accuracy: 0.9707 - val_loss: 0.1266 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.96650\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1085 - accuracy: 0.9708 - val_loss: 0.1253 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.96650\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1080 - accuracy: 0.9706 - val_loss: 0.1250 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00172: val_accuracy improved from 0.96650 to 0.96683, saving model to mnist_conv_best.h5\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1075 - accuracy: 0.9707 - val_loss: 0.1240 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.96683\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1069 - accuracy: 0.9710 - val_loss: 0.1247 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.96683\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1065 - accuracy: 0.9714 - val_loss: 0.1231 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.96683\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1059 - accuracy: 0.9714 - val_loss: 0.1230 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.96683\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1053 - accuracy: 0.9715 - val_loss: 0.1232 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.96683\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1048 - accuracy: 0.9716 - val_loss: 0.1227 - val_accuracy: 0.9671\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.96683 to 0.96708, saving model to mnist_conv_best.h5\n",
            "Epoch 179/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1044 - accuracy: 0.9718 - val_loss: 0.1207 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00179: val_accuracy improved from 0.96708 to 0.96800, saving model to mnist_conv_best.h5\n",
            "Epoch 180/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1040 - accuracy: 0.9715 - val_loss: 0.1214 - val_accuracy: 0.9671\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.96800\n",
            "Epoch 181/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1034 - accuracy: 0.9720 - val_loss: 0.1208 - val_accuracy: 0.9666\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.96800\n",
            "Epoch 182/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1030 - accuracy: 0.9720 - val_loss: 0.1201 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.96800\n",
            "Epoch 183/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1025 - accuracy: 0.9724 - val_loss: 0.1204 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.96800\n",
            "Epoch 184/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1019 - accuracy: 0.9722 - val_loss: 0.1190 - val_accuracy: 0.9674\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.96800\n",
            "Epoch 185/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1015 - accuracy: 0.9722 - val_loss: 0.1194 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.96800\n",
            "Epoch 186/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1011 - accuracy: 0.9722 - val_loss: 0.1188 - val_accuracy: 0.9676\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.96800\n",
            "Epoch 187/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1005 - accuracy: 0.9726 - val_loss: 0.1186 - val_accuracy: 0.9675\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.96800\n",
            "Epoch 188/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1003 - accuracy: 0.9724 - val_loss: 0.1178 - val_accuracy: 0.9674\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.96800\n",
            "Epoch 189/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0999 - accuracy: 0.9728 - val_loss: 0.1169 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00189: val_accuracy improved from 0.96800 to 0.96858, saving model to mnist_conv_best.h5\n",
            "Epoch 190/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0991 - accuracy: 0.9727 - val_loss: 0.1161 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00190: val_accuracy improved from 0.96858 to 0.96875, saving model to mnist_conv_best.h5\n",
            "Epoch 191/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0988 - accuracy: 0.9728 - val_loss: 0.1166 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.96875\n",
            "Epoch 192/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0982 - accuracy: 0.9733 - val_loss: 0.1160 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.96875\n",
            "Epoch 193/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0980 - accuracy: 0.9731 - val_loss: 0.1152 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00193: val_accuracy improved from 0.96875 to 0.96933, saving model to mnist_conv_best.h5\n",
            "Epoch 194/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0975 - accuracy: 0.9729 - val_loss: 0.1162 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.96933\n",
            "Epoch 195/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0973 - accuracy: 0.9731 - val_loss: 0.1150 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.96933\n",
            "Epoch 196/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0967 - accuracy: 0.9736 - val_loss: 0.1140 - val_accuracy: 0.9692\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.96933\n",
            "Epoch 197/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0963 - accuracy: 0.9734 - val_loss: 0.1133 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00197: val_accuracy improved from 0.96933 to 0.96967, saving model to mnist_conv_best.h5\n",
            "Epoch 198/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0959 - accuracy: 0.9736 - val_loss: 0.1137 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.96967\n",
            "Epoch 199/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0954 - accuracy: 0.9738 - val_loss: 0.1134 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.96967\n",
            "Epoch 200/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0951 - accuracy: 0.9738 - val_loss: 0.1135 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.96967\n",
            "Epoch 201/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0947 - accuracy: 0.9740 - val_loss: 0.1124 - val_accuracy: 0.9692\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.96967\n",
            "Epoch 202/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0943 - accuracy: 0.9739 - val_loss: 0.1119 - val_accuracy: 0.9694\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.96967\n",
            "Epoch 203/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0939 - accuracy: 0.9739 - val_loss: 0.1114 - val_accuracy: 0.9695\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.96967\n",
            "Epoch 204/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0936 - accuracy: 0.9745 - val_loss: 0.1117 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.96967\n",
            "Epoch 205/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0933 - accuracy: 0.9745 - val_loss: 0.1121 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.96967\n",
            "Epoch 206/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0928 - accuracy: 0.9747 - val_loss: 0.1104 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.96967\n",
            "Epoch 207/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0925 - accuracy: 0.9745 - val_loss: 0.1107 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.96967\n",
            "Epoch 00207: early stopping\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0992 - accuracy: 0.9733\n",
            "Accuracy for the training set: 0.9733499884605408\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0962 - accuracy: 0.9733\n",
            "Accuracy for the testing set: 0.9732999801635742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaZFJFjDpZaF"
      },
      "source": [
        "### Global Average Pooling Layer\n",
        "\n",
        "0.1973"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipibhIcMpZaG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc8c3487-7133-4bb7-9790-6cee04f2d7b3"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.GlobalAveragePooling2D(name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "pooling (GlobalAveragePoolin (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 442\n",
            "Trainable params: 442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 12s 61ms/step - loss: 2.2993 - accuracy: 0.0993 - val_loss: 2.2985 - val_accuracy: 0.0998\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09983, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 2.2980 - accuracy: 0.1214 - val_loss: 2.2972 - val_accuracy: 0.1473\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09983 to 0.14733, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 2.2968 - accuracy: 0.1711 - val_loss: 2.2961 - val_accuracy: 0.1834\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.14733 to 0.18342, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 2.2957 - accuracy: 0.1914 - val_loss: 2.2950 - val_accuracy: 0.1961\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.18342 to 0.19608, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 2.2946 - accuracy: 0.1970 - val_loss: 2.2939 - val_accuracy: 0.1983\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.19608 to 0.19833, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 2.2935 - accuracy: 0.1985 - val_loss: 2.2928 - val_accuracy: 0.1981\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.19833\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 2.2924 - accuracy: 0.1984 - val_loss: 2.2916 - val_accuracy: 0.1977\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.19833\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 2.2913 - accuracy: 0.1975 - val_loss: 2.2905 - val_accuracy: 0.1973\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.19833\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 2.2901 - accuracy: 0.1974 - val_loss: 2.2892 - val_accuracy: 0.1973\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.19833\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 11s 61ms/step - loss: 2.2889 - accuracy: 0.1971 - val_loss: 2.2879 - val_accuracy: 0.1970\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.19833\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 2.2876 - accuracy: 0.1970 - val_loss: 2.2866 - val_accuracy: 0.1973\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.19833\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 2.2862 - accuracy: 0.1973 - val_loss: 2.2852 - val_accuracy: 0.1973\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.19833\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 2.2847 - accuracy: 0.1971 - val_loss: 2.2836 - val_accuracy: 0.1974\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.19833\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 2.2832 - accuracy: 0.1975 - val_loss: 2.2821 - val_accuracy: 0.1975\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.19833\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 2.2816 - accuracy: 0.1980 - val_loss: 2.2804 - val_accuracy: 0.1976\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.19833\n",
            "Epoch 00015: early stopping\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 2.2940 - accuracy: 0.1986\n",
            "Accuracy for the training set: 0.19861666858196259\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2943 - accuracy: 0.1973\n",
            "Accuracy for the testing set: 0.1973000019788742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr9ye3L3plAx"
      },
      "source": [
        "### Global Max Pooling Layer\n",
        "\n",
        " accuracy: 0.8115"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGvMYBhqplAy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2420a4db-9afe-4553-db05-760e54498d66"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.GlobalMaxPool2D(name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "pooling (GlobalMaxPooling2D) (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 442\n",
            "Trainable params: 442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 14s 71ms/step - loss: 2.3026 - accuracy: 0.1121 - val_loss: 2.2921 - val_accuracy: 0.1336\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.13358, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 2.2881 - accuracy: 0.1417 - val_loss: 2.2830 - val_accuracy: 0.1447\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.13358 to 0.14475, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 2.2794 - accuracy: 0.1427 - val_loss: 2.2744 - val_accuracy: 0.1589\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.14475 to 0.15892, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 2.2707 - accuracy: 0.1678 - val_loss: 2.2654 - val_accuracy: 0.1818\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.15892 to 0.18183, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 2.2613 - accuracy: 0.2005 - val_loss: 2.2554 - val_accuracy: 0.2314\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.18183 to 0.23142, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 2.2508 - accuracy: 0.2407 - val_loss: 2.2440 - val_accuracy: 0.2648\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.23142 to 0.26483, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 2.2388 - accuracy: 0.2689 - val_loss: 2.2308 - val_accuracy: 0.2648\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.26483\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 2.2249 - accuracy: 0.2855 - val_loss: 2.2157 - val_accuracy: 0.2940\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.26483 to 0.29400, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 2.2091 - accuracy: 0.3065 - val_loss: 2.1986 - val_accuracy: 0.3097\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.29400 to 0.30975, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 2.1916 - accuracy: 0.3209 - val_loss: 2.1802 - val_accuracy: 0.3415\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.30975 to 0.34150, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 2.1726 - accuracy: 0.3385 - val_loss: 2.1598 - val_accuracy: 0.3613\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.34150 to 0.36125, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 2.1520 - accuracy: 0.3589 - val_loss: 2.1380 - val_accuracy: 0.3631\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.36125 to 0.36308, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 2.1299 - accuracy: 0.3664 - val_loss: 2.1149 - val_accuracy: 0.3823\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.36308 to 0.38233, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 2.1064 - accuracy: 0.3732 - val_loss: 2.0906 - val_accuracy: 0.3981\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.38233 to 0.39808, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 2.0818 - accuracy: 0.3916 - val_loss: 2.0651 - val_accuracy: 0.4010\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.39808 to 0.40100, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 2.0564 - accuracy: 0.4004 - val_loss: 2.0390 - val_accuracy: 0.4176\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.40100 to 0.41758, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 2.0303 - accuracy: 0.4122 - val_loss: 2.0128 - val_accuracy: 0.4169\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.41758\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 2.0041 - accuracy: 0.4183 - val_loss: 1.9862 - val_accuracy: 0.4402\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.41758 to 0.44017, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.9778 - accuracy: 0.4330 - val_loss: 1.9597 - val_accuracy: 0.4474\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.44017 to 0.44742, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.9513 - accuracy: 0.4443 - val_loss: 1.9334 - val_accuracy: 0.4583\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.44742 to 0.45833, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.9248 - accuracy: 0.4582 - val_loss: 1.9065 - val_accuracy: 0.4667\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.45833 to 0.46675, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.8980 - accuracy: 0.4706 - val_loss: 1.8794 - val_accuracy: 0.4847\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.46675 to 0.48467, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.8708 - accuracy: 0.4864 - val_loss: 1.8520 - val_accuracy: 0.4952\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.48467 to 0.49517, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.8428 - accuracy: 0.4962 - val_loss: 1.8237 - val_accuracy: 0.5135\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.49517 to 0.51350, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.8146 - accuracy: 0.5110 - val_loss: 1.7945 - val_accuracy: 0.5217\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.51350 to 0.52175, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.7854 - accuracy: 0.5216 - val_loss: 1.7652 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.52175 to 0.53650, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.7556 - accuracy: 0.5326 - val_loss: 1.7350 - val_accuracy: 0.5450\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.53650 to 0.54500, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.7252 - accuracy: 0.5418 - val_loss: 1.7046 - val_accuracy: 0.5443\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.54500\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.6945 - accuracy: 0.5485 - val_loss: 1.6734 - val_accuracy: 0.5621\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.54500 to 0.56208, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.6635 - accuracy: 0.5561 - val_loss: 1.6431 - val_accuracy: 0.5589\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.56208\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.6326 - accuracy: 0.5633 - val_loss: 1.6123 - val_accuracy: 0.5662\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.56208 to 0.56617, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.6019 - accuracy: 0.5684 - val_loss: 1.5809 - val_accuracy: 0.5788\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.56617 to 0.57875, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.5714 - accuracy: 0.5754 - val_loss: 1.5514 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.57875 to 0.58125, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.5417 - accuracy: 0.5818 - val_loss: 1.5219 - val_accuracy: 0.5905\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.58125 to 0.59050, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.5124 - accuracy: 0.5853 - val_loss: 1.4932 - val_accuracy: 0.6024\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.59050 to 0.60242, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.4841 - accuracy: 0.5919 - val_loss: 1.4651 - val_accuracy: 0.6049\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.60242 to 0.60492, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.4564 - accuracy: 0.5985 - val_loss: 1.4383 - val_accuracy: 0.6095\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.60492 to 0.60950, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.4296 - accuracy: 0.6043 - val_loss: 1.4117 - val_accuracy: 0.6116\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.60950 to 0.61158, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.4034 - accuracy: 0.6074 - val_loss: 1.3857 - val_accuracy: 0.6173\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.61158 to 0.61725, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.3780 - accuracy: 0.6143 - val_loss: 1.3610 - val_accuracy: 0.6217\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.61725 to 0.62167, saving model to mnist_conv_best.h5\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.3534 - accuracy: 0.6187 - val_loss: 1.3372 - val_accuracy: 0.6260\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.62167 to 0.62600, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.3297 - accuracy: 0.6235 - val_loss: 1.3141 - val_accuracy: 0.6274\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.62600 to 0.62742, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.3066 - accuracy: 0.6278 - val_loss: 1.2917 - val_accuracy: 0.6392\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.62742 to 0.63917, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.2847 - accuracy: 0.6335 - val_loss: 1.2704 - val_accuracy: 0.6405\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.63917 to 0.64050, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.2635 - accuracy: 0.6378 - val_loss: 1.2496 - val_accuracy: 0.6439\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.64050 to 0.64392, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.2432 - accuracy: 0.6411 - val_loss: 1.2294 - val_accuracy: 0.6428\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.64392\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.2236 - accuracy: 0.6454 - val_loss: 1.2102 - val_accuracy: 0.6517\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.64392 to 0.65167, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.2049 - accuracy: 0.6485 - val_loss: 1.1924 - val_accuracy: 0.6561\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.65167 to 0.65608, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.1870 - accuracy: 0.6541 - val_loss: 1.1751 - val_accuracy: 0.6498\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.65608\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.1699 - accuracy: 0.6565 - val_loss: 1.1583 - val_accuracy: 0.6587\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.65608 to 0.65867, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.1537 - accuracy: 0.6586 - val_loss: 1.1423 - val_accuracy: 0.6613\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.65867 to 0.66133, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.1381 - accuracy: 0.6629 - val_loss: 1.1275 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.66133 to 0.66892, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.1234 - accuracy: 0.6650 - val_loss: 1.1141 - val_accuracy: 0.6644\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.66892\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.1095 - accuracy: 0.6681 - val_loss: 1.0993 - val_accuracy: 0.6702\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.66892 to 0.67025, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.0960 - accuracy: 0.6700 - val_loss: 1.0867 - val_accuracy: 0.6753\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.67025 to 0.67533, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.0831 - accuracy: 0.6737 - val_loss: 1.0742 - val_accuracy: 0.6764\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.67533 to 0.67642, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.0710 - accuracy: 0.6743 - val_loss: 1.0622 - val_accuracy: 0.6814\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.67642 to 0.68142, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.0592 - accuracy: 0.6771 - val_loss: 1.0513 - val_accuracy: 0.6817\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.68142 to 0.68175, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.0483 - accuracy: 0.6804 - val_loss: 1.0407 - val_accuracy: 0.6812\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.68175\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 1.0377 - accuracy: 0.6826 - val_loss: 1.0298 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.68175 to 0.68717, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.0275 - accuracy: 0.6843 - val_loss: 1.0205 - val_accuracy: 0.6889\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.68717 to 0.68892, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.0179 - accuracy: 0.6856 - val_loss: 1.0101 - val_accuracy: 0.6864\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.68892\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 1.0088 - accuracy: 0.6874 - val_loss: 1.0022 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.68892\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 1.0000 - accuracy: 0.6892 - val_loss: 0.9924 - val_accuracy: 0.6935\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.68892 to 0.69350, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.9915 - accuracy: 0.6922 - val_loss: 0.9856 - val_accuracy: 0.6951\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.69350 to 0.69508, saving model to mnist_conv_best.h5\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9835 - accuracy: 0.6936 - val_loss: 0.9765 - val_accuracy: 0.6976\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.69508 to 0.69758, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9759 - accuracy: 0.6952 - val_loss: 0.9692 - val_accuracy: 0.6972\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.69758\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9683 - accuracy: 0.6959 - val_loss: 0.9626 - val_accuracy: 0.7003\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.69758 to 0.70033, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9615 - accuracy: 0.6981 - val_loss: 0.9548 - val_accuracy: 0.6991\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.70033\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9547 - accuracy: 0.6995 - val_loss: 0.9491 - val_accuracy: 0.7021\n",
            "\n",
            "Epoch 00070: val_accuracy improved from 0.70033 to 0.70208, saving model to mnist_conv_best.h5\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9480 - accuracy: 0.7015 - val_loss: 0.9418 - val_accuracy: 0.7016\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.70208\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9418 - accuracy: 0.7016 - val_loss: 0.9379 - val_accuracy: 0.6999\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.70208\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9359 - accuracy: 0.7037 - val_loss: 0.9296 - val_accuracy: 0.7046\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.70208 to 0.70458, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.9300 - accuracy: 0.7045 - val_loss: 0.9249 - val_accuracy: 0.7068\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.70458 to 0.70683, saving model to mnist_conv_best.h5\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9245 - accuracy: 0.7056 - val_loss: 0.9189 - val_accuracy: 0.7086\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.70683 to 0.70858, saving model to mnist_conv_best.h5\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9191 - accuracy: 0.7060 - val_loss: 0.9137 - val_accuracy: 0.7088\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.70858 to 0.70883, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9138 - accuracy: 0.7079 - val_loss: 0.9081 - val_accuracy: 0.7113\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.70883 to 0.71125, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9089 - accuracy: 0.7100 - val_loss: 0.9046 - val_accuracy: 0.7074\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.71125\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.9038 - accuracy: 0.7108 - val_loss: 0.8987 - val_accuracy: 0.7132\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.71125 to 0.71325, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8994 - accuracy: 0.7121 - val_loss: 0.8946 - val_accuracy: 0.7117\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.71325\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8946 - accuracy: 0.7126 - val_loss: 0.8899 - val_accuracy: 0.7160\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.71325 to 0.71600, saving model to mnist_conv_best.h5\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8902 - accuracy: 0.7134 - val_loss: 0.8862 - val_accuracy: 0.7166\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.71600 to 0.71658, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8859 - accuracy: 0.7148 - val_loss: 0.8815 - val_accuracy: 0.7156\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.71658\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8818 - accuracy: 0.7162 - val_loss: 0.8778 - val_accuracy: 0.7188\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.71658 to 0.71875, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8779 - accuracy: 0.7168 - val_loss: 0.8727 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.71875\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8739 - accuracy: 0.7185 - val_loss: 0.8696 - val_accuracy: 0.7199\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.71875 to 0.71992, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8700 - accuracy: 0.7200 - val_loss: 0.8652 - val_accuracy: 0.7201\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.71992 to 0.72008, saving model to mnist_conv_best.h5\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8663 - accuracy: 0.7203 - val_loss: 0.8616 - val_accuracy: 0.7200\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.72008\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8628 - accuracy: 0.7206 - val_loss: 0.8570 - val_accuracy: 0.7229\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.72008 to 0.72292, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8594 - accuracy: 0.7221 - val_loss: 0.8540 - val_accuracy: 0.7248\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.72292 to 0.72483, saving model to mnist_conv_best.h5\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8559 - accuracy: 0.7236 - val_loss: 0.8511 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.72483\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8526 - accuracy: 0.7240 - val_loss: 0.8474 - val_accuracy: 0.7245\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.72483\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8492 - accuracy: 0.7248 - val_loss: 0.8444 - val_accuracy: 0.7253\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.72483 to 0.72525, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8462 - accuracy: 0.7255 - val_loss: 0.8413 - val_accuracy: 0.7262\n",
            "\n",
            "Epoch 00094: val_accuracy improved from 0.72525 to 0.72617, saving model to mnist_conv_best.h5\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8428 - accuracy: 0.7268 - val_loss: 0.8395 - val_accuracy: 0.7226\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.72617\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8401 - accuracy: 0.7272 - val_loss: 0.8353 - val_accuracy: 0.7258\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.72617\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8369 - accuracy: 0.7283 - val_loss: 0.8316 - val_accuracy: 0.7280\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.72617 to 0.72800, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8342 - accuracy: 0.7285 - val_loss: 0.8291 - val_accuracy: 0.7273\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.72800\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8314 - accuracy: 0.7303 - val_loss: 0.8279 - val_accuracy: 0.7270\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.72800\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8286 - accuracy: 0.7304 - val_loss: 0.8233 - val_accuracy: 0.7303\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.72800 to 0.73025, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8258 - accuracy: 0.7321 - val_loss: 0.8208 - val_accuracy: 0.7320\n",
            "\n",
            "Epoch 00101: val_accuracy improved from 0.73025 to 0.73200, saving model to mnist_conv_best.h5\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8233 - accuracy: 0.7324 - val_loss: 0.8176 - val_accuracy: 0.7312\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.73200\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8205 - accuracy: 0.7326 - val_loss: 0.8150 - val_accuracy: 0.7341\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.73200 to 0.73408, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8177 - accuracy: 0.7345 - val_loss: 0.8126 - val_accuracy: 0.7326\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.73408\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.8153 - accuracy: 0.7347 - val_loss: 0.8100 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.73408\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8130 - accuracy: 0.7348 - val_loss: 0.8073 - val_accuracy: 0.7355\n",
            "\n",
            "Epoch 00106: val_accuracy improved from 0.73408 to 0.73550, saving model to mnist_conv_best.h5\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8106 - accuracy: 0.7362 - val_loss: 0.8058 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00107: val_accuracy improved from 0.73550 to 0.73667, saving model to mnist_conv_best.h5\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8081 - accuracy: 0.7371 - val_loss: 0.8029 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.73667\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8058 - accuracy: 0.7378 - val_loss: 0.8009 - val_accuracy: 0.7364\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.73667\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8035 - accuracy: 0.7396 - val_loss: 0.7993 - val_accuracy: 0.7378\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.73667 to 0.73783, saving model to mnist_conv_best.h5\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.8013 - accuracy: 0.7391 - val_loss: 0.7953 - val_accuracy: 0.7362\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.73783\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7989 - accuracy: 0.7393 - val_loss: 0.7953 - val_accuracy: 0.7364\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.73783\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7967 - accuracy: 0.7405 - val_loss: 0.7916 - val_accuracy: 0.7401\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.73783 to 0.74008, saving model to mnist_conv_best.h5\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7946 - accuracy: 0.7409 - val_loss: 0.7898 - val_accuracy: 0.7387\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.74008\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7923 - accuracy: 0.7422 - val_loss: 0.7875 - val_accuracy: 0.7393\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.74008\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7902 - accuracy: 0.7422 - val_loss: 0.7863 - val_accuracy: 0.7391\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.74008\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7882 - accuracy: 0.7448 - val_loss: 0.7826 - val_accuracy: 0.7408\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.74008 to 0.74075, saving model to mnist_conv_best.h5\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7861 - accuracy: 0.7444 - val_loss: 0.7808 - val_accuracy: 0.7427\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.74075 to 0.74275, saving model to mnist_conv_best.h5\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7841 - accuracy: 0.7446 - val_loss: 0.7781 - val_accuracy: 0.7428\n",
            "\n",
            "Epoch 00119: val_accuracy improved from 0.74275 to 0.74283, saving model to mnist_conv_best.h5\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7821 - accuracy: 0.7454 - val_loss: 0.7762 - val_accuracy: 0.7435\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.74283 to 0.74350, saving model to mnist_conv_best.h5\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7801 - accuracy: 0.7466 - val_loss: 0.7739 - val_accuracy: 0.7450\n",
            "\n",
            "Epoch 00121: val_accuracy improved from 0.74350 to 0.74500, saving model to mnist_conv_best.h5\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7781 - accuracy: 0.7467 - val_loss: 0.7722 - val_accuracy: 0.7458\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.74500 to 0.74575, saving model to mnist_conv_best.h5\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7763 - accuracy: 0.7473 - val_loss: 0.7700 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.74575\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7746 - accuracy: 0.7470 - val_loss: 0.7679 - val_accuracy: 0.7467\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.74575 to 0.74675, saving model to mnist_conv_best.h5\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7723 - accuracy: 0.7484 - val_loss: 0.7667 - val_accuracy: 0.7441\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.74675\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7706 - accuracy: 0.7491 - val_loss: 0.7652 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00126: val_accuracy improved from 0.74675 to 0.74767, saving model to mnist_conv_best.h5\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7689 - accuracy: 0.7500 - val_loss: 0.7622 - val_accuracy: 0.7480\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.74767 to 0.74800, saving model to mnist_conv_best.h5\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7669 - accuracy: 0.7498 - val_loss: 0.7641 - val_accuracy: 0.7458\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.74800\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7651 - accuracy: 0.7507 - val_loss: 0.7602 - val_accuracy: 0.7476\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.74800\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7635 - accuracy: 0.7512 - val_loss: 0.7577 - val_accuracy: 0.7511\n",
            "\n",
            "Epoch 00130: val_accuracy improved from 0.74800 to 0.75108, saving model to mnist_conv_best.h5\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7616 - accuracy: 0.7520 - val_loss: 0.7562 - val_accuracy: 0.7502\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.75108\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7598 - accuracy: 0.7528 - val_loss: 0.7534 - val_accuracy: 0.7504\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.75108\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7581 - accuracy: 0.7532 - val_loss: 0.7525 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.75108\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7564 - accuracy: 0.7535 - val_loss: 0.7510 - val_accuracy: 0.7534\n",
            "\n",
            "Epoch 00134: val_accuracy improved from 0.75108 to 0.75342, saving model to mnist_conv_best.h5\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7547 - accuracy: 0.7530 - val_loss: 0.7487 - val_accuracy: 0.7553\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.75342 to 0.75533, saving model to mnist_conv_best.h5\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7530 - accuracy: 0.7550 - val_loss: 0.7474 - val_accuracy: 0.7556\n",
            "\n",
            "Epoch 00136: val_accuracy improved from 0.75533 to 0.75558, saving model to mnist_conv_best.h5\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7512 - accuracy: 0.7560 - val_loss: 0.7457 - val_accuracy: 0.7513\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.75558\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7496 - accuracy: 0.7551 - val_loss: 0.7435 - val_accuracy: 0.7571\n",
            "\n",
            "Epoch 00138: val_accuracy improved from 0.75558 to 0.75708, saving model to mnist_conv_best.h5\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7480 - accuracy: 0.7560 - val_loss: 0.7421 - val_accuracy: 0.7558\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.75708\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7462 - accuracy: 0.7569 - val_loss: 0.7396 - val_accuracy: 0.7552\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.75708\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.7447 - accuracy: 0.7566 - val_loss: 0.7384 - val_accuracy: 0.7574\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.75708 to 0.75742, saving model to mnist_conv_best.h5\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7431 - accuracy: 0.7581 - val_loss: 0.7373 - val_accuracy: 0.7573\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.75742\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7415 - accuracy: 0.7585 - val_loss: 0.7354 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.75742\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7399 - accuracy: 0.7592 - val_loss: 0.7332 - val_accuracy: 0.7567\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.75742\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7384 - accuracy: 0.7590 - val_loss: 0.7330 - val_accuracy: 0.7575\n",
            "\n",
            "Epoch 00145: val_accuracy improved from 0.75742 to 0.75750, saving model to mnist_conv_best.h5\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7369 - accuracy: 0.7598 - val_loss: 0.7303 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00146: val_accuracy improved from 0.75750 to 0.75917, saving model to mnist_conv_best.h5\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7355 - accuracy: 0.7612 - val_loss: 0.7288 - val_accuracy: 0.7594\n",
            "\n",
            "Epoch 00147: val_accuracy improved from 0.75917 to 0.75942, saving model to mnist_conv_best.h5\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7338 - accuracy: 0.7616 - val_loss: 0.7290 - val_accuracy: 0.7581\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.75942\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7324 - accuracy: 0.7617 - val_loss: 0.7260 - val_accuracy: 0.7597\n",
            "\n",
            "Epoch 00149: val_accuracy improved from 0.75942 to 0.75967, saving model to mnist_conv_best.h5\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7308 - accuracy: 0.7624 - val_loss: 0.7244 - val_accuracy: 0.7596\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.75967\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7291 - accuracy: 0.7620 - val_loss: 0.7221 - val_accuracy: 0.7623\n",
            "\n",
            "Epoch 00151: val_accuracy improved from 0.75967 to 0.76225, saving model to mnist_conv_best.h5\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7277 - accuracy: 0.7634 - val_loss: 0.7211 - val_accuracy: 0.7621\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.76225\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7262 - accuracy: 0.7635 - val_loss: 0.7197 - val_accuracy: 0.7628\n",
            "\n",
            "Epoch 00153: val_accuracy improved from 0.76225 to 0.76275, saving model to mnist_conv_best.h5\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7246 - accuracy: 0.7645 - val_loss: 0.7181 - val_accuracy: 0.7641\n",
            "\n",
            "Epoch 00154: val_accuracy improved from 0.76275 to 0.76408, saving model to mnist_conv_best.h5\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7235 - accuracy: 0.7642 - val_loss: 0.7171 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.76408\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7220 - accuracy: 0.7649 - val_loss: 0.7156 - val_accuracy: 0.7668\n",
            "\n",
            "Epoch 00156: val_accuracy improved from 0.76408 to 0.76683, saving model to mnist_conv_best.h5\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7205 - accuracy: 0.7642 - val_loss: 0.7141 - val_accuracy: 0.7668\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.76683\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7192 - accuracy: 0.7668 - val_loss: 0.7137 - val_accuracy: 0.7638\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.76683\n",
            "Epoch 159/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7180 - accuracy: 0.7655 - val_loss: 0.7109 - val_accuracy: 0.7667\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.76683\n",
            "Epoch 160/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7165 - accuracy: 0.7666 - val_loss: 0.7098 - val_accuracy: 0.7682\n",
            "\n",
            "Epoch 00160: val_accuracy improved from 0.76683 to 0.76817, saving model to mnist_conv_best.h5\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7150 - accuracy: 0.7672 - val_loss: 0.7088 - val_accuracy: 0.7666\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.76817\n",
            "Epoch 162/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7138 - accuracy: 0.7680 - val_loss: 0.7063 - val_accuracy: 0.7697\n",
            "\n",
            "Epoch 00162: val_accuracy improved from 0.76817 to 0.76975, saving model to mnist_conv_best.h5\n",
            "Epoch 163/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7123 - accuracy: 0.7675 - val_loss: 0.7061 - val_accuracy: 0.7678\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.76975\n",
            "Epoch 164/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7108 - accuracy: 0.7685 - val_loss: 0.7058 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.76975\n",
            "Epoch 165/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7096 - accuracy: 0.7689 - val_loss: 0.7031 - val_accuracy: 0.7695\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.76975\n",
            "Epoch 166/10000\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.7081 - accuracy: 0.7695 - val_loss: 0.7016 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00166: val_accuracy improved from 0.76975 to 0.77117, saving model to mnist_conv_best.h5\n",
            "Epoch 167/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7069 - accuracy: 0.7693 - val_loss: 0.7008 - val_accuracy: 0.7701\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.77117\n",
            "Epoch 168/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7057 - accuracy: 0.7707 - val_loss: 0.6987 - val_accuracy: 0.7707\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.77117\n",
            "Epoch 169/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7040 - accuracy: 0.7703 - val_loss: 0.6972 - val_accuracy: 0.7713\n",
            "\n",
            "Epoch 00169: val_accuracy improved from 0.77117 to 0.77133, saving model to mnist_conv_best.h5\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7031 - accuracy: 0.7710 - val_loss: 0.6967 - val_accuracy: 0.7708\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.77133\n",
            "Epoch 171/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7018 - accuracy: 0.7708 - val_loss: 0.6947 - val_accuracy: 0.7724\n",
            "\n",
            "Epoch 00171: val_accuracy improved from 0.77133 to 0.77242, saving model to mnist_conv_best.h5\n",
            "Epoch 172/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.7002 - accuracy: 0.7724 - val_loss: 0.6944 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.77242\n",
            "Epoch 173/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6992 - accuracy: 0.7721 - val_loss: 0.6926 - val_accuracy: 0.7736\n",
            "\n",
            "Epoch 00173: val_accuracy improved from 0.77242 to 0.77358, saving model to mnist_conv_best.h5\n",
            "Epoch 174/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6980 - accuracy: 0.7727 - val_loss: 0.6909 - val_accuracy: 0.7722\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.77358\n",
            "Epoch 175/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6967 - accuracy: 0.7733 - val_loss: 0.6888 - val_accuracy: 0.7740\n",
            "\n",
            "Epoch 00175: val_accuracy improved from 0.77358 to 0.77400, saving model to mnist_conv_best.h5\n",
            "Epoch 176/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6952 - accuracy: 0.7736 - val_loss: 0.6891 - val_accuracy: 0.7749\n",
            "\n",
            "Epoch 00176: val_accuracy improved from 0.77400 to 0.77492, saving model to mnist_conv_best.h5\n",
            "Epoch 177/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6939 - accuracy: 0.7735 - val_loss: 0.6875 - val_accuracy: 0.7744\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.77492\n",
            "Epoch 178/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6929 - accuracy: 0.7747 - val_loss: 0.6856 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.77492 to 0.77575, saving model to mnist_conv_best.h5\n",
            "Epoch 179/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6915 - accuracy: 0.7748 - val_loss: 0.6849 - val_accuracy: 0.7766\n",
            "\n",
            "Epoch 00179: val_accuracy improved from 0.77575 to 0.77658, saving model to mnist_conv_best.h5\n",
            "Epoch 180/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6904 - accuracy: 0.7750 - val_loss: 0.6830 - val_accuracy: 0.7774\n",
            "\n",
            "Epoch 00180: val_accuracy improved from 0.77658 to 0.77742, saving model to mnist_conv_best.h5\n",
            "Epoch 181/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6890 - accuracy: 0.7764 - val_loss: 0.6824 - val_accuracy: 0.7754\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.77742\n",
            "Epoch 182/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6880 - accuracy: 0.7768 - val_loss: 0.6805 - val_accuracy: 0.7766\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.77742\n",
            "Epoch 183/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6868 - accuracy: 0.7763 - val_loss: 0.6807 - val_accuracy: 0.7760\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.77742\n",
            "Epoch 184/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6854 - accuracy: 0.7769 - val_loss: 0.6798 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00184: val_accuracy improved from 0.77742 to 0.77833, saving model to mnist_conv_best.h5\n",
            "Epoch 185/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6845 - accuracy: 0.7776 - val_loss: 0.6784 - val_accuracy: 0.7782\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.77833\n",
            "Epoch 186/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6831 - accuracy: 0.7777 - val_loss: 0.6794 - val_accuracy: 0.7779\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.77833\n",
            "Epoch 187/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6821 - accuracy: 0.7782 - val_loss: 0.6752 - val_accuracy: 0.7782\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.77833\n",
            "Epoch 188/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6810 - accuracy: 0.7791 - val_loss: 0.6747 - val_accuracy: 0.7780\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.77833\n",
            "Epoch 189/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6797 - accuracy: 0.7778 - val_loss: 0.6744 - val_accuracy: 0.7786\n",
            "\n",
            "Epoch 00189: val_accuracy improved from 0.77833 to 0.77858, saving model to mnist_conv_best.h5\n",
            "Epoch 190/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6786 - accuracy: 0.7795 - val_loss: 0.6721 - val_accuracy: 0.7813\n",
            "\n",
            "Epoch 00190: val_accuracy improved from 0.77858 to 0.78133, saving model to mnist_conv_best.h5\n",
            "Epoch 191/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6776 - accuracy: 0.7791 - val_loss: 0.6718 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.78133\n",
            "Epoch 192/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6765 - accuracy: 0.7798 - val_loss: 0.6693 - val_accuracy: 0.7797\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.78133\n",
            "Epoch 193/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6756 - accuracy: 0.7800 - val_loss: 0.6689 - val_accuracy: 0.7811\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.78133\n",
            "Epoch 194/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6744 - accuracy: 0.7806 - val_loss: 0.6670 - val_accuracy: 0.7807\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.78133\n",
            "Epoch 195/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6731 - accuracy: 0.7810 - val_loss: 0.6683 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.78133\n",
            "Epoch 196/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6723 - accuracy: 0.7815 - val_loss: 0.6665 - val_accuracy: 0.7828\n",
            "\n",
            "Epoch 00196: val_accuracy improved from 0.78133 to 0.78283, saving model to mnist_conv_best.h5\n",
            "Epoch 197/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6713 - accuracy: 0.7812 - val_loss: 0.6685 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.78283\n",
            "Epoch 198/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6703 - accuracy: 0.7818 - val_loss: 0.6643 - val_accuracy: 0.7818\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.78283\n",
            "Epoch 199/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6692 - accuracy: 0.7825 - val_loss: 0.6642 - val_accuracy: 0.7810\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.78283\n",
            "Epoch 200/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6683 - accuracy: 0.7820 - val_loss: 0.6626 - val_accuracy: 0.7818\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.78283\n",
            "Epoch 201/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6672 - accuracy: 0.7828 - val_loss: 0.6606 - val_accuracy: 0.7836\n",
            "\n",
            "Epoch 00201: val_accuracy improved from 0.78283 to 0.78358, saving model to mnist_conv_best.h5\n",
            "Epoch 202/10000\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.6663 - accuracy: 0.7831 - val_loss: 0.6620 - val_accuracy: 0.7827\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.78358\n",
            "Epoch 203/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6655 - accuracy: 0.7837 - val_loss: 0.6589 - val_accuracy: 0.7844\n",
            "\n",
            "Epoch 00203: val_accuracy improved from 0.78358 to 0.78442, saving model to mnist_conv_best.h5\n",
            "Epoch 204/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6644 - accuracy: 0.7838 - val_loss: 0.6585 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.78442\n",
            "Epoch 205/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6633 - accuracy: 0.7845 - val_loss: 0.6587 - val_accuracy: 0.7852\n",
            "\n",
            "Epoch 00205: val_accuracy improved from 0.78442 to 0.78517, saving model to mnist_conv_best.h5\n",
            "Epoch 206/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6624 - accuracy: 0.7851 - val_loss: 0.6562 - val_accuracy: 0.7841\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.78517\n",
            "Epoch 207/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6616 - accuracy: 0.7856 - val_loss: 0.6552 - val_accuracy: 0.7858\n",
            "\n",
            "Epoch 00207: val_accuracy improved from 0.78517 to 0.78583, saving model to mnist_conv_best.h5\n",
            "Epoch 208/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6607 - accuracy: 0.7856 - val_loss: 0.6539 - val_accuracy: 0.7859\n",
            "\n",
            "Epoch 00208: val_accuracy improved from 0.78583 to 0.78592, saving model to mnist_conv_best.h5\n",
            "Epoch 209/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6597 - accuracy: 0.7857 - val_loss: 0.6532 - val_accuracy: 0.7847\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.78592\n",
            "Epoch 210/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6587 - accuracy: 0.7864 - val_loss: 0.6532 - val_accuracy: 0.7862\n",
            "\n",
            "Epoch 00210: val_accuracy improved from 0.78592 to 0.78625, saving model to mnist_conv_best.h5\n",
            "Epoch 211/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6579 - accuracy: 0.7867 - val_loss: 0.6509 - val_accuracy: 0.7861\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.78625\n",
            "Epoch 212/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6569 - accuracy: 0.7868 - val_loss: 0.6501 - val_accuracy: 0.7862\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.78625\n",
            "Epoch 213/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6560 - accuracy: 0.7873 - val_loss: 0.6501 - val_accuracy: 0.7863\n",
            "\n",
            "Epoch 00213: val_accuracy improved from 0.78625 to 0.78633, saving model to mnist_conv_best.h5\n",
            "Epoch 214/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6552 - accuracy: 0.7876 - val_loss: 0.6492 - val_accuracy: 0.7879\n",
            "\n",
            "Epoch 00214: val_accuracy improved from 0.78633 to 0.78792, saving model to mnist_conv_best.h5\n",
            "Epoch 215/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6542 - accuracy: 0.7878 - val_loss: 0.6493 - val_accuracy: 0.7872\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.78792\n",
            "Epoch 216/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6533 - accuracy: 0.7878 - val_loss: 0.6484 - val_accuracy: 0.7858\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.78792\n",
            "Epoch 217/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6525 - accuracy: 0.7881 - val_loss: 0.6467 - val_accuracy: 0.7888\n",
            "\n",
            "Epoch 00217: val_accuracy improved from 0.78792 to 0.78883, saving model to mnist_conv_best.h5\n",
            "Epoch 218/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6516 - accuracy: 0.7887 - val_loss: 0.6461 - val_accuracy: 0.7884\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.78883\n",
            "Epoch 219/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6507 - accuracy: 0.7892 - val_loss: 0.6460 - val_accuracy: 0.7881\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.78883\n",
            "Epoch 220/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6498 - accuracy: 0.7897 - val_loss: 0.6445 - val_accuracy: 0.7895\n",
            "\n",
            "Epoch 00220: val_accuracy improved from 0.78883 to 0.78950, saving model to mnist_conv_best.h5\n",
            "Epoch 221/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6490 - accuracy: 0.7896 - val_loss: 0.6439 - val_accuracy: 0.7875\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.78950\n",
            "Epoch 222/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.6484 - accuracy: 0.7898 - val_loss: 0.6428 - val_accuracy: 0.7886\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.78950\n",
            "Epoch 223/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6474 - accuracy: 0.7896 - val_loss: 0.6415 - val_accuracy: 0.7902\n",
            "\n",
            "Epoch 00223: val_accuracy improved from 0.78950 to 0.79017, saving model to mnist_conv_best.h5\n",
            "Epoch 224/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6466 - accuracy: 0.7906 - val_loss: 0.6413 - val_accuracy: 0.7885\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.79017\n",
            "Epoch 225/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6456 - accuracy: 0.7908 - val_loss: 0.6409 - val_accuracy: 0.7908\n",
            "\n",
            "Epoch 00225: val_accuracy improved from 0.79017 to 0.79083, saving model to mnist_conv_best.h5\n",
            "Epoch 226/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6449 - accuracy: 0.7912 - val_loss: 0.6397 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.79083\n",
            "Epoch 227/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6444 - accuracy: 0.7908 - val_loss: 0.6389 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00227: val_accuracy improved from 0.79083 to 0.79167, saving model to mnist_conv_best.h5\n",
            "Epoch 228/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6434 - accuracy: 0.7915 - val_loss: 0.6384 - val_accuracy: 0.7904\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.79167\n",
            "Epoch 229/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6426 - accuracy: 0.7913 - val_loss: 0.6368 - val_accuracy: 0.7909\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.79167\n",
            "Epoch 230/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6419 - accuracy: 0.7917 - val_loss: 0.6375 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00230: val_accuracy improved from 0.79167 to 0.79208, saving model to mnist_conv_best.h5\n",
            "Epoch 231/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6411 - accuracy: 0.7921 - val_loss: 0.6351 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.79208\n",
            "Epoch 232/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6403 - accuracy: 0.7921 - val_loss: 0.6353 - val_accuracy: 0.7924\n",
            "\n",
            "Epoch 00232: val_accuracy improved from 0.79208 to 0.79242, saving model to mnist_conv_best.h5\n",
            "Epoch 233/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6395 - accuracy: 0.7929 - val_loss: 0.6347 - val_accuracy: 0.7937\n",
            "\n",
            "Epoch 00233: val_accuracy improved from 0.79242 to 0.79375, saving model to mnist_conv_best.h5\n",
            "Epoch 234/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6387 - accuracy: 0.7939 - val_loss: 0.6335 - val_accuracy: 0.7933\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.79375\n",
            "Epoch 235/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6380 - accuracy: 0.7937 - val_loss: 0.6325 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.79375\n",
            "Epoch 236/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6374 - accuracy: 0.7933 - val_loss: 0.6328 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.79375\n",
            "Epoch 237/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6366 - accuracy: 0.7935 - val_loss: 0.6313 - val_accuracy: 0.7937\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.79375\n",
            "Epoch 238/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.6358 - accuracy: 0.7946 - val_loss: 0.6305 - val_accuracy: 0.7945\n",
            "\n",
            "Epoch 00238: val_accuracy improved from 0.79375 to 0.79450, saving model to mnist_conv_best.h5\n",
            "Epoch 239/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6350 - accuracy: 0.7947 - val_loss: 0.6301 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.79450\n",
            "Epoch 240/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6346 - accuracy: 0.7950 - val_loss: 0.6305 - val_accuracy: 0.7952\n",
            "\n",
            "Epoch 00240: val_accuracy improved from 0.79450 to 0.79517, saving model to mnist_conv_best.h5\n",
            "Epoch 241/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.6336 - accuracy: 0.7948 - val_loss: 0.6291 - val_accuracy: 0.7943\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.79517\n",
            "Epoch 242/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.6330 - accuracy: 0.7958 - val_loss: 0.6279 - val_accuracy: 0.7957\n",
            "\n",
            "Epoch 00242: val_accuracy improved from 0.79517 to 0.79567, saving model to mnist_conv_best.h5\n",
            "Epoch 243/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6322 - accuracy: 0.7952 - val_loss: 0.6284 - val_accuracy: 0.7933\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.79567\n",
            "Epoch 244/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.6319 - accuracy: 0.7959 - val_loss: 0.6268 - val_accuracy: 0.7968\n",
            "\n",
            "Epoch 00244: val_accuracy improved from 0.79567 to 0.79675, saving model to mnist_conv_best.h5\n",
            "Epoch 245/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6309 - accuracy: 0.7959 - val_loss: 0.6264 - val_accuracy: 0.7950\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.79675\n",
            "Epoch 246/10000\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.6304 - accuracy: 0.7966 - val_loss: 0.6263 - val_accuracy: 0.7947\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.79675\n",
            "Epoch 247/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6295 - accuracy: 0.7972 - val_loss: 0.6255 - val_accuracy: 0.7984\n",
            "\n",
            "Epoch 00247: val_accuracy improved from 0.79675 to 0.79842, saving model to mnist_conv_best.h5\n",
            "Epoch 248/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6290 - accuracy: 0.7974 - val_loss: 0.6252 - val_accuracy: 0.7978\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.79842\n",
            "Epoch 249/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.6283 - accuracy: 0.7967 - val_loss: 0.6244 - val_accuracy: 0.7983\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.79842\n",
            "Epoch 250/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6276 - accuracy: 0.7974 - val_loss: 0.6231 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00250: val_accuracy improved from 0.79842 to 0.79908, saving model to mnist_conv_best.h5\n",
            "Epoch 251/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6270 - accuracy: 0.7971 - val_loss: 0.6223 - val_accuracy: 0.7974\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.79908\n",
            "Epoch 252/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6263 - accuracy: 0.7982 - val_loss: 0.6220 - val_accuracy: 0.7976\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.79908\n",
            "Epoch 253/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6259 - accuracy: 0.7978 - val_loss: 0.6213 - val_accuracy: 0.7993\n",
            "\n",
            "Epoch 00253: val_accuracy improved from 0.79908 to 0.79933, saving model to mnist_conv_best.h5\n",
            "Epoch 254/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6251 - accuracy: 0.7989 - val_loss: 0.6207 - val_accuracy: 0.7993\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.79933\n",
            "Epoch 255/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6243 - accuracy: 0.7990 - val_loss: 0.6228 - val_accuracy: 0.7962\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.79933\n",
            "Epoch 256/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6240 - accuracy: 0.7981 - val_loss: 0.6192 - val_accuracy: 0.7986\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.79933\n",
            "Epoch 257/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6232 - accuracy: 0.7991 - val_loss: 0.6184 - val_accuracy: 0.7992\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.79933\n",
            "Epoch 258/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.6225 - accuracy: 0.7989 - val_loss: 0.6191 - val_accuracy: 0.7992\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.79933\n",
            "Epoch 259/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.6222 - accuracy: 0.7992 - val_loss: 0.6174 - val_accuracy: 0.7997\n",
            "\n",
            "Epoch 00259: val_accuracy improved from 0.79933 to 0.79975, saving model to mnist_conv_best.h5\n",
            "Epoch 260/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.6214 - accuracy: 0.7991 - val_loss: 0.6170 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00260: val_accuracy improved from 0.79975 to 0.80000, saving model to mnist_conv_best.h5\n",
            "Epoch 261/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6208 - accuracy: 0.7996 - val_loss: 0.6160 - val_accuracy: 0.8011\n",
            "\n",
            "Epoch 00261: val_accuracy improved from 0.80000 to 0.80108, saving model to mnist_conv_best.h5\n",
            "Epoch 262/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6202 - accuracy: 0.7992 - val_loss: 0.6158 - val_accuracy: 0.8008\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.80108\n",
            "Epoch 263/10000\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.6195 - accuracy: 0.7996 - val_loss: 0.6154 - val_accuracy: 0.8016\n",
            "\n",
            "Epoch 00263: val_accuracy improved from 0.80108 to 0.80158, saving model to mnist_conv_best.h5\n",
            "Epoch 264/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6189 - accuracy: 0.8001 - val_loss: 0.6149 - val_accuracy: 0.8004\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.80158\n",
            "Epoch 265/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6184 - accuracy: 0.8000 - val_loss: 0.6148 - val_accuracy: 0.8026\n",
            "\n",
            "Epoch 00265: val_accuracy improved from 0.80158 to 0.80258, saving model to mnist_conv_best.h5\n",
            "Epoch 266/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6177 - accuracy: 0.8007 - val_loss: 0.6142 - val_accuracy: 0.8008\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.80258\n",
            "Epoch 267/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6171 - accuracy: 0.8007 - val_loss: 0.6133 - val_accuracy: 0.8002\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.80258\n",
            "Epoch 268/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6165 - accuracy: 0.8011 - val_loss: 0.6134 - val_accuracy: 0.8010\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.80258\n",
            "Epoch 269/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6161 - accuracy: 0.8007 - val_loss: 0.6122 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.80258\n",
            "Epoch 270/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6154 - accuracy: 0.8011 - val_loss: 0.6124 - val_accuracy: 0.8018\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.80258\n",
            "Epoch 271/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6150 - accuracy: 0.8019 - val_loss: 0.6111 - val_accuracy: 0.8017\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.80258\n",
            "Epoch 272/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.6143 - accuracy: 0.8014 - val_loss: 0.6107 - val_accuracy: 0.8035\n",
            "\n",
            "Epoch 00272: val_accuracy improved from 0.80258 to 0.80350, saving model to mnist_conv_best.h5\n",
            "Epoch 273/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.6137 - accuracy: 0.8027 - val_loss: 0.6099 - val_accuracy: 0.8022\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.80350\n",
            "Epoch 274/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6132 - accuracy: 0.8012 - val_loss: 0.6110 - val_accuracy: 0.8003\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.80350\n",
            "Epoch 275/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6126 - accuracy: 0.8020 - val_loss: 0.6093 - val_accuracy: 0.8004\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.80350\n",
            "Epoch 276/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6122 - accuracy: 0.8024 - val_loss: 0.6086 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.80350\n",
            "Epoch 277/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6116 - accuracy: 0.8026 - val_loss: 0.6082 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.80350\n",
            "Epoch 278/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.6111 - accuracy: 0.8028 - val_loss: 0.6073 - val_accuracy: 0.8024\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.80350\n",
            "Epoch 279/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6104 - accuracy: 0.8026 - val_loss: 0.6068 - val_accuracy: 0.8028\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.80350\n",
            "Epoch 280/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.6099 - accuracy: 0.8030 - val_loss: 0.6073 - val_accuracy: 0.8018\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.80350\n",
            "Epoch 281/10000\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.6094 - accuracy: 0.8032 - val_loss: 0.6073 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.80350\n",
            "Epoch 282/10000\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.6087 - accuracy: 0.8042 - val_loss: 0.6064 - val_accuracy: 0.8018\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.80350\n",
            "Epoch 00282: early stopping\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.6129 - accuracy: 0.8022\n",
            "Accuracy for the training set: 0.8021833300590515\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5814 - accuracy: 0.8115\n",
            "Accuracy for the testing set: 0.8115000128746033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-5PBi8CuLCR"
      },
      "source": [
        "## Number of Fully Connected Convulotional Layers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12yrrMZ2vviZ"
      },
      "source": [
        "### 2 Convolutional Layers\n",
        "\n",
        "0.9829"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sKnvowzYuXt0",
        "outputId": "212bfc1f-67d5-4baf-ab35-1fa33adeaace"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "#mnist_conv_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 128,042\n",
            "Trainable params: 128,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 1.3230 - accuracy: 0.6413 - val_loss: 0.4170 - val_accuracy: 0.8811\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88108, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.3834 - accuracy: 0.8882 - val_loss: 0.3496 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.88108 to 0.89958, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.3410 - accuracy: 0.9003 - val_loss: 0.3416 - val_accuracy: 0.9022\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89958 to 0.90225, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.3197 - accuracy: 0.9060 - val_loss: 0.3284 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.90225 to 0.90650, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.3035 - accuracy: 0.9114 - val_loss: 0.3053 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90650 to 0.91467, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.2897 - accuracy: 0.9151 - val_loss: 0.3032 - val_accuracy: 0.9143\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91467\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.2747 - accuracy: 0.9208 - val_loss: 0.3112 - val_accuracy: 0.9102\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91467\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.2631 - accuracy: 0.9237 - val_loss: 0.2701 - val_accuracy: 0.9243\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91467 to 0.92425, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.2476 - accuracy: 0.9294 - val_loss: 0.2596 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.92425 to 0.92683, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.2297 - accuracy: 0.9350 - val_loss: 0.2333 - val_accuracy: 0.9340\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.92683 to 0.93400, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.2160 - accuracy: 0.9389 - val_loss: 0.2260 - val_accuracy: 0.9379\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.93400 to 0.93792, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.2008 - accuracy: 0.9435 - val_loss: 0.2218 - val_accuracy: 0.9376\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.93792\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1865 - accuracy: 0.9473 - val_loss: 0.1958 - val_accuracy: 0.9467\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.93792 to 0.94667, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1749 - accuracy: 0.9504 - val_loss: 0.1875 - val_accuracy: 0.9474\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.94667 to 0.94742, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1632 - accuracy: 0.9541 - val_loss: 0.1694 - val_accuracy: 0.9540\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.94742 to 0.95400, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1534 - accuracy: 0.9569 - val_loss: 0.1861 - val_accuracy: 0.9471\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.95400\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1440 - accuracy: 0.9596 - val_loss: 0.1544 - val_accuracy: 0.9575\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.95400 to 0.95750, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.1365 - accuracy: 0.9615 - val_loss: 0.1606 - val_accuracy: 0.9549\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.95750\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1297 - accuracy: 0.9641 - val_loss: 0.1422 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.95750 to 0.96200, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1234 - accuracy: 0.9652 - val_loss: 0.1443 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.96200\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1184 - accuracy: 0.9665 - val_loss: 0.1336 - val_accuracy: 0.9633\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.96200 to 0.96333, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1139 - accuracy: 0.9678 - val_loss: 0.1290 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.96333 to 0.96425, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1093 - accuracy: 0.9688 - val_loss: 0.1232 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.96425 to 0.96642, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1057 - accuracy: 0.9699 - val_loss: 0.1226 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.96642\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.1023 - accuracy: 0.9710 - val_loss: 0.1256 - val_accuracy: 0.9634\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.96642\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0990 - accuracy: 0.9720 - val_loss: 0.1188 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.96642 to 0.96692, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0958 - accuracy: 0.9722 - val_loss: 0.1193 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.96692\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0938 - accuracy: 0.9733 - val_loss: 0.1128 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.96692 to 0.96792, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0911 - accuracy: 0.9735 - val_loss: 0.1077 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.96792 to 0.96958, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0888 - accuracy: 0.9750 - val_loss: 0.1058 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.96958 to 0.97033, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 40s 214ms/step - loss: 0.0865 - accuracy: 0.9751 - val_loss: 0.1040 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.97033 to 0.97108, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0843 - accuracy: 0.9757 - val_loss: 0.1047 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.97108\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0828 - accuracy: 0.9764 - val_loss: 0.1040 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.97108\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0808 - accuracy: 0.9766 - val_loss: 0.0996 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.97108 to 0.97192, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0791 - accuracy: 0.9767 - val_loss: 0.0989 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.97192 to 0.97200, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0777 - accuracy: 0.9776 - val_loss: 0.0988 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.97200\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0759 - accuracy: 0.9778 - val_loss: 0.0970 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.97200\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0746 - accuracy: 0.9788 - val_loss: 0.0933 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.97200 to 0.97283, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0730 - accuracy: 0.9790 - val_loss: 0.0974 - val_accuracy: 0.9710\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.97283\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0720 - accuracy: 0.9797 - val_loss: 0.0990 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.97283\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0704 - accuracy: 0.9793 - val_loss: 0.0970 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.97283\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 41s 218ms/step - loss: 0.0692 - accuracy: 0.9801 - val_loss: 0.0939 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.97283\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0678 - accuracy: 0.9804 - val_loss: 0.0904 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.97283 to 0.97383, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0666 - accuracy: 0.9807 - val_loss: 0.0970 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.97383\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0657 - accuracy: 0.9814 - val_loss: 0.0896 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.97383\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0644 - accuracy: 0.9822 - val_loss: 0.0883 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.97383 to 0.97433, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0635 - accuracy: 0.9820 - val_loss: 0.0861 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.97433 to 0.97542, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0622 - accuracy: 0.9821 - val_loss: 0.0878 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.97542\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0614 - accuracy: 0.9818 - val_loss: 0.0892 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.97542\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0606 - accuracy: 0.9830 - val_loss: 0.0861 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.97542\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0596 - accuracy: 0.9825 - val_loss: 0.0822 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.97542 to 0.97575, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0586 - accuracy: 0.9824 - val_loss: 0.0894 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.97575\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0575 - accuracy: 0.9833 - val_loss: 0.0864 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.97575\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0572 - accuracy: 0.9834 - val_loss: 0.0828 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.97575 to 0.97633, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 0.0787 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.97633 to 0.97683, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0555 - accuracy: 0.9841 - val_loss: 0.0826 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.97683\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 0.0769 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.97683 to 0.97725, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0534 - accuracy: 0.9847 - val_loss: 0.0839 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.97725\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0526 - accuracy: 0.9850 - val_loss: 0.0774 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.97725\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0524 - accuracy: 0.9846 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.97725 to 0.97783, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 0.0786 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.97783\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0507 - accuracy: 0.9855 - val_loss: 0.0754 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.97783 to 0.97833, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0499 - accuracy: 0.9853 - val_loss: 0.0754 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.97833 to 0.97942, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0497 - accuracy: 0.9854 - val_loss: 0.0748 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.97942\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 41s 216ms/step - loss: 0.0491 - accuracy: 0.9858 - val_loss: 0.0767 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.97942\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0485 - accuracy: 0.9866 - val_loss: 0.0766 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.97942\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0477 - accuracy: 0.9858 - val_loss: 0.0728 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.97942\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0471 - accuracy: 0.9862 - val_loss: 0.0738 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.97942\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0467 - accuracy: 0.9863 - val_loss: 0.0739 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.97942\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.0735 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.97942\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 41s 218ms/step - loss: 0.0452 - accuracy: 0.9868 - val_loss: 0.0763 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.97942\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0447 - accuracy: 0.9871 - val_loss: 0.0727 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.97942\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 41s 217ms/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 0.0745 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.97942\n",
            "Epoch 00073: early stopping\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0540 - accuracy: 0.9844\n",
            "Accuracy for the training set: 0.9844333529472351\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0592 - accuracy: 0.9829\n",
            "Accuracy for the testing set: 0.9829000234603882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMZnsF6SvtOl"
      },
      "source": [
        "### 3 Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JChcXJ0nvfvb",
        "outputId": "9cc9db98-1a9d-4094-e987-aa956e7af854"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "#mnist_conv_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 129,082\n",
            "Trainable params: 129,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 56s 294ms/step - loss: 1.0381 - accuracy: 0.6991 - val_loss: 0.4086 - val_accuracy: 0.8807\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88067, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 56s 295ms/step - loss: 0.3965 - accuracy: 0.8817 - val_loss: 0.5800 - val_accuracy: 0.8123\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.88067\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.3565 - accuracy: 0.8941 - val_loss: 0.3967 - val_accuracy: 0.8794\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.88067\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.3367 - accuracy: 0.9006 - val_loss: 0.3466 - val_accuracy: 0.8997\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.88067 to 0.89967, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.3177 - accuracy: 0.9076 - val_loss: 0.3383 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.89967\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.3045 - accuracy: 0.9113 - val_loss: 0.3151 - val_accuracy: 0.9112\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.89967 to 0.91117, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.2958 - accuracy: 0.9148 - val_loss: 0.3035 - val_accuracy: 0.9166\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.91117 to 0.91658, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.2886 - accuracy: 0.9164 - val_loss: 0.3613 - val_accuracy: 0.8911\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91658\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.2808 - accuracy: 0.9189 - val_loss: 0.2797 - val_accuracy: 0.9237\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91658 to 0.92367, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.2718 - accuracy: 0.9220 - val_loss: 0.2769 - val_accuracy: 0.9213\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.92367\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.2637 - accuracy: 0.9244 - val_loss: 0.2866 - val_accuracy: 0.9182\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.92367\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.2541 - accuracy: 0.9274 - val_loss: 0.2655 - val_accuracy: 0.9255\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.92367 to 0.92550, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 55s 294ms/step - loss: 0.2442 - accuracy: 0.9312 - val_loss: 0.2671 - val_accuracy: 0.9242\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.92550\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.2331 - accuracy: 0.9349 - val_loss: 0.2411 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.92550 to 0.93100, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 56s 295ms/step - loss: 0.2209 - accuracy: 0.9382 - val_loss: 0.2433 - val_accuracy: 0.9291\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.93100\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.2088 - accuracy: 0.9413 - val_loss: 0.2159 - val_accuracy: 0.9417\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.93100 to 0.94167, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1948 - accuracy: 0.9457 - val_loss: 0.1999 - val_accuracy: 0.9442\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.94167 to 0.94425, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1801 - accuracy: 0.9500 - val_loss: 0.1986 - val_accuracy: 0.9440\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.94425\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1672 - accuracy: 0.9539 - val_loss: 0.1753 - val_accuracy: 0.9508\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.94425 to 0.95083, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1539 - accuracy: 0.9575 - val_loss: 0.1621 - val_accuracy: 0.9552\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.95083 to 0.95517, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1431 - accuracy: 0.9598 - val_loss: 0.1497 - val_accuracy: 0.9583\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.95517 to 0.95833, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1324 - accuracy: 0.9623 - val_loss: 0.1409 - val_accuracy: 0.9608\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.95833 to 0.96083, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1227 - accuracy: 0.9658 - val_loss: 0.1306 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.96083 to 0.96258, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 56s 295ms/step - loss: 0.1150 - accuracy: 0.9681 - val_loss: 0.1228 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.96258 to 0.96467, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1081 - accuracy: 0.9695 - val_loss: 0.1400 - val_accuracy: 0.9619\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.96467\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.1023 - accuracy: 0.9712 - val_loss: 0.1184 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.96467 to 0.96692, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0963 - accuracy: 0.9733 - val_loss: 0.1145 - val_accuracy: 0.9674\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.96692 to 0.96742, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 56s 295ms/step - loss: 0.0923 - accuracy: 0.9739 - val_loss: 0.1022 - val_accuracy: 0.9710\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.96742 to 0.97100, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0880 - accuracy: 0.9753 - val_loss: 0.1019 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.97100\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0849 - accuracy: 0.9766 - val_loss: 0.1110 - val_accuracy: 0.9684\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.97100\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.0810 - accuracy: 0.9766 - val_loss: 0.1124 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.97100\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 56s 295ms/step - loss: 0.0783 - accuracy: 0.9778 - val_loss: 0.0916 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.97100 to 0.97375, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0759 - accuracy: 0.9786 - val_loss: 0.0894 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.97375 to 0.97442, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 55s 294ms/step - loss: 0.0736 - accuracy: 0.9789 - val_loss: 0.0916 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.97442\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0713 - accuracy: 0.9797 - val_loss: 0.0868 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.97442 to 0.97475, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0694 - accuracy: 0.9795 - val_loss: 0.0846 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.97475 to 0.97583, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.0676 - accuracy: 0.9799 - val_loss: 0.0843 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.97583\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0655 - accuracy: 0.9813 - val_loss: 0.0824 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.97583 to 0.97608, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0643 - accuracy: 0.9809 - val_loss: 0.0827 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.97608\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.0628 - accuracy: 0.9816 - val_loss: 0.0822 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.97608\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 56s 298ms/step - loss: 0.0609 - accuracy: 0.9827 - val_loss: 0.0859 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.97608\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.0602 - accuracy: 0.9829 - val_loss: 0.0821 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.97608 to 0.97658, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.0581 - accuracy: 0.9832 - val_loss: 0.0812 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.97658\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.0569 - accuracy: 0.9834 - val_loss: 0.0771 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.97658 to 0.97883, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.0560 - accuracy: 0.9837 - val_loss: 0.0797 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.97883\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 56s 296ms/step - loss: 0.0543 - accuracy: 0.9841 - val_loss: 0.0808 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.97883\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0537 - accuracy: 0.9842 - val_loss: 0.0746 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.97883\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0521 - accuracy: 0.9847 - val_loss: 0.0781 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.97883\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0508 - accuracy: 0.9851 - val_loss: 0.0915 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.97883\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.0983 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.97883\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.0781 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.97883\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0483 - accuracy: 0.9856 - val_loss: 0.0780 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.97883\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.0854 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.97883\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 55s 295ms/step - loss: 0.0469 - accuracy: 0.9861 - val_loss: 0.0769 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.97883\n",
            "Epoch 00054: early stopping\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0580 - accuracy: 0.9834\n",
            "Accuracy for the training set: 0.9833999872207642\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0645 - accuracy: 0.9805\n",
            "Accuracy for the testing set: 0.9804999828338623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpPDP5x6vn3h"
      },
      "source": [
        "### 4 Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dTqFwS3qvlRg",
        "outputId": "ab5518d2-5b91-4186-8c8e-3ff5f639c78d"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=1, activation='relu', padding='same', name='convolution4'))\n",
        "#mnist_conv_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "convolution4 (Conv2D)        (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 129,354\n",
            "Trainable params: 129,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 1.2641 - accuracy: 0.6518 - val_loss: 0.4251 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87192, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 65s 343ms/step - loss: 0.3937 - accuracy: 0.8842 - val_loss: 0.3629 - val_accuracy: 0.8952\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87192 to 0.89517, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.3444 - accuracy: 0.8990 - val_loss: 0.3443 - val_accuracy: 0.9029\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89517 to 0.90292, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.3234 - accuracy: 0.9046 - val_loss: 0.3078 - val_accuracy: 0.9126\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.90292 to 0.91258, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.3025 - accuracy: 0.9120 - val_loss: 0.3488 - val_accuracy: 0.8960\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91258\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.2867 - accuracy: 0.9161 - val_loss: 0.3154 - val_accuracy: 0.9077\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91258\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.2689 - accuracy: 0.9219 - val_loss: 0.2743 - val_accuracy: 0.9244\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.91258 to 0.92442, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.2498 - accuracy: 0.9294 - val_loss: 0.2482 - val_accuracy: 0.9313\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.92442 to 0.93133, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.2280 - accuracy: 0.9351 - val_loss: 0.2271 - val_accuracy: 0.9374\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.93133 to 0.93742, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.2065 - accuracy: 0.9414 - val_loss: 0.2122 - val_accuracy: 0.9438\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.93742 to 0.94383, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 64s 341ms/step - loss: 0.1821 - accuracy: 0.9476 - val_loss: 0.1846 - val_accuracy: 0.9490\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.94383 to 0.94900, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.1625 - accuracy: 0.9545 - val_loss: 0.1705 - val_accuracy: 0.9531\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.94900 to 0.95308, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.1471 - accuracy: 0.9582 - val_loss: 0.1652 - val_accuracy: 0.9517\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.95308\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.1371 - accuracy: 0.9615 - val_loss: 0.1852 - val_accuracy: 0.9441\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.95308\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.1279 - accuracy: 0.9636 - val_loss: 0.1546 - val_accuracy: 0.9569\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.95308 to 0.95692, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 65s 343ms/step - loss: 0.1204 - accuracy: 0.9655 - val_loss: 0.1328 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.95692 to 0.96258, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.1142 - accuracy: 0.9665 - val_loss: 0.1518 - val_accuracy: 0.9561\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.96258\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.1089 - accuracy: 0.9686 - val_loss: 0.1333 - val_accuracy: 0.9608\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.96258\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.1050 - accuracy: 0.9691 - val_loss: 0.1225 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.96258 to 0.96517, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.1009 - accuracy: 0.9706 - val_loss: 0.1236 - val_accuracy: 0.9631\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.96517\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0979 - accuracy: 0.9711 - val_loss: 0.1175 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.96517 to 0.96542, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0938 - accuracy: 0.9722 - val_loss: 0.1222 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.96542\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0912 - accuracy: 0.9730 - val_loss: 0.1187 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.96542\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0880 - accuracy: 0.9736 - val_loss: 0.1339 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.96542\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.1163 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.96542 to 0.96717, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0830 - accuracy: 0.9751 - val_loss: 0.1047 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.96717 to 0.96908, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 64s 340ms/step - loss: 0.0806 - accuracy: 0.9758 - val_loss: 0.1026 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.96908 to 0.97108, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0795 - accuracy: 0.9762 - val_loss: 0.1156 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.97108\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0767 - accuracy: 0.9769 - val_loss: 0.1072 - val_accuracy: 0.9695\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.97108\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0751 - accuracy: 0.9766 - val_loss: 0.1044 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.97108 to 0.97117, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0737 - accuracy: 0.9779 - val_loss: 0.1337 - val_accuracy: 0.9622\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.97117\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.0713 - accuracy: 0.9789 - val_loss: 0.1095 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.97117\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0700 - accuracy: 0.9789 - val_loss: 0.1085 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.97117\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0682 - accuracy: 0.9792 - val_loss: 0.0929 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.97117 to 0.97292, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0665 - accuracy: 0.9793 - val_loss: 0.1027 - val_accuracy: 0.9692\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.97292\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0657 - accuracy: 0.9799 - val_loss: 0.0915 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.97292 to 0.97358, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0643 - accuracy: 0.9807 - val_loss: 0.1026 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.97358\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.0953 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.97358\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.0609 - accuracy: 0.9818 - val_loss: 0.0935 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.97358 to 0.97383, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0601 - accuracy: 0.9813 - val_loss: 0.0882 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.97383 to 0.97442, saving model to mnist_conv_best.h5\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.0585 - accuracy: 0.9823 - val_loss: 0.0916 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.97442\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.0900 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.97442\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.0558 - accuracy: 0.9834 - val_loss: 0.0889 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.97442\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 64s 341ms/step - loss: 0.0548 - accuracy: 0.9837 - val_loss: 0.0888 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.97442\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.0541 - accuracy: 0.9835 - val_loss: 0.0832 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.97442 to 0.97533, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 64s 341ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.0881 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.97533\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0978 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.97533\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0510 - accuracy: 0.9847 - val_loss: 0.0892 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.97533\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 65s 343ms/step - loss: 0.0493 - accuracy: 0.9851 - val_loss: 0.0910 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.97533\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 0.0831 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.97533 to 0.97683, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0481 - accuracy: 0.9857 - val_loss: 0.0831 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.97683\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.0480 - accuracy: 0.9860 - val_loss: 0.0882 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.97683\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0463 - accuracy: 0.9866 - val_loss: 0.0836 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.97683\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 65s 343ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 0.0805 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.97683 to 0.97733, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.0880 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.97733\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0441 - accuracy: 0.9862 - val_loss: 0.0884 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.97733\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.0813 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.97733\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0418 - accuracy: 0.9876 - val_loss: 0.0798 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.97733\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.0795 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.97733 to 0.97750, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0414 - accuracy: 0.9873 - val_loss: 0.0805 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.97750\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0408 - accuracy: 0.9880 - val_loss: 0.0834 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.97750\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.0812 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.97750\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.0850 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.97750\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0381 - accuracy: 0.9887 - val_loss: 0.0783 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.97750 to 0.97758, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0975 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.97758\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0378 - accuracy: 0.9886 - val_loss: 0.0779 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.97758 to 0.97850, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0360 - accuracy: 0.9893 - val_loss: 0.0819 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.97850\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 0.0860 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.97850\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.0804 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.97850\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 0.0792 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.97850\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.0797 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.97850\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0333 - accuracy: 0.9899 - val_loss: 0.0781 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.97850\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.0896 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.97850\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0322 - accuracy: 0.9906 - val_loss: 0.0915 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.97850\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.0814 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.97850\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0306 - accuracy: 0.9913 - val_loss: 0.0863 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.97850\n",
            "Epoch 00076: early stopping\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0431 - accuracy: 0.9873\n",
            "Accuracy for the training set: 0.9872666597366333\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.0638 - accuracy: 0.9812\n",
            "Accuracy for the testing set: 0.9811999797821045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Yq6cQpzj4n"
      },
      "source": [
        "### 5 Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-6j7DOsCzj4v",
        "outputId": "861b108b-b3fa-4262-f2c5-15c4b2b2bc1d"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution1'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=1, activation='relu', padding='same', name='convolution4'))\n",
        "#mnist_conv_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        416       \n",
            "_________________________________________________________________\n",
            "convolution1 (Conv2D)        (None, 28, 28, 16)        4112      \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "convolution4 (Conv2D)        (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 133,610\n",
            "Trainable params: 133,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 122s 648ms/step - loss: 1.2343 - accuracy: 0.5986 - val_loss: 0.4478 - val_accuracy: 0.8687\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.86867, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 121s 643ms/step - loss: 0.4052 - accuracy: 0.8777 - val_loss: 0.3835 - val_accuracy: 0.8890\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.86867 to 0.88900, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 122s 647ms/step - loss: 0.3494 - accuracy: 0.8960 - val_loss: 0.3577 - val_accuracy: 0.8965\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.88900 to 0.89650, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 121s 644ms/step - loss: 0.3214 - accuracy: 0.9047 - val_loss: 0.3203 - val_accuracy: 0.9073\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89650 to 0.90733, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 120s 640ms/step - loss: 0.3028 - accuracy: 0.9111 - val_loss: 0.3055 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90733 to 0.91217, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 120s 640ms/step - loss: 0.2869 - accuracy: 0.9167 - val_loss: 0.2956 - val_accuracy: 0.9158\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.91217 to 0.91583, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 120s 641ms/step - loss: 0.2714 - accuracy: 0.9211 - val_loss: 0.2727 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.91583 to 0.92100, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 121s 643ms/step - loss: 0.2581 - accuracy: 0.9247 - val_loss: 0.2562 - val_accuracy: 0.9268\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.92100 to 0.92675, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 121s 643ms/step - loss: 0.2440 - accuracy: 0.9282 - val_loss: 0.2736 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.92675\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 120s 641ms/step - loss: 0.2295 - accuracy: 0.9326 - val_loss: 0.2516 - val_accuracy: 0.9264\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.92675\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 121s 641ms/step - loss: 0.2116 - accuracy: 0.9384 - val_loss: 0.2123 - val_accuracy: 0.9406\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.92675 to 0.94058, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 121s 644ms/step - loss: 0.1929 - accuracy: 0.9444 - val_loss: 0.2146 - val_accuracy: 0.9387\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.94058\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 120s 640ms/step - loss: 0.1811 - accuracy: 0.9474 - val_loss: 0.1784 - val_accuracy: 0.9493\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.94058 to 0.94933, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 120s 638ms/step - loss: 0.1524 - accuracy: 0.9560 - val_loss: 0.1586 - val_accuracy: 0.9542\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.94933 to 0.95425, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 121s 642ms/step - loss: 0.1372 - accuracy: 0.9604 - val_loss: 0.1502 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.95425 to 0.95733, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 121s 643ms/step - loss: 0.1252 - accuracy: 0.9630 - val_loss: 0.1284 - val_accuracy: 0.9635\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.95733 to 0.96350, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 120s 641ms/step - loss: 0.1154 - accuracy: 0.9660 - val_loss: 0.1592 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.96350\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 120s 640ms/step - loss: 0.1073 - accuracy: 0.9685 - val_loss: 0.1196 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.96350 to 0.96667, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 121s 642ms/step - loss: 0.1006 - accuracy: 0.9704 - val_loss: 0.1426 - val_accuracy: 0.9601\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.96667\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 121s 644ms/step - loss: 0.0951 - accuracy: 0.9722 - val_loss: 0.1062 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.96667 to 0.96992, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 121s 642ms/step - loss: 0.0909 - accuracy: 0.9733 - val_loss: 0.1128 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.96992 to 0.97025, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 120s 638ms/step - loss: 0.0883 - accuracy: 0.9741 - val_loss: 0.1027 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.97025 to 0.97058, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 120s 638ms/step - loss: 0.0843 - accuracy: 0.9756 - val_loss: 0.0961 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.97058 to 0.97300, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 120s 639ms/step - loss: 0.0811 - accuracy: 0.9758 - val_loss: 0.1013 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.97300\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 120s 640ms/step - loss: 0.0784 - accuracy: 0.9772 - val_loss: 0.0926 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.97300 to 0.97400, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 120s 639ms/step - loss: 0.0752 - accuracy: 0.9777 - val_loss: 0.0921 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.97400\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 120s 638ms/step - loss: 0.0729 - accuracy: 0.9780 - val_loss: 0.0933 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.97400\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 120s 638ms/step - loss: 0.0710 - accuracy: 0.9790 - val_loss: 0.1711 - val_accuracy: 0.9475\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.97400\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 120s 637ms/step - loss: 0.0701 - accuracy: 0.9792 - val_loss: 0.0843 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.97400 to 0.97600, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 120s 637ms/step - loss: 0.0672 - accuracy: 0.9798 - val_loss: 0.0864 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.97600\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 120s 639ms/step - loss: 0.0656 - accuracy: 0.9805 - val_loss: 0.0854 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.97600\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 120s 638ms/step - loss: 0.0638 - accuracy: 0.9808 - val_loss: 0.0862 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.97600\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 120s 640ms/step - loss: 0.0628 - accuracy: 0.9816 - val_loss: 0.0862 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.97600\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 121s 642ms/step - loss: 0.0617 - accuracy: 0.9816 - val_loss: 0.0791 - val_accuracy: 0.9780\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.97600 to 0.97800, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 120s 639ms/step - loss: 0.0596 - accuracy: 0.9824 - val_loss: 0.0794 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.97800\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 120s 637ms/step - loss: 0.0586 - accuracy: 0.9827 - val_loss: 0.0822 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.97800\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 120s 639ms/step - loss: 0.0571 - accuracy: 0.9831 - val_loss: 0.0815 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.97800\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 120s 639ms/step - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.0828 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.97800\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 120s 640ms/step - loss: 0.0545 - accuracy: 0.9841 - val_loss: 0.0735 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.97800 to 0.97883, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 122s 648ms/step - loss: 0.0537 - accuracy: 0.9840 - val_loss: 0.0761 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.97883\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 120s 641ms/step - loss: 0.0527 - accuracy: 0.9844 - val_loss: 0.0933 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.97883\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 120s 641ms/step - loss: 0.0517 - accuracy: 0.9849 - val_loss: 0.0711 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.97883 to 0.98050, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 120s 638ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.0913 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.98050\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 121s 641ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 0.0767 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.98050\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 121s 641ms/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 0.0695 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.98050\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 120s 639ms/step - loss: 0.0480 - accuracy: 0.9855 - val_loss: 0.0722 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.98050\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 120s 638ms/step - loss: 0.0469 - accuracy: 0.9862 - val_loss: 0.0715 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.98050\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 121s 646ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.0683 - val_accuracy: 0.9802\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.98050\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 121s 642ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 0.0691 - val_accuracy: 0.9802\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.98050\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 121s 643ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.0704 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.98050\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 121s 646ms/step - loss: 0.0434 - accuracy: 0.9875 - val_loss: 0.0701 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.98050\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 121s 643ms/step - loss: 0.0427 - accuracy: 0.9872 - val_loss: 0.0745 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.98050\n",
            "Epoch 00052: early stopping\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0528 - accuracy: 0.9845\n",
            "Accuracy for the training set: 0.9845499992370605\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.0550 - accuracy: 0.9818\n",
            "Accuracy for the testing set: 0.9818000197410583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h9XwG106XpZ"
      },
      "source": [
        "## No Regularization vs Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkNsx8VK6xfr"
      },
      "source": [
        "### Dropout after 1 Convolutional Layer\n",
        "\n",
        "0.9785"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZlCzIPyg6cxt",
        "outputId": "38882f3e-82c5-4fea-d66a-3146bcfa6be2"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dropout(0.5, name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,722\n",
            "Trainable params: 125,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 1.0319 - accuracy: 0.7353 - val_loss: 0.4800 - val_accuracy: 0.8720\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87200, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.4593 - accuracy: 0.8665 - val_loss: 0.3894 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87200 to 0.89125, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.4085 - accuracy: 0.8803 - val_loss: 0.3643 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89125 to 0.89817, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 20s 105ms/step - loss: 0.3855 - accuracy: 0.8865 - val_loss: 0.3468 - val_accuracy: 0.9018\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89817 to 0.90183, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.3706 - accuracy: 0.8919 - val_loss: 0.3375 - val_accuracy: 0.9044\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90183 to 0.90442, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.3585 - accuracy: 0.8943 - val_loss: 0.3264 - val_accuracy: 0.9091\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90442 to 0.90908, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 20s 105ms/step - loss: 0.3477 - accuracy: 0.8991 - val_loss: 0.3217 - val_accuracy: 0.9093\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90908 to 0.90933, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.3407 - accuracy: 0.9010 - val_loss: 0.3146 - val_accuracy: 0.9111\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.90933 to 0.91108, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.3327 - accuracy: 0.9024 - val_loss: 0.3069 - val_accuracy: 0.9146\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.91108 to 0.91458, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 20s 105ms/step - loss: 0.3259 - accuracy: 0.9046 - val_loss: 0.3026 - val_accuracy: 0.9178\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91458 to 0.91775, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 20s 105ms/step - loss: 0.3199 - accuracy: 0.9073 - val_loss: 0.2974 - val_accuracy: 0.9178\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91775 to 0.91783, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 20s 105ms/step - loss: 0.3150 - accuracy: 0.9088 - val_loss: 0.2922 - val_accuracy: 0.9201\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.91783 to 0.92008, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 20s 105ms/step - loss: 0.3088 - accuracy: 0.9107 - val_loss: 0.2894 - val_accuracy: 0.9203\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.92008 to 0.92033, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.3036 - accuracy: 0.9121 - val_loss: 0.2845 - val_accuracy: 0.9223\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.92033 to 0.92233, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.3003 - accuracy: 0.9130 - val_loss: 0.2802 - val_accuracy: 0.9244\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.92233 to 0.92442, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2960 - accuracy: 0.9148 - val_loss: 0.2769 - val_accuracy: 0.9243\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.92442\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2882 - accuracy: 0.9168 - val_loss: 0.2731 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.92442 to 0.92525, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2854 - accuracy: 0.9184 - val_loss: 0.2691 - val_accuracy: 0.9277\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92525 to 0.92767, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2790 - accuracy: 0.9196 - val_loss: 0.2673 - val_accuracy: 0.9282\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.92767 to 0.92817, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2745 - accuracy: 0.9210 - val_loss: 0.2598 - val_accuracy: 0.9298\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.92817 to 0.92983, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.2694 - accuracy: 0.9229 - val_loss: 0.2561 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92983 to 0.93033, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2646 - accuracy: 0.9233 - val_loss: 0.2533 - val_accuracy: 0.9302\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.93033\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.2616 - accuracy: 0.9247 - val_loss: 0.2491 - val_accuracy: 0.9330\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.93033 to 0.93300, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.2556 - accuracy: 0.9259 - val_loss: 0.2458 - val_accuracy: 0.9327\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.93300\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.2499 - accuracy: 0.9287 - val_loss: 0.2408 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.93300 to 0.93625, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2474 - accuracy: 0.9305 - val_loss: 0.2385 - val_accuracy: 0.9352\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.93625\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2419 - accuracy: 0.9320 - val_loss: 0.2330 - val_accuracy: 0.9368\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.93625 to 0.93683, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2367 - accuracy: 0.9329 - val_loss: 0.2276 - val_accuracy: 0.9380\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.93683 to 0.93800, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.2349 - accuracy: 0.9335 - val_loss: 0.2246 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93800 to 0.93925, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2289 - accuracy: 0.9348 - val_loss: 0.2209 - val_accuracy: 0.9397\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.93925 to 0.93967, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.2251 - accuracy: 0.9366 - val_loss: 0.2164 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.93967 to 0.94083, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.2223 - accuracy: 0.9373 - val_loss: 0.2129 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.94083 to 0.94325, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.2178 - accuracy: 0.9389 - val_loss: 0.2090 - val_accuracy: 0.9442\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.94325 to 0.94417, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2152 - accuracy: 0.9386 - val_loss: 0.2075 - val_accuracy: 0.9424\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.94417\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2116 - accuracy: 0.9400 - val_loss: 0.2016 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.94417 to 0.94483, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2072 - accuracy: 0.9413 - val_loss: 0.1992 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.94483\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2042 - accuracy: 0.9419 - val_loss: 0.1949 - val_accuracy: 0.9474\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.94483 to 0.94742, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.2007 - accuracy: 0.9438 - val_loss: 0.1923 - val_accuracy: 0.9483\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.94742 to 0.94833, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1970 - accuracy: 0.9443 - val_loss: 0.1887 - val_accuracy: 0.9493\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.94833 to 0.94933, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1935 - accuracy: 0.9446 - val_loss: 0.1871 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.94933\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1917 - accuracy: 0.9451 - val_loss: 0.1831 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.94933 to 0.95017, saving model to mnist_conv_best.h5\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1896 - accuracy: 0.9468 - val_loss: 0.1809 - val_accuracy: 0.9521\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.95017 to 0.95208, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1845 - accuracy: 0.9479 - val_loss: 0.1784 - val_accuracy: 0.9514\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.95208\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.1834 - accuracy: 0.9487 - val_loss: 0.1747 - val_accuracy: 0.9528\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.95208 to 0.95275, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1802 - accuracy: 0.9492 - val_loss: 0.1725 - val_accuracy: 0.9539\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.95275 to 0.95392, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1783 - accuracy: 0.9493 - val_loss: 0.1694 - val_accuracy: 0.9545\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.95392 to 0.95450, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 20s 105ms/step - loss: 0.1755 - accuracy: 0.9494 - val_loss: 0.1686 - val_accuracy: 0.9540\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.95450\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1731 - accuracy: 0.9504 - val_loss: 0.1645 - val_accuracy: 0.9565\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.95450 to 0.95650, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 21s 111ms/step - loss: 0.1715 - accuracy: 0.9517 - val_loss: 0.1629 - val_accuracy: 0.9567\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.95650 to 0.95667, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 22s 115ms/step - loss: 0.1676 - accuracy: 0.9527 - val_loss: 0.1607 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.95667 to 0.95708, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1660 - accuracy: 0.9529 - val_loss: 0.1594 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.95708 to 0.95733, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.1634 - accuracy: 0.9539 - val_loss: 0.1561 - val_accuracy: 0.9586\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.95733 to 0.95858, saving model to mnist_conv_best.h5\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.1612 - accuracy: 0.9541 - val_loss: 0.1544 - val_accuracy: 0.9585\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.95858\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.1581 - accuracy: 0.9554 - val_loss: 0.1528 - val_accuracy: 0.9592\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.95858 to 0.95925, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1572 - accuracy: 0.9555 - val_loss: 0.1507 - val_accuracy: 0.9602\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.95925 to 0.96017, saving model to mnist_conv_best.h5\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1569 - accuracy: 0.9550 - val_loss: 0.1496 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.96017\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1545 - accuracy: 0.9555 - val_loss: 0.1476 - val_accuracy: 0.9602\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.96017\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1523 - accuracy: 0.9562 - val_loss: 0.1453 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.96017 to 0.96033, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1509 - accuracy: 0.9563 - val_loss: 0.1439 - val_accuracy: 0.9613\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.96033 to 0.96125, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1477 - accuracy: 0.9577 - val_loss: 0.1419 - val_accuracy: 0.9613\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.96125\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1473 - accuracy: 0.9584 - val_loss: 0.1406 - val_accuracy: 0.9616\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.96125 to 0.96158, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1464 - accuracy: 0.9585 - val_loss: 0.1390 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.96158 to 0.96258, saving model to mnist_conv_best.h5\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1445 - accuracy: 0.9588 - val_loss: 0.1381 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.96258 to 0.96275, saving model to mnist_conv_best.h5\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1422 - accuracy: 0.9595 - val_loss: 0.1362 - val_accuracy: 0.9634\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.96275 to 0.96342, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1421 - accuracy: 0.9592 - val_loss: 0.1346 - val_accuracy: 0.9633\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.96342\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1393 - accuracy: 0.9609 - val_loss: 0.1339 - val_accuracy: 0.9641\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.96342 to 0.96408, saving model to mnist_conv_best.h5\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1390 - accuracy: 0.9605 - val_loss: 0.1328 - val_accuracy: 0.9651\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.96408 to 0.96508, saving model to mnist_conv_best.h5\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1354 - accuracy: 0.9614 - val_loss: 0.1316 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.96508\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1346 - accuracy: 0.9614 - val_loss: 0.1301 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.96508\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1358 - accuracy: 0.9609 - val_loss: 0.1291 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00070: val_accuracy improved from 0.96508 to 0.96517, saving model to mnist_conv_best.h5\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1326 - accuracy: 0.9628 - val_loss: 0.1272 - val_accuracy: 0.9655\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.96517 to 0.96550, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1336 - accuracy: 0.9618 - val_loss: 0.1264 - val_accuracy: 0.9662\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.96550 to 0.96617, saving model to mnist_conv_best.h5\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1295 - accuracy: 0.9633 - val_loss: 0.1256 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.96617\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1305 - accuracy: 0.9622 - val_loss: 0.1246 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.96617 to 0.96650, saving model to mnist_conv_best.h5\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1269 - accuracy: 0.9638 - val_loss: 0.1233 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.96650\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1265 - accuracy: 0.9642 - val_loss: 0.1228 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.96650 to 0.96725, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1254 - accuracy: 0.9641 - val_loss: 0.1215 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.96725\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1239 - accuracy: 0.9641 - val_loss: 0.1203 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.96725\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1238 - accuracy: 0.9645 - val_loss: 0.1206 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.96725 to 0.96733, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1231 - accuracy: 0.9644 - val_loss: 0.1184 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.96733\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 20s 106ms/step - loss: 0.1230 - accuracy: 0.9651 - val_loss: 0.1182 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.96733 to 0.96775, saving model to mnist_conv_best.h5\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1222 - accuracy: 0.9642 - val_loss: 0.1165 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.96775 to 0.96800, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1208 - accuracy: 0.9651 - val_loss: 0.1161 - val_accuracy: 0.9674\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.96800\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1199 - accuracy: 0.9656 - val_loss: 0.1150 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.96800 to 0.96850, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1183 - accuracy: 0.9658 - val_loss: 0.1152 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.96850 to 0.96867, saving model to mnist_conv_best.h5\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1172 - accuracy: 0.9661 - val_loss: 0.1134 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.96867\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1150 - accuracy: 0.9675 - val_loss: 0.1130 - val_accuracy: 0.9684\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.96867\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1163 - accuracy: 0.9666 - val_loss: 0.1124 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00088: val_accuracy improved from 0.96867 to 0.96933, saving model to mnist_conv_best.h5\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1150 - accuracy: 0.9667 - val_loss: 0.1116 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.96933\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1150 - accuracy: 0.9663 - val_loss: 0.1108 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.96933\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1132 - accuracy: 0.9677 - val_loss: 0.1103 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.96933\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1125 - accuracy: 0.9670 - val_loss: 0.1096 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.96933 to 0.97008, saving model to mnist_conv_best.h5\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1111 - accuracy: 0.9675 - val_loss: 0.1091 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.97008\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1107 - accuracy: 0.9681 - val_loss: 0.1076 - val_accuracy: 0.9695\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.97008\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1095 - accuracy: 0.9687 - val_loss: 0.1074 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00095: val_accuracy improved from 0.97008 to 0.97017, saving model to mnist_conv_best.h5\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1098 - accuracy: 0.9679 - val_loss: 0.1070 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.97017\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1083 - accuracy: 0.9685 - val_loss: 0.1063 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.97017\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1081 - accuracy: 0.9682 - val_loss: 0.1055 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.97017 to 0.97033, saving model to mnist_conv_best.h5\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1075 - accuracy: 0.9684 - val_loss: 0.1048 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00099: val_accuracy improved from 0.97033 to 0.97050, saving model to mnist_conv_best.h5\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1054 - accuracy: 0.9685 - val_loss: 0.1043 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.97050 to 0.97067, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1074 - accuracy: 0.9688 - val_loss: 0.1035 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00101: val_accuracy improved from 0.97067 to 0.97075, saving model to mnist_conv_best.h5\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1050 - accuracy: 0.9698 - val_loss: 0.1039 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.97075\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 20s 107ms/step - loss: 0.1041 - accuracy: 0.9699 - val_loss: 0.1024 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.97075 to 0.97108, saving model to mnist_conv_best.h5\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.1038 - accuracy: 0.9696 - val_loss: 0.1025 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.97108\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.1033 - accuracy: 0.9699 - val_loss: 0.1017 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00105: val_accuracy improved from 0.97108 to 0.97217, saving model to mnist_conv_best.h5\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.1040 - accuracy: 0.9695 - val_loss: 0.1010 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.97217\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.1019 - accuracy: 0.9706 - val_loss: 0.1007 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.97217\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.1033 - accuracy: 0.9696 - val_loss: 0.1001 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.97217\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.1010 - accuracy: 0.9700 - val_loss: 0.1002 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.97217 to 0.97225, saving model to mnist_conv_best.h5\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.1019 - accuracy: 0.9697 - val_loss: 0.0989 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.97225 to 0.97242, saving model to mnist_conv_best.h5\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.1002 - accuracy: 0.9714 - val_loss: 0.0986 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.97242\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.0993 - accuracy: 0.9708 - val_loss: 0.0980 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.97242\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.1003 - accuracy: 0.9701 - val_loss: 0.0977 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.97242 to 0.97267, saving model to mnist_conv_best.h5\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0988 - accuracy: 0.9708 - val_loss: 0.0971 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.97267\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.0973 - accuracy: 0.9718 - val_loss: 0.0972 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.97267\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.0965 - accuracy: 0.9722 - val_loss: 0.0965 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.97267 to 0.97292, saving model to mnist_conv_best.h5\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0976 - accuracy: 0.9709 - val_loss: 0.0957 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.97292\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.0968 - accuracy: 0.9714 - val_loss: 0.0950 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.97292\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0945 - accuracy: 0.9724 - val_loss: 0.0951 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.97292\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.0944 - accuracy: 0.9724 - val_loss: 0.0943 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.97292 to 0.97383, saving model to mnist_conv_best.h5\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.0952 - accuracy: 0.9717 - val_loss: 0.0946 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97383\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0929 - accuracy: 0.9724 - val_loss: 0.0939 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.97383\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0943 - accuracy: 0.9721 - val_loss: 0.0946 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.97383\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0929 - accuracy: 0.9723 - val_loss: 0.0935 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.97383 to 0.97408, saving model to mnist_conv_best.h5\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 20s 108ms/step - loss: 0.0939 - accuracy: 0.9720 - val_loss: 0.0925 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00125: val_accuracy improved from 0.97408 to 0.97417, saving model to mnist_conv_best.h5\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0931 - accuracy: 0.9720 - val_loss: 0.0926 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97417\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0915 - accuracy: 0.9737 - val_loss: 0.0922 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.97417\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0925 - accuracy: 0.9726 - val_loss: 0.0918 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97417\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0912 - accuracy: 0.9732 - val_loss: 0.0912 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.97417 to 0.97425, saving model to mnist_conv_best.h5\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0906 - accuracy: 0.9736 - val_loss: 0.0914 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97425\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0900 - accuracy: 0.9731 - val_loss: 0.0905 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97425\n",
            "Epoch 132/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.0901 - accuracy: 0.9738 - val_loss: 0.0901 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00132: val_accuracy improved from 0.97425 to 0.97467, saving model to mnist_conv_best.h5\n",
            "Epoch 133/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0882 - accuracy: 0.9744 - val_loss: 0.0902 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97467\n",
            "Epoch 134/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.0901 - accuracy: 0.9737 - val_loss: 0.0898 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97467\n",
            "Epoch 135/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.0885 - accuracy: 0.9735 - val_loss: 0.0893 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97467\n",
            "Epoch 136/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0887 - accuracy: 0.9738 - val_loss: 0.0895 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.97467\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0885 - accuracy: 0.9736 - val_loss: 0.0889 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.97467\n",
            "Epoch 138/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0879 - accuracy: 0.9746 - val_loss: 0.0887 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00138: val_accuracy improved from 0.97467 to 0.97492, saving model to mnist_conv_best.h5\n",
            "Epoch 139/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0861 - accuracy: 0.9749 - val_loss: 0.0882 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97492\n",
            "Epoch 140/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0869 - accuracy: 0.9746 - val_loss: 0.0879 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97492\n",
            "Epoch 141/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0858 - accuracy: 0.9744 - val_loss: 0.0874 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.97492\n",
            "Epoch 142/10000\n",
            "188/188 [==============================] - 20s 109ms/step - loss: 0.0855 - accuracy: 0.9749 - val_loss: 0.0871 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00142: val_accuracy improved from 0.97492 to 0.97517, saving model to mnist_conv_best.h5\n",
            "Epoch 143/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0848 - accuracy: 0.9752 - val_loss: 0.0870 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.97517\n",
            "Epoch 144/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.0850 - accuracy: 0.9745 - val_loss: 0.0866 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00144: val_accuracy improved from 0.97517 to 0.97567, saving model to mnist_conv_best.h5\n",
            "Epoch 145/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.0853 - accuracy: 0.9745 - val_loss: 0.0863 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.97567\n",
            "Epoch 146/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0865 - accuracy: 0.9744 - val_loss: 0.0859 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97567\n",
            "Epoch 147/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.0845 - accuracy: 0.9750 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00147: val_accuracy improved from 0.97567 to 0.97608, saving model to mnist_conv_best.h5\n",
            "Epoch 148/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0845 - accuracy: 0.9754 - val_loss: 0.0856 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.97608\n",
            "Epoch 149/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0835 - accuracy: 0.9754 - val_loss: 0.0857 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.97608\n",
            "Epoch 150/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.0826 - accuracy: 0.9752 - val_loss: 0.0856 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.97608\n",
            "Epoch 151/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0834 - accuracy: 0.9746 - val_loss: 0.0857 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.97608\n",
            "Epoch 152/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0842 - accuracy: 0.9751 - val_loss: 0.0856 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97608\n",
            "Epoch 153/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0836 - accuracy: 0.9751 - val_loss: 0.0845 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.97608\n",
            "Epoch 154/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0825 - accuracy: 0.9757 - val_loss: 0.0842 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97608\n",
            "Epoch 155/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0816 - accuracy: 0.9750 - val_loss: 0.0841 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.97608\n",
            "Epoch 156/10000\n",
            "188/188 [==============================] - 21s 109ms/step - loss: 0.0828 - accuracy: 0.9757 - val_loss: 0.0839 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.97608\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - 21s 110ms/step - loss: 0.0817 - accuracy: 0.9758 - val_loss: 0.0842 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97608\n",
            "Epoch 00157: early stopping\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0676 - accuracy: 0.9812\n",
            "Accuracy for the training set: 0.981166660785675\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0701 - accuracy: 0.9785\n",
            "Accuracy for the testing set: 0.9785000085830688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAGrCAYAAABXOYc2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5iU1fn/8ffZZSlLL4s0KdKxIiixIdEoYsdu1JhoJNGYqDGixqiJxhpj+dqNP40YS4wtQLATxIYBVLCgFGlL3aUt7C7LlvP741maoIBsY3i/rmuu2Xnmec6cWS5l+My57xNijEiSJEmSJCm1pVX3BCRJkiRJklT5DIEkSZIkSZJ2AoZAkiRJkiRJOwFDIEmSJEmSpJ2AIZAkSZIkSdJOwBBIkiRJkiRpJ2AIJEmSJEmStBMwBJL0vYUQZoUQflTd85AkSdpRhRDGhBCWhRDqVPdcJKU+QyBJkiRJqgYhhI7AIUAEjq/C161VVa8lqWYxBJJUoUIIdUIId4cQ5pff7l77zVYIoUUIYWQIYXkIYWkI4Z0QQlr5c1eGEOaFEFaGEL4KIRxeve9EkiSp0v0EGAf8HTh37cEQwq4hhBdDCDkhhCUhhPs2eO6CEMKU8s9MX4QQ9i0/HkMIXTY47+8hhD+X/zwghJBd/nlrIfB4CKFp+eeynPKVSCNDCO02uL5ZCOHx8s9zy0IIL5cf/yyEcNwG52WEEHJDCL0r7bckqcIYAkmqaNcAPwD2AfYG9gf+UP7c5UA2kAXsAvweiCGE7sDFwH4xxobAQGBW1U5bkiSpyv0EeKr8NjCEsEsIIR0YCcwGOgJtgWcBQginAn8sv64RyeqhJVv5Wq2AZkAHYAjJvwUfL3/cHigE7tvg/CeBTGB3oCVwV/nxYcDZG5x3NLAgxvjxVs5DUjVyGaCkinYW8OsY42KAEMKfgIeBa4FioDXQIcY4HXin/JxSoA7QK4SQE2OcVR0TlyRJqiohhINJApjnYoy5IYQZwI9JVga1Aa6IMZaUn/5u+f3PgdtjjOPLH0/fhpcsA66PMRaVPy4EXthgPjcB/y3/uTUwCGgeY1xWfsrb5ff/AK4NITSKMeYB55AERpJ2AK4EklTR2pB8c7XW7PJjAH8h+bDyegjh6xDCVQDlgdClJN9sLQ4hPBtCaIMkSVLqOhd4PcaYW/746fJjuwKzNwiANrQrMON7vl5OjHH12gchhMwQwsMhhNkhhDxgLNCkfCXSrsDSDQKgdWKM84H3gJNDCE1IwqKnvuecJFUxQyBJFW0+ybdaa7UvP0aMcWWM8fIY424ky5d/u7b3T4zx6Rjj2m/EInBb1U5bkiSpaoQQ6gGnAYeGEBaW9+m5jKSUfhHQ/luaN88FOn/LsAUk5VtrtfrG8/Ebjy8HugP9YoyNgP5rp1f+Os3KQ57NeYKkJOxU4IMY47xvOU9SDWMIJGl7ZYQQ6q69Ac8AfwghZIUQWgDXkSwbJoRwbAihSwghACuAUqAshNA9hHBYeQPp1STLk8uq5+1IkiRVuhNJPgf1IumjuA/Qk6RU/kRgAXBrCKF++Wesg8qvexT4XQihT0h0CSGs/fLtE+DHIYT0EMJRwKFbmENDks9cy0MIzYDr1z4RY1wAvAI8UN5AOiOE0H+Da18G9gUuIekRJGkHYQgkaXuNIvkAsfZWF5gATAY+BT4C/lx+blfgTWAV8AHwQIzxvyT9gG4FcoGFJM0Hr666tyBJklSlzgUejzHOiTEuXHsjacx8JnAc0AWYQ7KpxukAMcZ/ATeRlI6tJAljmpWPeUn5dctJejS+vIU53A3UI/n8NQ549RvPn0PSz/FLYDFJ6T7l81jbT6gT8OI2vndJ1SjE+M1VgZIkSZIkfbsQwnVAtxjj2Vs8WVKN4e5gkiRJkqStVl4+dj7JaiFJOxDLwSRJkiRJWyWEcAFJ4+hXYoxjq3s+kraN5WCSJEmSJEk7AVcCSZIkSZIk7QSqrSdQixYtYseOHavr5SVJUiWbOHFibowxq7rnoY35GUySpNT2XZ/Bqi0E6tixIxMmTKiul5ckSZUshDC7uuegTfkZTJKk1PZdn8EsB5MkSZIkSdoJGAJJkiRJkiTtBAyBJEmSJEmSdgKGQJIkSZIkSTsBQyBJkiRJkqSdgCGQJEmSJEnSTsAQSJIkSZIkaSdgCCRJkiRJkrQTMASSJEmSJEnaCRgCSZIkSZIk7QQMgSRJkiRJknYChkCSJEmSJEk7AUMgSZIkSZKknYAhkCRJkiRJ0k4g9UKg7GyYMqW6ZyFJkiRJkmqwkrIS5qyYQ4yxwseOMVJYXEheUd66W0lZSYW/zraqVd0TqHDXXgujR8Ps2dU9E0mSJEmSVMWKS4t5e/bbjJk1ht6tejOo6yAyMzIpi2V8tOAjXp/xOm/Pfpv35rxHfnE+3Zt355zdz+SUBvvTqCwDikuom16Hpm07Q8uWULfud77ejKUzeG36q0yY8iYT5nzI12VLKKCYyMbhUp2Yzj6Fjem7oj6H1O/J6X99rTJ/DZuVeiFQejqUVH+6JkmSJEnSzqS4tJhVa1bRtF7T73V9aVkpkxZN4v3Z79KqMJ1BBW2p//VcaNgQuneH7t1Z06g+ExZM5L057zEt9ytmz/uc7KWzqVdUStaqSGZ+EWNaF7E0rWjduPVq1ePAXQ9k0qJJ5BbkArBn8178tN4BdJ6/jJdzpvCHJX/kD9+YT/dc6D8b9slvSEnP7hT07ELpLlk0X7SSrJmLWJw7m380y+b9xnkAZOVD3/lweC40WAP1m7Yko24mYeYsAObvUocJbQp5Ims5U8oip3+v39L2Sb0QqFYtKC2t7llIkiRJklSjrCldw+iZo1m+ejn5a/LJSM/g5J4nU792/S1e+96c9xiXPY4jOx/JHi33IISw7rkYI899/hxXvnkls1fMpkNGFn1WNaJfcUv6738qfY4dwuq0MkZNG8VLX75EYUkhfVv3pU+bPqwpXcOE+ROYMH8CH8z9gLw1eevGrVcMA6dDVgHkZMKiBvBJKyjMSJ7PyocOy6FbHhTVSSenaW2WNwsM+rKUkyfD4SuaMb5bfV5ot5Kxue8wcGV9jlrRjYEL65P1/iQo+wJ22YXL+v6QmY3aM7rtGkpqp0N6LZaVrOS9upN4rsVU/sZKYALkToDc8sk1TG67r8rk1tldOS3uTseDjyX86kdQpw688AL861+QlweDz4NTT4UePQAoi2UsK1xWQX+q2yZURu3b1ujbt2+cMGFCxQ988cXw7LOQm7vlcyVJUqUJIUyMMfat7nloY5X2GUySVKXyivK473/38ehHj5JVP4u+rfuye8vdmblsJhMWTGDakmkc0fkIftnnl/Rt05enPn2K68dcz6zlszYaZ5f6u3DNIdcwpM8QVpesZsqIx1j0xkt0Pf0iugw4iXl58xj65lCe/+L5ddd0DS04vKwDjXfpQOauu/Ha3P/y/uKJ7J2XyWnjC5i8C0xoG5jRNMkbMouhND2NorQyWpZl0rSsNlPTlxPLc6T0GNh9TRN+MH01h35ZyEFtD2DmMQfyQr2ZDF/+IUUlRWRRnxbFtdi7sDH9lzXikAUZZLXvCQcckNzat4e1wVRBAYwaBSNHQmFhcizG5Of8/GThSP/+cPzx0KcPpH17u+TSslIWrlpI3ZBB5qQvSJs+nSU9O5LTrikZtevRs0XPjQKxmuC7PoOlXgh0ySXwxBOwfHnFjy1JkraaIVDNZAgkSVWvLJaxaNUi5qyYQ2ksJSszi6z6WTSu03hdgFBYXMiYWWN4a+ZbZGVmMajrIPZsuSer1qxi9MzRvDXzLYpKiqhfuz7FpcX849N/sHz1cg7vdDilsZSJ8yeycs1K6qTXYe9We9O+cXtemfYK+cX5NK3blGWrl7Fv6325/tDr6da8G5kZmcxePpvrxlzHmFljqFerHoUlhRvNu1YMENKoHQNXflyfc8au4PXO8HwvmNgGCjKgqBa0Wgl/Hg0/Db1JP3EwHHYY7Lcfi1Yu4J1RDzF20nBq5S5h8BQ48NPlpGfUIa/nbnzSsykZMbDP1JXUm5UNe+yR9Pk95JDq+GNKGTtXCHT55fDII7ByZcWPLUmStpohUM1kCCRJ327i/ImMnDqSTk070SurFz1b9PzWUqmFqxby2MeP8f7c98ktyCWnIAeADo070KFJB9JDOrOWz2L2itnMXTGXotKiTcaolVaLFpktaF63GTOWzmB1WRG1YzprQtLipGX9liwrXEZxWTH1M+rToHYD8gtXUFRSxDELGvCHz5rTZ3k96N+fstNPY97eu9Hqy2wyhv0D/vMf8to05+l9M3gzayVn5LXn5K/rEJYth06doFcv6NyZGAJvrPyElz95lo4TZ9Czx8G0/M3vmf7So0z5YARFZcVc+lFt2h44EAYNgj33hJ49oV49+OQTSieMJxQVkTb4JOjSZcu/5BjXr9hRpdi5QqArr4T/+7/1S74kSVK1MASqmQyBJGlTywqXcc3oa3howkMb7egUCPTM6knfNn3p1qwb6WnpAExcMJGXv3yZkrIS9my5J60btiYrM4vSWMrs5bOZnTOdspJiOrTonNwad6Bjk450aNyB9LR0cvJzkuBo6VxyJrxN7vRP6ZBbzKBpSSPipfXgtZ8cwOiD2tK2xW4MatKXAycvo/Zf74YpU5KwZa+9ko2RCguTHbILCiAzM7mvVw+OPhpWrYKpU2HOHGjWDNq0gcaNYcYMmDdv419CCHDLLTB06PqQZvFi+OQTOPBAaNCgqv44tJ2+6zNY6jWGdncwSZIkSdpprG2yu3Y1Tk5+DksKl5C/Jp/84nzWlK6had2mtMhsQa20WozLHsfYOWP5fPHnNKnbhKz6WSxYuYBlq5fx6/1/zbWHXktuQS5f5HzB5EWTmbhgIq9PfZVhhcPWvWazes24pN8lDOkzhG7Nu62fTIxw333wh8uSvjO1JsGApnBifzjheGjXLjnnk0/ghafgb/8vaRx8wglw3lnJKptdd6Xtbbdx3i23cN5z06HhR/D17cn4e+wBzzyTNBlOT1//uvn58J//wBtvJP1xTjkFGjXaeF7fXH2zYgXMnp38nJa2PiTaUMuWcOSRFfCnpJoi9VYCXXcd/PnPUFZW8WNLkqSt5kqgmsmVQJKq26JVi3j2s2dpUrcJJ/U8iYZ1Gm70fEFxAa9Nf42RU0eyomgFACEEds/anf4d+tOndR8+nPchL055kVHTRjF/5XxK49bvEF03rTYHZHZnnzodWNWgNjkZxaRn1OYPe17EPktqJ/1l9903CURWrYLbb4e//IXVJathv/3ghhuoffiRpM2bD//7HyxbBp07w267wc03w8MPJw2Hr7giaU780kvw5ZfJi/ftm4Q+U6cmO1ufdBJcc02yquebJk+Gq66CunWTJsb9+8M++3xnE2MJtnMlUAjhMeBYYHGMcY/NPB+Ae4CjgQLgpzHGj7ZvytshPT1JOcvK/I9DkiRJkipZWSzjlWmvsHz1co7uejRN6zUFoKikiPfnvs/8lfMBKI2ljJo2ihenvEhxWTEAF/7nQk7scSLtGrUjtyCXBasWMHb2WAqKC2hatyltGiYrU4rLinlxyouUxfVf9tfPqM+groPo3rw7LTJbrGu2nJWZRYvMFjSo3YDMjEwy0mqx7D8vkPOXP1IwfQq7L15DndJPgU/Xv4mGDWHlCxu/sQ4doKgIFi6EM86g7iGHJOVSRwyC5s1hyZLN/0Kuugpuuin59+jBByfB0Jdfwr//DcOHJ7tYXXEFDB6cjPNt9torCZGkCrQ15WB/B+4Dhn3L84OAruW3fsCD5ffVo1b5Wyopgdq1q20akiRJkrSjWr56OWNnj2Vx/mJyC3KJMdKjRQ96ZvWkVYNWFBYXkl+cz+szXueucXcxfel0IGl0fFinw6hbqy5vff0W+cX5G43bpG4TfrXfrxjSZwjLVy9n2KRh/PPzf1JQXEBW/SS8+cnuP+bkNV049NM8Mrrsm6yqychgxeoVvD9tNBP+9xJ7t9qHIw75KfUaNUsGXrEi6XuzpBAWFkDBl0mp08yZMHYszd99l+YdO8IfH4auXZPQJy0Npk+Hr76CnJxkJU/37slz48fDBx8k/XWuuSYpsQI47zx46KGknGvffaFfP8jKgq+/hmnTkjEGDtz0F9qjR3K78spK/FOTtmyrysFCCB2Bkd+yEuhhYEyM8Znyx18BA2KMC75rzEpbinzbbUnyurYZliRJqhaWg9VMloNJKikrYcL8CcxcNpNZy2exumQ1AzoO4KD2B1FcWsw9H97D7e/dvq4Ua0v2b7s/lx9wOR2bdOTFKS/y4pQXKY2lDOw8kEFdBtG9RXcCAdasYdeGbanboMlG18cYYckSwr//Dc8/D2PGwOrV609o0wZ+8pOkmfHIkes3AUpPT3a5Wro0uW1OenrSRPnXv4YLLnChgHYKld0Yui0wd4PH2eXHNgmBQghDgCEA7du3r4CX3oy1zbFsDi1JkiQpRS1atYjhXw3n0I6HbtyYuNzCVQt5bfprTF40mX7t+nHEbkdQv3Z9hk0axi3v3sLXy75ed25aSOOGsTfQoHYD6taqS25BLsd2O5bfHfA7OjbpSFb9LMpiGV/mfskXOV+QW5BLZjHU/9fLdJ9TwH57XUXoeQKkpbF/2/259Ue3bjyZGOHpp5Mgpqgo2bXq5JOTKo4JEwj/+x+8807yb7hOneAXv0hW0xx8MLz9Ntx/P9x6a9Kk+Kc/TZoor1yZ9Mz58kto0SJZgdOhA9SvDxkZUKcO7LprcquVevshSd9Xlf7XEGN8BHgEkm+hKuVF1v4HXrr1jcEkSZIkqSZaVriMV6e/Sr2MenRo3IH6tevzwPgHeGTiIxSWJCtijut2HBfsewE5BTlMmD+BD7I/4JOFnwCQHtIpHVdKWkijad2mLClcQt82fbnpsJvYa5e9aN+4PTFGRs8czavTXyWnIIffHvBbDtz1wE3m0rdNX/q26QvvvgvnnAXz5yerdE46CXr1gkGDkj45OTnJduK9eye7Xf3tb/Dyy0lJ1T77JI2Sn38+GTQjIznnt7+F005LSqw23MXq2GOT29KlydbmG+6IdcoplfZ7l1JVRYRA84BdN3jcrvxY9diwJ5AkSZIk1WClZaW8N/c9XvjiBUZNH0WTuk3o27ovu7fcnTGzxjBi6gjWlK7Z6Jr0kM45e5/DL/v8klemv8L94+9nxNQRADSs3XBdyDOoyyD2aLkH4+eP55VprzB16VR+ts/PGNh5IOEb24Wf0OMETuhxwvoDq1Ylq2yWLk2CnYULk743M2bAa68lK3beey8Jbf71r2Slzn33Jf1xWrRIdsz65z+TserUgb/8BS67LAlx7r036blTq1YSANWps+VfVLNm2/V7lpSoiBBoOHBxCOFZkobQK7bUD6hSWQ4mSZIkqZpMmJ/03OrTus8mQQvAitUrePazZxk/fzxf5HzBFzlfsKJoBXXS6/Cj3X5EYUkhT3/2NHlFebSs35IL+17ImXucSa20WsxaPotF+Ys4uuvRdGzSEYB+7fpx5UFXMnb2WDo26UjX5l1JCxvvknzgrgeuX9kTI0yaBFOmJCtsGm6wPfsnnyRlW2+/DRMnblpd0bBhshX6RRclO16tvfbMM5PbNy1dmrxWp07QseP64+np8IMfbMuvVVIF2Zot4p8BBgAtQgjZwPVABkCM8SFgFMn28NNJtoj/WWVNdqtYDiZJkiSpCq0tp7px7I28PfttAPZptQ+/6PML9muzH/nF+eQV5fHyly/zzGfPJDthZWaxe8vd+fGeP2ZAxwEc3fVoGtRuACRbrmfnZdO6QWsy0jPWvU6fNn02fuHVqyE9nXoZ9RjYZYMdqYqL4fPPYcKEZDVP7dqQmQl5eUkp1vRkJy+aNIFf/hIOOihZnfP668m5/folm+306ZP04WnWbP39ZoKtb9WsGfzwh9/rdyqpcmwxBIoxbibS3ej5CPyqwma0vVwJJEmSJKkKLFq1iGc+e4Zhk4bx8cKPad2gNXceeSeZGZk8OOFBLvzPhRudn5mRyZl7nMkv+/4y6a3zLdJCGu0bb2YjnaKipL/Oe+8lAc/aMKdWrWRn5BihrCw5b+2X4nXqJP82Ki1N/q102GEwdGiyTfr998PttyfX7LJLsrrnwguTcEhSSkq9Nun2BJIkSZJUQWKMfLb4M16Y8gIvTHmBGUtnkJmRSWZGJvNXzqc0ltKndR8ePOZBfrrPT6lbqy4AQ/oMYeKCiSxYuWDd+b2yetG4buONX6CsDNI2Lt9iypQkqOnXDy65JCm7mjEDTj89KdNq3x769oVzzkmuLShItk0PIXlcty7ssUdyzm67JceKi5MgqG7d9a8zYEAy7uTJcNRRSZAkKaWlbghkOZgkSZKkbbQ4fzF3fnAnr814jZz8HHILcikqLSIQOKTDIQzcbyCFxYUUlBTQpkEbztrrLHpl9dpknBDCd672AZJA59hjkx22fve7ZLerRx+Fyy9PgpuRI+Gee+Dss+H//b9kJc9LL8GJJ277G8vISG7f1LlzcpO0U0i9EMhyMEmSJEnbYEnBEr7I+YIXprzAIxMfoai0iMM6HUbvVr3JysyiS7MuHN/9eHZpsMu2DVxcDMuXJ6t9ysqSXbPWBjGvv55srd6iBeTnw49/nJRirVgBAwfC3/8Oc+bAtdfC3Xcn26s/8wx06FDh71/SziP1QiBXAkmSJEnajOlLp3PPuHt4dcarlMUyAPKK8sgtyAXWb71+9cFX0615t60fePbsZPv0Hj2gVaukxOqhh+Cxx5Kt0tfKzEzCnF694MEHYffd4ZVXkn48I0fCsGFJidZFFyUrgVq1SrZjnzo1KeuqlXr/fJNUtVLv/yL2BJIkSZJ2GqtLVjN+3nj2abUPDeus3+58ScES3pnzDotWLSKnIIfx88cz4qsR1EqrxdFdj153br1a9ejRogc9W/Skd+vetGrQatsm8Nxz8LOfJX15ABo3Tlbz1KoFgwdD//7rqxWmTIGxY+G++5Jds158MTkf4Pjjk9vmdNuGQEqSvkPqhUCWg0mSJEkpb3H+Yh4c/yAPTHiAxfmLqZNehyM6H8GB7Q5k9KzR/HfmfymN66sDWjVoxTWHXMNF+11E64atv9+LfvllUqLVvj20awd//jPcdhsceCBcc02yAmjKFGjdGs4/P+n1szmFhUmD5m3Zbl2SKkDqhUCWg0mSJEkpo7SslBACaSGN4tJiXp3+Kk9OfpLhXw2nqLSIY7oew9l7nc2H2R/y4pcvMnLqSLo178bQg4ZybLdj6dC4Ay0yW1CnVp1te+EYYdGipMxr7NikH8/kyZue98tfJs2ba9fe+rHdhUtSNUndEMiVQJIkSdIOq6ikiDvev4Ob372ZguIC6tVKgpPCkkJaZLbggn0v4KL9LqJnVk8AztjjDO4ceCeL8xfTsn5LwtausokR/vc/ePZZGDcO8vJg5UrIzU1W7Kx14IHwf/8He+8Nc+fCrFlJD6CTT67gdy5JlSf1QiDLwSRJkqQdUlksY+GqhYyfN56hbw5l6pKpDO4xmD1b7klBcQHFZcUc3ulwjupyFBnpm253HkLY+h28Ykx24LrxRpg5M1nJc+CB0LYtNGgAzZsnzZg7dYI994Rdd63YNytJ1SD1QiDLwSRJkqQaq6SshEWrFpFbkMui/EV8uuhTJi6YyEcLPmLm8pmsKV0DQJdmXXj1rFcZ2GVgxU9iwQK44AL4z3+S3bquvx5OPHF9k2ZJSlGpFwK5EkiSJEmqkeblzePgxw9m1vJZGx3ftdGu9GnThxN7nEiHxh3o1LQTAzoOoG6tutv/oqtWJduwv/tusl378uXJz4WFSS+fiy9OtmOXpJ1A6oVA9gSSJEmSapzC4kJO/OeJ5Bbk8n9H/R9tGrahRWYLemb1pGX9lts22KpVSaPmuXMhJwfy86F372Q79t13Txo4v/sujB4Nb74JRUVQvz5kZUGTJnDooXDrrdC9e+W8WUmqoVI3BLIcTJIkSao2Ofk51KlVh0Z1GhFj5Pzh5zNx/kRePuNlju9+/PcbNEZ46SW49NIkAAoh6d1Tpw48+eSm53fuDBdeCIMHJ/1+aqXeP38kaVuk3v8FLQeTJEmSqsUnCz/huc+f49Xpr/Lxwo9JC2n0btWbNg3bMGLqCG4+7OZtC4BKSuCNN2DGDJg/Hz78MFnds9de8NRTSbCz9vP/vHnJVu5ffJHs4HXQQdC6deW8UUnaQaVeCORKIEmSJKlKZedl8/u3fs+Tk58kPaRzUPuDuOmwmygqKWLsnLG88fUbnLPXOVx18FVbN+CaNfCPf8Att8D06cmxWrWgXTu4666kj883V/W0bQtnnlmxb0ySUkzqhkCuBJIkSZIq1ZrSNdz+3u3c/M7NlMUyrjroKoYeNJSm9ZpudF5pWSlpIY0QwuYHmjMHHnwQvvoqWfEzYwbk5sK++8Lzz8Mhh0CLFjZwlqTtlHohkOVgkiRJUoX7+yd/56MFH3Fct+MY0HEAnyz8hPOGn8dniz/jlF6n8Jcj/kLHJh03e216WvrmB50xI2nQ/MQTSb+fbt2gTRs45hg4/XQ46qik748kqUKkXghkOZgkSdqBhBCOAu4B0oFHY4y3fuP5DsBjQBawFDg7xphd/lwp8Gn5qXNijN+z26707WKM/GH0H7j53ZtJD+nc+797aVq3KSuKVtC6QWtGnDmCY7sdu22DFhbCTTfB7bcnq3uGDIGhQ6F9+8p5E5IkIJVDIFcCSZKkGi6EkA7cDxwBZAPjQwjDY4xfbHDaHcCwGOMTIYTDgFuAc8qfK4wx7lOlk9ZOpSyWcfGoi3lwwoNcsO8F3DnwTt76+i1e+vIlWmS24Nr+19K4buOtHzBGGDUKfvMb+PprOOecZCVQmzaV9yYkSeukXghkOZgkSdpx7A9MjzF+DRBCeBY4AdgwBOoF/Lb85/8CL1fpDLXTKotlnPfv83hi0hMMPXAot/7oVkIInNDjBE7occK2DRYjvPYa/OlPMG4cdO+e7PL1wx9WzuQlSZuVeiGQ5WCSJGnH0RaYu8HjbKDfN86ZBJxEUjI2GGgYQmgeY1wC1A0hTABKgFtjjJsNiEIIQ4AhAO0tt9E35BTn8VgAACAASURBVBbkcv//7mdR/iKuOeQa2jZqS4yRi0ddzBOTnuBPA/7EdYde992DlJTARx/BO+/A7NmwYgXk5a2/5eQkx9u3h4cegp/9DGrXrpo3KElaJ/VCIFcCSZKk1PI74L4Qwk+BscA8YO23XR1ijPNCCLsBo0MIn8YYZ3xzgBjjI8AjAH379o1VM23VdLOXz+avH/yVRz96lMKSQmqn1+apT5/ijiPuYNrSaTw44UGuPOhKru1/7eYHWL0aRo5MtnJ/803Iz0+ON26c3Bo1Su6zsqBzZ7jmGjj3XMMfSapGqRcC2RNIkiTtOOYBu27wuF35sXVijPNJVgIRQmgAnBxjXF7+3Lzy+69DCGOA3sAmIZC0ocmLJnP7e7fz7GfPkhbSOHuvs7niwCvISM/gghEXMGTkEAB+td+vuOXwWzbd1j03N2nq/PjjyYqfNm2ScGfAgGQr91atqv5NSZK2SuqGQJaDSZKkmm880DWE0Ikk/DkD+PGGJ4QQWgBLY4xlwNUkO4URQmgKFMQYi8rPOQi4vSonrx3PHe/fwRVvXEGD2g24pN8lXHbAZbRr1G7d86N/MprHP3mceXnzuKb/NRsHQIWFcPfdSSPnVavgjDOSsq4f/nD9anxJUo2WeiGQ5WCSJGkHEWMsCSFcDLxGskX8YzHGz0MINwATYozDgQHALSGESFIO9qvyy3sCD4cQyoA0kp5AX2zyIlK5V6e/ytA3hnJyz5N55LhHaFav2SbnhBA4r/d5m148axYceyx8/jkcfzzccgv06lX5k5YkVajUC4FcCSRJknYgMcZRwKhvHLtug5+fB57fzHXvA3tW+gSVEmYsncGZL5zJXrvsxbDBw8jMyNz6i8eNgxNOgKIieOUVOOqoypuoJKlSpV4IlJaW3LsSSJIkSTupkrIS3p3zLkUlRUQiQ98YSlpI46XTX9q6AGjFCvjww2S3rzvuSPr+vP029OhR+ZOXJFWa1AuBQkhKwgyBJEmSlOLy1+QzYf4EDulwCGkh+TI0xsi5L5/L058+ve68tJDGK2e9QqemnTYdZO5ceP99+Phj+OKL5Pb11xBj8tn6iCPgqaegRYuqeluSpEqSeiEQJCVhloNJkiQpRc3Lm8d9/7uPhyc+zLLVyzil1ykMO3EY9TLqccPbN/D0p09z9cFXc1y34wBo3bA1HZt03HiQRx+FP/4R5pVvSJeRAd27w777Jrt9HXAA7L9/stW7JCklpGYI5EogSZIkpahR00Yx+J+DKS4tZnDPwfRo3oNb3r2FOSvmcNaeZ/HHt//IuXufy02H3bTp9u5r3XYbXHUVHHwwXHllEvjsvXcSBEmSUlZqhkC1ahkCSZIkKeVMWjiJ058/nd2zdudfp/6Lzs06A7Bf2/0468WzuOTVSzi0w6E8ctwjmw+AYoRrrkl29zrjDBg2zOBHknYiqRsCWQ4mSZKkFLJg5QKOfeZYGtdpzIgzR9C2Udt1z53Y40Te+dk7PPrRo9z4wxupnV57/YUxJk2ehw+Hf/876flzwQXw4IPJCnpJ0k4jNUMgy8EkSZKUQuavnM/xzxzPssJlvHveuxsFQGvt23pfHjjmgY0PfvYZXHRRsstXejoceihcein8/OdJ02dJ0k4lNUMgy8EkSZKUAgqKC7jj/Tu47b3bKCkr4YXTXmCfVvts+cJVq5Kmz3ffDU2awAMPJOVfTZtW+pwlSTVX6oZAloNJkiRpBxNjZFz2ON6f+z4TFkxgzKwxLFy1kJN7nsztR9zObk132/IgY8bAeefBzJlJ2dctt0Dz5pU+d0lSzZeaIZDlYJIkSdrBfJn7JZe+eimvzXgNgPaN23PQrgfxm36/oX+H/pu/6MMP4a9/TVb7dOgAc+fCww9D584wdiwcckgVvgNJUk2XmiGQK4EkSZK0g8gryuPGt2/k7g/vJjMjkzuPvJOz9zqbrPpZ335RjEmp19Ch0LgxpKVBTk7S5+eSS+DmmyEzs+rehCRph5C6IZArgSRJklSDlcUynpz0JFe+eSWL8xdzXu/zuPnwm2lZv+W3XxQjjB8Pf/4zjBgBgwfDY48lK4EKCqCw0NIvSdK3Ss0QyHIwSZIk1WCzl8/mrBfP4r2579GvbT9GnDmC/dru9+0XrFqVBD/PPguzZ0OdOslKoN/8Zv0uX5mZrv6RJH2n1AyBLAeTJElSDbC6ZDVHPHkETes25ZpDrqFfu36MmjaKs188m9JYymPHP8a5+5xLWkj79kEWLYJjjoGPP4ZBg+BPf4ITTkhW/0iStA1SMwRyJZAkSZJqgDs/uJN357xL4zqNGTF1BH3b9GXC/AnsvcvePH/a83Rp1uW7B5g6FY46KgmChg9PwiBJkr6n7/jKYQdmTyBJkiRVs+y8bG565yYG9xjM3MvmcvuPbmfBygWc3/t8Pjj/g+8OgGKE556DAw+ElSvhv/81AJIkbbfUXAlkOZgkSZKq2RVvXEFZLOPOgXfSsE5DrjjoCq446IotX5idDRddlDR+3nffpA9Q166VP2FJUspLzRDIcjBJkiRVsUWrFjFr+Sw6NOnAV7lf8exnz3L9odfTsUnHrbh4EYwcmQQ/r7+eHLvjjmS791qp+ZFdklT1UvNvFMvBJEmSVIVmL5/NPg/vw/LVy9cda9+4PUMPGvrtF8UIo0fD/fcn/X5KS6F9ezj/fLjsMthttyqYuSRpZ5K6IdDq1dU9C0mSJO0ESspK+PGLP6a0rJSnT3qaJYVLmLtiLif2OJHMjG/Zsn3yZDj7bPj0U2jeHH77WzjrLNhrr/VbvkuSVMFSMwSyHEySJElV5Ia3b+D9ue/z9ElPc+aeZ275gsceg1/9Cpo2hb//HU4/HerWrfR5SpKUmiGQjaElSZJUCeaumMs7c95hxeoVZNXPYmXRSv489s/8dJ+fbjkAWr06afj8+ONw+OHw1FOwyy5VM3FJkkjlEMiVQJIkSaoApWWl3PzOzTz+yePMXD5zk+e7NuvKvYPu/e5BFi6EwYNh3Di49lq4/vpk9bokSVUoNUMgy8EkSZJUAVasXsFZL57Ff6b9h4GdB3JJv0vo36E/rRq0Ircgl9yCXPZtvS8Najf49kE+/hhOOAGWLIHnn4eTT666NyBJ0gZSMwSyHEySJEnbYU3pGsZlj2PIiCHMWDaDB45+gF/2/SVhg6bNrRu23vJAM2fCD38IjRrBu+9C796VOGtJkr5baoZArgSSJEnS9/Dq9Fe54/07+CD7AwqKC8jKzOKtn7xF/w79t32w4mI4s7xP0NtvQ6dOFTtZSZK2UWqGQPYEkiRJ0jb6YO4HnPjsibRp2Iaf9/45/Tv057BOh9G0XtPvN+C118KHH8JzzxkASZJqhNQNgSwHkyRJ0laauWwmJzx7Au0atWPcz8fRIrPF9g34+utw220wZAicemrFTFKSpO2UVt0TqBSWg0mSJGkrrVi9gmOfOZbismL+8+P/bF8AVFwMd9yRNH/efXe4666Km6gkSdspNUMgVwJJkiRpCwqLC7n3w3vZ48E9mLpkKi+e9iLdW3T//gOOGQN77w1XXAEDBsCoUZCZWVHTlSRpu6VuOZgrgSRJklQuxsiNY2/k/vH307hOY7LqZzFj6QwW5S/ikPaH8NRJT32/5s8AK1fC0KHw0EOw224wYgQce2zFvgFJkipAaoZAloNJkiSpXIyRa0Zfwy3v3sKRnY+kad2m5BTk8IN2P+C3B/z2+4U/McLcucm277//PcyZA5dfDjfeCPXqVfybkCSpAqRmCGQ5mCRJkkgCoKvfuprb3ruNX/T5BQ8c8wBpYTs6IpSUwO9+B08/DTk5ybFu3ZIw6MADK2bSkiRVktQMgVwJJEmStNOLMXLlm1fyl/f/woV9L+S+o+/bvgCooADOOCMp9zrtNDj0UOjbF3r3hoyMipu4JEmVJDVDIHsCSZIk7dRijFzxxhX89YO/8qv9fsW9g+4lhPD9B1y2DI47Dt5/H+6/Hy66qOImK0lSFUndEKisLKnV3p6/7CVJkrTDKS0r5Yo3ruCucXfx6/1/zT1H3bN9AdC4cXDOOUnfn3/+E049teImK0lSFUrNECg9PbkvLU0CIUmSJKW0ifMnctVbVzF96XSy87IpKSvhkn6XcNfAu75/AFRcDH/+M9x0E7RtC2+9BQcfXLETlySpCqVmQrI2+CkpMQSSJElKcV/mfsnAfwykdnptBnQcQIfGHdin1T6ctvtp3z8AGjsWfvMbmDQpWQV0773QuHHFTlySpCq2VQlJCOEo4B4gHXg0xnjrN55vDzwBNCk/56oY46gKnuvWWxv8uEOYJElSSsvOy+bIJ4+kVlot3vnZO3Ru1nn7Bpw/P9n965lnYNdd4YUX4KSTKmaykiRVsy2GQCGEdOB+4AggGxgfQhgeY/xig9P+ADwXY3wwhNALGAV0rIT5bp215WA2h5YkSUopJWUlvPzlyyzOX0z+mnwe/+Rxlq9ezts/fXv7A6AxY5Jdv/Ly4Npr4aqrIDOzQuYtSVJNsDUrgfYHpscYvwYIITwLnABsGAJFoFH5z42B+RU5yW3mSiBJkqSUdMPbN3Dj2BvXPW5cpzHDzxxO79a9v/+gMcJdd8HQodC1K7z9NvTsWQGzlSSpZtmaEKgtMHeDx9lAv2+c80fg9RDCr4H6wI82N1AIYQgwBKB9+/bbOtett2FPIEmSJKWESQsnccu7t3DWnmdx58A7yczIJDMjk7SQ9v0HLSmBIUPg8cdh8GD4+9+hUaMtXiZJ0o5oO/7G3MiZwN9jjO2Ao4EnQ9j0b+MY4yMxxr4xxr5ZWVkV9NKbYTmYJElSSikpK+H84efTrF4z7jnqHlrWb0mD2g22LwAqKoIzzkgCoOuuS/r/GABJklLY1qwEmgfsusHjduXHNnQ+cBRAjPGDEEJdoAWwuCImuc0sB5MkSUopd31wFxMXTOS5U56jeWbz7R8wPz9p+Pz663D33XDJJds/piRJNdzWfHUyHugaQugUQqgNnAEM/8Y5c4DDAUIIPYG6QE5FTnSbuBJIkiQpZcxYOoPrxlzHiT1O5JRep2z/gDk58KMfwZtvwv/7fwZAkqSdxhZXAsUYS0IIFwOvkWz//liM8fMQwg3AhBjjcOBy4G8hhMtImkT/NMYYK3Pi38meQJIkSSnj0tcupVZaLe4/+n5CCNs32PTpMGgQZGfD888nfYAkSdpJbE05GDHGUSTbvm947LoNfv4COKhip7YdLAeTJElKCaOmjWLk1JHc/qPbadOwzfcfqKQEXnoJLroo2Q1s9Gg44ICKm6gkSTuAimoMXbNYDiZJkrTDKyop4tJXL6V78+5c8oPvWbK1YgXcfDN06gSnnQYtWsD77xsASZJ2Slu1EmiHYzmYJEnSDu+eD+9h2tJpvHLWK9ROr73tA7z9NvzkJzBnTtID6P774Zhj1n9hKEnSTia1QyDLwSRJknZIkxZO4saxN3J89+M5qstR23bxmjXwhz/AHXdA587wwQfwgx9UzkQlSdqBWA4mSZKkGmXk1JEc9NhBNKnbhHuOumfbLs7LSxo//+UvMGQIfPKJAZAkSeVcCSRJkqRqV1hcyOwVs/n3l//m96N/T+9WvRlx5ghaN2y99YMsXpwEQJMnw7BhcM45lTdhSZJ2QKkdArkSSJIkqUZbUrCEw4YdxuRFk9cdG9xjME8OfpL6tetv/UBTpyb9fubNg+HDkzBIkiRtJDVDIMvBJEmSdggPTXiIyYsmc23/a+nWvBudm3amX7t+pIWt7FoQIzzxBFx8MdStC2+95c5fkiR9i9QMgSwHkyRJqvHWlK7h/vH3c8RuR3DDD2/Y9gHy85O+P08/DQMGwD/+AW3bVvg8JUlKFTaGliRJUrV47vPnWLBqAZf94LJtvzhG+PnP4dln4cYb4c03DYAkSdqC1F4JZAgkSZJUI8UYuWvcXfRo0YOBXQZu+wAPPpgEQDfdBL//fcVPUJKkFJSaK4EsB5MkSarR3p3zLh8t+IhL+1269f1/1ho/Hi67DI4+Gq66qnImKElSCkrNEMhyMEmSpBrtrnF30axeM87Zexu3cV+yBE49FVq3hiefhLTU/DgrSVJlSO1yMFcCSZIk1Thvff0WL3/5MlcffDWZGZlbf2FBARx3HCxcCGPHQrNmlTdJSZJSUGqHQK4EkiRJqlFmLZ/F6c+fTq+sXlx9yNVbf2FJCZxxBowbB88/D/vvX3mTlCQpRaVmCGQ5mCRJUo1TUFzA4H8OpjSW8vIZL9OgdoOtuzBGuPBCGDECHngATjqpcicqSVKKSs0QyHIwSZKkGucXI3/BpIWTGPnjkXRp1mXrLpoxAy64AP77X7jmmiQMkiRJ30tqdtJzJZAkSdpBhBCOCiF8FUKYHkLYZKurEEKHEMJbIYTJIYQxIYR2Gzx3bghhWvnt3Kqd+bZ5dfqr/GPyP7j+0Os5uuvRW76grAzuvBP23BMmToSHH4Ybb6z8iUqSlMJSMwSyJ5AkSdoBhBDSgfuBQUAv4MwQQq9vnHYHMCzGuBdwA3BL+bXNgOuBfsD+wPUhhKZVNfdtUVJWwu9e/x2dm3beuj5AJSXws5/B5ZfDj34EX3wBQ4ZACJU/WUmSUlhqh0CWg0mSpJptf2B6jPHrGOMa4FnghG+c0wsYXf7zfzd4fiDwRoxxaYxxGfAGcFQVzHmbPfbxY3ye8zm3H3E7tdNrf/fJq1fDySfDsGHJyp9//xvatq2aiUqSlOJSMwSyHEySJO0Y2gJzN3icXX5sQ5OAtZ2QBwMNQwjNt/JaAEIIQ0IIE0IIE3Jycipk4lsrryiPa/97LYe0P4TBPQZ/98lr1sAxx8Dw4XDvvfCHP7j6R5KkCpSaIZDlYJIkKXX8Djg0hPAxcCgwD9im5c4xxkdijH1jjH2zsrIqY47f6tZ3b2Vx/mL+euRfCVsKdP75Txg9Gv72N7j44qqZoCRJOxF3B5MkSao+84BdN3jcrvzYOjHG+ZSvBAohNABOjjEuDyHMAwZ849oxlTnZbZW/Jp+7x93NmXucyX5t9/vuk2OEe+6Bnj3h/POrZoKSJO1kUnMlkOVgkiRpxzAe6BpC6BRCqA2cAQzf8IQQQosQwtrPbFcDj5X//BpwZAihaXlD6CPLj9UYb818i8KSQs7vvRWhzgcfJLuA/eY3loBJklRJUjsEciWQJEmqwWKMJcDFJOHNFOC5GOPnIYQbQgjHl582APgqhDAV2AW4qfzapcCNJEHSeOCG8mM1xsipI2lUpxGHdDhkyyffcw80aQLnnFP5E5MkaSeVmuVgaWnJzZVAkiSphosxjgJGfePYdRv8/Dzw/Ldc+xjrVwbVKDFGRk4dycDOA7e8I1h2NrzwAlx2GdSvXzUTlCRpJ5SaK4EgWQ1kCCRJklQtPlrwEQtWLeDYbsdu+eQHH0x6Av3qV5U/MUmSdmKpGwLVqmU5mCRJUjUZOXUkgcCgLoO++8Tly+Hhh+GEE6BjxyqZmyRJO6vUDYFcCSRJklRtRk4byQ/a/YCs+t+xJX1JCZx+OuTlwdVXV93kJEnaSaVuCFSrliGQJElSNViwcgET5k/YcinY734Hr7+elIPtt4Ut5CVJ0nZL7RDIcjBJkqQqN2pa0uf6uG7HfftJf/tbsiPYZZfB+VuxhbwkSdpuqRsCWQ4mSZJULUZMHUH7xu3Zo+Uemz9h/vykCfRRR8Htt1ft5CRJ2omlbghkOZgkSVK1GDNrDAM7DySEsPkThg2D4mK4997kM5skSaoSqR0CWQ4mSZJUpfKK8lhRtIKuzbpu/oQY4bHHoH9/6NKlaicnSdJOLnVDIMvBJEmSqty8vHkAtG3UdvMnvP8+TJsG551XhbOSJEmQyiGQK4EkSZKq3LyVSQjUrlG7zZ/w2GPQoAGcckoVzkqSJEGqh0CuBJIkSapS2XnZALRtuJmVQKtWwT//CaefDvXrV/HMJElS6oZAloNJkiRVubXlYG0attn0yeefh/x8S8EkSaomqRsCWQ4mSZJU5bLzsmlerzn1Mupt+uRjj0H37nDAAVU/MUmSlMIhkCuBJEmSqty8lfM23xR61ix45x0491z4tq3jJUlSpUrdEMieQJIkSVVu3sp5m+8H9Pzzyf0ZZ1TthCRJ0jqpHQJZDiZJklSlsvOyN78z2HPPQd++0KlT1U9KkiQBqRwCWQ4mSZJUpdaUrmFx/uJNVwLNnAnjx8Npp1XPxCRJEpDKIZDlYJIkSVVqwcoFAJv2BFpbCnbqqVU8I0mStKHUDoEsB5MkSaoy2XnZAJuWgz33HOy3H3TsWPWTkiRJ66RuCGQ5mCRJUpWat3IewMblYF9/DRMmWAomSVINkLohkCuBJEmSqtS8vPIQaMNyMEvBJEmqMVI3BHIlkCRJUpXKzsumXq16NK3bdP3B556D/feHDh2qb2KSJAlI5RDIxtCSJElVat7KebRt1JYQQnIgPx8mToRjjqneiUmSJCDVQyDLwSRJkqrMvJXzNm4KPW1act+rV/VMSJIkbSR1QyDLwSRJkqpUdl72xk2hp05N7rt1q54JSZKkjaRuCGQ5mCRJUpUpi2XMXzl/8yFQly7VMylJkrSR1A6BLAeTJEmqErkFuawpXbNxOdhXX8Guu0JmZvVNTJIkrZO6IZDlYJIkSVVms9vDT51qKZgkSTVI6oZArgSSJEmqMvNWlodAa8vBYkxCoO7dq3FWkiRpQ6kdArkSSJIkqUpk52UDrC8Hy82F5ctdCSRJUg2SuiGQ5WCSJElVZl7ePNJCGrs02CU54M5gkiTVOKkbAlkOJkmSVGXmrZxHqwatqJVWKznw1VfJvSGQJEk1RuqGQK4EkiRJqjLZedkb7ww2dSpkZECHDtU3KUmStJHUDYHsCSRJklRl5q2ct74pNCQhUOfOyWcySZJUI6R2CARQVla985AkSdoJNKvXjB4teqw/4M5gkiTVOKn71Ux6enJfUgK1a1fvXCRJklLcOz97Z/2D0lKYPh2OPrr6JiRJkjaR+iuBLAmTJEmqWnPmQFGRTaElSaphUj8EcocwSZKkquX28JIk1UipGwJtWA4mSZKkqmMIJElSjbRVIVAI4agQwlchhOkhhKu+5ZzTQghfhBA+DyE8XbHT/B5cCSRJklQ9pk6Fhg1hl12qeyaSJGkDW2wMHUJIB+4HjgCygfEhhOExxi82OKcrcDVwUIxxWQihZWVNeKvZE0iSJKl6rN0ZLITqnokkSdrA1qwE2h+YHmP8Osa4BngWOOEb51wA3B9jXAYQY1xcsdP8HiwHkyRJqh5Tp1oKJklSDbQ1IVBbYO4Gj7PLj22oG9AthPBeCGFcCOGozQ0UQhgSQpgQQpiQk5Pz/Wa8tSwHkyRJqh5LlkBWVnXPQpIkfUNFNYauBXQFBgBnAn8LITT55kkxxkdijH1jjH2zKvuDgSuBJEmSqkdJCWRkVPcsJEnSN2xNCDQP2HWDx+3Kj20oGxgeYyyOMc4EppKEQtXHnkCSJEnVo6Rk/WcxSZJUY2xNCDQe6BpC6BTC/2fvvsOrrO8+jr9/CRkkJKxAQMLeOBBEBVGcqLioFhWsj6utbZ+6ta1V665tlbZ02mJbbdUKKtWHKmrVihsFZSgiCsgII0DYkJ37+eOOGBQUFJLDyft1XedKzr3O95dwcd98+I2QDowEJn7qmMeJewERQsgjHh62YDfWuescDiZJklQ/DIEkSUpIXxgCRVFUCVwCPAPMAR6Oomh2COHWEMJpNYc9AxSHEN4DXgB+EEVR8Z4qeqc4HEySJKnuVVdDFBkCSZKUgHbq7hxF0SRg0qe23Vjr+wi4quaVGBwOJkmSVPc+fvYyBJIkKeHsromhE4/DwSRJkuqeIZAkSQkreUMgh4NJkiTVPUMgSZISVvKGQPYEkiRJqnuGQJIkJazkDYHsCSRJklT3DIEkSUpYyRsCOTG0JElS3fv42SstrX7rkCRJn5H8IZDDwSRJkuqOPYEkSUpYyRsCORxMkiSp7hkCSZKUsJI3BHI4mCRJUt0zBJIkKWElfwjkcDBJkqS6YwgkSVLCSt4QyOFgkiRJdc8QSJKkhJW8IZDDwSRJkuqeIZAkSQkr+UMgh4NJkiTVHUMgSZISVvKGQA4HkyRJqnuGQJIkJazkDYHsCSRJklT3DIEkSUpYyRsC2RNIkiSp7hkCSZKUsJI3BHJiaEmStBcIIZwYQpgbQpgXQrh2O/s7hBBeCCFMDyHMCiGcVLO9UwihJIQwo+b1p7qvfjsMgSRJSljJe3d2OJgkSUpwIYRU4A/AUKAQmBpCmBhF0Xu1DrsBeDiKortDCH2ASUCnmn3zoyg6sC5r/kKGQJIkJazk7QnkcDBJkpT4DgHmRVG0IIqicmAcMPxTx0RAbs33TYFldVjfrjMEkiQpYSVvCORwMEmSlPjaAUtqvS+s2VbbzcC5IYRC4l5Al9ba17lmmNiLIYQjdvQhIYSLQwjTQgjTVq1atZtK3wFDIEmSElbyh0AOB5MkSXu3UcB9URQVACcB94cQUoDlQIcoivoBVwH/DCHkbu8CURSNjaJoQBRFA1q1arVnqzUEkiQpYSVvCORwMEmSlPiWAu1rvS+o2VbbN4GHAaIoeh3IBPKiKCqLoqi4ZvtbwHygxx6v+IsYAkmSlLCSNwRKqWmaPYEkSVLimgp0DyF0DiGkAyOBiZ86ZjFwLEAIoTdxCLQqhNCqZmJpQghdgO7AgjqrfEcMgSRJSljJe3cOIX74sCeQJElKUFEUVYYQLgGeAVKBv0VRNDuEcCswLYqiicDVwD0hhCuJJ4m+IIqiKIQwBLg1hFABVAPfjaJoTT015ROGQJIkJazkvjunphoCSZKkhBZF0STiCZ9rb7ux1vfvAYO3c94EYMIeL3BXGQJJkpSwknc4GMQPHw4HkyRJqjuGQJIkJazkDoHsCSRJklS3DIEkSUpYyR0COSeQJElS3TIEkiQpYSV/CORwMEmSpLpjCCRJUsJK9uOjZQAAIABJREFU7hDI4WCSJEl1yxBIkqSEldwhkMPBJEmS6pYhkCRJCSv5QyCHg0mSJNWdykoIAVKS+zFTkqS9UXLfnR0OJkmSVLcqK+0FJElSgkruEMieQJIkSXXLEEiSpISV3CGQPYEkSZLqliGQJEkJK7lDICeGliRJqluGQJIkJazkD4EcDiZJklR3DIEkSUpYSRcCvVP0Ds/OfzZ+43AwSZKkumUIJElSwkq6EOjXU37Nhf93YfzG4WCSJEl1yxBIkqSElXQhUH52Pis3rySKIoeDSZIk1TVDIEmSElbyhUBN8qmormBt6VqHg0mSJNU1QyBJkhJW8oVA2fkAFG0qcjiYJElSXTMEkiQpYSVdCNQ6uzUAKzevdDiYJElSXTMEkiQpYSVdCJTfpKYn0OYih4NJkiTVNUMgSZISVvKFQJ8eDmZPIEmSpLpjCCRJUsJKuhCoZVZLUkPqJz2BKirquyRJkqSGwxBIkqSElXQhUEpIoVV2q7gnUF4erFgBUVTfZUmSJDUMhkCSJCWspAuBIB4SVrS5CHr1grVrYeXK+i5JkiSpYTAEkiQpYSVnCNSkJgTq3Tve8P779VuQJElSQ2EIJElSwkrOECg7Px4O9nEINGdO/RYkSZLUUBgCSZKUsJI3BNpcRFRQANnZhkCSJEl1xRBIkqSElZwhUJN8SitL2VixKZ4XyBBIkiSpblRUGAJJkpSgkjMEys4H+GRImCGQJElS3bAnkCRJCSs5Q6AmNSHQx5NDFxbCxo31XJUkSVIDYAgkSVLCSs4Q6NM9gcAVwiRJkuqCIZAkSQkrOUOgT/cEAoeESZIk1QVDIEmSElZShkB5WXkEQtwTqGvX+EHEnkCSJEl7niGQJEkJKylDoEYpjcjLyot7AqWlQffu9gSSJEmqC4ZAkiQlrKQMgSAeEla0uSh+4wphkiRJdcMQSJKkhJW8IVB2Pis3r4zf9OoF8+ZBeXn9FiVJkpTsDIEkSUpYSRsCtc5uHc8JBHFPoKqqOAiSJEnSnmMIJElSwkraECg/+1PDwcAhYZIkSXuaIZAkSQkreUOgJvlsKt/Eloot8XAwMASSJEnak6LIEEiSpASWvCFQdj5APCQsOxs6dHCZeEmSpD2pujr+aggkSVJCSt4QqElNCPTxkLD99oOpU+P/oZIkSdLuV1kZfzUEkiQpIe1UCBRCODGEMDeEMC+EcO3nHPf1EEIUQhiw+0r8crbpCQQwfDh88AHMmFGPVUmSJCUxQyBJkhLaF4ZAIYRU4A/AMKAPMCqE0Gc7x+UAlwNv7O4iv4zP9AQaMQLS0uCf/6zHqiRJkpLYxyFQWlr91iFJkrZrZ3oCHQLMi6JoQRRF5cA4YPh2jrsN+AVQuhvr+9JaZ7cGavUEatEChg2Dhx6Kl4uXJEnS7mVPIEmSEtrOhEDtgCW13hfWbNsqhNAfaB9F0ZOfd6EQwsUhhGkhhGmrVq3a5WJ3RXpqOs0zm3/SEwjgnHNg6VJ4+eU9+tmSJEkNkiGQJEkJ7StPDB1CSAF+BVz9RcdGUTQ2iqIBURQNaNWq1Vf96C+U3yR/2xDo1FOhSRN48ME9/tmSJEkNjiGQJEkJbWdCoKVA+1rvC2q2fSwH2A+YHEJYCAwEJibK5NBbh4MBZGXB6afDo49CWVn9FSZJkpSMDIEkSUpoOxMCTQW6hxA6hxDSgZHAxI93RlG0PoqivCiKOkVR1AmYApwWRdG0PVLxLijILeDDNR9SHVV/svEb34B16+Cpp+qvMEmSpGRkCCRJUkL7whAoiqJK4BLgGWAO8HAURbNDCLeGEE7b0wV+FSd2O5EVm1bw5tI3P9l47LHQujXcd1+91SVJkpSUDIEkSUpoOzUnUBRFk6Io6hFFUdcoin5as+3GKIombufYoxKhFxDAKT1OIS0ljQnvTfhkY6NG8N3vwv/9H0ydWn/FSZIkJRtDIEmSEtpXnhg6kTXLbMaxXY5lwpwJRFH0yY5rroFWreCHP4Ta2yVJkvTlGQJJkpTQkjoEAvh676/z0bqPmFk085ONOTlw440webJzA0mSJO0uhkCSJCW0pA+BhvccTkpI2XZIGMDFF0PXrvCjH0FVVf0UJ0mSlEwMgSRJSmhJHwK1ym7FkR2PZMKcT4VA6elwxx3w7rtw//31U5wkSVIyMQSSJCmhJX0IBHBG7zOYs3oOc1bN2XbHmWfCoYfGcwOtWlU/xUmSJCULQyBJkhJagwiBTu91OsBnewOFAH/5C6xfD9//fj1UJkmSlEQMgSRJSmgNIgRql9uOQQWD+Oc7/6Q6qt525377wc03wyOPwMMP10t9kiRJScEQSJKkhNYgQiCA7w34HnNWz2HSh5M+u/MHP4CDD4b//V8oKqr74iRJkpKBIZAkSQmtwYRAI/cbSYemHfjFq7/47M5GjeC++2DTJvjWtyCK6rw+SZKkvZ4hkCRJCa3BhEBpqWlcNfAqXln8Cq8tee2zB/TpA3fdBU88Ab/6Vd0XKEmStLczBJIkKaE1mBAI4Fv9v0WLxi223xsI4JJL4Iwz4Npr4fXX67Y4SZKkvZ0hkCRJCa1BhUDZ6dlccvAlTJw78bPLxUO8Wthf/wrt28PZZ0Nxcd0XKUmStLcyBJIkKaE1qBAI4NJDL6Vxo8bcNPkmou3N/dOsWbxSWFERnHwyrFxZ90VKkiTtjQyBJElKaA0uBMrLyuPHh/+YR957hJ+98rPtH3TQQTB+PMycCYMGwdy5dVukJElqMEIIJ4YQ5oYQ5oUQrt3O/g4hhBdCCNNDCLNCCCfV2vfjmvPmhhBOqNvKt8MQSJKkhNbgQiCAG4bcwDf2/wbX//d6Hpz14PYP+trXYPJk2LgxDoJeeaVOa5QkSckvhJAK/AEYBvQBRoUQ+nzqsBuAh6Mo6geMBP5Yc26fmvf7AicCf6y5Xv0xBJIkKaE1yBAohMBfT/srR3U6igv/70ImL5y8/QMPPRSmTIFWreCEE+CFF+q0TkmSlPQOAeZFUbQgiqJyYBww/FPHREBuzfdNgWU13w8HxkVRVBZF0UfAvJrr1R9DIEmSElqDDIEAMhpl8NjZj9GtRTfOeuQsVmxasf0Du3SBl16CTp3gpJPg2WfrtE5JkpTU2gFLar0vrNlW283AuSGEQmAScOkunFu3DIEkSUpoDTYEAmiW2YxHz3qUTeWbOO+x86iOqrd/YH5+PDSse3c49VSYOLFO65QkSQ3aKOC+KIoKgJOA+0MIu/QMF0K4OIQwLYQwbdWqVXukSMAQSJKkBNegQyCAPq368JsTf8OzC57ll6/9cscHtmoVDwfbb794vqDRo2F7q4tJkiTtvKVA+1rvC2q21fZN4GGAKIpeBzKBvJ08l5rzxkZRNCCKogGtWrXaTaVvhyGQJEkJrcGHQADf6v8tRvQZwXX/vY7Xl7y+4wNbtoQXX4Svfx1+8AO46CIoK6u7QiVJUrKZCnQPIXQOIaQTT/T86S7Hi4FjAUIIvYlDoFU1x40MIWSEEDoD3YE366zy7TEEkiQpoRkCEU8UPfaUsbTLaceQ+4Zw9TNXs6503fYPzs6Ol4+/8Ua47z44/HCYP79O65UkSckhiqJK4BLgGWAO8Spgs0MIt4YQTqs57Grg2yGEmcBDwAVRbDZxD6H3gKeB70dRVFX3rajl4xAotX4XKZMkSdtnCFSjeePmvPntN7nwwAv59ZRf0/133Xl49sPbPzglBW65Bf71L5g3D/r3h4d3cKwkSdLniKJoUhRFPaIo6hpF0U9rtt0YRdHEmu/fi6JocBRFfaMoOjCKov/UOvenNef1jKLoqfpqw1aVlfFzUoqPmJIkJSLv0LW0zm7N2FPH8tbFb9GtRTfOfvRs7nj5DqIdzf1z+ukwfTr06QNnnw3nnAPLl9dt0ZIkSYmistKhYJIkJTBDoO3o17Yfk8+fzDf2/wbX//d6Lv73xVRUVWz/4E6d4iXkb7oJJkyAnj3h17/+pDu0JElSQ2EIJElSQjME2oGMRhncf/r93HDEDfxl+l84ffzplFSUbP/gtDS4+WaYPRsGD4arroJjj4Vly+q0ZkmSpHplCCRJUkIzBPocIQRuO+Y2/nzKn5n04SRO/ufJbCzbuOMTunWDSZPg73+HadOgXz/473/rrmBJkqT6ZAgkSVJCMwTaCRcfdDEPnPEALy16iaH3D2X1ltU7PjgEOO88ePPNeEn5oUPhhz+Ekh30IpIkSUoWhkCSJCU0Q6CddM7+5zDhrAlMXzGd7r/rzi9e+QVbKrbs+IR9942DoG9+E+66Cw44AF58se4KliRJqmuGQJIkJTRDoF0wvNdwpn17God3OJxrn7+W7r/rzgOzHtjx6mFNmsDYsfD881BdDUcdBccdB488AuXldVq7JEnSHmcIJElSQjME2kX75+/Pv0f9m5cueImC3AL+57H/YdiDw/ho7Uc7PumYY+Cdd+COO2DePDjrLOjYEcaMgdLSuitekiRpTzIEkiQpoRkCfUlHdDyC1y56jd8N+x2vLnmV/e7ej1+9/isqq3ewNHxWFvz4xzB/Pjz5ZDxc7MoroUcPuPde2FFvIkmSpL2FIZAkSQnNEOgrSE1J5ZJDLuG9/32PYzofw9X/uZpBfx3EzBUzP+ekVDjpJHjuufjVti1cdBF85ztQVVV3xUuSJO1uhkCSJCU0Q6DdoH3T9kwcOZFxXx/H4vWLOWjsQZw+/nTGvzuezeWbd3ziscfClClw3XVwzz1w/vnxw5MkSdLeyBBIkqSEZgi0m4QQOHu/s5nz/TlcMfAK3ih8g5ETRpI/Op+bXriJkoodLBEfAvz0p/HrwQfhzDPjeYMkSZL2NoZAkiQlNEOg3axF4xaMPn40S65cwuTzJ3Nyj5O59aVb2e/u/Xjygyd3fOJ118Gvfw0TJ0L37nDwwfDb30JFRd0VL0mS9FUYAkmSlNAMgfaQ1JRUjux0JONHjOf5854nPTWdUx46hePvP563lr21/ZOuuAIWLoTRo+P3l18eLylfVFRndUuSJH1phkCSJCU0Q6A6cEznY5j53Zn86vhf8fbytxlwzwDOfORM3ih8g+jTq4K1bw9XXw1Tp8L998df+/eP5w6SJElKZIZAkiQlNEOgOpKems6Vg65kweULuHHIjTw972kG/nUg/f7cjz9N+9P25ww691x47TXIyIAjjoBLLoGVK+u+eEmSpJ1hCCRJUkIzBKpjuRm53HL0LSy7ahl/OvlPAHzvye/R+TeduevVu9hYtnHbEw48EKZNg29/G/70J+jWDe64A0pL66F6SZKkz2EIJElSQjMEqic5GTl8Z8B3mP6d6bx4wYv0bdOXHz73Qzr9phO3vXgb60rXfXJwixbwxz/C7NnxsvLXXw8HHADPPlt/DZAkSfo0QyBJkhKaIVA9CyEwpOMQnjn3Gd741hsMbj+YGyffSIdfd+AH//kB/5n/n08CoZ494bHH4JlnIIrg+ONh5EhYtqx+GyFJkgSGQJIkJThDoARySLtDmDhqIjO+M4Nh3Yfxy9d/yQkPnEDzXzRnwNgBfFj8YXzg8cfDO+/ALbfA449Dr17wm9/ED16SJEn1xRBIkqSEZgiUgPq26cv4EeNZ+6O1PPs/z3L70bezeP1iBv9tMNOXT48PysyEG2+Ed9+Fww6Ll5c/4AD45S9h+fL6bYAkSWqYKioMgSRJSmCGQAmsaWZTjutyHNcPuZ5XLnqFxmmNOfK+I5m8cPInB3XrBk89BY8+Cjk5cM01UFAAZ5wBK1bUW+2SJKkBsieQJEkJzRBoL9GjZQ9evehV2jdtz7H/OJaRj45k2rJp8c4Q4OtfhzfegPffh2uvhaefhr5944BIkiSpLhgCSZKU0AyB9iIFuQW8cuErXDPoGp6a9xQH33MwR9x7BGPfGkvxluL4oJ494ac/jZeVz8+Hk06CK6+EsrL6LV6SJCU/QyBJkhKaIdBepnnj5vxi6C9YcuUSRg8dzcrNK/nOE9+hzS/b8LVxX+Pt5W/HB/bpA2++CZdeCmPGwMCBcS8hSZKkPcUQSJKkhGYItJfKzcjl6sOu5v3vv8/bF7/NlQOv5KVFL3HQ2IMY8fAI3il6J548+re/hX//GwoL4aCD4M47YeHC+i5fkiQlI0MgSZISmiHQXi6EQL+2/bhz6J18dPlH3HTkTfxn/n844E8HcNR9RzHu3XGUnTgUZs6Eww+HH/0IOneOVxIbMwaqquq7CZIkKVkYAkmSlNAMgZJI08ym3HzUzXx0+Uf8/Nifs3j9YkZNGEX333Xn8Q1vEj39NMydC6NHxyuJXXklDBkC8+fXd+mSJCkZGAJJkpTQDIGSUMuslvzo8B8x77J5TDpnEs0ym3H6+NMZPm44H7YMcPXV8MorcP/9MHt2vIrY3XdDdXV9ly5JkvZmhkCSJCU0Q6AklhJSGNZ9GG9d/BZ3Db2L5z96nh6/78F+f9yPHz73I2Yetz+88w4cdhj87//CkUfCnDn1XbYkSdpbGQJJkpTQDIEagLTUNK457Bo+uOQDfnn8L2nTpA1jpoyh/9j+/HjuHyl7ciLce2/cK+jAA+Gb34T77ouHjkVRfZcvSZL2BlEUzzVoCCRJUsIyBGpA2uW246pBV/Hcec9RdE0RFx54IT9/9ef0v+cgpg7dN15CftQo+Ne/4MILoVcvOOIIWLSovkuXJEmJ7uPFJtLS6rcOSZK0Q4ZADVTzxs35y2l/YdI5k1hfup5Bfx3Ede+Moewvf4bi4rhX0JgxMGtW3Dvoscfqu2RJkpTIKivjr/YEkiQpYRkCNXDDug/j3f99l/P6nsfPXvkZB409iOcXvkB1715w+eUwfTp06wZnnAEjR8ahkCRJ0qcZAkmSlPAMgUSzzGb8bfjfePKcJ1lXuo7j7j+Orr/tyo0v3Miilo3g1VfhhhvgySfjlcROPhmeegoqKuq7dEmSlCgMgSRJSniGQNrqpO4n8cGlH/DA6Q/Qo2UPbn/pdrr+tivfeOJCZnz/67B4Mdx2G7z5Jpx0ErRpAxdfbO8gSZJkCCRJ0l7AEEjbyErL4hsHfINnzn2GRVcs4oqBVzBx7kT6/bkfpz59HrMvPh0KC2HiRDjxRPjnP+M5gy68MN4uSZIaJkMgSZISniGQdqh90/aMPn40S65cwu1H385Li17igD8dwLee+T6Lh/SFBx+EJUvg6qvjMKhHDzjvPHj8cdiypb7LlyRJdckQSJKkhGcIpC/ULLMZ1w+5ngWXLeDyQy/nHzP/QZffdOGsR87itU1ziO68E+bOhW98A554Ak4/HfLy4Nvfhjlz6rt8SZJUFwyBJElKeIZA2mkts1ryqxN+xfzL5nP1oKt5dsGzDP7bYAb/bTBPls8mGjsWiorguefiQOiBB6BPHzj1VJg6tb7LlyRJe5IhkCRJCc8QSLusfdP2/GLoLyi8spDfD/s9Szcu5ZSHTqH/2P7c+trPmFiwmcWjfxJPJH3LLTBlChxyCJx1Fnz4YX2XL0mS9gRDIEmSEt5OhUAhhBNDCHNDCPNCCNduZ/9VIYT3QgizQgjPhxA67v5SlWiy07P5/iHfZ96l87h3+L1UR9XcPPlmho8bTscxHTn7xUtY98PLYMECuOkmmDQJeveG4cNhwgQoK6vvJkiSpN3FEEiSpIT3hSFQCCEV+AMwDOgDjAoh9PnUYdOBAVEUHQA8Cty5uwtV4kpLTeOCAy9g5ndnsuHHG3jtote44Ygb+Necf9H3T315Ze1MuPlmmD8/nkR66lQYMQLatoVrroFFi+q7CZIk6asyBJIkKeHtTE+gQ4B5URQtiKKoHBgHDK99QBRFL0RR9PFyUFOAgt1bpvYWTdKbMKj9IG475jZevehV0lLSOPK+IznxgRP5w6JHWXzd9+MVxZ55BoYOhTFjoEsXOPNMeO01iKL6boIkSfoyDIEkSUp4OxMCtQOW1HpfWLNtR74JPLW9HSGEi0MI00II01atWrXzVWqvdEi7Q5j+nen8aPCPWLB2AZc8dQkdx3Tk6xPOYk6/9jB+fDxU7Jpr4smkBw+GQw+Nl5uvqKjv8iVJ0q4wBJIkKeHt1omhQwjnAgOAu7a3P4qisVEUDYiiaECrVq1250crQeVk5HDHsXfwwaUf8P733+cnQ37Cs/OfZb+79+P8x8/n5WgRVT+7AwoL4Q9/gPXr45XFOnWCn/0MiovruwmSJGlnGAJJkpTwdiYEWgq0r/W+oGbbNkIIxwHXA6dFUeSMv/qMnnk9ufXoW1lw+QKuHHglD89+mCH3DWGfX+3Dxf+9kumnD4I5c+DJJ+Ol5a+7Lp43aOBAuOIKePhhsAeZJEmJyRBIkqSEtzMh0FSgewihcwghHRgJTKx9QAihH/Bn4gBo5e4vU8kkLyuP0cePpuiaIsaPGM8xnY/hoXcfov/Y/hz7wFCe6FbNxif+Be+8A1deCenpMHYsnH02tG4N/fvDjTfGvYYkSVJiMASSJCnhfWEIFEVRJXAJ8AwwB3g4iqLZIYRbQwin1Rx2F9AEeCSEMCOEMHEHl5O2ys3I5ax9z+Khrz9E4ZWF3DX0LuaunsupD51K0583pdfkEZw/aAVTH/plHPhMmQK33QY5OXD77fFy848+6mTSkiQlAkMgSZISXojq6R/QAwYMiKZNm1Yvn63EVV5VzvMLnmfasmm8veJtJi+czLrSdQzrNozrj7iew9ofRggBpk2D73wH3n4bhgyBgw+OVxk74AA47DBI2a3TXUmSvoQQwltRFA2o7zq0rT32DPbEE3DqqTB1Kgzw1y5JUn35vGcw/6tGCSU9NZ1h3YcxrPswADaUbeCPU//I6NdGc/i9h7NPzj6c2PVETup+Ese9+B+a/uV+uOeeeFLp0tL4Il27wje/CeedB+0+byE7SZK029gTSJKkhGd3CSW03Ixcrj38WhZesZB7h9/L4R0OZ8KcCYx4ZAR5v27Dkc0e45f3XMTa1YXxCmMPPAAFBfGk0gUF0KNHHAg9+CBs2FDfzZEkKXkZAkmSlPAMgbRXaJLehAsOvIDxI8az+oereemCl/jBYT9gfel6rnn2Gtr/piOXz7qT+cMGwuTJ8P778ItfQK9e8NhjcO658aTSX/taHAi59LwkSbuXIZAkSQnPu7T2Oo1SGnFExyM4ouMR3HHsHcxcMZNfTfkVf5z2R3775m/pndebE7udyMkjTuaoa64mlQBvvAHjx8Mjj8D//V88Z9CgQXDccXDQQfGrbVsIob6bJ0nS3skQSJKkhGdPIO31+rbpy9+/9nc+uvwjfnn8L2nftD1/nPpHjrv/OLr8tgs3vXgLMztnseZnNxItXhwHQjfcACUlcOutcNpp8dxB++8fDyf7+CFWkiTtPEMgSZISniGQkkZBbgFXDbqKZ859hjU/WsP4EePpndeb2166jQP/fCAt72xJ459lM+idy/n3OQOIpk2L5wl65RUYMybuHfQ//xPPI3T77fCf/8CaNfXdLEmS9g6GQJIkJTzv0kpKWWlZnLXvWZy171ksXr+Y15a8xvKNy1m2cRn/ev9fnDbuNAbsM4DLDrmMQ3oeQvfDLiXl0kvj5W1//nP4yU8+udgBB8RzCZ1+OvTt65AxSZK2xxBIkqSE511aSa9D0w50aNph6/s7jr2Df8z8B7e/fDvnPX4eANlp2RzS7hCO73o8x0/4PQdmdiLl7enw5pvw1FNw223x0LF27WDo0Pg1bBg0b15fzZIkKbEYAkmSlPC8S6vBSUtN45v9v8n5B57P7JWzmb5iOm8te4uXF7/Mj5//MT9+/sc0btSYnnk96d2jN0cO/QbntLmPnGdegGeeiSeWvu8+yMiAM86ACy+EI46AzMz6bpokSfXHEEiSpITnXVoNVqOURvRt05e+bfpywYEXALBi0wqeW/Acby9/m/dXv88ri1/hoXcf4uq0bM7Z/xzO/Nm3OfS+P5M7a2681PyDD8JDD8UXbNUKCgqgaVPIyopf/fvHPYYcRiZJSnaGQJIkJTzv0lItbZq04dwDzuXcA84FIIoi3lz6JmPfGsuD7zzIPW/fQyCwb+t9GXT8IAb9z88ZNL+MHvPWkrJ0GRQWxpNNFxXFXx99FK67Dtq0gRNPjF9Dh0KLFvXcUkmSdjNDIEmSEp53aelzhBA4tOBQDi04lDEnjmFK4RReL3yd1wtf55H3HuGet+8BoHlmcwYeMZBBBYPYt/W+dG3elS7Nu5CzZlO8ythTT30yjCwE6N49nnC6b994SFmfPvXbUEmSvipDIEmSEp53aWkn5WTkMLTrUIZ2HQpAdVTN3NVz41BoyetMWTqFpyc/TUS09Zw+rfowtMtQjrv1XI7825/ImfU+PPsszJgRvyZMiFciGzQILrgAunSBnBzIzYV99omHlkmStDf4OARKTa3fOiRJ0g4ZAklfUkpIoXer3vRu1ZuL+l0EwIayDcxbM4/5a+bzQfEHvLT4Jf781p/5zRu/oVFKIwYWDOS4I47joLMvZN9W+9KxvDEpDzwIf/kLfOc7n/2QnBzo1AkOPhgOOwwOPxx69HB+IUlKIiGEE4HfAKnAX6Io+vmn9v8aOLrmbRbQOoqiZjX7qoB3avYtjqLotLqpejsqK+MAyHuUJEkJyxBI2o1yM3Lp37Y//dv2B+B6rqe0spTXlrzGcwue49kFz3LLi7ds7S3UJL0JAwsGMuRPozgi6sAB1a1oURpg3TpYuhSWLIF58+Dxx+Fvf4s/pGNHOOkkOOqoePLplBRo1gwOPdT/fZWkvUwIIRX4AzAUKASmhhAmRlH03sfHRFF0Za3jLwX61bpESRRFB9ZVvZ+rstKhYJIkJTjv1NIeltkok2M6H8MxnY/hjmPvYH3pemavms3slbOZWTSTVxa/wk2Tb94aDOVn59OnVR/69+3PwcMG06/tJXTIbU/mgsUweXI8v9A//gF3373tB+Xnw5lnwimnxMPIGjeOJ6TOz6/7RkuSdtYhwLwoihYAhBDGAcOB93Zw/Cg9SlYKAAAcQ0lEQVTgpjqqbdcYAkmSlPC8U0t1rGlmUw5rfxiHtT9s67Y1JWuYUjiF2StnM2f1HN5d+S6/f/P3lFWVbT2mZeOWtG/angEXDWDgdaMZWJJH78btSSHAokUwfjzccw/8/veffFhKCnz963D11XFPIUlSomkHLKn1vhDY7l/YIYSOQGfgv7U2Z4YQpgGVwM+jKHp8B+deDFwM0KFDh91Q9nYYAkmSlPC8U0sJoEXjFpzU/SRO6n7S1m0VVRXMXjWbGStmULihkKUblrJg3QImzJnAX6b/BYiHnx28z8H0b9ufNlcfRsurjyN/+Qa6hzw6VufQ6M1p8Oc/wyOPQO/e0LkztG0bz9fw4Ycwd248pOyCC+Cii6BdO6iqioeiNWsWT1AtSUoUI4FHoyiqqrWtYxRFS0MIXYD/hhDeiaJo/qdPjKJoLDAWYMCAAdGn9+8WhkCSpM9RUVFBYWEhpaWl9V1K0sjMzKSgoIC0tLSdPsc7tZSg0lLTOLDNgRzYZtupHqqjaj4s/pA3lr7BlMIpTCmcwpgpY6iortj2/JQ0urTvQo/fHUaPpaX0fH81ByyZz37/eYvs0up4gulhw2DxYrjxRrj5ZmjfPg6AKiuhSRO47LK4F1GLFvFFq6ri3kVO+ilJu8tSoH2t9wU127ZnJPD92huiKFpa83VBCGEy8XxBnwmB6oQhkCTpcxQWFpKTk0OnTp0I/nviK4uiiOLiYgoLC+ncufNOn+edWtrLpIQUeub1pGdeT87rex4Q/wWwoWwDq7esZtnGZXy45kM+LP6QD9Z8wAfFH/Bs1TxKO5dCZwhDAh2bdaRzs3Q6NYNeeccz+LaLGfDvaWQsWhqvRtahA7zwAvzsZ/C730HfvnFYtLRm/2WXwYUXxquXSZK+iqlA9xBCZ+LwZyRwzqcPCiH0ApoDr9fa1hzYEkVRWQghDxgM3FknVW+PIZAk6XOUlpYaAO1GIQRatmzJqlWrduk879RSEggh0DSzKU0zm9K1RVeO6HjENvuro2oWrlvIrKJZzCqaxfur32fR+kU8Pe9p7p1xLwAZWRn0HtKbfXLW0bZJEW0v7s4+o66n7ZMvUrBsEx2OOYRWbbsRJr8Il18e9x4aODAOgpo0iSeh7to1fu27L7RuXR8/Cknaq0RRVBlCuAR4hniJ+L9FUTQ7hHArMC2Kook1h44ExkVRVHsoV2/gzyGEaiCFeE6gHU0ovecZAkmSvoAB0O71ZX6e3qmlBiAlpNCleRe6NO/C13p9bZt9Kzev5LUlr/HK4ld4f/X7LN+0nLeXv83KzSupjqrjKUvbAUwns1Em3f6nG33OP5Y+s1fSfukHNF1fQbPFZRRMWkOX1VWkVddcuE2buAdRy5bxPwoaNYrnGcrLi19ZWZCeHr9atYrnKmrbFjIz6/inI0n1K4qiScCkT2278VPvb97Oea8B++/R4naFIZAkSQnPO7XUwLXObs3Xen3tM+FQZXUlqzavYtnGZRRuKGTx+sUsWr+ID4o/4K1V7/FIywVELbedWzQ1pNIlow09KnLpWRzovug90ovLKAmVlEdV7Pd6KYd/WEbjys8pqEMH6NPnk4msO3aMh6D16hUHRpKkxGQIJElKYMXFxRx77LEArFixgtTUVFq1agXAm2++Sfrn/Ftj2rRp/OMf/+C3v/1tndS6J3mnlrRdjVIa0TanLW1z2nLQPgd9Zn9JRQmrtqxiXek61pWuY+G6hXxQHM9BNLd4Lv8NH1LSrGTbkwZBZqNMDm89gHYZrcgMjciK0ugd5XFwSXP2XQlpH8yD996DF1+Eklrnp6XF4VDfvtCtG3TpEk9u3a+f/+iQpERgCCRJSmAtW7ZkxowZANx88800adKEa665Zuv+yspKGu3gPjZgwAAGDBhQJ3Xuad6pJX0pjdMa06FpBzo07QDAkI5DttlfHVWzbOMyqqqraJzWmNSQyptL3+SZ+c8weeFkPlizmNLKUjaVb2JLxRYgXtGsWd9mZB+cTU56Nzo1bkuPlFZ02pxGtHQppcsWE5Y/Tr+XN3DIUsgpJ17G/phjoH//ePLquXNh1ap4bqKePeOeRampcVE5OXDIIfH2lJS6/HFJUvIzBJIk7awrroCaQGa3OfBAGDNml0654IILyMzMZPr06QwePJiRI0dy+eWXU1paSuPGjbn33nvp2bMnkydPZvTo0TzxxBPcfPPNLF68mAULFrB48WKuuOIKLrvsst3blj3IO7WkPSIlpFCQW7DNtmHdhzGs+7BttkVRxIK1C5i6bCozVsxgfel6NldsZn3ZehasXcCza16itLIU0oCONa+B8fX7pLcjb0MlzVY8Q9O3H6dpaEyzznk069WM1stmkf/kf2i9roLWmyFvCzT6eL6iZs3iHkVt2sQTWBcUwH77wf77x987YZ0k7TpDIEnSXqiwsJDXXnuN1NRUNmzYwMsvv0yjRo147rnnuO6665gwYcJnznn//fd54YUX2LhxIz179uR73/seaWlp9VD9rvNOLalehRDo2qIrXVt0ZeR+Iz+zvzqqZtXmVaSmpJLZKJPyqnKmLp3Kq0teZcaKGawrXcf89utYX7KOdeXr2VC2BFgST2Z98LbXapnejNbVjWm9GVqte5cWG2bQcn4pLd4qo+VD0KIECkoasW9ZUzKzm0J+PnTvHg87a9oUNm+GTZugRYt4GNqBB8aBkiTJEEiStPN2scfOnnTmmWeSWjNyYP369Zx//vl8+OGHhBCoqKjY7jknn3wyGRkZZGRk0Lp1a4qKiigoKNjusYnGO7WkhJYSUshvkr/NthO6ncAJ3U7Y7vHVUTXrStexavMqVm5euc2raHPR1u/f3bKKNSVrWFOymcrq2leoJDVaQ+/ySjpvXE/j9TPInFZC40rIrITGFdC0DFrfD/mboHXUmNZlabQuT6NxVu4nq5/tt188TO3ww+PhaS++CFOmxJNdn3pqPPG1PY4kJRNDIEnSXig7O3vr9z/5yU84+uijeeyxx1i4cCFHHXXUds/JyMjY+n1qaiqVlZ+38k1i8U4tKamkhBRaNG5Bi8Yt6JnX8wuPj6KIjeUbWVOyhuItxXy07iNmrJjBjBUzWLJxKaWVpZSUb6G0ooSSqjJKKkuoqK79PwIlNS9oUr2e1uUryN+SQuvCp2n9x7tofRe03lzzqm5M1bMlbLrvWjbvk0fH/J70bd6L3H06Q/Pm8fxGOTmfvLKyYO1aKCqCDRvieY/23/+T+YwqK6G4OB7SZqAkqb4ZAkmS9nLr16+nXbt2ANx33331W8we4p1aUoMWQiA3I5fcjFw6NevEQfscxIg+Iz73nC0VWz7by2hTTS+jLfH7BRuWM2X9MlaVr6M6RDVn1l4tbXXN61U6r4KsZVAdICIeltZ6M+TXhEf5m6DVFmhSDo2zcsnq3oe8JcW0mr2QnE0VhM6dqR52IgwcSMrqYli0KA6N+vaFQw+Nh61lZm7biOpqqKiAWv+LIUlfSWXlZ/+ukSRpL/LDH/6Q888/n9tvv52TTz65vsvZI0IURV981B4wYMCAaNq0afXy2ZJUV6qjataUrNkaFjVKaUROeg6ZjTJZsHYBM1bM4J3lMygr3URqVURUUc7akrUUlRZTVLGW1VUbidjx39OppFAdVRMFSKmGzuug19pUum5Op9maEnLKIbcMcjJzyc1tTU5aNjnLVpO7qIjckiqadehJWt+a+Y369o2/5ud/9oMqK6GqytBIuySE8FYURcmxnmoS2WPPYAMHxvOkPf307r+2JGmvN2fOHHr37l3fZSSd7f1cP+8ZzJ5AkrQHpYQU8rLyyMvKo0+rPtvs65nX8zOrpX1aVXUVq7esZtWWVWyp2EJJRQmbyjdt3ba2ZC0pIYVGEZSvLmJe5Sre37iAl9Z+xMby2lfaUPMC+tfe/j5NKuaSveohoueA5yCzOoXWlenkR9nkV6STv3IL+cs3kL8xIj80IT87n+zOPag48nAqBx9GdvuutGnShrTUNIiiuBdSUVG8+lpu7lf/IUraOzgcTJKkhOedWpISWGpKKvlN8j8zOfbOqI6q2Vy+mQ1lG9hYvpENZRvi78vi79eXrWdd6TrWlqxl86Y1hDVrCKuLKd2whiLWsYxNTM/eQFF+JVUHfNwbaVPNaz6seApqVswMEeSVBNKqIjanweY0yKqAtlWNadOkDeVRJUXla1gVSmha1YhOqS3pnNOeTlW5dF5TTcflJWRkZFHdogXVLZuT3aUXTfseQm5BN5pm5JK5diOsWAEFBfHqbJISjyGQJEkJzzu1JCWplJBCTkYOORk5X+k6Hw9pK9pURNHmIoo2FVFaWULa8pWkznqXTWtXsIyNLGcTlZmpZGc1JSurKZuLV7C8eB4rVn9EVhUMJJtWWR1YV7WZhdUreXHzch7MheocoHaJ5cD7Na8a6ZXxsLamZZBb1YgmjbKoTG9EaVqgslEKbRo1o6BxPu2y29IspTG5UTrZadlUd+lEVfPmADRplEXu8mJyijeR2/MAcjr3IjOtMRXVFZRXlRMI5GXlkZ2ejaQvwRBIkqSE551akvS5ag9p25d9P9nRDzhpJy6walU8WWxOraQniqCwkIqsTJakbGTRukVUVFeQGlJhy2a2fPge6z98lw3LPmJ9dirrczPYkBdYv2k1GzYWs6lsA5mbysgrqSSlrJzl2auYnfshy3Mgqr1QWuEOapq743IbV6XQrLIR6aER6SlpZDbKJDc3j9wW+5CT3ZzclCxyK1LITc8hp1U7crOak5WWRUZqBhmNMrb5mp6a/plttfeFKPpktTdpb2cIJElSwvNOLUnas1q1+uy2EKB9e9KALrSiS/Mu2+7f77Sdv34UwcaNUFxM9do1bIrK2EAZmzcUkzJzJqnT3obCQjbt35MNB/RkY6umbFg4l42LPqC0uIj0KIW0KFAVIoobVbAqrYL1lFFRXkJ5ZRlbqtazMb2IVRmzWdA4hQ1p1WzIgM3pX+mnAkBaFWRUBzJS0slIaxwHRCGN9NCIjPTGZDTOISMrh5SQQgiBQCCEEL8nEKKIUFZOo4oq2uW2o3PrnnTI70FWRhMyG2VuDZ0+/j4tNY20lDRCCJRUlLC5YjNbKrZwaLtDCSF8ccHS5zEEkiQp4XmnliTt3UKIJ6DOzSWlc2dyga3TUR894qtff906eOMNeP11WLsW8trCPvtQVVHOxoVz2bDoA7ZsKKa8vISyss2UbdlI2YY1lFWUUp4KZalQ1gjKMlIpy0yjPD2VsuY5lLVqQVnzXMrWF1O+bAllFevi42qO//jc0rRAdUY6UUYGUXoa1VWVRBXlRBUVRJWVVIf42OeawsYvuXjb5mvWkpXd7Kv/rNSwVVQYAkmSlOC8U0uS9HmaNYMTTohftaQCzWpe27VlS9wzIiMD0tPjsGpHogjmzYNNm+L31dXxRNiLF8evRYvir8uWQfPmsM8+8atdu/hrXh7Rxo2sXb2EJcULKFlRSFnRUspWLqdsfTGlNcFSRQpUZGVQnZtD1sq1ZJdUkVUBaVdEO65N2ln2BJIkJbijjz6aa6+9lhNqPdeNGTOGuXPncvfdd3/m+KOOOorRo0czYMAATjrpJP75z3/SrNm2T38333wzTZo04Zprrtnh5z7++OP06NGDPn3i1YJvvPFGhgwZwnHHHbebWrbzvFNLkrQnZGXt/LEhQPfuX+njAtCi5rWNsrI4QFq9Gjp3hvz8+POqqqCwEBYuhKbNv9JnSwA88oir90mSEtqoUaMYN27cNiHQuHHjuPPOO7/w3EmTJn3pz3388cc55ZRTtoZAt95665e+1ldlCCRJUjLLyIgDpk+HTKmp0LFj/JJ2h8MOq+8KJEl7iSuevoIZK2bs1mse2OZAxpw45nOPGTFiBDfccAPl5eWkp6ezcOFCli1bxkMPPcRVV11FSUkJI0aM4JZbbvnMuZ06dWLatGnk5eXx05/+lL///e+0bt2a9u3bc9BBBwFwzz33MHbsWMrLy+nWrRv3338/M2bMYOLEibz44ovcfvvtTJgwgdtuu41TTjmFESNG8Pzzz3PNNddQWVnJwQcfzN13301GRgadOnXi/PPP59///jcVFRU88sgj9OrV6yv/nFySRJIkSZIkJb0WLVpwyCGH8NRTTwFxL6CzzjqLn/70p0ybNo1Zs2bx4osvMmvWrB1e46233mLcuHHMmDGDSZMmMXXq1K37zjjjDKZOncrMmTPp3bs3f/3rXznssMM47bTTuOuuu5gxYwZdu3bdenxpaSkXXHAB48eP55133qGysnKbYWl5eXm8/fbbfO9732P06NG75WdgTyBJkiRJklRnvqjHzp708ZCw4cOHM27cOP7617/y8MMPM3bsWCorK1m+fDnvvfceBxxwwHbPf/nllzn99NPJqhn6f9ppn6xq++6773LDDTewbt06Nm3atM2ws+2ZO3cunTt3pkePHgCcf/75/OEPf+CKK64A4lAJ4KCDDuJf//rXV2472BNIkiRJkiQ1EMOHD+f555/n7bffZsuWLbRo0YLRo0fz/PPPM2vWLE4++WRKS0u/1LUvuOACfv/73/POO+9w0003fenrfCwjI176NTU1lcrKyq90rY8ZAkmSJEmSpAahSZMmHH300Vx00UWMGjWKDRs2kJ2dTdOmTSkqKto6VGxHhgwZwuOPP05JSQkbN27k3//+99Z9GzdupG3btlRUVPDggw9u3Z6Tk8PGjRs/c62ePXuycOFC5s2bB8D999/PkUceuZtaun2GQJIkSZIkqcEYNWoUM2fOZNSoUfTt25d+/frRq1cvzjnnHAYPHvy55/bv35+zzz6bvn37MmzYMA4++OCt+2677TYOPfRQBg8evM0kziNHjuSuu+6iX79+zJ8/f+v2zMxM7r33Xs4880z2339/UlJS+O53v7v7G1xLiKJoj37AjgwYMCCaNm1avXy2JEna80IIb0VRNKC+69C2fAaTJNWHOXPm0Lt37/ouI+ls7+f6ec9g9gSSJEmSJElqAAyBJEmSJEmSGgBDIEmSJEmStMfV13Q0yerL/DwNgSRJkiRJ0h6VmZlJcXGxQdBuEkURxcXFZGZm7tJ5jfZQPZIkSZIkSQAUFBRQWFjIqlWr6ruUpJGZmUlBQcEunWMIJEmSJEmS9qi0tDQ6d+5c32U0eA4HkyRJkiRJagAMgSRJkiRJkhoAQyBJkiRJkqQGINTXzNwhhFXAoj10+Txg9R66dqKxrcmrIbXXtiYn25qcdqWtHaMoarUni9Gu8xlst7Gtycm2JqeG1FZoWO21rdu3w2eweguB9qQQwrQoigbUdx11wbYmr4bUXtuanGxrcmpIbdWua0h/PmxrcrKtyakhtRUaVntt665zOJgkSZIkSVIDYAgkSZIkSZLUACRrCDS2vguoQ7Y1eTWk9trW5GRbk1NDaqt2XUP682Fbk5NtTU4Nqa3QsNprW3dRUs4JJEmSJEmSpG0la08gSZIkSZIk1WIIJEmSJEmS1AAkXQgUQjgxhDA3hDAvhHBtfdezO4UQ2ocQXgghvBdCmB1CuLxme4sQwrMhhA9rvjav71p3lxBCaghhegjhiZr3nUMIb9T8fseHENLru8bdIYTQLITwaAjh/RDCnBDCoGT9vYYQrqz58/tuCOGhEEJmsvxeQwh/CyGsDCG8W2vbdn+PIfbbmjbPCiH0r7/Kd90O2npXzZ/hWSGEx0IIzWrt+3FNW+eGEE6on6q/vO21t9a+q0MIUQghr+Z90v1ua7ZfWvP7nR1CuLPW9r36d6vdw+ev5LlPQ8N5/gKfwZLld+szWHI+g/n8tWeev5IqBAohpAJ/AIYBfYBRIYQ+9VvVblUJXB1FUR9gIPD9mvZdCzwfRVF34Pma98nicmBOrfe/AH4dRVE3YC3wzXqpavf7DfB0FEW9gL7EbU6632sIoR1wGTAgiqL9gFRgJMnze70P/r+9+wmxqgzjOP59YFLSIDXJyhG00BZGpVAI/SEtQk2cFi0EIaMgaNemwISgXYuoVtlCaawkKRMbgqC/1EotJSv6O6boiKYRWhSo0a/F+w7cRi9ic5zLPPf3gYv3nHNneB+fO+f8eHnPvSwdsa9dH5cBc+vjUWD9GI2xKf2cXesHwA2SbgR+BNYC1PPUKmB+/ZmX6vl6POnn7HqJiFnAvcDBlt3pehsRi4E+4CZJ84Hn6v4MvbVRcv7Kc51u0S35C5zBsvS2H2ewjBmsH+evxvNXqkkg4FZgUNLPkk4DWyj/aSlIOiJpT33+B+UiNZNS46b6sk3A/Z0ZYbMiohe4D9hQtwNYAmytL0lRa0RcDtwJbASQdFrSCZL2FegBLo2IHmAScIQkfZX0GfDbiN3t+tgHvKpiBzAlIq4em5GO3rlqlfS+pL/r5g6gtz7vA7ZIOiVpPzBIOV+PG216C/AC8CTQ+i0L6XoLPAY8K+lUfc2xun/c99Ya4fw1jq9dI3VL/gJnMJzB0lyns2Yw56+Lk7+yTQLNBA61bA/VfelExGxgAbATmCHpSD10FJjRoWE17UXKH/c/dfsK4ETLCS5Lf+cAx4FX6tLrDRExmYR9lXSYMoN9kBI8TgK7ydnXYe36mP189TDwXn2estaI6AMOS9o74lDGeucBd9RbBj6NiFvq/oy12oXrmveB8xeQq7/OYHl7C85gkLBW5y9glLVmmwTqChFxGfA28Lik31uPSRL/nREdlyJiBXBM0u5Oj2UM9AALgfWSFgB/MmLZcaK+TqXMXM8BrgEmc44lnlll6eP5RMQ6yu0Tmzs9loslIiYBTwFPd3osY6QHmEa5FeYJ4M26OsCsazh/peQM1iWy9PF8smcw569m8le2SaDDwKyW7d66L42IuIQSQDZL2lZ3/zK81K3+e6zdz48jtwErI+IAZVn5Eso921PqElbI098hYEjSzrq9lRJIMvb1HmC/pOOSzgDbKL3O2Ndh7fqY8nwVEQ8BK4DVNXBBzlqvowTpvfU81QvsiYiryFnvELCtLrHeRVkhMJ2ctdqFS/8+cP5Ke512BsvbW3AGg3y1On81kL+yTQJ9DsyN8in3EygfljTQ4TE1ps76bQS+k/R8y6EBYE19vgZ4Z6zH1jRJayX1SppN6ePHklYDnwAP1JdlqfUocCgirq+77ga+JWFfKUuQF0XEpPp+Hq41XV9btOvjAPBg/SaDRcDJliXL41JELKXcQrBS0l8thwaAVRExMSLmUD6wb1cnxtgUSV9LulLS7HqeGgIW1r/ndL0FtgOLASJiHjAB+JWEvbX/xfkrybWrm/IXOIPhDJbmOt0tGcz5q6H8JSnVA1hO+UT0fcC6To+n4dpupyxj/Ar4sj6WU+7V/gj4CfgQmNbpsTZc913Au/X5tfUNPgi8BUzs9PgaqvFm4Iva2+3A1Kx9BZ4Bvge+AV4DJmbpK/AG5T77M5SL0iPt+ggE5dt09gFfU76to+M1jLLWQcr9ycPnp5dbXr+u1voDsKzT42+i3hHHDwDTE/d2AvB6/bvdAyzJ0ls/GnvfOH8luU631J0+f9XanMES9NYZLGcGc/66OPkr6i8wMzMzMzMzM7PEst0OZmZmZmZmZmZm5+BJIDMzMzMzMzOzLuBJIDMzMzMzMzOzLuBJIDMzMzMzMzOzLuBJIDMzMzMzMzOzLuBJIDMzMzMzMzOzLuBJIDMzMzMzMzOzLvAv/PbWx5VLv2UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlFjPjkp66qG"
      },
      "source": [
        "### Dropout after 2 Convolutional Layer\n",
        "\n",
        "0.9855\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pJIflEBx66qG",
        "outputId": "d1d8fbc0-33fd-4889-db4d-180ac1f15424"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dropout(0.5, name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 128,042\n",
            "Trainable params: 128,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 49s 257ms/step - loss: 1.0880 - accuracy: 0.6824 - val_loss: 0.4222 - val_accuracy: 0.8789\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87892, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 49s 258ms/step - loss: 0.4471 - accuracy: 0.8641 - val_loss: 0.3524 - val_accuracy: 0.9011\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87892 to 0.90108, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.3991 - accuracy: 0.8809 - val_loss: 0.3525 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.90108\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.3679 - accuracy: 0.8926 - val_loss: 0.3226 - val_accuracy: 0.9093\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.90108 to 0.90925, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.3511 - accuracy: 0.8966 - val_loss: 0.3033 - val_accuracy: 0.9174\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90925 to 0.91742, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 49s 258ms/step - loss: 0.3324 - accuracy: 0.9027 - val_loss: 0.2934 - val_accuracy: 0.9188\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.91742 to 0.91883, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 49s 258ms/step - loss: 0.3179 - accuracy: 0.9063 - val_loss: 0.2771 - val_accuracy: 0.9227\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.91883 to 0.92267, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 49s 258ms/step - loss: 0.3010 - accuracy: 0.9125 - val_loss: 0.2687 - val_accuracy: 0.9264\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.92267 to 0.92642, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 48s 257ms/step - loss: 0.2870 - accuracy: 0.9164 - val_loss: 0.2542 - val_accuracy: 0.9302\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.92642 to 0.93025, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.2732 - accuracy: 0.9200 - val_loss: 0.2421 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.93025 to 0.93325, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.2589 - accuracy: 0.9255 - val_loss: 0.2283 - val_accuracy: 0.9380\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.93325 to 0.93800, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.2412 - accuracy: 0.9310 - val_loss: 0.2181 - val_accuracy: 0.9388\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.93800 to 0.93875, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.2256 - accuracy: 0.9350 - val_loss: 0.2030 - val_accuracy: 0.9450\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.93875 to 0.94500, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 48s 256ms/step - loss: 0.2144 - accuracy: 0.9385 - val_loss: 0.1878 - val_accuracy: 0.9497\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.94500 to 0.94967, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 48s 256ms/step - loss: 0.2002 - accuracy: 0.9424 - val_loss: 0.1765 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.94967 to 0.95317, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.1894 - accuracy: 0.9456 - val_loss: 0.1649 - val_accuracy: 0.9558\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.95317 to 0.95583, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.1759 - accuracy: 0.9501 - val_loss: 0.1543 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.95583 to 0.95883, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 50s 267ms/step - loss: 0.1663 - accuracy: 0.9528 - val_loss: 0.1484 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.95883 to 0.96025, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.1566 - accuracy: 0.9552 - val_loss: 0.1379 - val_accuracy: 0.9636\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.96025 to 0.96358, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.1479 - accuracy: 0.9567 - val_loss: 0.1312 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.96358 to 0.96517, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.1409 - accuracy: 0.9594 - val_loss: 0.1263 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.96517 to 0.96700, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.1346 - accuracy: 0.9617 - val_loss: 0.1203 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.96700 to 0.96775, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.1290 - accuracy: 0.9629 - val_loss: 0.1142 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.96775 to 0.96967, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.1237 - accuracy: 0.9638 - val_loss: 0.1109 - val_accuracy: 0.9700\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.96967 to 0.97000, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.1173 - accuracy: 0.9663 - val_loss: 0.1071 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.97000 to 0.97117, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.1154 - accuracy: 0.9660 - val_loss: 0.1026 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.97117 to 0.97208, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.1103 - accuracy: 0.9675 - val_loss: 0.1000 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.97208 to 0.97250, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.1068 - accuracy: 0.9688 - val_loss: 0.0976 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.97250 to 0.97267, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.1038 - accuracy: 0.9693 - val_loss: 0.0943 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.97267 to 0.97383, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.1008 - accuracy: 0.9703 - val_loss: 0.0925 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.97383 to 0.97442, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0975 - accuracy: 0.9710 - val_loss: 0.0901 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.97442 to 0.97583, saving model to mnist_conv_best.h5\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0957 - accuracy: 0.9709 - val_loss: 0.0878 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.97583\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0931 - accuracy: 0.9721 - val_loss: 0.0860 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.97583\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0907 - accuracy: 0.9730 - val_loss: 0.0845 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.97583\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0895 - accuracy: 0.9736 - val_loss: 0.0840 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.97583 to 0.97650, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0868 - accuracy: 0.9746 - val_loss: 0.0830 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.97650 to 0.97692, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0865 - accuracy: 0.9743 - val_loss: 0.0822 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.97692\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0838 - accuracy: 0.9759 - val_loss: 0.0801 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.97692\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0813 - accuracy: 0.9751 - val_loss: 0.0779 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.97692 to 0.97708, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0804 - accuracy: 0.9761 - val_loss: 0.0789 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.97708 to 0.97742, saving model to mnist_conv_best.h5\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0795 - accuracy: 0.9764 - val_loss: 0.0770 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.97742\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0793 - accuracy: 0.9765 - val_loss: 0.0757 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.97742 to 0.97758, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0761 - accuracy: 0.9766 - val_loss: 0.0749 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.97758 to 0.97842, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0747 - accuracy: 0.9774 - val_loss: 0.0737 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.97842\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0741 - accuracy: 0.9779 - val_loss: 0.0726 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.97842\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0741 - accuracy: 0.9772 - val_loss: 0.0727 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.97842 to 0.97875, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0713 - accuracy: 0.9785 - val_loss: 0.0717 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.97875 to 0.97892, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0713 - accuracy: 0.9789 - val_loss: 0.0708 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.97892 to 0.97917, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0712 - accuracy: 0.9779 - val_loss: 0.0704 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.97917\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0701 - accuracy: 0.9784 - val_loss: 0.0704 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.97917 to 0.97933, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0690 - accuracy: 0.9792 - val_loss: 0.0686 - val_accuracy: 0.9802\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.97933 to 0.98017, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0672 - accuracy: 0.9795 - val_loss: 0.0687 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.98017\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0676 - accuracy: 0.9794 - val_loss: 0.0681 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.98017 to 0.98033, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0665 - accuracy: 0.9794 - val_loss: 0.0680 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.98033\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.0665 - accuracy: 0.9795 - val_loss: 0.0674 - val_accuracy: 0.9796\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.98033\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0654 - accuracy: 0.9798 - val_loss: 0.0663 - val_accuracy: 0.9802\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.98033\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0665 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.98033\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.0657 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.98033 to 0.98125, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0631 - accuracy: 0.9808 - val_loss: 0.0660 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.98125\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.0654 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.98125\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.98125 to 0.98142, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0609 - accuracy: 0.9816 - val_loss: 0.0652 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.98142\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0606 - accuracy: 0.9818 - val_loss: 0.0638 - val_accuracy: 0.9810\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.98142\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0590 - accuracy: 0.9821 - val_loss: 0.0637 - val_accuracy: 0.9809\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.98142\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0575 - accuracy: 0.9823 - val_loss: 0.0633 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.98142\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0571 - accuracy: 0.9827 - val_loss: 0.0639 - val_accuracy: 0.9810\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.98142\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 49s 263ms/step - loss: 0.0596 - accuracy: 0.9819 - val_loss: 0.0631 - val_accuracy: 0.9810\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.98142\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 0.0624 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.98142 to 0.98175, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.0621 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.98175 to 0.98217, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0565 - accuracy: 0.9827 - val_loss: 0.0623 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.98217\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.0619 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.98217\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0550 - accuracy: 0.9829 - val_loss: 0.0617 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.98217\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0551 - accuracy: 0.9831 - val_loss: 0.0618 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.98217\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0547 - accuracy: 0.9829 - val_loss: 0.0615 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.98217\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0549 - accuracy: 0.9831 - val_loss: 0.0607 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.98217\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0553 - accuracy: 0.9835 - val_loss: 0.0610 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.98217\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.0607 - val_accuracy: 0.9826\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.98217 to 0.98258, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0527 - accuracy: 0.9839 - val_loss: 0.0607 - val_accuracy: 0.9826\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.98258\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0523 - accuracy: 0.9839 - val_loss: 0.0605 - val_accuracy: 0.9824\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.98258\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.0600 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.98258\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0512 - accuracy: 0.9840 - val_loss: 0.0605 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.98258\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 49s 259ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 0.0598 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.98258 to 0.98292, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0504 - accuracy: 0.9844 - val_loss: 0.0591 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.98292\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0522 - accuracy: 0.9837 - val_loss: 0.0593 - val_accuracy: 0.9824\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.98292\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.0598 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.98292\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.0592 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.98292\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 0.0590 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.98292\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0489 - accuracy: 0.9844 - val_loss: 0.0585 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.98292\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 0.0581 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.98292\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0486 - accuracy: 0.9850 - val_loss: 0.0579 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.98292 to 0.98308, saving model to mnist_conv_best.h5\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0486 - accuracy: 0.9847 - val_loss: 0.0579 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.98308\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0478 - accuracy: 0.9851 - val_loss: 0.0593 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.98308\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0471 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.98308\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 0.0574 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.98308\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0462 - accuracy: 0.9853 - val_loss: 0.0575 - val_accuracy: 0.9826\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.98308\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 0.0575 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.98308\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 49s 263ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.0568 - val_accuracy: 0.9832\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.98308 to 0.98317, saving model to mnist_conv_best.h5\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0462 - accuracy: 0.9856 - val_loss: 0.0577 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.98317\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.0567 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00099: val_accuracy improved from 0.98317 to 0.98392, saving model to mnist_conv_best.h5\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 49s 263ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.0575 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.98392\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.0566 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.98392\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0453 - accuracy: 0.9850 - val_loss: 0.0568 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.98392\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.0562 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.98392\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 49s 263ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.0565 - val_accuracy: 0.9835\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.98392\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 0.0561 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.98392\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.0570 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.98392\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 49s 260ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.0561 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.98392\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 49s 263ms/step - loss: 0.0424 - accuracy: 0.9867 - val_loss: 0.0560 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.98392\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 49s 261ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.98392\n",
            "Epoch 00109: early stopping\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0352 - accuracy: 0.9902\n",
            "Accuracy for the training set: 0.9901999831199646\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0447 - accuracy: 0.9855\n",
            "Accuracy for the testing set: 0.9854999780654907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qODUJu_yiNbv"
      },
      "source": [
        "### Dropout after 3 Convolutional Layer\n",
        "\n",
        "0.9862"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6MfitggBiNb1",
        "outputId": "2d21d1b1-7044-4b30-dd2e-e5b9e2f925c9"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dropout(0.5, name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 129,082\n",
            "Trainable params: 129,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 66s 347ms/step - loss: 0.8664 - accuracy: 0.7344 - val_loss: 0.4322 - val_accuracy: 0.8712\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87125, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.4428 - accuracy: 0.8658 - val_loss: 0.3681 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87125 to 0.89542, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 65s 349ms/step - loss: 0.3964 - accuracy: 0.8819 - val_loss: 0.3344 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89542 to 0.90642, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.3711 - accuracy: 0.8916 - val_loss: 0.3305 - val_accuracy: 0.9057\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.90642\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 68s 360ms/step - loss: 0.3556 - accuracy: 0.8962 - val_loss: 0.3205 - val_accuracy: 0.9095\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90642 to 0.90950, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 67s 359ms/step - loss: 0.3392 - accuracy: 0.9011 - val_loss: 0.2989 - val_accuracy: 0.9176\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90950 to 0.91758, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 67s 356ms/step - loss: 0.3255 - accuracy: 0.9058 - val_loss: 0.2888 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.91758 to 0.92117, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 69s 367ms/step - loss: 0.3120 - accuracy: 0.9105 - val_loss: 0.2801 - val_accuracy: 0.9222\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.92117 to 0.92217, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.2993 - accuracy: 0.9121 - val_loss: 0.2680 - val_accuracy: 0.9277\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.92217 to 0.92767, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.2833 - accuracy: 0.9190 - val_loss: 0.2589 - val_accuracy: 0.9281\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.92767 to 0.92808, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.2696 - accuracy: 0.9234 - val_loss: 0.2472 - val_accuracy: 0.9319\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.92808 to 0.93192, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.2560 - accuracy: 0.9262 - val_loss: 0.2354 - val_accuracy: 0.9341\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.93192 to 0.93408, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.2389 - accuracy: 0.9319 - val_loss: 0.2192 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.93408 to 0.94142, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 64s 340ms/step - loss: 0.2240 - accuracy: 0.9369 - val_loss: 0.2043 - val_accuracy: 0.9451\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.94142 to 0.94508, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 64s 340ms/step - loss: 0.2107 - accuracy: 0.9401 - val_loss: 0.1888 - val_accuracy: 0.9492\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.94508 to 0.94925, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 65s 343ms/step - loss: 0.1977 - accuracy: 0.9435 - val_loss: 0.1757 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.94925 to 0.95250, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.1849 - accuracy: 0.9480 - val_loss: 0.1665 - val_accuracy: 0.9554\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.95250 to 0.95542, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.1740 - accuracy: 0.9500 - val_loss: 0.1594 - val_accuracy: 0.9563\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.95542 to 0.95633, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.1634 - accuracy: 0.9534 - val_loss: 0.1465 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.95633 to 0.96042, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 63s 333ms/step - loss: 0.1556 - accuracy: 0.9556 - val_loss: 0.1418 - val_accuracy: 0.9616\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.96042 to 0.96158, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.1484 - accuracy: 0.9578 - val_loss: 0.1390 - val_accuracy: 0.9621\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.96158 to 0.96208, saving model to mnist_conv_best.h5\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 63s 338ms/step - loss: 0.1423 - accuracy: 0.9584 - val_loss: 0.1315 - val_accuracy: 0.9641\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.96208 to 0.96408, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 63s 337ms/step - loss: 0.1378 - accuracy: 0.9597 - val_loss: 0.1271 - val_accuracy: 0.9657\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.96408 to 0.96575, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 64s 340ms/step - loss: 0.1319 - accuracy: 0.9617 - val_loss: 0.1222 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.96575 to 0.96683, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.1263 - accuracy: 0.9630 - val_loss: 0.1171 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.96683 to 0.96858, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.1236 - accuracy: 0.9642 - val_loss: 0.1134 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.96858 to 0.96925, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.1186 - accuracy: 0.9653 - val_loss: 0.1131 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.96925 to 0.96992, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.1164 - accuracy: 0.9657 - val_loss: 0.1090 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.96992 to 0.97050, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.1136 - accuracy: 0.9674 - val_loss: 0.1053 - val_accuracy: 0.9713\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.97050 to 0.97133, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.1096 - accuracy: 0.9678 - val_loss: 0.1061 - val_accuracy: 0.9714\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.97133 to 0.97142, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.1068 - accuracy: 0.9678 - val_loss: 0.1035 - val_accuracy: 0.9710\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.97142\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.1055 - accuracy: 0.9681 - val_loss: 0.0992 - val_accuracy: 0.9716\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.97142 to 0.97158, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.1026 - accuracy: 0.9693 - val_loss: 0.0981 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.97158 to 0.97283, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.1000 - accuracy: 0.9703 - val_loss: 0.0956 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.97283 to 0.97367, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0956 - accuracy: 0.9714 - val_loss: 0.0938 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.97367 to 0.97475, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0947 - accuracy: 0.9715 - val_loss: 0.0954 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.97475\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.0936 - accuracy: 0.9723 - val_loss: 0.0945 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.97475\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0926 - accuracy: 0.9724 - val_loss: 0.0888 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.97475 to 0.97575, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0906 - accuracy: 0.9726 - val_loss: 0.0876 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.97575\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0881 - accuracy: 0.9730 - val_loss: 0.0877 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.97575\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0858 - accuracy: 0.9741 - val_loss: 0.0856 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.97575\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0847 - accuracy: 0.9744 - val_loss: 0.0842 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.97575 to 0.97717, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.0829 - accuracy: 0.9749 - val_loss: 0.0853 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.97717\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.0806 - accuracy: 0.9758 - val_loss: 0.0813 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.97717\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.0805 - accuracy: 0.9754 - val_loss: 0.0869 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.97717\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.0780 - accuracy: 0.9762 - val_loss: 0.0805 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.97717\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 64s 340ms/step - loss: 0.0766 - accuracy: 0.9774 - val_loss: 0.0832 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.97717\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0770 - accuracy: 0.9765 - val_loss: 0.0822 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.97717\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0756 - accuracy: 0.9765 - val_loss: 0.0787 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.97717 to 0.97775, saving model to mnist_conv_best.h5\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0748 - accuracy: 0.9769 - val_loss: 0.0770 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.97775 to 0.97833, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.0725 - accuracy: 0.9778 - val_loss: 0.0767 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.97833\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0719 - accuracy: 0.9778 - val_loss: 0.0764 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.97833\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 64s 341ms/step - loss: 0.0713 - accuracy: 0.9789 - val_loss: 0.0751 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.97833\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.0691 - accuracy: 0.9797 - val_loss: 0.0739 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.97833\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0675 - accuracy: 0.9802 - val_loss: 0.0752 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.97833\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0688 - accuracy: 0.9790 - val_loss: 0.0728 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.97833 to 0.97875, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0684 - accuracy: 0.9785 - val_loss: 0.0737 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.97875 to 0.97883, saving model to mnist_conv_best.h5\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0676 - accuracy: 0.9796 - val_loss: 0.0724 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.97883\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0661 - accuracy: 0.9801 - val_loss: 0.0723 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.97883\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 65s 344ms/step - loss: 0.0644 - accuracy: 0.9801 - val_loss: 0.0712 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.97883 to 0.97925, saving model to mnist_conv_best.h5\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 65s 343ms/step - loss: 0.0637 - accuracy: 0.9803 - val_loss: 0.0720 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.97925 to 0.97933, saving model to mnist_conv_best.h5\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 65s 345ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.0706 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.97933\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.0724 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.97933\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0620 - accuracy: 0.9813 - val_loss: 0.0687 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.97933 to 0.97942, saving model to mnist_conv_best.h5\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 65s 346ms/step - loss: 0.0607 - accuracy: 0.9815 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.97942 to 0.97983, saving model to mnist_conv_best.h5\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0610 - accuracy: 0.9819 - val_loss: 0.0677 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.97983\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0597 - accuracy: 0.9817 - val_loss: 0.0671 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.97983\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 66s 352ms/step - loss: 0.0592 - accuracy: 0.9815 - val_loss: 0.0673 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.97983\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.0584 - accuracy: 0.9820 - val_loss: 0.0664 - val_accuracy: 0.9804\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.97983 to 0.98042, saving model to mnist_conv_best.h5\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0582 - accuracy: 0.9817 - val_loss: 0.0671 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.98042\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0572 - accuracy: 0.9823 - val_loss: 0.0664 - val_accuracy: 0.9802\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.98042\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0562 - accuracy: 0.9821 - val_loss: 0.0663 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.98042\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 65s 347ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 0.0668 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.98042\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0553 - accuracy: 0.9829 - val_loss: 0.0642 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.98042\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.0652 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.98042 to 0.98050, saving model to mnist_conv_best.h5\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0543 - accuracy: 0.9839 - val_loss: 0.0643 - val_accuracy: 0.9809\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.98050 to 0.98092, saving model to mnist_conv_best.h5\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 66s 352ms/step - loss: 0.0548 - accuracy: 0.9829 - val_loss: 0.0646 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.98092\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0536 - accuracy: 0.9835 - val_loss: 0.0643 - val_accuracy: 0.9807\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.98092\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.0527 - accuracy: 0.9833 - val_loss: 0.0644 - val_accuracy: 0.9810\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.98092 to 0.98100, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0534 - accuracy: 0.9833 - val_loss: 0.0636 - val_accuracy: 0.9807\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.98100\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0527 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.98100 to 0.98125, saving model to mnist_conv_best.h5\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.0526 - accuracy: 0.9841 - val_loss: 0.0618 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.98125 to 0.98167, saving model to mnist_conv_best.h5\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.0626 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.98167\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0630 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.98167\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 65s 348ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.0611 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.98167\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 0.0615 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.98167 to 0.98192, saving model to mnist_conv_best.h5\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.0609 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.98192\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.0609 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.98192\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0479 - accuracy: 0.9845 - val_loss: 0.0612 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.98192 to 0.98233, saving model to mnist_conv_best.h5\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.0479 - accuracy: 0.9851 - val_loss: 0.0612 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.98233\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0473 - accuracy: 0.9849 - val_loss: 0.0602 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.98233\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0479 - accuracy: 0.9848 - val_loss: 0.0602 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.98233\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0593 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.98233 to 0.98250, saving model to mnist_conv_best.h5\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 0.0602 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.98250\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0471 - accuracy: 0.9848 - val_loss: 0.0596 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.98250\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 66s 350ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.0591 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.98250\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 66s 349ms/step - loss: 0.0463 - accuracy: 0.9848 - val_loss: 0.0591 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.98250\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.0588 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.98250\n",
            "Epoch 99/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.0456 - accuracy: 0.9863 - val_loss: 0.0578 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.98250\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - 67s 354ms/step - loss: 0.0459 - accuracy: 0.9853 - val_loss: 0.0605 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.98250 to 0.98300, saving model to mnist_conv_best.h5\n",
            "Epoch 101/10000\n",
            "188/188 [==============================] - 66s 352ms/step - loss: 0.0442 - accuracy: 0.9855 - val_loss: 0.0590 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.98300\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - 67s 355ms/step - loss: 0.0436 - accuracy: 0.9859 - val_loss: 0.0580 - val_accuracy: 0.9824\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.98300\n",
            "Epoch 103/10000\n",
            "188/188 [==============================] - 66s 352ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.0577 - val_accuracy: 0.9820\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.98300\n",
            "Epoch 104/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.0442 - accuracy: 0.9857 - val_loss: 0.0578 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.98300 to 0.98308, saving model to mnist_conv_best.h5\n",
            "Epoch 105/10000\n",
            "188/188 [==============================] - 66s 352ms/step - loss: 0.0437 - accuracy: 0.9854 - val_loss: 0.0563 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00105: val_accuracy improved from 0.98308 to 0.98325, saving model to mnist_conv_best.h5\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0426 - accuracy: 0.9865 - val_loss: 0.0577 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00106: val_accuracy improved from 0.98325 to 0.98392, saving model to mnist_conv_best.h5\n",
            "Epoch 107/10000\n",
            "188/188 [==============================] - 66s 352ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.0577 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.98392\n",
            "Epoch 108/10000\n",
            "188/188 [==============================] - 66s 352ms/step - loss: 0.0423 - accuracy: 0.9868 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.98392\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - 66s 351ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.0573 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.98392\n",
            "Epoch 110/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 0.0574 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.98392\n",
            "Epoch 111/10000\n",
            "188/188 [==============================] - 66s 353ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0551 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.98392\n",
            "Epoch 112/10000\n",
            "188/188 [==============================] - 66s 352ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00112: val_accuracy improved from 0.98392 to 0.98400, saving model to mnist_conv_best.h5\n",
            "Epoch 113/10000\n",
            "188/188 [==============================] - 67s 354ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.0555 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.98400 to 0.98408, saving model to mnist_conv_best.h5\n",
            "Epoch 114/10000\n",
            "188/188 [==============================] - 71s 376ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.0556 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.98408\n",
            "Epoch 115/10000\n",
            "188/188 [==============================] - 70s 374ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.0569 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.98408\n",
            "Epoch 116/10000\n",
            "188/188 [==============================] - 70s 375ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 0.0563 - val_accuracy: 0.9834\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.98408\n",
            "Epoch 117/10000\n",
            "188/188 [==============================] - 72s 383ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0555 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.98408\n",
            "Epoch 118/10000\n",
            "188/188 [==============================] - 73s 387ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.0550 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.98408\n",
            "Epoch 119/10000\n",
            "188/188 [==============================] - 70s 375ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.0553 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.98408\n",
            "Epoch 120/10000\n",
            "188/188 [==============================] - 72s 383ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 0.0562 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.98408\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - 70s 373ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 0.0551 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00121: val_accuracy improved from 0.98408 to 0.98475, saving model to mnist_conv_best.h5\n",
            "Epoch 122/10000\n",
            "188/188 [==============================] - 70s 374ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.0540 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.98475\n",
            "Epoch 123/10000\n",
            "188/188 [==============================] - 70s 371ms/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.0554 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.98475\n",
            "Epoch 124/10000\n",
            "188/188 [==============================] - 69s 369ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0546 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.98475\n",
            "Epoch 125/10000\n",
            "188/188 [==============================] - 70s 373ms/step - loss: 0.0379 - accuracy: 0.9876 - val_loss: 0.0547 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.98475\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - 70s 373ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 0.0548 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.98475\n",
            "Epoch 127/10000\n",
            "188/188 [==============================] - 71s 376ms/step - loss: 0.0385 - accuracy: 0.9879 - val_loss: 0.0544 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.98475\n",
            "Epoch 128/10000\n",
            "188/188 [==============================] - 71s 380ms/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.0549 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.98475\n",
            "Epoch 129/10000\n",
            "188/188 [==============================] - 69s 369ms/step - loss: 0.0373 - accuracy: 0.9878 - val_loss: 0.0542 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.98475\n",
            "Epoch 130/10000\n",
            "188/188 [==============================] - 70s 374ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 0.0541 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.98475\n",
            "Epoch 131/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.0545 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.98475\n",
            "Epoch 00131: early stopping\n",
            "1875/1875 [==============================] - 29s 16ms/step - loss: 0.0301 - accuracy: 0.9916\n",
            "Accuracy for the training set: 0.9916166663169861\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.0442 - accuracy: 0.9862\n",
            "Accuracy for the testing set: 0.9861999750137329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy8rIlDxnbhU"
      },
      "source": [
        "### Dropout after 4 Convolutional Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggZL3i-Inbhb",
        "outputId": "34a0e837-40a4-4b80-a2fe-503055c44394"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=1, activation='relu', padding='same', name='convolution4'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dropout(0.5, name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 129,082\n",
            "Trainable params: 129,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 66s 348ms/step - loss: 1.0711 - accuracy: 0.6666 - val_loss: 0.4116 - val_accuracy: 0.8823\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88233, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 64s 342ms/step - loss: 0.4556 - accuracy: 0.8606 - val_loss: 0.3653 - val_accuracy: 0.8976\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.88233 to 0.89758, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 64s 343ms/step - loss: 0.4119 - accuracy: 0.8762 - val_loss: 0.3441 - val_accuracy: 0.9013\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89758 to 0.90133, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            " 50/188 [======>.......................] - ETA: 44s - loss: 0.3946 - accuracy: 0.8827"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-1RFhyasSlO"
      },
      "source": [
        "### Dropout after 4 Convolutional Layer\n",
        "\n",
        "0.9871"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ilEbAnYgsSlc",
        "outputId": "1d4e2fb5-e8c9-4991-c664-2cecefcffa34"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution4'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dropout(0.5, name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        416       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        4112      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution4 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 133,338\n",
            "Trainable params: 133,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 145s 765ms/step - loss: 1.1910 - accuracy: 0.6207 - val_loss: 0.4176 - val_accuracy: 0.8776\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87758, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.4533 - accuracy: 0.8630 - val_loss: 0.3521 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.87758 to 0.89850, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 145s 772ms/step - loss: 0.3750 - accuracy: 0.8892 - val_loss: 0.2992 - val_accuracy: 0.9168\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.89850 to 0.91675, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 145s 771ms/step - loss: 0.3311 - accuracy: 0.9036 - val_loss: 0.2698 - val_accuracy: 0.9243\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.91675 to 0.92425, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 144s 765ms/step - loss: 0.2935 - accuracy: 0.9141 - val_loss: 0.2443 - val_accuracy: 0.9295\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.92425 to 0.92950, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 143s 762ms/step - loss: 0.2614 - accuracy: 0.9236 - val_loss: 0.2199 - val_accuracy: 0.9371\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.92950 to 0.93708, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.2340 - accuracy: 0.9311 - val_loss: 0.1926 - val_accuracy: 0.9455\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.93708 to 0.94550, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 143s 762ms/step - loss: 0.2076 - accuracy: 0.9394 - val_loss: 0.1894 - val_accuracy: 0.9452\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.94550\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 144s 766ms/step - loss: 0.1878 - accuracy: 0.9449 - val_loss: 0.1588 - val_accuracy: 0.9545\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.94550 to 0.95450, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 144s 765ms/step - loss: 0.1679 - accuracy: 0.9509 - val_loss: 0.1406 - val_accuracy: 0.9601\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.95450 to 0.96008, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.1510 - accuracy: 0.9549 - val_loss: 0.1303 - val_accuracy: 0.9627\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.96008 to 0.96267, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 143s 762ms/step - loss: 0.1411 - accuracy: 0.9586 - val_loss: 0.1188 - val_accuracy: 0.9656\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.96267 to 0.96558, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 143s 761ms/step - loss: 0.1293 - accuracy: 0.9617 - val_loss: 0.1134 - val_accuracy: 0.9668\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.96558 to 0.96675, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 144s 764ms/step - loss: 0.1222 - accuracy: 0.9634 - val_loss: 0.1089 - val_accuracy: 0.9678\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.96675 to 0.96775, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 144s 765ms/step - loss: 0.1152 - accuracy: 0.9654 - val_loss: 0.1020 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.96775 to 0.97008, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 144s 769ms/step - loss: 0.1101 - accuracy: 0.9668 - val_loss: 0.0983 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.97008 to 0.97067, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.1029 - accuracy: 0.9686 - val_loss: 0.0939 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.97067 to 0.97258, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 144s 764ms/step - loss: 0.0985 - accuracy: 0.9703 - val_loss: 0.0892 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.97258 to 0.97433, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0946 - accuracy: 0.9711 - val_loss: 0.0880 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.97433 to 0.97475, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 145s 772ms/step - loss: 0.0919 - accuracy: 0.9723 - val_loss: 0.0847 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.97475 to 0.97567, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 145s 771ms/step - loss: 0.0889 - accuracy: 0.9729 - val_loss: 0.0827 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.97567\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0864 - accuracy: 0.9740 - val_loss: 0.0830 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.97567 to 0.97575, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 144s 767ms/step - loss: 0.0839 - accuracy: 0.9741 - val_loss: 0.0781 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.97575 to 0.97683, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 145s 770ms/step - loss: 0.0795 - accuracy: 0.9765 - val_loss: 0.0780 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.97683\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 145s 770ms/step - loss: 0.0771 - accuracy: 0.9766 - val_loss: 0.0765 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.97683 to 0.97733, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0754 - accuracy: 0.9761 - val_loss: 0.0742 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.97733 to 0.97833, saving model to mnist_conv_best.h5\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 145s 771ms/step - loss: 0.0738 - accuracy: 0.9772 - val_loss: 0.0734 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.97833\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 144s 766ms/step - loss: 0.0718 - accuracy: 0.9780 - val_loss: 0.0733 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.97833 to 0.97842, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0716 - accuracy: 0.9778 - val_loss: 0.0697 - val_accuracy: 0.9799\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.97842 to 0.97992, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 145s 770ms/step - loss: 0.0705 - accuracy: 0.9793 - val_loss: 0.0690 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.97992\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 145s 773ms/step - loss: 0.0682 - accuracy: 0.9798 - val_loss: 0.0683 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.97992\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 145s 771ms/step - loss: 0.0655 - accuracy: 0.9806 - val_loss: 0.0694 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.97992\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.0645 - accuracy: 0.9805 - val_loss: 0.0669 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.97992\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.0638 - accuracy: 0.9801 - val_loss: 0.0662 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.97992 to 0.98025, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 143s 761ms/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 0.0658 - val_accuracy: 0.9809\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.98025 to 0.98092, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 144s 764ms/step - loss: 0.0607 - accuracy: 0.9810 - val_loss: 0.0708 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.98092\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.0598 - accuracy: 0.9817 - val_loss: 0.0663 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.98092\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.0589 - accuracy: 0.9826 - val_loss: 0.0628 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.98092 to 0.98150, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 144s 765ms/step - loss: 0.0580 - accuracy: 0.9816 - val_loss: 0.0633 - val_accuracy: 0.9811\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.98150\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 144s 764ms/step - loss: 0.0575 - accuracy: 0.9822 - val_loss: 0.0615 - val_accuracy: 0.9810\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.98150\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.0555 - accuracy: 0.9830 - val_loss: 0.0620 - val_accuracy: 0.9806\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.98150\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 0.0619 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.98150 to 0.98158, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 143s 761ms/step - loss: 0.0547 - accuracy: 0.9833 - val_loss: 0.0603 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.98158 to 0.98175, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.0522 - accuracy: 0.9834 - val_loss: 0.0608 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.98175\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 143s 761ms/step - loss: 0.0531 - accuracy: 0.9838 - val_loss: 0.0591 - val_accuracy: 0.9820\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.98175 to 0.98200, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 143s 760ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.0620 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.98200 to 0.98208, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 143s 759ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.0585 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.98208 to 0.98300, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 143s 761ms/step - loss: 0.0497 - accuracy: 0.9847 - val_loss: 0.0574 - val_accuracy: 0.9826\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.98300\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 143s 762ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 0.0592 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.98300\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 143s 761ms/step - loss: 0.0478 - accuracy: 0.9850 - val_loss: 0.0568 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.98300\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 143s 760ms/step - loss: 0.0484 - accuracy: 0.9845 - val_loss: 0.0569 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.98300 to 0.98325, saving model to mnist_conv_best.h5\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 143s 762ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0568 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.98325\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 144s 765ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.0555 - val_accuracy: 0.9826\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.98325\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 144s 764ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.0552 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.98325 to 0.98333, saving model to mnist_conv_best.h5\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 143s 763ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.0554 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.98333\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 143s 759ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.0550 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.98333 to 0.98367, saving model to mnist_conv_best.h5\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 143s 760ms/step - loss: 0.0437 - accuracy: 0.9863 - val_loss: 0.0549 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.98367\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 143s 760ms/step - loss: 0.0436 - accuracy: 0.9862 - val_loss: 0.0552 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.98367 to 0.98383, saving model to mnist_conv_best.h5\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 143s 760ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.0531 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.98383 to 0.98417, saving model to mnist_conv_best.h5\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 143s 759ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 0.0542 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.98417\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 143s 759ms/step - loss: 0.0421 - accuracy: 0.9865 - val_loss: 0.0538 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.98417\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 143s 762ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.0533 - val_accuracy: 0.9835\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.98417\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 143s 759ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.0522 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.98417\n",
            "Epoch 64/10000\n",
            "188/188 [==============================] - 143s 762ms/step - loss: 0.0413 - accuracy: 0.9869 - val_loss: 0.0525 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.98417\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - 144s 764ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 0.0524 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.98417\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - 144s 766ms/step - loss: 0.0404 - accuracy: 0.9873 - val_loss: 0.0517 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.98417\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - 144s 767ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0528 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.98417\n",
            "Epoch 68/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.0516 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.98417 to 0.98425, saving model to mnist_conv_best.h5\n",
            "Epoch 69/10000\n",
            "188/188 [==============================] - 145s 773ms/step - loss: 0.0395 - accuracy: 0.9875 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.98425\n",
            "Epoch 70/10000\n",
            "188/188 [==============================] - 145s 770ms/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.0506 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.98425\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - 145s 770ms/step - loss: 0.0374 - accuracy: 0.9876 - val_loss: 0.0508 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.98425 to 0.98450, saving model to mnist_conv_best.h5\n",
            "Epoch 72/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.0510 - val_accuracy: 0.9844\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.98450\n",
            "Epoch 73/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.0371 - accuracy: 0.9879 - val_loss: 0.0506 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.98450 to 0.98475, saving model to mnist_conv_best.h5\n",
            "Epoch 74/10000\n",
            "188/188 [==============================] - 144s 767ms/step - loss: 0.0372 - accuracy: 0.9879 - val_loss: 0.0506 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.98475\n",
            "Epoch 75/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.0513 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.98475\n",
            "Epoch 76/10000\n",
            "188/188 [==============================] - 144s 766ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.0523 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.98475\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - 144s 766ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0504 - val_accuracy: 0.9851\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.98475 to 0.98508, saving model to mnist_conv_best.h5\n",
            "Epoch 78/10000\n",
            "188/188 [==============================] - 145s 772ms/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.0502 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.98508\n",
            "Epoch 79/10000\n",
            "188/188 [==============================] - 145s 772ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0496 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.98508 to 0.98542, saving model to mnist_conv_best.h5\n",
            "Epoch 80/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.0497 - val_accuracy: 0.9852\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.98542\n",
            "Epoch 81/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 0.0500 - val_accuracy: 0.9852\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.98542\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - 144s 767ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 0.0493 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.98542\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - 144s 767ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0493 - val_accuracy: 0.9850\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.98542\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - 144s 767ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.0487 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00084: val_accuracy improved from 0.98542 to 0.98600, saving model to mnist_conv_best.h5\n",
            "Epoch 85/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.0482 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.98600\n",
            "Epoch 86/10000\n",
            "188/188 [==============================] - 144s 767ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.0490 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.98600\n",
            "Epoch 87/10000\n",
            "188/188 [==============================] - 145s 771ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0481 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.98600\n",
            "Epoch 88/10000\n",
            "188/188 [==============================] - 145s 772ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.0482 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00088: val_accuracy improved from 0.98600 to 0.98650, saving model to mnist_conv_best.h5\n",
            "Epoch 89/10000\n",
            "188/188 [==============================] - 145s 773ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 0.0485 - val_accuracy: 0.9858\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.98650\n",
            "Epoch 90/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.0487 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.98650\n",
            "Epoch 91/10000\n",
            "188/188 [==============================] - 145s 771ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.0478 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.98650\n",
            "Epoch 92/10000\n",
            "188/188 [==============================] - 144s 768ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0477 - val_accuracy: 0.9857\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.98650\n",
            "Epoch 93/10000\n",
            "188/188 [==============================] - 145s 770ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.0474 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.98650\n",
            "Epoch 94/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0485 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.98650\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.0475 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.98650\n",
            "Epoch 96/10000\n",
            "188/188 [==============================] - 145s 770ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.0487 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.98650\n",
            "Epoch 97/10000\n",
            "188/188 [==============================] - 145s 771ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0470 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.98650\n",
            "Epoch 98/10000\n",
            "188/188 [==============================] - 145s 769ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.0490 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.98650\n",
            "Epoch 00098: early stopping\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.0240 - accuracy: 0.9934\n",
            "Accuracy for the training set: 0.9933833479881287\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.0382 - accuracy: 0.9871\n",
            "Accuracy for the testing set: 0.9871000051498413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ltOAjXdng_m"
      },
      "source": [
        "### Dropout after 5 Convolutional Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_C7TOe9Mng_n",
        "outputId": "cded710c-5901-4375-9041-b887053b8452"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution1'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=1, activation='relu', padding='same', name='convolution4'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dropout(0.5, name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        416       \n",
            "_________________________________________________________________\n",
            "convolution1 (Conv2D)        (None, 28, 28, 16)        4112      \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "convolution4 (Conv2D)        (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 133,610\n",
            "Trainable params: 133,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 130s 687ms/step - loss: 1.9328 - accuracy: 0.3538 - val_loss: 0.6700 - val_accuracy: 0.7799\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.77992, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 129s 688ms/step - loss: 0.5484 - accuracy: 0.8286 - val_loss: 0.3890 - val_accuracy: 0.8857\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.77992 to 0.88567, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 127s 674ms/step - loss: 0.4165 - accuracy: 0.8752 - val_loss: 0.3389 - val_accuracy: 0.9014\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.88567 to 0.90142, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 126s 669ms/step - loss: 0.3703 - accuracy: 0.8913 - val_loss: 0.3086 - val_accuracy: 0.9135\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.90142 to 0.91350, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 127s 673ms/step - loss: 0.3375 - accuracy: 0.8995 - val_loss: 0.2883 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.91350 to 0.91725, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 126s 671ms/step - loss: 0.3108 - accuracy: 0.9087 - val_loss: 0.2732 - val_accuracy: 0.9223\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.91725 to 0.92233, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 126s 671ms/step - loss: 0.2848 - accuracy: 0.9181 - val_loss: 0.2457 - val_accuracy: 0.9308\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.92233 to 0.93075, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 126s 670ms/step - loss: 0.2624 - accuracy: 0.9248 - val_loss: 0.2207 - val_accuracy: 0.9372\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.93075 to 0.93717, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 126s 669ms/step - loss: 0.2356 - accuracy: 0.9315 - val_loss: 0.2107 - val_accuracy: 0.9401\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.93717 to 0.94008, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 127s 675ms/step - loss: 0.2113 - accuracy: 0.9377 - val_loss: 0.1740 - val_accuracy: 0.9520\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.94008 to 0.95200, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.1846 - accuracy: 0.9465 - val_loss: 0.1638 - val_accuracy: 0.9532\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.95200 to 0.95317, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 126s 673ms/step - loss: 0.1670 - accuracy: 0.9515 - val_loss: 0.1431 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.95317 to 0.95950, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 126s 671ms/step - loss: 0.1532 - accuracy: 0.9549 - val_loss: 0.1314 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.95950 to 0.96242, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 127s 674ms/step - loss: 0.1414 - accuracy: 0.9579 - val_loss: 0.1225 - val_accuracy: 0.9644\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.96242 to 0.96442, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 133s 709ms/step - loss: 0.1306 - accuracy: 0.9604 - val_loss: 0.1119 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.96442 to 0.96925, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 128s 678ms/step - loss: 0.1240 - accuracy: 0.9623 - val_loss: 0.1058 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.96925 to 0.97033, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 127s 675ms/step - loss: 0.1169 - accuracy: 0.9647 - val_loss: 0.1046 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.97033 to 0.97050, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 128s 680ms/step - loss: 0.1104 - accuracy: 0.9665 - val_loss: 0.0985 - val_accuracy: 0.9705\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.97050\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 128s 683ms/step - loss: 0.1085 - accuracy: 0.9667 - val_loss: 0.0985 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.97050 to 0.97117, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 127s 676ms/step - loss: 0.1016 - accuracy: 0.9697 - val_loss: 0.0959 - val_accuracy: 0.9715\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.97117 to 0.97150, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0982 - accuracy: 0.9697 - val_loss: 0.1018 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.97150\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0951 - accuracy: 0.9712 - val_loss: 0.0856 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.97150 to 0.97592, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 128s 678ms/step - loss: 0.0913 - accuracy: 0.9723 - val_loss: 0.0865 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.97592\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 127s 678ms/step - loss: 0.0901 - accuracy: 0.9726 - val_loss: 0.0816 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.97592 to 0.97700, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 127s 678ms/step - loss: 0.0866 - accuracy: 0.9740 - val_loss: 0.0873 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.97700\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 128s 683ms/step - loss: 0.0855 - accuracy: 0.9735 - val_loss: 0.0834 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.97700\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 128s 682ms/step - loss: 0.0834 - accuracy: 0.9741 - val_loss: 0.0785 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.97700\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 128s 680ms/step - loss: 0.0814 - accuracy: 0.9753 - val_loss: 0.0836 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.97700\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 129s 684ms/step - loss: 0.0801 - accuracy: 0.9758 - val_loss: 0.0854 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.97700\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 130s 690ms/step - loss: 0.0775 - accuracy: 0.9767 - val_loss: 0.0749 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.97700 to 0.97767, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 148s 788ms/step - loss: 0.0754 - accuracy: 0.9770 - val_loss: 0.0770 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.97767\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 128s 682ms/step - loss: 0.0759 - accuracy: 0.9775 - val_loss: 0.0739 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.97767 to 0.97783, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0729 - accuracy: 0.9778 - val_loss: 0.0756 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.97783\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0704 - accuracy: 0.9786 - val_loss: 0.0704 - val_accuracy: 0.9796\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.97783 to 0.97958, saving model to mnist_conv_best.h5\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 130s 689ms/step - loss: 0.0724 - accuracy: 0.9778 - val_loss: 0.0722 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.97958\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0717 - accuracy: 0.9784 - val_loss: 0.0693 - val_accuracy: 0.9799\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.97958 to 0.97992, saving model to mnist_conv_best.h5\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 127s 676ms/step - loss: 0.0676 - accuracy: 0.9793 - val_loss: 0.0680 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.97992\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0684 - accuracy: 0.9791 - val_loss: 0.0667 - val_accuracy: 0.9807\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.97992 to 0.98067, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 0.0715 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.98067\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0647 - accuracy: 0.9796 - val_loss: 0.0687 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.98067\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 127s 678ms/step - loss: 0.0641 - accuracy: 0.9805 - val_loss: 0.0704 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.98067\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 128s 680ms/step - loss: 0.0632 - accuracy: 0.9803 - val_loss: 0.0644 - val_accuracy: 0.9811\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.98067 to 0.98108, saving model to mnist_conv_best.h5\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 128s 683ms/step - loss: 0.0629 - accuracy: 0.9808 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.98108\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 128s 679ms/step - loss: 0.0618 - accuracy: 0.9813 - val_loss: 0.0665 - val_accuracy: 0.9802\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.98108\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0606 - accuracy: 0.9817 - val_loss: 0.0623 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.98108 to 0.98158, saving model to mnist_conv_best.h5\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 127s 678ms/step - loss: 0.0597 - accuracy: 0.9813 - val_loss: 0.0654 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.98158\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 132s 703ms/step - loss: 0.0597 - accuracy: 0.9819 - val_loss: 0.0612 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.98158\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 141s 753ms/step - loss: 0.0572 - accuracy: 0.9824 - val_loss: 0.0589 - val_accuracy: 0.9832\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.98158 to 0.98317, saving model to mnist_conv_best.h5\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 129s 683ms/step - loss: 0.0580 - accuracy: 0.9818 - val_loss: 0.0612 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.98317\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 128s 681ms/step - loss: 0.0549 - accuracy: 0.9828 - val_loss: 0.0594 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.98317\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 129s 684ms/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.0578 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.98317\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 127s 675ms/step - loss: 0.0548 - accuracy: 0.9825 - val_loss: 0.0618 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.98317\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 126s 673ms/step - loss: 0.0545 - accuracy: 0.9834 - val_loss: 0.0591 - val_accuracy: 0.9826\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.98317\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 126s 673ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.0571 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.98317\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 127s 675ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.0574 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.98317\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 128s 678ms/step - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.0573 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.98317\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 127s 675ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.0576 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.98317\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 127s 674ms/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 0.0699 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.98317\n",
            "Epoch 00058: early stopping\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0446 - accuracy: 0.9865\n",
            "Accuracy for the training set: 0.9864833354949951\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.0462 - accuracy: 0.9844\n",
            "Accuracy for the testing set: 0.9843999743461609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heVQJrluGQ8Y"
      },
      "source": [
        "### BatchNormalization after 1 Convolutional Layer\n",
        "\n",
        "0.9831"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZB9HtjaSGUpm",
        "outputId": "ddeb8864-21b7-4142-c59d-2543c9552e71"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.BatchNormalization(name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "dropout (BatchNormalization) (None, 28, 28, 16)        64        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 125,786\n",
            "Trainable params: 125,754\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 22s 113ms/step - loss: 0.3839 - accuracy: 0.8878 - val_loss: 1.0537 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.92108, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.1790 - accuracy: 0.9501 - val_loss: 0.3976 - val_accuracy: 0.9434\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.92108 to 0.94342, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.1315 - accuracy: 0.9635 - val_loss: 0.1718 - val_accuracy: 0.9584\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.94342 to 0.95842, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.1063 - accuracy: 0.9714 - val_loss: 0.1183 - val_accuracy: 0.9680\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.95842 to 0.96800, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0898 - accuracy: 0.9766 - val_loss: 0.1019 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.96800 to 0.97225, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0787 - accuracy: 0.9798 - val_loss: 0.0929 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.97225 to 0.97492, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0704 - accuracy: 0.9820 - val_loss: 0.0921 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.97492\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0638 - accuracy: 0.9837 - val_loss: 0.0843 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.97492 to 0.97592, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0584 - accuracy: 0.9855 - val_loss: 0.0813 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.97592 to 0.97658, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0541 - accuracy: 0.9860 - val_loss: 0.0780 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.97658 to 0.97750, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0503 - accuracy: 0.9872 - val_loss: 0.0757 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.97750\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0470 - accuracy: 0.9882 - val_loss: 0.0730 - val_accuracy: 0.9779\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.97750 to 0.97792, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0440 - accuracy: 0.9893 - val_loss: 0.0707 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.97792 to 0.97883, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0416 - accuracy: 0.9896 - val_loss: 0.0705 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.97883 to 0.97908, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0392 - accuracy: 0.9906 - val_loss: 0.0696 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.97908\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0373 - accuracy: 0.9911 - val_loss: 0.0694 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.97908 to 0.97933, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0354 - accuracy: 0.9915 - val_loss: 0.0679 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.97933 to 0.98000, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0336 - accuracy: 0.9919 - val_loss: 0.0662 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.98000 to 0.98033, saving model to mnist_conv_best.h5\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0320 - accuracy: 0.9928 - val_loss: 0.0657 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.98033\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.0652 - val_accuracy: 0.9799\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.98033\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0294 - accuracy: 0.9936 - val_loss: 0.0649 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.98033\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 21s 114ms/step - loss: 0.0281 - accuracy: 0.9937 - val_loss: 0.0645 - val_accuracy: 0.9809\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.98033 to 0.98092, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: 0.0637 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.98092\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 21s 114ms/step - loss: 0.0258 - accuracy: 0.9945 - val_loss: 0.0642 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.98092\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 21s 114ms/step - loss: 0.0246 - accuracy: 0.9950 - val_loss: 0.0629 - val_accuracy: 0.9809\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.98092\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.0629 - val_accuracy: 0.9802\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.98092\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0228 - accuracy: 0.9955 - val_loss: 0.0624 - val_accuracy: 0.9809\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.98092\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.0620 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.98092 to 0.98117, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0211 - accuracy: 0.9959 - val_loss: 0.0624 - val_accuracy: 0.9804\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.98117\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 21s 114ms/step - loss: 0.0203 - accuracy: 0.9961 - val_loss: 0.0622 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.98117 to 0.98158, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0197 - accuracy: 0.9963 - val_loss: 0.0622 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.98158\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 21s 112ms/step - loss: 0.0189 - accuracy: 0.9966 - val_loss: 0.0619 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.98158\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0184 - accuracy: 0.9964 - val_loss: 0.0613 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.98158\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 0.0616 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.98158\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0171 - accuracy: 0.9974 - val_loss: 0.0613 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.98158\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 0.0611 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.98158\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 21s 114ms/step - loss: 0.0162 - accuracy: 0.9975 - val_loss: 0.0615 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.98158\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0155 - accuracy: 0.9978 - val_loss: 0.0610 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.98158 to 0.98183, saving model to mnist_conv_best.h5\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 21s 114ms/step - loss: 0.0151 - accuracy: 0.9980 - val_loss: 0.0611 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.98183\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0146 - accuracy: 0.9980 - val_loss: 0.0612 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.98183\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0143 - accuracy: 0.9982 - val_loss: 0.0609 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.98183\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 0.0616 - val_accuracy: 0.9811\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.98183\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0134 - accuracy: 0.9984 - val_loss: 0.0611 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.98183\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0129 - accuracy: 0.9986 - val_loss: 0.0611 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.98183 to 0.98217, saving model to mnist_conv_best.h5\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0125 - accuracy: 0.9986 - val_loss: 0.0611 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.98217\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0122 - accuracy: 0.9987 - val_loss: 0.0606 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.98217\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 21s 114ms/step - loss: 0.0119 - accuracy: 0.9988 - val_loss: 0.0611 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.98217\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0116 - accuracy: 0.9987 - val_loss: 0.0611 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.98217\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 0.0616 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.98217\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0110 - accuracy: 0.9990 - val_loss: 0.0612 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.98217\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.0107 - accuracy: 0.9990 - val_loss: 0.0612 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.98217\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 22s 115ms/step - loss: 0.0104 - accuracy: 0.9992 - val_loss: 0.0612 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.98217\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 22s 115ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.0618 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.98217\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 21s 114ms/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.0618 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.98217\n",
            "Epoch 00054: early stopping\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0218 - accuracy: 0.9955\n",
            "Accuracy for the training set: 0.9955000281333923\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0516 - accuracy: 0.9831\n",
            "Accuracy for the testing set: 0.9830999970436096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76iJIfHdsbIs"
      },
      "source": [
        "### BatchNormalization after 2 Convolutional Layer\n",
        "\n",
        "0.9870"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h9XoPT3usbJL",
        "outputId": "75bfee49-082e-44be-b4d4-0b071908e222"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.BatchNormalization(name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "dropout (BatchNormalization) (None, 28, 28, 16)        64        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 128,106\n",
            "Trainable params: 128,074\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 58s 305ms/step - loss: 0.3439 - accuracy: 0.8999 - val_loss: 1.1949 - val_accuracy: 0.9341\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.93408, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.1353 - accuracy: 0.9619 - val_loss: 0.3858 - val_accuracy: 0.9591\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.93408 to 0.95908, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 58s 307ms/step - loss: 0.1002 - accuracy: 0.9718 - val_loss: 0.1284 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.95908 to 0.97125, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 58s 307ms/step - loss: 0.0830 - accuracy: 0.9771 - val_loss: 0.0920 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.97125 to 0.97433, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 57s 305ms/step - loss: 0.0722 - accuracy: 0.9804 - val_loss: 0.0817 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.97433 to 0.97717, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0647 - accuracy: 0.9824 - val_loss: 0.0766 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.97717 to 0.97850, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0586 - accuracy: 0.9838 - val_loss: 0.0741 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.97850 to 0.97858, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0539 - accuracy: 0.9853 - val_loss: 0.0726 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.97858 to 0.97942, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0496 - accuracy: 0.9863 - val_loss: 0.0699 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.97942 to 0.97975, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0462 - accuracy: 0.9875 - val_loss: 0.0657 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.97975 to 0.98117, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0432 - accuracy: 0.9879 - val_loss: 0.0634 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.98117 to 0.98133, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0406 - accuracy: 0.9890 - val_loss: 0.0639 - val_accuracy: 0.9809\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.98133\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0621 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.98133 to 0.98192, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0362 - accuracy: 0.9905 - val_loss: 0.0599 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.98192 to 0.98217, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.0615 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.98217\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.0589 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.98217 to 0.98233, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0310 - accuracy: 0.9922 - val_loss: 0.0571 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.98233 to 0.98292, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 0.0576 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.98292\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0283 - accuracy: 0.9929 - val_loss: 0.0571 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.98292\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0271 - accuracy: 0.9934 - val_loss: 0.0550 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.98292 to 0.98367, saving model to mnist_conv_best.h5\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0563 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.98367\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0551 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.98367\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0237 - accuracy: 0.9943 - val_loss: 0.0555 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.98367\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0228 - accuracy: 0.9951 - val_loss: 0.0571 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.98367\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 0.0544 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.98367\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 0.0543 - val_accuracy: 0.9835\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.98367\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0202 - accuracy: 0.9958 - val_loss: 0.0543 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.98367\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 57s 305ms/step - loss: 0.0195 - accuracy: 0.9960 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.98367 to 0.98383, saving model to mnist_conv_best.h5\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0186 - accuracy: 0.9964 - val_loss: 0.0526 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.98383 to 0.98408, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0180 - accuracy: 0.9965 - val_loss: 0.0525 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.98408\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0172 - accuracy: 0.9968 - val_loss: 0.0527 - val_accuracy: 0.9834\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.98408\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 0.0526 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.98408\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0161 - accuracy: 0.9973 - val_loss: 0.0525 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.98408 to 0.98417, saving model to mnist_conv_best.h5\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0156 - accuracy: 0.9973 - val_loss: 0.0527 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.98417\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0150 - accuracy: 0.9976 - val_loss: 0.0537 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.98417\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0145 - accuracy: 0.9979 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.98417\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.98417 to 0.98458, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.0525 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.98458\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 57s 305ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.0522 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.98458\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.0518 - val_accuracy: 0.9844\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.98458\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0123 - accuracy: 0.9984 - val_loss: 0.0523 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.98458\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 57s 305ms/step - loss: 0.0120 - accuracy: 0.9986 - val_loss: 0.0519 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.98458\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 0.0515 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.98458\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.0526 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.98458\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0108 - accuracy: 0.9987 - val_loss: 0.0512 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.98458\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.0515 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.98458 to 0.98492, saving model to mnist_conv_best.h5\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.0517 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.98492\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 57s 302ms/step - loss: 0.0099 - accuracy: 0.9989 - val_loss: 0.0512 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.98492\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 0.0513 - val_accuracy: 0.9848\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.98492\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.0513 - val_accuracy: 0.9852\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.98492 to 0.98517, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0091 - accuracy: 0.9990 - val_loss: 0.0517 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.98517\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 57s 305ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.0517 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.98517\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0086 - accuracy: 0.9992 - val_loss: 0.0522 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.98517\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.0511 - val_accuracy: 0.9850\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.98517\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0082 - accuracy: 0.9994 - val_loss: 0.0512 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.98517\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.0513 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.98517\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.0520 - val_accuracy: 0.9848\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.98517\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.98517\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 57s 303ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.0520 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.98517\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 57s 304ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.0517 - val_accuracy: 0.9851\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.98517\n",
            "Epoch 00060: early stopping\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0172 - accuracy: 0.9964\n",
            "Accuracy for the training set: 0.996399998664856\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0433 - accuracy: 0.9870\n",
            "Accuracy for the testing set: 0.9869999885559082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDbUX2iDtBlP"
      },
      "source": [
        "### BatchNormalization after 3 Convolutional Layer\n",
        "\n",
        "0.9856"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W12oR3lftBld",
        "outputId": "7cc1d064-f3a3-4217-bff3-cd8fa0413dd7"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.BatchNormalization(name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        272       \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "dropout (BatchNormalization) (None, 28, 28, 16)        64        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 129,146\n",
            "Trainable params: 129,114\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 74s 392ms/step - loss: 0.3875 - accuracy: 0.8885 - val_loss: 0.9695 - val_accuracy: 0.9179\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.91792, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.1645 - accuracy: 0.9540 - val_loss: 0.3442 - val_accuracy: 0.9431\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.91792 to 0.94308, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.1212 - accuracy: 0.9670 - val_loss: 0.1403 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.94308 to 0.96525, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0988 - accuracy: 0.9731 - val_loss: 0.1047 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.96525 to 0.97108, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0847 - accuracy: 0.9770 - val_loss: 0.0919 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.97108 to 0.97325, saving model to mnist_conv_best.h5\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0755 - accuracy: 0.9789 - val_loss: 0.0888 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.97325 to 0.97375, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0682 - accuracy: 0.9811 - val_loss: 0.0828 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.97375 to 0.97517, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 75s 397ms/step - loss: 0.0624 - accuracy: 0.9830 - val_loss: 0.0778 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.97517 to 0.97658, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0580 - accuracy: 0.9840 - val_loss: 0.0750 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.97658 to 0.97717, saving model to mnist_conv_best.h5\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0544 - accuracy: 0.9853 - val_loss: 0.0699 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.97717 to 0.97867, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0510 - accuracy: 0.9862 - val_loss: 0.0728 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.97867 to 0.97925, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0482 - accuracy: 0.9870 - val_loss: 0.0667 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.97925 to 0.97967, saving model to mnist_conv_best.h5\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0455 - accuracy: 0.9876 - val_loss: 0.0625 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.97967 to 0.98125, saving model to mnist_conv_best.h5\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 76s 402ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.0636 - val_accuracy: 0.9811\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.98125\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0415 - accuracy: 0.9890 - val_loss: 0.0607 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.98125 to 0.98292, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0399 - accuracy: 0.9893 - val_loss: 0.0599 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.98292\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0379 - accuracy: 0.9899 - val_loss: 0.0583 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.98292 to 0.98358, saving model to mnist_conv_best.h5\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0365 - accuracy: 0.9901 - val_loss: 0.0561 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.98358\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0350 - accuracy: 0.9909 - val_loss: 0.0566 - val_accuracy: 0.9824\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.98358\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.0562 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.98358\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0326 - accuracy: 0.9911 - val_loss: 0.0564 - val_accuracy: 0.9820\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.98358\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 0.0525 - val_accuracy: 0.9844\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.98358 to 0.98442, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.0546 - val_accuracy: 0.9832\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.98442\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0292 - accuracy: 0.9924 - val_loss: 0.0522 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.98442\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0283 - accuracy: 0.9928 - val_loss: 0.0526 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.98442\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 75s 397ms/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.0522 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.98442\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 0.0549 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.98442\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0255 - accuracy: 0.9938 - val_loss: 0.0522 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.98442\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0248 - accuracy: 0.9937 - val_loss: 0.0503 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.98442 to 0.98467, saving model to mnist_conv_best.h5\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 0.0519 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.98467\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 75s 397ms/step - loss: 0.0232 - accuracy: 0.9945 - val_loss: 0.0503 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.98467\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 74s 396ms/step - loss: 0.0226 - accuracy: 0.9945 - val_loss: 0.0493 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.98467 to 0.98533, saving model to mnist_conv_best.h5\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.0528 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.98533\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.0626 - val_accuracy: 0.9818\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.98533\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 0.0494 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.98533 to 0.98558, saving model to mnist_conv_best.h5\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 0.0507 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.98558\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0194 - accuracy: 0.9955 - val_loss: 0.0505 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.98558\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 0.0518 - val_accuracy: 0.9844\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.98558\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 0.0478 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.98558 to 0.98592, saving model to mnist_conv_best.h5\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0179 - accuracy: 0.9964 - val_loss: 0.0489 - val_accuracy: 0.9857\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.98592\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0175 - accuracy: 0.9962 - val_loss: 0.0477 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.98592\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0169 - accuracy: 0.9965 - val_loss: 0.0504 - val_accuracy: 0.9844\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.98592\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.0495 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.98592\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 75s 398ms/step - loss: 0.0159 - accuracy: 0.9968 - val_loss: 0.0474 - val_accuracy: 0.9858\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.98592\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0474 - val_accuracy: 0.9858\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.98592\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.0502 - val_accuracy: 0.9851\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.98592\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.0476 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.98592 to 0.98617, saving model to mnist_conv_best.h5\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.0515 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.98617\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.0475 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.98617\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 76s 402ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.0489 - val_accuracy: 0.9848\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.98617\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 76s 402ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.0506 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.98617\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.0483 - val_accuracy: 0.9857\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.98617\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0482 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.98617 to 0.98650, saving model to mnist_conv_best.h5\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0498 - val_accuracy: 0.9850\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.98650\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.0473 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.98650\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 76s 402ms/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.0485 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.98650\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 76s 402ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0473 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.98650\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 76s 402ms/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.0475 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.98650\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 75s 401ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.0472 - val_accuracy: 0.9858\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.98650\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.0474 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.98650\n",
            "Epoch 61/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.0484 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.98650\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - 75s 399ms/step - loss: 0.0101 - accuracy: 0.9986 - val_loss: 0.0472 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.98650\n",
            "Epoch 63/10000\n",
            "188/188 [==============================] - 75s 400ms/step - loss: 0.0099 - accuracy: 0.9987 - val_loss: 0.0472 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.98650\n",
            "Epoch 00063: early stopping\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0192 - accuracy: 0.9958\n",
            "Accuracy for the training set: 0.9957500100135803\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0428 - accuracy: 0.9856\n",
            "Accuracy for the testing set: 0.9855999946594238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7KQJhNBtHND"
      },
      "source": [
        "### BatchNormalization after 4 Convolutional Layer\n",
        "\n",
        "0.9878"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SoWFK6QNtHNd",
        "outputId": "cbe947d8-8522-4102-a7cf-a0cec4f5a1f7"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution1'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.BatchNormalization(name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        416       \n",
            "_________________________________________________________________\n",
            "convolution1 (Conv2D)        (None, 28, 28, 16)        4112      \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "dropout (BatchNormalization) (None, 28, 28, 16)        64        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                125450    \n",
            "=================================================================\n",
            "Total params: 133,402\n",
            "Trainable params: 133,370\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 130s 688ms/step - loss: 0.3577 - accuracy: 0.8942 - val_loss: 1.2438 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.94825, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "188/188 [==============================] - 129s 687ms/step - loss: 0.1381 - accuracy: 0.9603 - val_loss: 0.4035 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.94825 to 0.96467, saving model to mnist_conv_best.h5\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - 128s 680ms/step - loss: 0.1025 - accuracy: 0.9709 - val_loss: 0.1261 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.96467 to 0.97042, saving model to mnist_conv_best.h5\n",
            "Epoch 4/10000\n",
            "188/188 [==============================] - 129s 686ms/step - loss: 0.0847 - accuracy: 0.9757 - val_loss: 0.0886 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.97042 to 0.97558, saving model to mnist_conv_best.h5\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - 136s 722ms/step - loss: 0.0729 - accuracy: 0.9795 - val_loss: 0.0810 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.97558\n",
            "Epoch 6/10000\n",
            "188/188 [==============================] - 126s 669ms/step - loss: 0.0654 - accuracy: 0.9814 - val_loss: 0.0739 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.97558 to 0.97733, saving model to mnist_conv_best.h5\n",
            "Epoch 7/10000\n",
            "188/188 [==============================] - 125s 667ms/step - loss: 0.0589 - accuracy: 0.9833 - val_loss: 0.0701 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.97733 to 0.97883, saving model to mnist_conv_best.h5\n",
            "Epoch 8/10000\n",
            "188/188 [==============================] - 127s 675ms/step - loss: 0.0542 - accuracy: 0.9846 - val_loss: 0.0669 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.97883 to 0.98033, saving model to mnist_conv_best.h5\n",
            "Epoch 9/10000\n",
            "188/188 [==============================] - 130s 693ms/step - loss: 0.0502 - accuracy: 0.9858 - val_loss: 0.0652 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.98033\n",
            "Epoch 10/10000\n",
            "188/188 [==============================] - 124s 662ms/step - loss: 0.0466 - accuracy: 0.9866 - val_loss: 0.0607 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.98033 to 0.98167, saving model to mnist_conv_best.h5\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - 124s 662ms/step - loss: 0.0437 - accuracy: 0.9879 - val_loss: 0.0593 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.98167 to 0.98217, saving model to mnist_conv_best.h5\n",
            "Epoch 12/10000\n",
            "188/188 [==============================] - 127s 675ms/step - loss: 0.0410 - accuracy: 0.9888 - val_loss: 0.0600 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.98217\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - 128s 682ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.0563 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.98217\n",
            "Epoch 14/10000\n",
            "188/188 [==============================] - 128s 683ms/step - loss: 0.0367 - accuracy: 0.9897 - val_loss: 0.0540 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.98217 to 0.98333, saving model to mnist_conv_best.h5\n",
            "Epoch 15/10000\n",
            "188/188 [==============================] - 125s 664ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.0547 - val_accuracy: 0.9834\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.98333 to 0.98342, saving model to mnist_conv_best.h5\n",
            "Epoch 16/10000\n",
            "188/188 [==============================] - 124s 662ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.0517 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.98342 to 0.98400, saving model to mnist_conv_best.h5\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - 124s 662ms/step - loss: 0.0311 - accuracy: 0.9918 - val_loss: 0.0531 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.98400\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - 126s 669ms/step - loss: 0.0297 - accuracy: 0.9925 - val_loss: 0.0523 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.98400\n",
            "Epoch 19/10000\n",
            "188/188 [==============================] - 125s 667ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.0515 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.98400 to 0.98450, saving model to mnist_conv_best.h5\n",
            "Epoch 20/10000\n",
            "188/188 [==============================] - 125s 665ms/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 0.0519 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.98450\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - 125s 667ms/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.0569 - val_accuracy: 0.9832\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.98450\n",
            "Epoch 22/10000\n",
            "188/188 [==============================] - 125s 664ms/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 0.0487 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.98450 to 0.98475, saving model to mnist_conv_best.h5\n",
            "Epoch 23/10000\n",
            "188/188 [==============================] - 127s 678ms/step - loss: 0.0240 - accuracy: 0.9944 - val_loss: 0.0486 - val_accuracy: 0.9848\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.98475 to 0.98483, saving model to mnist_conv_best.h5\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - 135s 716ms/step - loss: 0.0230 - accuracy: 0.9946 - val_loss: 0.0466 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.98483 to 0.98533, saving model to mnist_conv_best.h5\n",
            "Epoch 25/10000\n",
            "188/188 [==============================] - 130s 693ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0457 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.98533 to 0.98558, saving model to mnist_conv_best.h5\n",
            "Epoch 26/10000\n",
            "188/188 [==============================] - 127s 674ms/step - loss: 0.0214 - accuracy: 0.9954 - val_loss: 0.0462 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.98558\n",
            "Epoch 27/10000\n",
            "188/188 [==============================] - 125s 668ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.0455 - val_accuracy: 0.9858\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.98558 to 0.98575, saving model to mnist_conv_best.h5\n",
            "Epoch 28/10000\n",
            "188/188 [==============================] - 125s 666ms/step - loss: 0.0198 - accuracy: 0.9959 - val_loss: 0.0471 - val_accuracy: 0.9851\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.98575\n",
            "Epoch 29/10000\n",
            "188/188 [==============================] - 125s 665ms/step - loss: 0.0190 - accuracy: 0.9960 - val_loss: 0.0475 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.98575\n",
            "Epoch 30/10000\n",
            "188/188 [==============================] - 124s 662ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.0441 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.98575 to 0.98625, saving model to mnist_conv_best.h5\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - 124s 661ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.0488 - val_accuracy: 0.9848\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.98625\n",
            "Epoch 32/10000\n",
            "188/188 [==============================] - 123s 656ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.0453 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.98625\n",
            "Epoch 33/10000\n",
            "188/188 [==============================] - 125s 663ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0445 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.98625\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - 125s 665ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.0447 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.98625\n",
            "Epoch 35/10000\n",
            "188/188 [==============================] - 124s 658ms/step - loss: 0.0152 - accuracy: 0.9971 - val_loss: 0.0460 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.98625\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - 123s 653ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0456 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.98625\n",
            "Epoch 37/10000\n",
            "188/188 [==============================] - 123s 656ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.0430 - val_accuracy: 0.9866\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.98625 to 0.98658, saving model to mnist_conv_best.h5\n",
            "Epoch 38/10000\n",
            "188/188 [==============================] - 123s 653ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.0478 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.98658\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - 124s 661ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.0438 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.98658\n",
            "Epoch 40/10000\n",
            "188/188 [==============================] - 124s 659ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.0434 - val_accuracy: 0.9866\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.98658\n",
            "Epoch 41/10000\n",
            "188/188 [==============================] - 124s 658ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.0484 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.98658\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - 122s 650ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.0427 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.98658\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - 125s 665ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.0421 - val_accuracy: 0.9871\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.98658 to 0.98708, saving model to mnist_conv_best.h5\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - 128s 680ms/step - loss: 0.0113 - accuracy: 0.9984 - val_loss: 0.0427 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.98708\n",
            "Epoch 45/10000\n",
            "188/188 [==============================] - 126s 669ms/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 0.0426 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.98708\n",
            "Epoch 46/10000\n",
            "188/188 [==============================] - 126s 669ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0420 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.98708\n",
            "Epoch 47/10000\n",
            "188/188 [==============================] - 126s 668ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0433 - val_accuracy: 0.9866\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.98708\n",
            "Epoch 48/10000\n",
            "188/188 [==============================] - 126s 668ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0449 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.98708\n",
            "Epoch 49/10000\n",
            "188/188 [==============================] - 127s 677ms/step - loss: 0.0097 - accuracy: 0.9986 - val_loss: 0.0425 - val_accuracy: 0.9870\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.98708\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - 127s 678ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.0416 - val_accuracy: 0.9877\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.98708 to 0.98775, saving model to mnist_conv_best.h5\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - 125s 665ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.0420 - val_accuracy: 0.9868\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.98775\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - 126s 671ms/step - loss: 0.0089 - accuracy: 0.9989 - val_loss: 0.0432 - val_accuracy: 0.9866\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.98775\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - 129s 685ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.0429 - val_accuracy: 0.9876\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.98775\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - 126s 672ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.0422 - val_accuracy: 0.9868\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.98775\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - 126s 668ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.0411 - val_accuracy: 0.9876\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.98775\n",
            "Epoch 56/10000\n",
            "188/188 [==============================] - 125s 667ms/step - loss: 0.0079 - accuracy: 0.9990 - val_loss: 0.0424 - val_accuracy: 0.9868\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.98775\n",
            "Epoch 57/10000\n",
            "188/188 [==============================] - 125s 664ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.0417 - val_accuracy: 0.9864\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.98775\n",
            "Epoch 58/10000\n",
            "188/188 [==============================] - 125s 665ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0434 - val_accuracy: 0.9871\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.98775\n",
            "Epoch 59/10000\n",
            "188/188 [==============================] - 126s 670ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0424 - val_accuracy: 0.9877\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.98775\n",
            "Epoch 60/10000\n",
            "188/188 [==============================] - 127s 678ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0424 - val_accuracy: 0.9866\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.98775\n",
            "Epoch 00060: early stopping\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0152 - accuracy: 0.9967\n",
            "Accuracy for the training set: 0.996749997138977\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.0352 - accuracy: 0.9878\n",
            "Accuracy for the testing set: 0.9878000020980835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D9E6Vp6QP4n"
      },
      "source": [
        "### BatchNormalization after 4 Convolutional Layer w/ Max Pooling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9z8kJrVQP4t",
        "outputId": "d1d7e946-6abf-42b1-f0f8-15cfc44f5c96"
      },
      "source": [
        "mnist_conv_model = tf.keras.Sequential(name='mnist_cnn')\n",
        "mnist_conv_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='same', name='convolution'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu', padding='same', name='convolution1'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', name='convolution2'))\n",
        "mnist_conv_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation='relu', padding='same', name='convolution3'))\n",
        "mnist_conv_model.add(tf.keras.layers.BatchNormalization(name='dropout'))\n",
        "mnist_conv_model.add(tf.keras.layers.MaxPool2D(pool_size=2, name='pooling'))\n",
        "mnist_conv_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "mnist_conv_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "mnist_conv_model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "mnist_conv_model.summary()\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mnist_conv_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "mnist_conv_model_train = mnist_conv_model.fit(mnist_x, mnist_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "\n",
        "mnist_conv_model.load_weights('mnist_conv_best.h5')\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_x, mnist_y)\n",
        "print('Accuracy for the training set: {}'.format(acc))\n",
        "loss, acc = mnist_conv_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for the testing set: {}'.format(acc))\n",
        "fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "\n",
        "\n",
        "loss_ax.set_title('Loss')\n",
        "loss_ax.plot(mnist_conv_model_train.history['loss'], '-r', label='Train')\n",
        "loss_ax.plot(mnist_conv_model_train.history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "acc_ax.set_title('Accuracy')\n",
        "acc_ax.plot(mnist_conv_model_train.history['accuracy'], '-r', label='Train')\n",
        "acc_ax.plot(mnist_conv_model_train.history['val_accuracy'], '-g', label='Validation')\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"mnist_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution (Conv2D)         (None, 28, 28, 16)        416       \n",
            "_________________________________________________________________\n",
            "convolution1 (Conv2D)        (None, 28, 28, 16)        4112      \n",
            "_________________________________________________________________\n",
            "convolution2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "convolution3 (Conv2D)        (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "dropout (BatchNormalization) (None, 28, 28, 16)        64        \n",
            "_________________________________________________________________\n",
            "pooling (MaxPooling2D)       (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                31370     \n",
            "=================================================================\n",
            "Total params: 39,322\n",
            "Trainable params: 39,290\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "188/188 [==============================] - 129s 680ms/step - loss: 0.4662 - accuracy: 0.8683 - val_loss: 1.1869 - val_accuracy: 0.9277\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.92767, saving model to mnist_conv_best.h5\n",
            "Epoch 2/10000\n",
            "  3/188 [..............................] - ETA: 1:59 - loss: 0.2000 - accuracy: 0.9427"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}